{
  "ft_included": [
    {
      "openalex_id": "https://openalex.org/W7105585868",
      "doi": "10.48550/arxiv.2511.07700",
      "title": "On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection",
      "abstract": "Artificial Intelligence (AI) models have demonstrated expert-level performance in melanoma detection, yet their clinical adoption is hindered by performance disparities across demographic subgroups such as gender, race, and age. Previous efforts to benchmark the performance of AI models have primarily focused on assessing model performance using group fairness metrics that rely on the Area Under the Receiver Operating Characteristic curve (AUROC), which does not provide insights into a model's ability to provide accurate estimates. In line with clinical assessments, this paper addresses this gap by incorporating calibration as a complementary benchmarking metric to AUROC-based fairness metrics. Calibration evaluates the alignment between predicted probabilities and observed event rates, offering deeper insights into subgroup biases. We assess the performance of the leading skin cancer detection algorithm of the ISIC 2020 Challenge on the ISIC 2020 Challenge dataset and the PROVE-AI dataset, and compare it with the second and third place models, focusing on subgroups defined by sex, race (Fitzpatrick Skin Tone), and age. Our findings reveal that while existing models enhance discriminative accuracy, they often over-diagnose risk and exhibit calibration issues when applied to new datasets. This study underscores the necessity for comprehensive model auditing strategies and extensive metadata collection to achieve equitable AI-driven healthcare solutions. All code is publicly available at https://github.com/bdominique/testing_strong_calibration.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Dominique, Brandon et al.",
      "keywords": "Benchmarking; Metric (unit); Benchmark (surveying); Discriminative model; Calibration; Audit; Receiver operating characteristic; Performance metric",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2511.07700",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Empirical Study",
      "ai_ml_method": "Not specified",
      "health_domain": "Dermatology; Oncology",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age",
      "lifecycle_stage": "Data Collection; Model Development/Training; Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Calibration; Fairness Metrics Evaluation; Bias Auditing Framework",
      "clinical_setting": "Not specified",
      "key_findings": "This study underscores the necessity for comprehensive model auditing strategies and extensive metadata collection to achieve equitable AI-driven healthcare solutions. All code is publicly available at https://github.com/bdominique/testing_strong_calibration."
    },
    {
      "openalex_id": "https://openalex.org/W4414939213",
      "doi": "10.48550/arxiv.2505.09295",
      "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance",
      "abstract": "Ensuring fairness is critical when applying artificial intelligence to high-stakes domains such as healthcare, where predictive models trained on imbalanced and demographically skewed data risk exacerbating existing disparities. Federated learning (FL) enables privacy-preserving collaboration across institutions, but remains vulnerable to both algorithmic bias and subgroup imbalance - particularly when multiple sensitive attributes intersect. We propose FedIDA (Fed erated Learning for Imbalance and D isparity A wareness), a framework-agnostic method that combines fairness-aware regularization with group-conditional oversampling. FedIDA supports multiple sensitive attributes and heterogeneous data distributions without altering the convergence behavior of the underlying FL algorithm. We provide theoretical analysis establishing fairness improvement bounds using Lipschitz continuity and concentration inequalities, and show that FedIDA reduces the variance of fairness metrics across test sets. Empirical results on both benchmark and real-world clinical datasets confirm that FedIDA consistently improves fairness while maintaining competitive predictive performance, demonstrating its effectiveness for equitable and privacy-preserving modeling in healthcare. The source code is available on GitHub.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Qiming Wu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.09295",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "Federated Learning; Clinical Prediction Model",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Intersectional",
      "lifecycle_stage": "Data Collection; Data Preprocessing; Model Development/Training; Model Evaluation; Deployment",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Reweighting/Resampling; Fairness Metrics Evaluation; Federated Learning; Regularization",
      "clinical_setting": "ICU",
      "key_findings": "Empirical results on both benchmark and real-world clinical datasets confirm that FedIDA consistently improves fairness while maintaining competitive predictive performance, demonstrating its effectiveness for equitable and privacy-preserving modeling in healthcare. The source code is available on GitHub."
    },
    {
      "openalex_id": "https://openalex.org/W4416282421",
      "doi": "10.48550/arxiv.2505.04931",
      "title": "Fair Uncertainty Quantification for Depression Prediction",
      "abstract": "Trustworthy depression prediction based on deep learning, incorporating both predictive reliability and algorithmic fairness across diverse demographic groups, is crucial for clinical application. Recently, achieving reliable depression predictions through uncertainty quantification has attracted increasing attention. However, few studies have focused on the fairness of uncertainty quantification (UQ) in depression prediction. In this work, we investigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage (EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for depression prediction. FUQ pursues reliable and fair depression predictions through group-based analysis. Specifically, we first group all the participants by different sensitive attributes and leverage conformal prediction to quantify uncertainty within each demographic group, which provides a theoretically guaranteed and valid way to quantify uncertainty for depression prediction and facilitates the investigation of fairness across different demographic groups. Furthermore, we propose a fairness-aware optimization strategy that formulates fairness as a constrained optimization problem under EOC constraints. This enables the model to preserve predictive reliability while adapting to the heterogeneous uncertainty levels across demographic groups, thereby achieving optimal fairness. Through extensive evaluations on several visual and audio depression datasets, our approach demonstrates its effectiveness.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yonghong Li et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04931",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Methodology",
      "ai_ml_method": "Deep Learning",
      "health_domain": "Mental Health/Psychiatry",
      "bias_axes": "Age",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Fairness Metrics Evaluation; Explainability/Interpretability",
      "clinical_setting": "Not specified",
      "key_findings": "This enables the model to preserve predictive reliability while adapting to the heterogeneous uncertainty levels across demographic groups, thereby achieving optimal fairness. Through extensive evaluations on several visual and audio depression datasets, our approach demonstrates its effectiveness."
    },
    {
      "openalex_id": "https://openalex.org/W4415334237",
      "doi": "10.48550/arxiv.2506.15620",
      "title": "GFLC: Graph-based Fairness-aware Label Correction for Fair Classification",
      "abstract": "Fairness in machine learning (ML) has a critical importance for building trustworthy machine learning system as artificial intelligence (AI) systems increasingly impact various aspects of society, including healthcare decisions and legal judgments. Moreover, numerous studies demonstrate evidence of unfair outcomes in ML and the need for more robust fairness-aware methods. However, the data we use to train and develop debiasing techniques often contains biased and noisy labels. As a result, the label bias in the training data affects model performance and misrepresents the fairness of classifiers during testing. To tackle this problem, our paper presents Graph-based Fairness-aware Label Correction (GFLC), an efficient method for correcting label noise while preserving demographic parity in datasets. In particular, our approach combines three key components: prediction confidence measure, graph-based regularization through Ricci-flow-optimized graph Laplacians, and explicit demographic parity incentives. Our experimental findings show the effectiveness of our proposed approach and show significant improvements in the trade-off between performance and fairness metrics compared to the baseline.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Modar Sulaiman et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.15620",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Empirical Study",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex",
      "lifecycle_stage": "Model Development/Training; Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Fairness Metrics Evaluation; Regularization",
      "clinical_setting": "ICU",
      "key_findings": "In particular, our approach combines three key components: prediction confidence measure, graph-based regularization through Ricci-flow-optimized graph Laplacians, and explicit demographic parity incentives. Our experimental findings show the effectiveness of our proposed approach and show significant improvements in the trade-off between performance and fairness metrics compared to the baseline."
    },
    {
      "openalex_id": "https://openalex.org/W4415329344",
      "doi": "10.48550/arxiv.2505.15788",
      "title": "Fair Supervised Learning Through Constraints on Smooth Nonconvex Unfairness-Measure Surrogates",
      "abstract": "A new strategy for fair supervised machine learning is proposed. The main advantages of the proposed strategy as compared to others in the literature are as follows. (a) We introduce a new smooth nonconvex surrogate to approximate the Heaviside functions involved in discontinuous unfairness measures. The surrogate is based on smoothing methods from the optimization literature, and is new for the fair supervised learning literature. The surrogate is a tight approximation which ensures the trained prediction models are fair, as opposed to other (e.g., convex) surrogates that can fail to lead to a fair prediction model in practice. (b) Rather than rely on regularizers (that lead to optimization problems that are difficult to solve) and corresponding regularization parameters (that can be expensive to tune), we propose a strategy that employs hard constraints so that specific tolerances for unfairness can be enforced without the complications associated with the use of regularization. (c) Our proposed strategy readily allows for constraints on multiple (potentially conflicting) unfairness measures at the same time. Multiple measures can be considered with a regularization approach, but at the cost of having even more difficult optimization problems to solve and further expense for tuning. By contrast, through hard constraints, our strategy leads to optimization models that can be solved tractably with minimal tuning.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Zahra Khatti et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.15788",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Methodology",
      "ai_ml_method": "Clinical Prediction Model",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Age",
      "lifecycle_stage": "Model Development/Training",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Regularization",
      "clinical_setting": "ICU",
      "key_findings": "Multiple measures can be considered with a regularization approach, but at the cost of having even more difficult optimization problems to solve and further expense for tuning. By contrast, through hard constraints, our strategy leads to optimization models that can be solved tractably with minimal tuning."
    },
    {
      "openalex_id": "https://openalex.org/W4394973582",
      "doi": "10.48550/arxiv.2404.12076",
      "title": "Evolutionary Multi-Objective Optimisation for Fairness-Aware Self Adjusting Memory Classifiers in Data Streams",
      "abstract": "This paper introduces a novel approach, evolutionary multi-objective optimisation for fairness-aware self-adjusting memory classifiers, designed to enhance fairness in machine learning algorithms applied to data stream classification. With the growing concern over discrimination in algorithmic decision-making, particularly in dynamic data stream environments, there is a need for methods that ensure fair treatment of individuals across sensitive attributes like race or gender. The proposed approach addresses this challenge by integrating the strengths of the self-adjusting memory K-Nearest-Neighbour algorithm with evolutionary multi-objective optimisation. This combination allows the new approach to efficiently manage concept drift in streaming data and leverage the flexibility of evolutionary multi-objective optimisation to maximise accuracy and minimise discrimination simultaneously. We demonstrate the effectiveness of the proposed approach through extensive experiments on various datasets, comparing its performance against several baseline methods in terms of accuracy and fairness metrics. Our results show that the proposed approach maintains competitive accuracy and significantly reduces discrimination, highlighting its potential as a robust solution for fairness-aware data stream classification. Further analyses also confirm the effectiveness of the strategies to trigger evolutionary multi-objective optimisation and adapt classifiers in the proposed approach.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Pivithuru Thejan Amarasinghe et al.",
      "keywords": "Computer science; STREAMS; Data stream mining; Artificial intelligence; Machine learning; Data mining; Computer network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.12076",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Methodology",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Fairness Metrics Evaluation",
      "clinical_setting": "ICU",
      "key_findings": "Our results show that the proposed approach maintains competitive accuracy and significantly reduces discrimination, highlighting its potential as a robust solution for fairness-aware data stream classification. Further analyses also confirm the effectiveness of the strategies to trigger evolutionary multi-objective optimisation and adapt classifiers in the proposed approach."
    },
    {
      "openalex_id": "https://openalex.org/W4393335379",
      "doi": "10.48550/arxiv.2403.19057",
      "title": "Equity in Healthcare: Analyzing Disparities in Machine Learning Predictions of Diabetic Patient Readmissions",
      "abstract": "This study investigates how machine learning (ML) models can predict hospital readmissions for diabetic patients fairly and accurately across different demographics (age, gender, race). We compared models like Deep Learning, Generalized Linear Models, Gradient Boosting Machines (GBM), and Naive Bayes. GBM stood out with an F1-score of 84.3% and accuracy of 82.2%, accurately predicting readmissions across demographics. A fairness analysis was conducted across all the models. GBM minimized disparities in predictions, achieving balanced results across genders and races. It showed low False Discovery Rates (FDR) (6-7%) and False Positive Rates (FPR) (5%) for both genders. Additionally, FDRs remained low for racial groups, such as African Americans (8%) and Asians (7%). Similarly, FPRs were consistent across age groups (4%) for both patients under 40 and those above 40, indicating its precision and ability to reduce bias. These findings emphasize the importance of choosing ML models carefully to ensure both accuracy and fairness for all patients. By showcasing effectiveness of various models with fairness metrics, this study promotes personalized medicine and the need for fair ML algorithms in healthcare. This can ultimately reduce disparities and improve outcomes for diabetic patients of all backgrounds.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zainab Al-Zanbouri et al.",
      "keywords": "Health equity; Equity (law); Health care; Healthcare system; Medicine; Computer science; Artificial intelligence; Machine learning; Political science; Economics; Economic growth",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.19057",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Empirical Study",
      "ai_ml_method": "Deep Learning; XGBoost/Gradient Boosting",
      "health_domain": "Endocrinology/Diabetes",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Fairness Metrics Evaluation",
      "clinical_setting": "Hospital/Inpatient",
      "key_findings": "By showcasing effectiveness of various models with fairness metrics, this study promotes personalized medicine and the need for fair ML algorithms in healthcare. This can ultimately reduce disparities and improve outcomes for diabetic patients of all backgrounds."
    },
    {
      "openalex_id": "https://openalex.org/W4393924520",
      "doi": "10.48550/arxiv.2404.01349",
      "title": "Fairness in Large Language Models: A Taxonomic Survey",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across various domains. However, despite their promising performance in numerous real-world applications, most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations, prompting extensive study in fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in traditional machine learning, entails exclusive backgrounds, taxonomies, and fulfillment techniques. To this end, this survey presents a comprehensive overview of recent advances in the existing literature concerning fair LLMs. Specifically, a brief introduction to LLMs is provided, followed by an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms for promoting fairness. Furthermore, resources for evaluating bias in LLMs, including toolkits and datasets, are summarized. Finally, existing research challenges and open questions are discussed.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhibo Chu et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.01349",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "NLP/LLM",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age; Language",
      "lifecycle_stage": "Deployment",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Not specified",
      "clinical_setting": "ICU; Public Health/Population",
      "key_findings": "Furthermore, resources for evaluating bias in LLMs, including toolkits and datasets, are summarized. Finally, existing research challenges and open questions are discussed."
    },
    {
      "openalex_id": "https://openalex.org/W4402345548",
      "doi": "10.48550/arxiv.2407.12031",
      "title": "Evaluation of Bias Towards Medical Professionals in Large Language Models",
      "abstract": "This study evaluates whether large language models (LLMs) exhibit biases towards medical professionals. Fictitious candidate resumes were created to control for identity factors while maintaining consistent qualifications. Three LLMs (GPT-4, Claude-3-haiku, and Mistral-Large) were tested using a standardized prompt to evaluate resumes for specific residency programs. Explicit bias was tested by changing gender and race information, while implicit bias was tested by changing names while hiding race and gender. Physician data from the Association of American Medical Colleges was used to compare with real-world demographics. 900,000 resumes were evaluated. All LLMs exhibited significant gender and racial biases across medical specialties. Gender preferences varied, favoring male candidates in surgery and orthopedics, while preferring females in dermatology, family medicine, obstetrics and gynecology, pediatrics, and psychiatry. Claude-3 and Mistral-Large generally favored Asian candidates, while GPT-4 preferred Black and Hispanic candidates in several specialties. Tests revealed strong preferences towards Hispanic females and Asian males in various specialties. Compared to real-world data, LLMs consistently chose higher proportions of female and underrepresented racial candidates than their actual representation in the medical workforce. GPT-4, Claude-3, and Mistral-Large showed significant gender and racial biases when evaluating medical professionals for residency selection. These findings highlight the potential for LLMs to perpetuate biases and compromise healthcare workforce diversity if used without proper bias mitigation strategies.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Xi Chen et al.",
      "keywords": "Health professionals; Psychology; Business; Political science; Health care",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.12031",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Empirical Study",
      "ai_ml_method": "NLP/LLM",
      "health_domain": "Dermatology; Mental Health/Psychiatry; Primary Care; Surgery; Pediatrics; Obstetrics/Maternal Health",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age; Language",
      "lifecycle_stage": "Model Evaluation; Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "Not specified",
      "key_findings": "GPT-4, Claude-3, and Mistral-Large showed significant gender and racial biases when evaluating medical professionals for residency selection. These findings highlight the potential for LLMs to perpetuate biases and compromise healthcare workforce diversity if used without proper bias mitigation strategies."
    },
    {
      "openalex_id": "https://openalex.org/W4400434644",
      "doi": "10.48550/arxiv.2407.04268",
      "title": "NeuFair: Neural Network Fairness Repair with Dropout",
      "abstract": "This paper investigates neuron dropout as a post-processing bias mitigation for deep neural networks (DNNs). Neural-driven software solutions are increasingly applied in socially critical domains with significant fairness implications. While neural networks are exceptionally good at finding statistical patterns from data, they may encode and amplify existing biases from the historical data. Existing bias mitigation algorithms often require modifying the input dataset or the learning algorithms. We posit that the prevalent dropout methods that prevent over-fitting during training by randomly dropping neurons may be an effective and less intrusive approach to improve the fairness of pre-trained DNNs. However, finding the ideal set of neurons to drop is a combinatorial problem. We propose NeuFair, a family of post-processing randomized algorithms that mitigate unfairness in pre-trained DNNs via dropouts during inference after training. Our randomized search is guided by an objective to minimize discrimination while maintaining the model's utility. We show that our design of randomized algorithms is effective and efficient in improving fairness (up to 69%) with minimal or no model performance degradation. We provide intuitive explanations of these phenomena and carefully examine the influence of various hyperparameters of search algorithms on the results. Finally, we empirically and conceptually compare NeuFair to different state-of-the-art bias mitigators.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Vishnu Asutosh Dasu et al.",
      "keywords": "Dropout (neural networks); Artificial neural network; Computer science; Psychology; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.04268",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Methodology",
      "ai_ml_method": "Deep Learning; Neural Network",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Post-hoc Correction",
      "clinical_setting": "Not specified",
      "key_findings": "We provide intuitive explanations of these phenomena and carefully examine the influence of various hyperparameters of search algorithms on the results. Finally, we empirically and conceptually compare NeuFair to different state-of-the-art bias mitigators."
    },
    {
      "openalex_id": "https://openalex.org/W4403345272",
      "doi": "10.48550/arxiv.2410.06566",
      "title": "Detecting Bias and Enhancing Diagnostic Accuracy in Large Language Models for Healthcare",
      "abstract": "Biased AI-generated medical advice and misdiagnoses can jeopardize patient safety, making the integrity of AI in healthcare more critical than ever. As Large Language Models (LLMs) take on a growing role in medical decision-making, addressing their biases and enhancing their accuracy is key to delivering safe, reliable care. This study addresses these challenges head-on by introducing new resources designed to promote ethical and precise AI in healthcare. We present two datasets: BiasMD, featuring 6,007 question-answer pairs crafted to evaluate and mitigate biases in health-related LLM outputs, and DiseaseMatcher, with 32,000 clinical question-answer pairs spanning 700 diseases, aimed at assessing symptom-based diagnostic accuracy. Using these datasets, we developed the EthiClinician, a fine-tuned model built on the ChatDoctor framework, which outperforms GPT-4 in both ethical reasoning and clinical judgment. By exposing and correcting hidden biases in existing models for healthcare, our work sets a new benchmark for safer, more reliable patient outcomes.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Pardis Sadat Zahraei et al.",
      "keywords": "Health care; Computer science; Natural language processing; Psychology; Artificial intelligence; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.06566",
      "cited_by_count": 2,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "NLP/LLM",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex; Age; Language",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Both",
      "approach_method": "Transfer Learning",
      "clinical_setting": "Not specified",
      "key_findings": "Using these datasets, we developed the EthiClinician, a fine-tuned model built on the ChatDoctor framework, which outperforms GPT-4 in both ethical reasoning and clinical judgment. By exposing and correcting hidden biases in existing models for healthcare, our work sets a new benchmark for safer, more reliable patient outcomes."
    },
    {
      "openalex_id": "https://openalex.org/W4405656930",
      "doi": "10.48550/arxiv.2408.12055",
      "title": "Aligning (Medical) LLMs for (Counterfactual) Fairness",
      "abstract": "Large Language Models (LLMs) have emerged as promising solutions for a variety of medical and clinical decision support applications. However, LLMs are often subject to different types of biases, which can lead to unfair treatment of individuals, worsening health disparities, and reducing trust in AI-augmented medical tools. Aiming to address this important issue, in this study, we present a new model alignment approach for aligning LLMs using a preference optimization method within a knowledge distillation framework. Prior to presenting our proposed method, we first use an evaluation framework to conduct a comprehensive (largest to our knowledge) empirical evaluation to reveal the type and nature of existing biases in LLMs used for medical applications. We then offer a bias mitigation technique to reduce the unfair patterns in LLM outputs across different subgroups identified by the protected attributes. We show that our mitigation method is effective in significantly reducing observed biased patterns. Our code is publicly available at \\url{https://github.com/healthylaife/FairAlignmentLLM}.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Raphael Poulain et al.",
      "keywords": "Counterfactual thinking; Medicine; Business; Actuarial science; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.12055",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "NLP/LLM; Clinical Decision Support",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex; Age; Language",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "Not specified",
      "key_findings": "We show that our mitigation method is effective in significantly reducing observed biased patterns. Our code is publicly available at \\url{https://github.com/healthylaife/FairAlignmentLLM}."
    },
    {
      "openalex_id": "https://openalex.org/W4391835572",
      "doi": "10.48550/arxiv.2402.08879",
      "title": "Inference for an Algorithmic Fairness-Accuracy Frontier",
      "abstract": "Algorithms are increasingly used to aid with high-stakes decision making. Yet, their predictive ability frequently exhibits systematic variation across population subgroups. To assess the trade-off between fairness and accuracy using finite data, we propose a debiased machine learning estimator for the fairness-accuracy frontier introduced by Liang, Lu, Mu, and Okumura (2024). We derive its asymptotic distribution and propose inference methods to test key hypotheses in the fairness literature, such as (i) whether excluding group identity from use in training the algorithm is optimal and (ii) whether there are less discriminatory alternatives to a given algorithm. In addition, we construct an estimator for the distance between a given algorithm and the fairest point on the frontier, and characterize its asymptotic distribution. Using Monte Carlo simulations, we evaluate the finite-sample performance of our inference methods. We apply our framework to re-evaluate algorithms used in hospital care management and show that our approach yields alternative algorithms that lie on the fairness-accuracy frontier, offering improvements along both dimensions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yiqi Liu et al.",
      "keywords": "Frontier; Inference; Computer science; Econometrics; Economics; Artificial intelligence; Political science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.08879",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "Not specified",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "Hospital/Inpatient; Public Health/Population",
      "key_findings": "Using Monte Carlo simulations, we evaluate the finite-sample performance of our inference methods. We apply our framework to re-evaluate algorithms used in hospital care management and show that our approach yields alternative algorithms that lie on the fairness-accuracy frontier, offering improvements along both dimensions."
    },
    {
      "openalex_id": "https://openalex.org/W4376122664",
      "doi": "10.48550/arxiv.2305.05101",
      "title": "Towards unraveling calibration biases in medical image analysis",
      "abstract": "In recent years the development of artificial intelligence (AI) systems for automated medical image analysis has gained enormous momentum. At the same time, a large body of work has shown that AI systems can systematically and unfairly discriminate against certain populations in various application scenarios. These two facts have motivated the emergence of algorithmic fairness studies in this field. Most research on healthcare algorithmic fairness to date has focused on the assessment of biases in terms of classical discrimination metrics such as AUC and accuracy. Potential biases in terms of model calibration, however, have only recently begun to be evaluated. This is especially important when working with clinical decision support systems, as predictive uncertainty is key for health professionals to optimally evaluate and combine multiple sources of information. In this work we study discrimination and calibration biases in models trained for automatic detection of malignant dermatological conditions from skin lesions images. Importantly, we show how several typically employed calibration metrics are systematically biased with respect to sample sizes, and how this can lead to erroneous fairness analysis if not taken into consideration. This is of particular relevance to fairness studies, where data imbalance results in drastic sample size differences between demographic sub-groups, which, if not taken into account, can act as confounders.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Mar\u00eda Agustina Ricci Lara et al.",
      "keywords": "Computer science; Relevance (law); Calibration; Field (mathematics); Artificial intelligence; Sample (material); Machine learning; Confounding; Data science; Sample size determination; Econometrics; Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.05101",
      "cited_by_count": 5,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Empirical Study",
      "ai_ml_method": "Clinical Decision Support",
      "health_domain": "Dermatology; Oncology; ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Model Development/Training",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Calibration",
      "clinical_setting": "ICU; Public Health/Population",
      "key_findings": "Importantly, we show how several typically employed calibration metrics are systematically biased with respect to sample sizes, and how this can lead to erroneous fairness analysis if not taken into consideration. This is of particular relevance to fairness studies, where data imbalance results in drastic sample size differences between demographic sub-groups, which, if not taken into account, can act as confounders."
    },
    {
      "openalex_id": "https://openalex.org/W4366388571",
      "doi": "10.48550/arxiv.2304.07683",
      "title": "Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
      "abstract": "The significant advancements in applying Artificial Intelligence (AI) to healthcare decision-making, medical diagnosis, and other domains have simultaneously raised concerns about the fairness and bias of AI systems. This is particularly critical in areas like healthcare, employment, criminal justice, credit scoring, and increasingly, in generative AI models (GenAI) that produce synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including generative biases that affect the representation of individuals in synthetic data. This survey paper offers a succinct, comprehensive overview of fairness and bias in AI, addressing their sources, impacts, and mitigation strategies. We review sources of bias, such as data, algorithm, and human decision biases - highlighting the emergent issue of generative AI bias where models may reproduce and amplify societal stereotypes. We assess the societal impact of biased AI systems, focusing on the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI becomes more prevalent in creating content that influences public perception. We explore various proposed mitigation strategies, discussing the ethical considerations of their implementation and emphasizing the need for interdisciplinary collaboration to ensure effectiveness. Through a systematic literature review spanning multiple academic disciplines, we present definitions of AI bias and its different types, including a detailed look at generative AI bias. We discuss the negative impacts of AI bias on individuals and society and provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. We emphasize the unique challenges presented by generative AI models and the importance of strategies specifically tailored to address these.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Emilio Ferrara",
      "keywords": "Generative grammar; Artificial intelligence; Generative model; Computer science; Perception; Selection bias; Economic Justice; Data science; Management science; Machine learning; Psychology; Political science; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.07683",
      "cited_by_count": 73,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Systematic Review",
      "ai_ml_method": "Generative AI",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Socioeconomic Status",
      "lifecycle_stage": "Data Preprocessing; Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Data Augmentation; Post-hoc Correction",
      "clinical_setting": "ICU",
      "key_findings": "We discuss the negative impacts of AI bias on individuals and society and provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. We emphasize the unique challenges presented by generative AI models and the importance of strategies specifically tailored to address these."
    },
    {
      "openalex_id": "https://openalex.org/W4365456813",
      "doi": "10.48550/arxiv.2304.05986",
      "title": "Auditing ICU Readmission Rates in an Clinical Database: An Analysis of Risk Factors and Clinical Outcomes",
      "abstract": "This study presents a machine learning (ML) pipeline for clinical data classification in the context of a 30-day readmission problem, along with a fairness audit on subgroups based on sensitive attributes. A range of ML models are used for classification and the fairness audit is conducted on the model predictions. The fairness audit uncovers disparities in equal opportunity, predictive parity, false positive rate parity, and false negative rate parity criteria on the MIMIC III dataset based on attributes such as gender, ethnicity, language, and insurance group. The results identify disparities in the model's performance across different groups and highlights the need for better fairness and bias mitigation strategies. The study suggests the need for collaborative efforts among researchers, policymakers, and practitioners to address bias and fairness in artificial intelligence (AI) systems.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shaina Raza",
      "keywords": "Audit; Parity (physics); Context (archaeology); Actuarial science; Computer science; Business; Accounting; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.05986",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: substantial approach content in abstract",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age; Socioeconomic Status; Language; Insurance Status",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Fairness Metrics Evaluation; Bias Auditing Framework",
      "clinical_setting": "ICU",
      "key_findings": "The results identify disparities in the model's performance across different groups and highlights the need for better fairness and bias mitigation strategies. The study suggests the need for collaborative efforts among researchers, policymakers, and practitioners to address bias and fairness in artificial intelligence (AI) systems."
    },
    {
      "openalex_id": "https://openalex.org/W4321472024",
      "doi": "10.48550/arxiv.2302.09157",
      "title": "Designing Equitable Algorithms",
      "abstract": "Predictive algorithms are now used to help distribute a large share of our society's resources and sanctions, such as healthcare, loans, criminal detentions, and tax audits. Under the right circumstances, these algorithms can improve the efficiency and equity of decision-making. At the same time, there is a danger that the algorithms themselves could entrench and exacerbate disparities, particularly along racial, ethnic, and gender lines. To help ensure their fairness, many researchers suggest that algorithms be subject to at least one of three constraints: (1) no use of legally protected features, such as race, ethnicity, and gender; (2) equal rates of \"positive\" decisions across groups; and (3) equal error rates across groups. Here we show that these constraints, while intuitively appealing, often worsen outcomes for individuals in marginalized groups, and can even leave all groups worse off. The inherent trade-off we identify between formal fairness constraints and welfare improvements -- particularly for the marginalized -- highlights the need for a more robust discussion on what it means for an algorithm to be \"fair\". We illustrate these ideas with examples from healthcare and the criminal-legal system, and make several proposals to help practitioners design more equitable algorithms.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Alex Chohlas-Wood et al.",
      "keywords": "Sanctions; Equity (law); Ethnic group; Audit; Algorithm; Computer science; Welfare; Criminal justice; Health care; Law and economics; Public economics; Political science; Economics; Criminology; Sociology; Law; Accounting",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.09157",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Empirical Study",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex",
      "lifecycle_stage": "Model Development/Training; Model Evaluation",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Fairness Constraints; Bias Auditing Framework",
      "clinical_setting": "ICU",
      "key_findings": "The inherent trade-off we identify between formal fairness constraints and welfare improvements -- particularly for the marginalized -- highlights the need for a more robust discussion on what it means for an algorithm to be \"fair\". We illustrate these ideas with examples from healthcare and the criminal-legal system, and make several proposals to help practitioners design more equitable algorithms."
    },
    {
      "openalex_id": "https://openalex.org/W4389072684",
      "doi": "10.48550/arxiv.2311.14214",
      "title": "Extending Variability-Aware Model Selection with Bias Detection in Machine Learning Projects",
      "abstract": "Data science projects often involve various machine learning (ML) methods that depend on data, code, and models. One of the key activities in these projects is the selection of a model or algorithm that is appropriate for the data analysis at hand. ML model selection depends on several factors, which include data-related attributes such as sample size, functional requirements such as the prediction algorithm type, and non-functional requirements such as performance and bias. However, the factors that influence such selection are often not well understood and explicitly represented. This paper describes ongoing work on extending an adaptive variability-aware model selection method with bias detection in ML projects. The method involves: (i) modeling the variability of the factors that affect model selection using feature models based on heuristics proposed in the literature; (ii) instantiating our variability model with added features related to bias (e.g., bias-related metrics); and (iii) conducting experiments that illustrate the method in a specific case study to illustrate our approach based on a heart failure prediction project. The proposed approach aims to advance the state of the art by making explicit factors that influence model selection, particularly those related to bias, as well as their interactions. The provided representations can transform model selection in ML projects into a non ad hoc, adaptive, and explainable process.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Cristina Tavares et al.",
      "keywords": "Computer science; Heuristics; Selection (genetic algorithm); Model selection; Machine learning; Selection bias; Process (computing); Feature selection; Artificial intelligence; Data mining; Sample (material); Code (set theory); Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.14214",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Empirical Study",
      "ai_ml_method": "Not specified",
      "health_domain": "Cardiology; ICU/Critical Care; Genomics/Genetics",
      "bias_axes": "Gender/Sex",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Explainability/Interpretability",
      "clinical_setting": "ICU",
      "key_findings": "The proposed approach aims to advance the state of the art by making explicit factors that influence model selection, particularly those related to bias, as well as their interactions. The provided representations can transform model selection in ML projects into a non ad hoc, adaptive, and explainable process."
    },
    {
      "openalex_id": "https://openalex.org/W4380993348",
      "doi": "10.48550/arxiv.2306.08402",
      "title": "Fairness and Privacy-Preserving in Federated Learning: A Survey",
      "abstract": "Federated learning (FL) as distributed machine learning has gained popularity as privacy-aware Machine Learning (ML) systems have emerged as a technique that prevents privacy leakage by building a global model and by conducting individualized training of decentralized edge clients on their own private data. The existing works, however, employ privacy mechanisms such as Secure Multiparty Computing (SMC), Differential Privacy (DP), etc. Which are immensely susceptible to interference, massive computational overhead, low accuracy, etc. With the increasingly broad deployment of FL systems, it is challenging to ensure fairness and maintain active client participation in FL systems. Very few works ensure reasonably satisfactory performances for the numerous diverse clients and fail to prevent potential bias against particular demographics in FL systems. The current efforts fail to strike a compromise between privacy, fairness, and model performance in FL systems and are vulnerable to a number of additional problems. In this paper, we provide a comprehensive survey stating the basic concepts of FL, the existing privacy challenges, techniques, and relevant works concerning privacy in FL. We also provide an extensive overview of the increasing fairness challenges, existing fairness notions, and the limited works that attempt both privacy and fairness in FL. By comprehensively describing the existing FL systems, we present the potential future directions pertaining to the challenges of privacy-preserving and fairness-aware FL systems.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Taki Hasan Rafi et al.",
      "keywords": "Computer science; Differential privacy; Popularity; Information privacy; Computer security; Software deployment; Overhead (engineering); Compromise; Internet privacy; Adversarial system; Artificial intelligence; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.08402",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Federated Learning",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Deployment",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Federated Learning",
      "clinical_setting": "ICU",
      "key_findings": "We also provide an extensive overview of the increasing fairness challenges, existing fairness notions, and the limited works that attempt both privacy and fairness in FL. By comprehensively describing the existing FL systems, we present the potential future directions pertaining to the challenges of privacy-preserving and fairness-aware FL systems."
    },
    {
      "openalex_id": "https://openalex.org/W4323066662",
      "doi": "10.48550/arxiv.2303.00968",
      "title": "Dynamic fairness-aware recommendation through multi-agent social choice",
      "abstract": "Algorithmic fairness in the context of personalized recommendation presents significantly different challenges to those commonly encountered in classification tasks. Researchers studying classification have generally considered fairness to be a matter of achieving equality of outcomes between a protected and unprotected group, and built algorithmic interventions on this basis. We argue that fairness in real-world application settings in general, and especially in the context of personalized recommendation, is much more complex and multi-faceted, requiring a more general approach. We propose a model to formalize multistakeholder fairness in recommender systems as a two stage social choice problem. In particular, we express recommendation fairness as a novel combination of an allocation and an aggregation problem, which integrate both fairness concerns and personalized recommendation provisions, and derive new recommendation techniques based on this formulation. Simulations demonstrate the ability of the framework to integrate multiple fairness concerns in a dynamic way.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Amanda Aird et al.",
      "keywords": "Computer science; Recommender system; Context (archaeology); Fairness measure; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.00968",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Deployment",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Not specified",
      "clinical_setting": "ICU",
      "key_findings": "In particular, we express recommendation fairness as a novel combination of an allocation and an aggregation problem, which integrate both fairness concerns and personalized recommendation provisions, and derive new recommendation techniques based on this formulation. Simulations demonstrate the ability of the framework to integrate multiple fairness concerns in a dynamic way."
    },
    {
      "openalex_id": "https://openalex.org/W4298180163",
      "doi": "10.48550/arxiv.2208.03621",
      "title": "Bias Reducing Multitask Learning on Mental Health Prediction",
      "abstract": "There has been an increase in research in developing machine learning models for mental health detection or prediction in recent years due to increased mental health issues in society. Effective use of mental health prediction or detection models can help mental health practitioners re-define mental illnesses more objectively than currently done, and identify illnesses at an earlier stage when interventions may be more effective. However, there is still a lack of standard in evaluating bias in such machine learning models in the field, which leads to challenges in providing reliable predictions and in addressing disparities. This lack of standards persists due to factors such as technical difficulties, complexities of high dimensional clinical health data, etc., which are especially true for physiological signals. This along with prior evidence of relations between some physiological signals with certain demographic identities restates the importance of exploring bias in mental health prediction models that utilize physiological signals. In this work, we aim to perform a fairness analysis and implement a multi-task learning based bias mitigation method on anxiety prediction models using ECG data. Our method is based on the idea of epistemic uncertainty and its relationship with model weights and feature space representation. Our analysis showed that our anxiety prediction base model introduced some bias with regards to age, income, ethnicity, and whether a participant is born in the U.S. or not, and our bias mitigation method performed better at reducing the bias in the model, when compared to the reweighting mitigation technique. Our analysis on feature importance also helped identify relationships between heart rate variability and multiple demographic groupings.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Khadija Zanna et al.",
      "keywords": "Mental health; Machine learning; Anxiety; Artificial intelligence; Psychological intervention; Feature (linguistics); Representation (politics); Computer science; Multi-task learning; Field (mathematics); Task (project management); Psychology; Cognitive psychology; Psychiatry; Engineering; Political science; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.03621",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Empirical Study",
      "ai_ml_method": "Clinical Prediction Model",
      "health_domain": "Cardiology; Mental Health/Psychiatry; ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age; Socioeconomic Status",
      "lifecycle_stage": "Data Preprocessing",
      "assessment_or_mitigation": "Both",
      "approach_method": "Reweighting/Resampling; Multi-task Learning",
      "clinical_setting": "ICU",
      "key_findings": "or not, and our bias mitigation method performed better at reducing the bias in the model, when compared to the reweighting mitigation technique. Our analysis on feature importance also helped identify relationships between heart rate variability and multiple demographic groupings."
    },
    {
      "openalex_id": "https://openalex.org/W4320560900",
      "doi": "10.48550/arxiv.2211.08742",
      "title": "Auditing Algorithmic Fairness in Machine Learning for Health with Severity-Based LOGAN",
      "abstract": "Auditing machine learning-based (ML) healthcare tools for bias is critical to preventing patient harm, especially in communities that disproportionately face health inequities. General frameworks are becoming increasingly available to measure ML fairness gaps between groups. However, ML for health (ML4H) auditing principles call for a contextual, patient-centered approach to model assessment. Therefore, ML auditing tools must be (1) better aligned with ML4H auditing principles and (2) able to illuminate and characterize communities vulnerable to the most harm. To address this gap, we propose supplementing ML4H auditing frameworks with SLOGAN (patient Severity-based LOcal Group biAs detectioN), an automatic tool for capturing local biases in a clinical prediction task. SLOGAN adapts an existing tool, LOGAN (LOcal Group biAs detectioN), by contextualizing group bias detection in patient illness severity and past medical history. We investigate and compare SLOGAN's bias detection capabilities to LOGAN and other clustering techniques across patient subgroups in the MIMIC-III dataset. On average, SLOGAN identifies larger fairness disparities in over 75% of patient groups than LOGAN while maintaining clustering quality. Furthermore, in a diabetes case study, health disparity literature corroborates the characterizations of the most biased clusters identified by SLOGAN. Our results contribute to the broader discussion of how machine learning biases may perpetuate existing healthcare disparities.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Anaelia Ovalle et al.",
      "keywords": "Slogan; Audit; Harm; Health care; Machine learning; Cluster analysis; Artificial intelligence; Computer science; Quality (philosophy); Medicine; Psychology; Political science; Business; Social psychology; Accounting",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2211.08742",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "Clinical Prediction Model; Generative AI; Clustering",
      "health_domain": "Endocrinology/Diabetes",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Bias Auditing Framework",
      "clinical_setting": "Not specified",
      "key_findings": "Furthermore, in a diabetes case study, health disparity literature corroborates the characterizations of the most biased clusters identified by SLOGAN. Our results contribute to the broader discussion of how machine learning biases may perpetuate existing healthcare disparities."
    },
    {
      "openalex_id": "https://openalex.org/W4307769930",
      "doi": "10.48550/arxiv.2205.08875",
      "title": "Multi-disciplinary fairness considerations in machine learning for clinical trials",
      "abstract": "While interest in the application of machine learning to improve healthcare has grown tremendously in recent years, a number of barriers prevent deployment in medical practice. A notable concern is the potential to exacerbate entrenched biases and existing health disparities in society. The area of fairness in machine learning seeks to address these issues of equity; however, appropriate approaches are context-dependent, necessitating domain-specific consideration. We focus on clinical trials, i.e., research studies conducted on humans to evaluate medical treatments. Clinical trials are a relatively under-explored application in machine learning for healthcare, in part due to complex ethical, legal, and regulatory requirements and high costs. Our aim is to provide a multi-disciplinary assessment of how fairness for machine learning fits into the context of clinical trials research and practice. We start by reviewing the current ethical considerations and guidelines for clinical trials and examine their relationship with common definitions of fairness in machine learning. We examine potential sources of unfairness in clinical trials, providing concrete examples, and discuss the role machine learning might play in either mitigating potential biases or exacerbating them when applied without care. Particular focus is given to adaptive clinical trials, which may employ machine learning. Finally, we highlight concepts that require further investigation and development, and emphasize new approaches to fairness that may be relevant to the design of clinical trials.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Isabel Chien et al.",
      "keywords": "Clinical trial; Health care; Context (archaeology); Artificial intelligence; Equity (law); Discipline; Machine learning; Computer science; Clinical Practice; Management science; Engineering ethics; Medicine; Political science; Sociology; Engineering; Nursing; Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.08875",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex",
      "lifecycle_stage": "Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "ICU; Clinical Trial",
      "key_findings": "Particular focus is given to adaptive clinical trials, which may employ machine learning. Finally, we highlight concepts that require further investigation and development, and emphasize new approaches to fairness that may be relevant to the design of clinical trials."
    },
    {
      "openalex_id": "https://openalex.org/W4283324770",
      "doi": "10.48550/arxiv.2203.10190",
      "title": "Fair Federated Learning via Bounded Group Loss",
      "abstract": "Fair prediction across protected groups is an important constraint for many federated learning applications. However, prior work studying group fair federated learning lacks formal convergence or fairness guarantees. In this work we propose a general framework for provably fair federated learning. In particular, we explore and extend the notion of Bounded Group Loss as a theoretically-grounded approach for group fairness. Using this setup, we propose a scalable federated optimization method that optimizes the empirical risk under a number of group fairness constraints. We provide convergence guarantees for the method as well as fairness guarantees for the resulting solution. Empirically, we evaluate our method across common benchmarks from fair ML and federated learning, showing that it can provide both fairer and more accurate predictions than baseline approaches.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Shengyuan Hu et al.",
      "keywords": "Computer science; Bounded function; Scalability; Convergence (economics); Federated learning; Group (periodic table); Baseline (sea); Constraint (computer-aided design); Work (physics); Theoretical computer science; Artificial intelligence; Database; Mathematics; Political science; Law; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.10190",
      "cited_by_count": 2,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "Federated Learning",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Not specified",
      "lifecycle_stage": "Model Development/Training",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Fairness Constraints; Federated Learning",
      "clinical_setting": "ICU",
      "key_findings": "We provide convergence guarantees for the method as well as fairness guarantees for the resulting solution. Empirically, we evaluate our method across common benchmarks from fair ML and federated learning, showing that it can provide both fairer and more accurate predictions than baseline approaches."
    },
    {
      "openalex_id": "https://openalex.org/W4286235924",
      "doi": "10.48550/arxiv.2207.07704",
      "title": "Maximizing Fair Content Spread via Edge Suggestion in Social Networks",
      "abstract": "Content spread inequity is a potential unfairness issue in online social networks, disparately impacting minority groups. In this paper, we view friendship suggestion, a common feature in social network platforms, as an opportunity to achieve an equitable spread of content. In particular, we propose to suggest a subset of potential edges (currently not existing in the network but likely to be accepted) that maximizes content spread while achieving fairness. Instead of re-engineering the existing systems, our proposal builds a fairness wrapper on top of the existing friendship suggestion components. We prove the problem is NP-hard and inapproximable in polynomial time unless P = NP. Therefore, allowing relaxation of the fairness constraint, we propose an algorithm based on LP-relaxation and randomized rounding with fixed approximation ratios on fairness and content spread. We provide multiple optimizations, further improving the performance of our algorithm in practice. Besides, we propose a scalable algorithm that dynamically adds subsets of nodes, chosen via iterative sampling, and solves smaller problems corresponding to these nodes. Besides theoretical analysis, we conduct comprehensive experiments on real and synthetic data sets. Across different settings, our algorithms found solutions with nearzero unfairness while significantly increasing the content spread. Our scalable algorithm could process a graph with half a million nodes on a single machine, reducing the unfairness to around 0.0004 while lifting content spread by 43%.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Ian P. Swift et al.",
      "keywords": "Scalability; Computer science; Rounding; Randomized rounding; Approximation algorithm; Constraint (computer-aided design); Friendship; Social network (sociolinguistics); Theoretical computer science; Distributed computing; Algorithm; Social media; Mathematics; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2207.07704",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Methodology",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex",
      "lifecycle_stage": "Data Collection; Model Development/Training",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Fairness Constraints; Data Augmentation",
      "clinical_setting": "ICU",
      "key_findings": "Across different settings, our algorithms found solutions with nearzero unfairness while significantly increasing the content spread. Our scalable algorithm could process a graph with half a million nodes on a single machine, reducing the unfairness to around 0.0004 while lifting content spread by 43%."
    },
    {
      "openalex_id": "https://openalex.org/W3135158964",
      "doi": "10.48550/arxiv.2103.05841",
      "title": "Interpretable bias mitigation for textual data: Reducing gender bias in patient notes while maintaining classification performance",
      "abstract": "Medical systems in general, and patient treatment decisions and outcomes in particular, are affected by bias based on gender and other demographic elements. As language models are increasingly applied to medicine, there is a growing interest in building algorithmic fairness into processes impacting patient care. Much of the work addressing this question has focused on biases encoded in language models -- statistical estimates of the relationships between concepts derived from distant reading of corpora. Building on this work, we investigate how word choices made by healthcare practitioners and language models interact with regards to bias. We identify and remove gendered language from two clinical-note datasets and describe a new debiasing procedure using BERT-based gender classifiers. We show minimal degradation in health condition classification tasks for low- to medium-levels of bias removal via data augmentation. Finally, we compare the bias semantically encoded in the language models with the bias empirically observed in health records. This work outlines an interpretable approach for using data augmentation to identify and reduce the potential for bias in natural language processing pipelines.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Joshua R. Minot et al.",
      "keywords": "Debiasing; Computer science; Gender bias; Health care; Language model; Artificial intelligence; Natural language processing; Work (physics); Reading (process); Data science; Machine learning; Psychology; Social psychology; Linguistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2103.05841",
      "cited_by_count": 4,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "NLP/LLM",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age; Language",
      "lifecycle_stage": "Data Preprocessing",
      "assessment_or_mitigation": "Both",
      "approach_method": "Data Augmentation; Explainability/Interpretability",
      "clinical_setting": "ICU",
      "key_findings": "Finally, we compare the bias semantically encoded in the language models with the bias empirically observed in health records. This work outlines an interpretable approach for using data augmentation to identify and reduce the potential for bias in natural language processing pipelines."
    },
    {
      "openalex_id": "https://openalex.org/W4214835294",
      "doi": "10.1002/widm.1452",
      "title": "A survey on datasets for fairness-aware machine learning",
      "abstract": "As decision-making increasingly relies on Machine Learning (ML) and (big) data, the issue of fairness in data-driven Artificial Intelligence (AI) systems is receiving increasing attention from both research and industry. A large variety of fairness-aware machine learning solutions have been proposed which involve fairness-related interventions in the data, learning algorithms and/or model outputs. However, a vital part of proposing new approaches is evaluating them empirically on benchmark datasets that represent realistic and diverse settings. Therefore, in this paper, we overview real-world datasets used for fairness-aware machine learning. We focus on tabular data as the most common data representation for fairness-aware machine learning. We start our analysis by identifying relationships between the different attributes, particularly w.r.t. protected attributes and class attribute, using a Bayesian network. For a deeper understanding of bias in the datasets, we investigate the interesting relationships using exploratory analysis.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Tai Le Quy et al.",
      "keywords": "Computer science; Data pre-processing; Variety (cybernetics); Machine learning; Benchmark (surveying); Big data; Bayesian network; Artificial intelligence; Data science; Preprocessor; Data mining; Class (philosophy)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1002/widm.1452",
      "cited_by_count": 221,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Not specified",
      "lifecycle_stage": "Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Explainability/Interpretability",
      "clinical_setting": "ICU",
      "key_findings": "protected attributes and class attribute, using a Bayesian network. For a deeper understanding of bias in the datasets, we investigate the interesting relationships using exploratory analysis."
    },
    {
      "openalex_id": "https://openalex.org/W4287182083",
      "doi": "10.48550/arxiv.2105.06442",
      "title": "An Empirical Comparison of Bias Reduction Methods on Real-World Problems\\n in High-Stakes Policy Settings",
      "abstract": "Applications of machine learning (ML) to high-stakes policy settings -- such\\nas education, criminal justice, healthcare, and social service delivery -- have\\ngrown rapidly in recent years, sparking important conversations about how to\\nensure fair outcomes from these systems. The machine learning research\\ncommunity has responded to this challenge with a wide array of proposed\\nfairness-enhancing strategies for ML models, but despite the large number of\\nmethods that have been developed, little empirical work exists evaluating these\\nmethods in real-world settings. Here, we seek to fill this research gap by\\ninvestigating the performance of several methods that operate at different\\npoints in the ML pipeline across four real-world public policy and social good\\nproblems. Across these problems, we find a wide degree of variability and\\ninconsistency in the ability of many of these methods to improve model\\nfairness, but post-processing by choosing group-specific score thresholds\\nconsistently removes disparities, with important implications for both the ML\\nresearch community and practitioners deploying machine learning to inform\\nconsequential policy decisions.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Hemank Lamba et al.",
      "keywords": "Pipeline (software); Empirical research; Computer science; Machine learning; Work (physics); Social work; Reduction (mathematics); Artificial intelligence; Economics; Engineering; Economic growth",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2105.06442",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Not specified",
      "health_domain": "General Healthcare",
      "bias_axes": "Not specified",
      "lifecycle_stage": "Model Evaluation; Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Threshold Adjustment; Post-hoc Correction",
      "clinical_setting": "Public Health/Population",
      "key_findings": "Here, we seek to fill this research gap by\\ninvestigating the performance of several methods that operate at different\\npoints in the ML pipeline across four real-world public policy and social good\\nproblems. Across these problems, we find a wide degree of variability and\\ninconsistency in the ability of many of these methods to improve model\\nfairness, but post-processing by choosing group-specific score thresholds\\nconsistently removes disparities, with important implications for both the ML\\..."
    },
    {
      "openalex_id": "https://openalex.org/W4287025772",
      "doi": "10.48550/arxiv.2108.05523",
      "title": "Fair Decision-Making for Food Inspections",
      "abstract": "Data and algorithms are essential and complementary parts of a large-scale decision-making process. However, their injudicious use can lead to unforeseen consequences, as has been observed by researchers and activists alike in the recent past. In this paper, we revisit the application of predictive models by the Chicago Department of Public Health to schedule restaurant inspections and prioritize the detection of critical food code violations. We perform the first analysis of the model's fairness to the population served by the restaurants in terms of average time to find a critical violation. We find that the model treats inspections unequally based on the sanitarian who conducted the inspection and that, in turn, there are geographic disparities in the benefits of the model. We examine four alternate methods of model training and two alternative ways of scheduling using the model and find that the latter generate more desirable results. The challenges from this application point to important directions for future work around fairness with collective entities rather than individuals, the use of critical violations as a proxy, and the disconnect between fair classification and fairness in the dynamic scheduling system.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Shubham Singh et al.",
      "keywords": "Computer science; Proxy (statistics); Schedule; Scheduling (production processes); Operations research; Risk analysis (engineering); Population; Operations management; Business; Machine learning; Economics; Engineering; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2108.05523",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Empirical Study",
      "ai_ml_method": "Clinical Prediction Model",
      "health_domain": "Public Health",
      "bias_axes": "Gender/Sex; Age; Geographic",
      "lifecycle_stage": "Model Development/Training",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Not specified",
      "clinical_setting": "Public Health/Population",
      "key_findings": "We examine four alternate methods of model training and two alternative ways of scheduling using the model and find that the latter generate more desirable results. The challenges from this application point to important directions for future work around fairness with collective entities rather than individuals, the use of critical violations as a proxy, and the disconnect between fair classification and fairness in the dynamic scheduling system."
    },
    {
      "openalex_id": "https://openalex.org/W4312117768",
      "doi": "10.48550/arxiv.2010.12089",
      "title": "The Pursuit of Algorithmic Fairness: On \"Correcting\" Algorithmic Unfairness in a Child Welfare Reunification Success Classifier",
      "abstract": "The algorithmic fairness of predictive analytic tools in the public sector has increasingly become a topic of rigorous exploration. While instruments pertaining to criminal recidivism and academic admissions, for example, have garnered much attention, the predictive instruments of Child Welfare jurisdictions have received considerably less attention. This is in part because comparatively few such instruments exist and because even fewer have been scrutinized through the lens of algorithmic fairness. In this work, we seek to address both of these gaps. To this end, a novel classification algorithm for predicting reunification success within Oregon Child Welfare is presented, including all of the relevant details associated with building such an instrument. The purpose of this tool is to maximize the number of stable reunifications and identify potentially unstable reunifications which may require additional resources and scrutiny. Additionally, because the algorithmic fairness of the resulting tool, if left unaltered, is unquestionably lacking, the utilized procedure for mitigating such unfairness is presented, along with the rationale behind each difficult and unavoidable choice. This procedure, though similar to other post-processing group-specific thresholding methods, is novel in its use of a penalized optimizer and contextually requisite subsampling. These novel methodological components yield a rich and informative empirical understanding of the trade-off continuum between fairness and accuracy. As the developed procedure is generalizable across a variety of group-level definitions of algorithmic fairness, as well as across an arbitrary number of protected attribute levels and risk thresholds, the approach is broadly applicable both within and beyond Child Welfare.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Jordan Purdy et al.",
      "keywords": "Welfare; Computer science; Recidivism; Scrutiny; Classifier (UML); Capability approach; Machine learning; Artificial intelligence; Psychology; Economics; Political science; Criminology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2010.12089",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Methodology",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care; Pediatrics",
      "bias_axes": "Gender/Sex",
      "lifecycle_stage": "Data Collection; Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Threshold Adjustment; Explainability/Interpretability; Post-hoc Correction",
      "clinical_setting": "ICU",
      "key_findings": "These novel methodological components yield a rich and informative empirical understanding of the trade-off continuum between fairness and accuracy. As the developed procedure is generalizable across a variety of group-level definitions of algorithmic fairness, as well as across an arbitrary number of protected attribute levels and risk thresholds, the approach is broadly applicable both within and beyond Child Welfare."
    },
    {
      "openalex_id": "https://openalex.org/W2947305394",
      "doi": "10.48550/arxiv.1906.00285",
      "title": "Assessing Algorithmic Fairness with Unobserved Protected Class Using Data Combination",
      "abstract": "The increasing impact of algorithmic decisions on people's lives compels us to scrutinize their fairness and, in particular, the disparate impacts that ostensibly-color-blind algorithms can have on different groups. Examples include credit decisioning, hiring, advertising, criminal justice, personalized medicine, and targeted policymaking, where in some cases legislative or regulatory frameworks for fairness exist and define specific protected classes. In this paper we study a fundamental challenge to assessing disparate impacts in practice: protected class membership is often not observed in the data. This is particularly a problem in lending and healthcare. We consider the use of an auxiliary dataset, such as the US census, to construct models that predict the protected class from proxy variables, such as surname and geolocation. We show that even with such data, a variety of common disparity measures are generally unidentifiable, providing a new perspective on the documented biases of popular proxy-based methods. We provide exact characterizations of the tightest-possible set of all possible true disparities that are consistent with the data (and possibly any assumptions). We further provide optimization-based algorithms for computing and visualizing these sets and statistical tools to assess sampling uncertainty. Together, these enable reliable and robust assessments of disparities -- an important tool when disparity assessment can have far-reaching policy implications. We demonstrate this in two case studies with real data: mortgage lending and personalized medicine dosing.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Nathan Kallus et al.",
      "keywords": "Computer science; Disparate impact; Proxy (statistics); Geolocation; Class (philosophy); Set (abstract data type); Data science; Variety (cybernetics); Data mining; Machine learning; Artificial intelligence; World Wide Web; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1906.00285",
      "cited_by_count": 31,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Commentary/Editorial",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Data Collection",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Fairness Metrics Evaluation",
      "clinical_setting": "ICU",
      "key_findings": "Together, these enable reliable and robust assessments of disparities -- an important tool when disparity assessment can have far-reaching policy implications. We demonstrate this in two case studies with real data: mortgage lending and personalized medicine dosing."
    },
    {
      "openalex_id": "https://openalex.org/W2773523653",
      "doi": "10.48550/arxiv.1712.03586",
      "title": "Fairness in Machine Learning: Lessons from Political Philosophy",
      "abstract": "What does it mean for a machine learning model to be `fair', in terms which can be operationalised? Should fairness consist of ensuring everyone has an equal probability of obtaining some benefit, or should we aim instead to minimise the harms to the least advantaged? Can the relevant ideal be determined by reference to some alternative state of affairs in which a particular social pattern of discrimination does not exist? Various definitions proposed in recent literature make different assumptions about what terms like discrimination and fairness mean and how they can be defined in mathematical terms. Questions of discrimination, egalitarianism and justice are of significant interest to moral and political philosophers, who have expended significant efforts in formalising and defending these central concepts. It is therefore unsurprising that attempts to formalise `fairness' in machine learning contain echoes of these old philosophical debates. This paper draws on existing work in moral and political philosophy in order to elucidate emerging debates about fair machine learning.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Reuben Binns",
      "keywords": "Egalitarianism; Politics; Ideal (ethics); Political philosophy; Order (exchange); Economic Justice; Epistemology; Work (physics); Artificial intelligence; Sociology; Positive economics; Computer science; Law and economics; Political science; Law; Economics; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1712.03586",
      "cited_by_count": 390,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Empirical Study",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Age",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Not specified",
      "clinical_setting": "ICU",
      "key_findings": "It is therefore unsurprising that attempts to formalise `fairness' in machine learning contain echoes of these old philosophical debates. This paper draws on existing work in moral and political philosophy in order to elucidate emerging debates about fair machine learning."
    }
  ],
  "ft_excluded": [
    {
      "openalex_id": "https://openalex.org/W4225679496",
      "doi": "10.48550/arxiv.2202.08821",
      "title": "Human-Algorithm Collaboration: Achieving Complementarity and Avoiding Unfairness",
      "abstract": "Much of machine learning research focuses on predictive accuracy: given a task, create a machine learning model (or algorithm) that maximizes accuracy. In many settings, however, the final prediction or decision of a system is under the control of a human, who uses an algorithm's output along with their own personal expertise in order to produce a combined prediction. One ultimate goal of such collaborative systems is \"complementarity\": that is, to produce lower loss (equivalently, greater payoff or utility) than either the human or algorithm alone. However, experimental results have shown that even in carefully-designed systems, complementary performance can be elusive. Our work provides three key contributions. First, we provide a theoretical framework for modeling simple human-algorithm systems and demonstrate that multiple prior analyses can be expressed within it. Next, we use this model to prove conditions where complementarity is impossible, and give constructive examples of where complementarity is achievable. Finally, we discuss the implications of our findings, especially with respect to the fairness of a classifier. In sum, these results deepen our understanding of key factors influencing the combined performance of human-algorithm systems, giving insight into how algorithmic tools can best be designed for collaborative environments.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Kate Donahue et al.",
      "keywords": "Computer science; Complementarity (molecular biology); Constructive; Stochastic game; Machine learning; Key (lock); Artificial intelligence; Algorithm; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.08821",
      "cited_by_count": 5,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4380994586",
      "doi": "10.48550/arxiv.2306.09264",
      "title": "Harvard Glaucoma Fairness: A Retinal Nerve Disease Dataset for Fairness Learning and Fair Identity Normalization",
      "abstract": "Fairness (also known as equity interchangeably) in machine learning is important for societal well-being, but limited public datasets hinder its progress. Currently, no dedicated public medical datasets with imaging data for fairness learning are available, though minority groups suffer from more health issues. To address this gap, we introduce Harvard Glaucoma Fairness (Harvard-GF), a retinal nerve disease dataset with both 2D and 3D imaging data and balanced racial groups for glaucoma detection. Glaucoma is the leading cause of irreversible blindness globally with Blacks having doubled glaucoma prevalence than other races. We also propose a fair identity normalization (FIN) approach to equalize the feature importance between different identity groups. Our FIN approach is compared with various the-state-of-the-art fairness learning methods with superior performance in the racial, gender, and ethnicity fairness tasks with 2D and 3D imaging data, which demonstrate the utilities of our dataset Harvard-GF for fairness learning. To facilitate fairness comparisons between different models, we propose an equity-scaled performance measure, which can be flexibly used to compare all kinds of performance metrics in the context of fairness. The dataset and code are publicly accessible via \\url{https://ophai.hms.harvard.edu/datasets/harvard-glaucoma-fairness-3300-samples/}.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yan Luo et al.",
      "keywords": "Glaucoma; Normalization (sociology); Computer science; Equity (law); Artificial intelligence; Machine learning; Health equity; Ethnic group; Public health; Medicine; Political science; Ophthalmology; Sociology; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.09264",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4312226187",
      "doi": "10.48550/arxiv.2212.12799",
      "title": "A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models",
      "abstract": "Chemical named entity recognition (NER) models are used in many downstream tasks, from adverse drug reaction identification to pharmacoepidemiology. However, it is unknown whether these models work the same for everyone. Performance disparities can potentially cause harm rather than the intended good. This paper assesses gender-related performance disparities in chemical NER systems. We develop a framework for measuring gender bias in chemical NER models using synthetic data and a newly annotated corpus of over 92,405 words with self-identified gender information from Reddit. Our evaluation of multiple biomedical NER models reveals evident biases. For instance, synthetic data suggests female-related names are frequently misclassified as chemicals, especially for brand name mentions. Additionally, we observe performance disparities between female- and male-associated data in both datasets. Many systems fail to detect contraceptives such as birth control. Our findings emphasize the biases in chemical NER models, urging practitioners to account for these biases in downstream applications.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Xingmeng Zhao et al.",
      "keywords": "Named-entity recognition; Harm; Computer science; Downstream (manufacturing); Pharmacoepidemiology; Natural language processing; Drug reaction; Identification (biology); Chemical safety; Sequence labeling; Data science; Artificial intelligence; Medicine; Drug; Psychology; Risk analysis (engineering); Biology; Engineering; Pharmacology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.12799",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4365441044",
      "doi": "10.48550/arxiv.2304.04761",
      "title": "Connecting Fairness in Machine Learning with Public Health Equity",
      "abstract": "Machine learning (ML) has become a critical tool in public health, offering the potential to improve population health, diagnosis, treatment selection, and health system efficiency. However, biases in data and model design can result in disparities for certain protected groups and amplify existing inequalities in healthcare. To address this challenge, this study summarizes seminal literature on ML fairness and presents a framework for identifying and mitigating biases in the data and model. The framework provides guidance on incorporating fairness into different stages of the typical ML pipeline, such as data processing, model design, deployment, and evaluation. To illustrate the impact of biases in data on ML models, we present examples that demonstrate how systematic biases can be amplified through model predictions. These case studies suggest how the framework can be used to prevent these biases and highlight the need for fair and equitable ML models in public health. This work aims to inform and guide the use of ML in public health towards a more ethical and equitable outcome for all populations.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shaina Raza",
      "keywords": "Equity (law); Health equity; Software deployment; Computer science; Public health; Health care; Inequality; Work (physics); Population health; Risk analysis (engineering); Management science; Population; Public economics; Actuarial science; Machine learning; Medicine; Business; Economics; Political science; Environmental health; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.04761",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4385934230",
      "doi": "10.48550/arxiv.2308.04356",
      "title": "Learning Unbiased Image Segmentation: A Case Study with Plain Knee Radiographs",
      "abstract": "Automatic segmentation of knee bony anatomy is essential in orthopedics, and it has been around for several years in both pre-operative and post-operative settings. While deep learning algorithms have demonstrated exceptional performance in medical image analysis, the assessment of fairness and potential biases within these models remains limited. This study aims to revisit deep learning-powered knee-bony anatomy segmentation using plain radiographs to uncover visible gender and racial biases. The current contribution offers the potential to advance our understanding of biases, and it provides practical insights for researchers and practitioners in medical imaging. The proposed mitigation strategies mitigate gender and racial biases, ensuring fair and unbiased segmentation results. Furthermore, this work promotes equal access to accurate diagnoses and treatment outcomes for diverse patient populations, fostering equitable and inclusive healthcare provision.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Nickolas Littlefield et al.",
      "keywords": "Segmentation; Deep learning; Orthopedic surgery; Medical imaging; Medical diagnosis; Radiography; Artificial intelligence; Medicine; Computer science; Data science; Orthodontics; Medical physics; Radiology; Surgery",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.04356",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4406121147",
      "doi": "10.48550/arxiv.2501.02442",
      "title": "Unsupervised Search for Ethnic Minorities' Medical Segmentation Training Set",
      "abstract": "This article investigates the critical issue of dataset bias in medical imaging, with a particular emphasis on racial disparities caused by uneven population distribution in dataset collection. Our analysis reveals that medical segmentation datasets are significantly biased, primarily influenced by the demographic composition of their collection sites. For instance, Scanning Laser Ophthalmoscopy (SLO) fundus datasets collected in the United States predominantly feature images of White individuals, with minority racial groups underrepresented. This imbalance can result in biased model performance and inequitable clinical outcomes, particularly for minority populations. To address this challenge, we propose a novel training set search strategy aimed at reducing these biases by focusing on underrepresented racial groups. Our approach utilizes existing datasets and employs a simple greedy algorithm to identify source images that closely match the target domain distribution. By selecting training data that aligns more closely with the characteristics of minority populations, our strategy improves the accuracy of medical segmentation models on specific minorities, i.e., Black. Our experimental results demonstrate the effectiveness of this approach in mitigating bias. We also discuss the broader societal implications, highlighting how addressing these disparities can contribute to more equitable healthcare outcomes.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yixiao Chen et al.",
      "keywords": "Ethnic group; Segmentation; Training (meteorology); Set (abstract data type); Training set; Computer science; Artificial intelligence; Political science; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2501.02442",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4415307114",
      "doi": "10.48550/arxiv.2504.17279",
      "title": "Evaluating and Mitigating Bias in AI-Based Medical Text Generation",
      "abstract": "Artificial intelligence (AI) systems, particularly those based on deep learning models, have increasingly achieved expert-level performance in medical applications. However, there is growing concern that such AI systems may reflect and amplify human bias, and reduce the quality of their performance in historically under-served populations. The fairness issue has attracted considerable research interest in the medical imaging classification field, yet it remains understudied in the text generation domain. In this study, we investigate the fairness problem in text generation within the medical field and observe significant performance discrepancies across different races, sexes, and age groups, including intersectional groups, various model scales, and different evaluation metrics. To mitigate this fairness issue, we propose an algorithm that selectively optimizes those underperformed groups to reduce bias. The selection rules take into account not only word-level accuracy but also the pathology accuracy to the target reference, while ensuring that the entire process remains fully differentiable for effective model training. Our evaluations across multiple backbones, datasets, and modalities demonstrate that our proposed algorithm enhances fairness in text generation without compromising overall performance. Specifically, the disparities among various groups across different metrics were diminished by more than 30% with our algorithm, while the relative change in text generation accuracy was typically within 2%. By reducing the bias generated by deep learning models, our proposed approach can potentially alleviate concerns about the fairness and reliability of text generation diagnosis in medical domain. Our code is publicly available to facilitate further research at https://github.com/iriscxy/GenFair.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiuying Chen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.17279",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4416097329",
      "doi": "10.48550/arxiv.2505.04886",
      "title": "Fairness Perceptions in Regression-based Predictive Models",
      "abstract": "Regression-based predictive analytics used in modern kidney transplantation is known to inherit biases from training data. This leads to social discrimination and inefficient organ utilization, particularly in the context of a few social groups. Despite this concern, there is limited research on fairness in regression and its impact on organ utilization and placement. This paper introduces three novel divergence-based group fairness notions: (i) independence, (ii) separation, and (iii) sufficiency to assess the fairness of regression-based analytics tools. In addition, fairness preferences are investigated from crowd feedback, in order to identify a socially accepted group fairness criterion for evaluating these tools. A total of 85 participants were recruited from the Prolific crowdsourcing platform, and a Mixed-Logit discrete choice model was used to model fairness feedback and estimate social fairness preferences. The findings clearly depict a strong preference towards the separation and sufficiency fairness notions, and that the predictive analytics is deemed fair with respect to gender and race groups, but unfair in terms of age groups.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mukund Telukunta et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04886",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4405032087",
      "doi": "10.48550/arxiv.2411.18122",
      "title": "Using Machine Bias To Measure Human Bias",
      "abstract": "Biased human decisions have consequential impacts across various domains, yielding unfair treatment of individuals and resulting in suboptimal outcomes for organizations and society. In recognition of this fact, organizations regularly design and deploy interventions aimed at mitigating these biases. However, measuring human decision biases remains an important but elusive task. Organizations are frequently concerned with mistaken decisions disproportionately affecting one group. In practice, however, this is typically not possible to assess due to the scarcity of a gold standard: a label that indicates what the correct decision would have been. In this work, we propose a machine learning-based framework to assess bias in human-generated decisions when gold standard labels are scarce. We provide theoretical guarantees and empirical evidence demonstrating the superiority of our method over existing alternatives. This proposed methodology establishes a foundation for transparency in human decision-making, carrying substantial implications for managerial duties, and offering potential for alleviating algorithmic biases when human decisions are used as labels to train algorithms.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Wanxue Dong et al.",
      "keywords": "Gender bias; Information bias; Computer science; Artificial intelligence; Selection bias; Cognitive psychology; Psychology; Econometrics; Machine learning; Economics; Statistics; Social psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.18122",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4416546120",
      "doi": "10.48550/arxiv.2504.21688",
      "title": "Assessing Racial Disparities in Healthcare Expenditures via Mediator Distribution Shifts",
      "abstract": "Racial disparities in healthcare expenditures are well-documented, yet the underlying drivers remain complex and require further investigation. This study develops a framework for decomposing such disparities through shifts in the distributions of mediating variables, rather than treating race itself as a manipulable exposure. We define disparities as differences in covariate-adjusted outcome distributions across racial groups, and decompose the total disparity into two components: one attributable to differences in mediator distributions, and another residual component that would remain even after equalizing these distributions. Using data from the Medical Expenditures Panel Survey, we examine the extent to which expenditure disparities would persist or be reduced if mediators such as socioeconomic status, insurance access, health behaviors, or health status were equalized across racial groups. To ensure valid inference, we derive asymptotically linear estimators based on influence-function techniques and flexible machine learning tools, including super learners and a two-part model designed for the zero-inflated, right-skewed nature of expenditure data.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiaojie Ou et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.21688",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4226066577",
      "doi": "10.48550/arxiv.2203.10264",
      "title": "Assessing Gender Bias in Predictive Algorithms using eXplainable AI",
      "abstract": "Predictive algorithms have a powerful potential to offer benefits in areas as varied as medicine or education. However, these algorithms and the data they use are built by humans, consequently, they can inherit the bias and prejudices present in humans. The outcomes can systematically repeat errors that create unfair results, which can even lead to situations of discrimination (e.g. gender, social or racial). In order to illustrate how important is to count with a diverse training dataset to avoid bias, we manipulate a well-known facial expression recognition dataset to explore gender bias and discuss its implications.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Cristina Manresa-Yee et al.",
      "keywords": "Gender bias; Implicit bias; Computer science; Machine learning; Racial bias; Artificial intelligence; Psychology; Race (biology); Social psychology; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.10264",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4384112444",
      "doi": "10.48550/arxiv.2307.05333",
      "title": "Wearable-based Fair and Accurate Pain Assessment Using Multi-Attribute Fairness Loss in Convolutional Neural Networks",
      "abstract": "The integration of diverse health data, such as IoT (Internet of Things), EHR (Electronic Health Record), and clinical surveys, with scalable AI(Artificial Intelligence) has enabled the identification of physical, behavioral, and psycho-social indicators of pain. However, the adoption of AI in clinical pain evaluation is hindered by challenges like personalization and fairness. Many AI models, including machine and deep learning, exhibit biases, discriminating against specific groups based on gender or ethnicity, causing skepticism among medical professionals about their reliability. This paper proposes a Multi-attribute Fairness Loss (MAFL) based Convolutional Neural Network (CNN) model designed to account for protected attributes in data, ensuring fair pain status predictions while minimizing disparities between privileged and unprivileged groups. We evaluate whether a balance between accuracy and fairness is achievable by comparing the proposed model with existing mitigation methods. Our findings indicate that the model performs favorably against state-of-the-art techniques. Using the NIH All-Of-US dataset, comprising data from 868 individuals over 1500 days, we demonstrate our model's effectiveness, achieving accuracy rates between 75% and 85%.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Sharmin Sultana et al.",
      "keywords": "Personalization; Machine learning; Computer science; Artificial intelligence; Adaptability; Wearable computer; Health care; Scalability; Data sharing; Big data; Data science; Applied psychology; Psychology; Medicine; Data mining; World Wide Web; Database",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.05333",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4292106866",
      "doi": "10.17863/cam.92891",
      "title": "Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness",
      "abstract": "Biases have marked medical history, leading to unequal care affecting marginalised groups. The patterns of missingness in observational data often reflect these group discrepancies, but the algorithmic fairness implications of group-specific missingness are not well understood. Despite its potential impact, imputation is too often an overlooked preprocessing step. When explicitly considered, attention is placed on overall performance, ignoring how this preprocessing can reinforce groupspecific inequities. Our work questions this choice by studying how imputation affects downstream algorithmic fairness. First, we provide a structured view of the relationship between clinical presence mechanisms and groupspecific missingness patterns. Then, through simulations and real-world experiments, we demonstrate that the imputation choice influences marginalised group performance and that no imputation strategy consistently reduces disparities. Importantly, our results show that current practices may endanger health equity as similarly performing imputation strategies at the population level can affect marginalised groups differently. Finally, we propose recommendations for mitigating inequities that may stem from a neglected step of the machine learning pipeline.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Vincent Jeanselme et al.",
      "keywords": "Imputation (statistics); Missing data; Preprocessor; Computer science; Affect (linguistics); Data pre-processing; Machine learning; Artificial intelligence; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.17863/cam.92891",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4383605182",
      "doi": "10.48550/arxiv.2307.03157",
      "title": "Achieving Reliable and Fair Skin Lesion Diagnosis via Unsupervised Domain Adaptation",
      "abstract": "The development of reliable and fair diagnostic systems is often constrained by the scarcity of labeled data. To address this challenge, our work explores the feasibility of unsupervised domain adaptation (UDA) to integrate large external datasets for developing reliable classifiers. The adoption of UDA with multiple sources can simultaneously enrich the training set and bridge the domain gap between different skin lesion datasets, which vary due to distinct acquisition protocols. Particularly, UDA shows practical promise for improving diagnostic reliability when training with a custom skin lesion dataset, where only limited labeled data are available from the target domain. In this study, we investigate three UDA training schemes based on source data utilization: single-source, combined-source, and multi-source UDA. Our findings demonstrate the effectiveness of applying UDA on multiple sources for binary and multi-class classification. A strong correlation between test error and label shift in multi-class tasks has been observed in the experiment. Crucially, our study shows that UDA can effectively mitigate bias against minority groups and enhance fairness in diagnostic systems, while maintaining superior classification performance. This is achieved even without directly implementing fairness-focused techniques. This success is potentially attributed to the increased and well-adapted demographic information obtained from multiple sources.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Janet Wang et al.",
      "keywords": "Domain adaptation; Adaptation (eye); Computer science; Domain (mathematical analysis); Lesion; Artificial intelligence; Pattern recognition (psychology); Psychology; Medicine; Mathematics; Neuroscience; Pathology; Classifier (UML)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.03157",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4389216617",
      "doi": "10.48550/arxiv.2311.16180",
      "title": "Aiming to Minimize Alcohol-Impaired Road Fatalities: Utilizing Fairness-Aware and Domain Knowledge-Infused Artificial Intelligence",
      "abstract": "Approximately 30% of all traffic fatalities in the United States are attributed to alcohol-impaired driving. This means that, despite stringent laws against this offense in every state, the frequency of drunk driving accidents is alarming, resulting in approximately one person being killed every 45 minutes. The process of charging individuals with Driving Under the Influence (DUI) is intricate and can sometimes be subjective, involving multiple stages such as observing the vehicle in motion, interacting with the driver, and conducting Standardized Field Sobriety Tests (SFSTs). Biases have been observed through racial profiling, leading to some groups and geographical areas facing fewer DUI tests, resulting in many actual DUI incidents going undetected, ultimately leading to a higher number of fatalities. To tackle this issue, our research introduces an Artificial Intelligence-based predictor that is both fairness-aware and incorporates domain knowledge to analyze DUI-related fatalities in different geographic locations. Through this model, we gain intriguing insights into the interplay between various demographic groups, including age, race, and income. By utilizing the provided information to allocate policing resources in a more equitable and efficient manner, there is potential to reduce DUI-related fatalities and have a significant impact on road safety.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Tejas Venkateswaran et al.",
      "keywords": "Sobriety; Driving under the influence; Drunk driving; Racial profiling; Computer security; Transport engineering; Computer science; Poison control; Human factors and ergonomics; Race (biology); Psychology; Engineering; Environmental health; Medicine; Sociology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.16180",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3194597281",
      "doi": "10.48550/arxiv.2108.08504",
      "title": "Understanding and Mitigating Annotation Bias in Facial Expression Recognition",
      "abstract": "The performance of a computer vision model depends on the size and quality of its training data. Recent studies have unveiled previously-unknown composition biases in common image datasets which then lead to skewed model outputs, and have proposed methods to mitigate these biases. However, most existing works assume that human-generated annotations can be considered gold-standard and unbiased. In this paper, we reveal that this assumption can be problematic, and that special care should be taken to prevent models from learning such annotation biases. We focus on facial expression recognition and compare the label biases between lab-controlled and in-the-wild datasets. We demonstrate that many expression datasets contain significant annotation biases between genders, especially when it comes to the happy and angry expressions, and that traditional methods cannot fully mitigate such biases in trained models. To remove expression annotation bias, we propose an AU-Calibrated Facial Expression Recognition (AUC-FER) framework that utilizes facial action units (AUs) and incorporates the triplet loss into the objective function. Experimental results suggest that the proposed method is more effective in removing expression annotation bias than existing techniques.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Yunliang Chen et al.",
      "keywords": "Annotation; Facial expression recognition; Computer science; Facial expression; Artificial intelligence; Expression (computer science); Quality (philosophy); Focus (optics); Function (biology); Machine learning; Pattern recognition (psychology); Facial recognition system; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2108.08504",
      "cited_by_count": 11,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4225424248",
      "doi": "10.48550/arxiv.2205.01038",
      "title": "Demographic-Reliant Algorithmic Fairness: Characterizing the Risks of Demographic Data Collection in the Pursuit of Fairness",
      "abstract": "Most proposed algorithmic fairness techniques require access to data on a \"sensitive attribute\" or \"protected category\" (such as race, ethnicity, gender, or sexuality) in order to make performance comparisons and standardizations across groups, however this data is largely unavailable in practice, hindering the widespread adoption of algorithmic fairness. Through this paper, we consider calls to collect more data on demographics to enable algorithmic fairness and challenge the notion that discrimination can be overcome with smart enough technical methods and sufficient data alone. We show how these techniques largely ignore broader questions of data governance and systemic oppression when categorizing individuals for the purpose of fairer algorithmic processing. In this work, we explore under what conditions demographic data should be collected and used to enable algorithmic fairness methods by characterizing a range of social risks to individuals and communities. For the risks to individuals we consider the unique privacy risks associated with the sharing of sensitive attributes likely to be the target of fairness analysis, the possible harms stemming from miscategorizing and misrepresenting individuals in the data collection process, and the use of sensitive data beyond data subjects' expectations. Looking more broadly, the risks to entire groups and communities include the expansion of surveillance infrastructure in the name of fairness, misrepresenting and mischaracterizing what it means to be part of a demographic group or to hold a certain identity, and ceding the ability to define for themselves what constitutes biased or unfair treatment. We argue that, by confronting these questions before and during the collection of demographic data, algorithmic fairness methods are more likely to actually mitigate harmful treatment disparities without reinforcing systems of oppression.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "McKane Andrus et al.",
      "keywords": "Data collection; Data sharing; Computer science; Demographics; Internet privacy; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.01038",
      "cited_by_count": 7,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4298646754",
      "doi": "10.48550/arxiv.2109.09061",
      "title": "Model-Based Approach for Measuring the Fairness in ASR",
      "abstract": "The issue of fairness arises when the automatic speech recognition (ASR) systems do not perform equally well for all subgroups of the population. In any fairness measurement studies for ASR, the open questions of how to control the nuisance factors, how to handle unobserved heterogeneity across speakers, and how to trace the source of any word error rate (WER) gap among different subgroups are especially important - if not appropriately accounted for, incorrect conclusions will be drawn. In this paper, we introduce mixed-effects Poisson regression to better measure and interpret any WER difference among subgroups of interest. Particularly, the presented method can effectively address the three problems raised above and is very flexible to use in practical disparity analyses. We demonstrate the validity of proposed model-based approach on both synthetic and real-world speech data.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhe Liu et al.",
      "keywords": "Computer science; TRACE (psycholinguistics); Measure (data warehouse); Poisson distribution; Word (group theory); Population; Econometrics; Poisson regression; Word error rate; Speech recognition; Control (management); Statistics; Artificial intelligence; Data mining; Mathematics; Linguistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2109.09061",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3107756945",
      "doi": "10.48550/arxiv.2011.14906",
      "title": "Person Perception Biases Exposed: Revisiting the First Impressions Dataset",
      "abstract": "This work revisits the ChaLearn First Impressions database, annotated for personality perception using pairwise comparisons via crowdsourcing. We analyse for the first time the original pairwise annotations, and reveal existing person perception biases associated to perceived attributes like gender, ethnicity, age and face attractiveness. We show how person perception bias can influence data labelling of a subjective task, which has received little attention from the computer vision and machine learning communities by now. We further show that the mechanism used to convert pairwise annotations to continuous values may magnify the biases if no special treatment is considered. The findings of this study are relevant for the computer vision community that is still creating new datasets on subjective tasks, and using them for practical applications, ignoring these perceptual biases.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Julio C. S. Jacques et al.",
      "keywords": "Pairwise comparison; Crowdsourcing; Perception; Computer science; Attractiveness; Task (project management); Artificial intelligence; Face (sociological concept); Personality; Face perception; Rubric; Cognitive psychology; Psychology; Machine learning; Social psychology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2011.14906",
      "cited_by_count": 2,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4287815023",
      "doi": "",
      "title": "Bias in Multimodal AI: Testbed for Fair Automatic Recruitment",
      "abstract": "The presence of decision-making algorithms in society is rapidly increasing nowadays, while concerns about their transparency and the possibility of these algorithms becoming new sources of discrimination are arising. In fact, many relevant automated systems have been shown to make decisions based on sensitive information or discriminate certain social groups (e.g. certain biometric systems for person recognition). With the aim of studying how current multimodal algorithms based on heterogeneous sources of information are affected by sensitive elements and inner biases in the data, we propose a fictitious automated recruitment testbed: FairCVtest. We train automatic recruitment algorithms using a set of multimodal synthetic profiles consciously scored with gender and racial biases. FairCVtest shows the capacity of the Artificial Intelligence (AI) behind such recruitment tool to extract sensitive information from unstructured data, and exploit it in combination to data biases in undesirable (unfair) ways. Finally, we present a list of recent works developing techniques capable of removing sensitive information from the decision-making process of deep learning architectures. We have used one of these algorithms (SensitiveNets) to experiment discrimination-aware learning for the elimination of sensitive information in our multimodal AI framework. Our methodology and results show how to generate fairer AI-based tools in general, and in particular fairer automated recruitment systems.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Alejandro Pe\u00f1a et al.",
      "keywords": "Testbed; Exploit; Computer science; Artificial intelligence; Machine learning; Process (computing); Biometrics; Transparency (behavior); Computer security; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://openalex.org/W4287815023",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4384390308",
      "doi": "10.48550/arxiv.2307.06751",
      "title": "Watch Where You Head: A View-biased Domain Gap in Gait Recognition and Unsupervised Adaptation",
      "abstract": "Gait Recognition is a computer vision task aiming to identify people by their walking patterns. Although existing methods often show high performance on specific datasets, they lack the ability to generalize to unseen scenarios. Unsupervised Domain Adaptation (UDA) tries to adapt a model, pre-trained in a supervised manner on a source domain, to an unlabelled target domain. There are only a few works on UDA for gait recognition proposing solutions to limited scenarios. In this paper, we reveal a fundamental phenomenon in adaptation of gait recognition models, caused by the bias in the target domain to viewing angle or walking direction. We then suggest a remedy to reduce this bias with a novel triplet selection strategy combined with curriculum learning. To this end, we present Gait Orientation-based method for Unsupervised Domain Adaptation (GOUDA). We provide extensive experiments on four widely-used gait datasets, CASIA-B, OU-MVLP, GREW, and Gait3D, and on three backbones, GaitSet, GaitPart, and GaitGL, justifying the view bias and showing the superiority of our proposed method over prior UDA works.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Gavriel Habib et al.",
      "keywords": "Gait; Computer science; Adaptation (eye); Domain (mathematical analysis); Artificial intelligence; Task (project management); Domain adaptation; Orientation (vector space); Machine learning; Pattern recognition (psychology); Selection (genetic algorithm); Computer vision; Psychology; Physical medicine and rehabilitation; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.06751",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4286588309",
      "doi": "10.48550/arxiv.2207.10020",
      "title": "MANI-Rank: Multiple Attribute and Intersectional Group Fairness for Consensus Ranking",
      "abstract": "Combining the preferences of many rankers into one single consensus ranking is critical for consequential applications from hiring and admissions to lending. While group fairness has been extensively studied for classification, group fairness in rankings and in particular rank aggregation remains in its infancy. Recent work introduced the concept of fair rank aggregation for combining rankings but restricted to the case when candidates have a single binary protected attribute, i.e., they fall into two groups only. Yet it remains an open problem how to create a consensus ranking that represents the preferences of all rankers while ensuring fair treatment for candidates with multiple protected attributes such as gender, race, and nationality. In this work, we are the first to define and solve this open Multi-attribute Fair Consensus Ranking (MFCR) problem. As a foundation, we design novel group fairness criteria for rankings, called MANI-RANK, ensuring fair treatment of groups defined by individual protected attributes and their intersection. Leveraging the MANI-RANK criteria, we develop a series of algorithms that for the first time tackle the MFCR problem. Our experimental study with a rich variety of consensus scenarios demonstrates our MFCR methodology is the only approach to achieve both intersectional and protected attribute fairness while also representing the preferences expressed through many base rankings. Our real-world case study on merit scholarships illustrates the effectiveness of our MFCR methods to mitigate bias across multiple protected attributes and their intersections. This is an extended version of \"MANI-Rank: Multiple Attribute and Intersectional Group Fairness for Consensus Ranking\", to appear in ICDE 2022.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Kathleen Cachel et al.",
      "keywords": "Ranking (information retrieval); Rank (graph theory); Intersection (aeronautics); Computer science; Variety (cybernetics); Group (periodic table); Aggregation problem; Machine learning; Mathematics; Artificial intelligence; Mathematical economics; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2207.10020",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4405903431",
      "doi": "10.48550/arxiv.2412.19654",
      "title": "Asymmetrical Reciprocity-based Federated Learning for Resolving Disparities in Medical Diagnosis",
      "abstract": "Geographic health disparities pose a pressing global challenge, particularly in underserved regions of low- and middle-income nations. Addressing this issue requires a collaborative approach to enhance healthcare quality, leveraging support from medically more developed areas. Federated learning emerges as a promising tool for this purpose. However, the scarcity of medical data and limited computation resources in underserved regions make collaborative training of powerful machine learning models challenging. Furthermore, there exists an asymmetrical reciprocity between underserved and developed regions. To overcome these challenges, we propose a novel cross-silo federated learning framework, named FedHelp, aimed at alleviating geographic health disparities and fortifying the diagnostic capabilities of underserved regions. Specifically, FedHelp leverages foundational model knowledge via one-time API access to guide the learning process of underserved small clients, addressing the challenge of insufficient data. Additionally, we introduce a novel asymmetric dual knowledge distillation module to manage the issue of asymmetric reciprocity, facilitating the exchange of necessary knowledge between developed large clients and underserved small clients. We validate the effectiveness and utility of FedHelp through extensive experiments on both medical image classification and segmentation tasks. The experimental results demonstrate significant performance improvement compared to state-of-the-art baselines, particularly benefiting clients in underserved regions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiaqi Wang et al.",
      "keywords": "Reciprocity (cultural anthropology); Federated learning; Computer science; Psychology; Artificial intelligence; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.19654",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4312072635",
      "doi": "10.48550/arxiv.1910.08520",
      "title": "Optimization Hierarchy for Fair Statistical Decision Problems",
      "abstract": "Data-driven decision-making has drawn scrutiny from policy makers due to fears of potential discrimination, and a growing literature has begun to develop fair statistical techniques. However, these techniques are often specialized to one model context and based on ad-hoc arguments, which makes it difficult to perform theoretical analysis. This paper develops an optimization hierarchy, which is a sequence of optimization problems with an increasing number of constraints, for fair statistical decision problems. Because our hierarchy is based on the framework of statistical decision problems, this means it provides a systematic approach for developing and studying fair versions of hypothesis testing, decision-making, estimation, regression, and classification. We use the insight that qualitative definitions of fairness are equivalent to statistical independence between the output of a statistical technique and a random variable that measures attributes for which fairness is desired. We use this insight to construct an optimization hierarchy that lends itself to numerical computation, and we use tools from variational analysis and random set theory to prove that higher levels of this hierarchy lead to consistency in the sense that it asymptotically imposes this independence as a constraint in corresponding statistical decision problems. We demonstrate numerical effectiveness of our hierarchy using several data sets, and we use our hierarchy to fairly perform automated dosing of morphine.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Anil Aswani et al.",
      "keywords": "Hierarchy; Computer science; Context (archaeology); Mathematical optimization; Statistical model; Mathematics; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1910.08520",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4288253537",
      "doi": "10.48550/arxiv.1908.10414",
      "title": "Artificial Intelligence Fairness in the Context of Accessibility\\n Research on Intelligent Systems for People who are Deaf or Hard of Hearing",
      "abstract": "We discuss issues of Artificial Intelligence (AI) fairness for people with\\ndisabilities, with examples drawn from our research on human-computer\\ninteraction (HCI) for AI-based systems for people who are Deaf or Hard of\\nHearing (DHH). In particular, we discuss the need for inclusion of data from\\npeople with disabilities in training sets, the lack of interpretability of AI\\nsystems, ethical responsibilities of access technology researchers and\\ncompanies, the need for appropriate evaluation metrics for AI-based access\\ntechnologies (to determine if they are ready to be deployed and if they can be\\ntrusted by users), and the ways in which AI systems influence human behavior\\nand influence the set of abilities needed by users to successfully interact\\nwith computing systems.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Sushant Kafle et al.",
      "keywords": "Interpretability; Computer science; Set (abstract data type); Inclusion (mineral); Context (archaeology); Human\u2013computer interaction; Universal design; Knowledge management; Artificial intelligence; World Wide Web; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1908.10414",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4380715587",
      "doi": "10.48550/arxiv.2306.07957",
      "title": "Hidden Biases of End-to-End Driving Models",
      "abstract": "End-to-end driving systems have recently made rapid progress, in particular on CARLA. Independent of their major contribution, they introduce changes to minor system components. Consequently, the source of improvements is unclear. We identify two biases that recur in nearly all state-of-the-art methods and are critical for the observed progress on CARLA: (1) lateral recovery via a strong inductive bias towards target point following, and (2) longitudinal averaging of multimodal waypoint predictions for slowing down. We investigate the drawbacks of these biases and identify principled alternatives. By incorporating our insights, we develop TF++, a simple end-to-end method that ranks first on the Longest6 and LAV benchmarks, gaining 11 driving score over the best prior work on Longest6.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Bernhard Jaeger et al.",
      "keywords": "End-to-end principle; Waypoint; Computer science; End point; Simple (philosophy); Point (geometry); Artificial intelligence; Machine learning; Real-time computing; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.07957",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399353867",
      "doi": "10.48550/arxiv.2406.00020",
      "title": "Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias",
      "abstract": "Content moderation on social media platforms shapes the dynamics of online discourse, influencing whose voices are amplified and whose are suppressed. Recent studies have raised concerns about the fairness of content moderation practices, particularly for aggressively flagging posts from transgender and non-binary individuals as toxic. In this study, we investigate the presence of bias in harmful speech classification of gender-queer dialect online, focusing specifically on the treatment of reclaimed slurs. We introduce a novel dataset, QueerReclaimLex, based on 109 curated templates exemplifying non-derogatory uses of LGBTQ+ slurs. Dataset instances are scored by gender-queer annotators for potential harm depending on additional context about speaker identity. We systematically evaluate the performance of five off-the-shelf language models in assessing the harm of these texts and explore the effectiveness of chain-of-thought prompting to teach large language models (LLMs) to leverage author identity context. We reveal a tendency for these models to inaccurately flag texts authored by gender-queer individuals as harmful. Strikingly, across all LLMs the performance is poorest for texts that show signs of being written by individuals targeted by the featured slur (F1 &lt;= 0.24). We highlight an urgent need for fairness and inclusivity in content moderation systems. By uncovering these biases, this work aims to inform the development of more equitable content moderation practices and contribute to the creation of inclusive online spaces for all users.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Rebecca Dorn et al.",
      "keywords": "Queer; Linguistics; Computer science; Psychology; Sociology; Speech recognition; Gender studies; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.00020",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W3209530451",
      "doi": "10.48550/arxiv.2110.15310",
      "title": "On the Fairness of Machine-Assisted Human Decisions",
      "abstract": "When machine-learning algorithms are used in high-stakes decisions, we want to ensure that their deployment leads to fair and equitable outcomes. This concern has motivated a fast-growing literature that focuses on diagnosing and addressing disparities in machine predictions. However, many machine predictions are deployed to assist in decisions where a human decision-maker retains the ultimate decision authority. In this article, we therefore consider in a formal model and in a lab experiment how properties of machine predictions affect the resulting human decisions. In our formal model of statistical decision-making, we show that the inclusion of a biased human decision-maker can revert common relationships between the structure of the algorithm and the qualities of resulting decisions. Specifically, we document that excluding information about protected groups from the prediction may fail to reduce, and may even increase, ultimate disparities. In the lab experiment, we demonstrate how predictions informed by gender-specific information can reduce average gender disparities in decisions. While our concrete theoretical results rely on specific assumptions about the data, algorithm, and decision-maker, and the experiment focuses on a particular prediction task, our findings show more broadly that any study of critical properties of complex decision systems, such as the fairness of machine-assisted human decisions, should go beyond focusing on the underlying algorithmic predictions in isolation.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Talia B. Gillis et al.",
      "keywords": "Computer science; Software deployment; Decision maker; Machine learning; Artificial intelligence; Human\u2013machine system; Isolation (microbiology); Inclusion (mineral); Operations research; Risk analysis (engineering); Business; Psychology; Software engineering; Engineering; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.15310",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4400484940",
      "doi": "10.48550/arxiv.2407.06003",
      "title": "Surprising gender biases in GPT",
      "abstract": "We present seven experiments exploring gender biases in GPT. Initially, GPT was asked to generate demographics of a potential writer of twenty phrases containing feminine stereotypes and twenty with masculine stereotypes. Results show a strong asymmetry, with stereotypically masculine sentences attributed to a female more often than vice versa. For example, the sentence \"I love playing fotbal! Im practicing with my cosin Michael\" was constantly assigned by ChatGPT to a female writer. This phenomenon likely reflects that while initiatives to integrate women in traditionally masculine roles have gained momentum, the reverse movement remains relatively underdeveloped. Subsequent experiments investigate the same issue in high-stakes moral dilemmas. GPT-4 finds it more appropriate to abuse a man to prevent a nuclear apocalypse than to abuse a woman. This bias extends to other forms of violence central to the gender parity debate (abuse), but not to those less central (torture). Moreover, this bias increases in cases of mixed-sex violence for the greater good: GPT-4 agrees with a woman using violence against a man to prevent a nuclear apocalypse but disagrees with a man using violence against a woman for the same purpose. Finally, these biases are implicit, as they do not emerge when GPT-4 is directly asked to rank moral violations. These results highlight the necessity of carefully managing inclusivity efforts to prevent unintended discrimination.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Raluca Alexandra Fulgu et al.",
      "keywords": "Psychology; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.06003",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4404340912",
      "doi": "10.48550/arxiv.2410.21495",
      "title": "RoBIn: A Transformer-Based Model For Risk Of Bias Inference With Machine Reading Comprehension",
      "abstract": "Objective: Scientific publications play a crucial role in uncovering insights, testing novel drugs, and shaping healthcare policies. Accessing the quality of publications requires evaluating their Risk of Bias (RoB), a process typically conducted by human reviewers. In this study, we introduce a new dataset for machine reading comprehension and RoB assessment and present RoBIn (Risk of Bias Inference), an innovative model crafted to automate such evaluation. The model employs a dual-task approach, extracting evidence from a given context and assessing the RoB based on the gathered evidence. Methods: We use data from the Cochrane Database of Systematic Reviews (CDSR) as ground truth to label open-access clinical trial publications from PubMed. This process enabled us to develop training and test datasets specifically for machine reading comprehension and RoB inference. Additionally, we created extractive (RoBInExt) and generative (RoBInGen) Transformer-based approaches to extract relevant evidence and classify the RoB effectively. Results: RoBIn is evaluated across various settings and benchmarked against state-of-the-art methods for RoB inference, including large language models in multiple scenarios. In most cases, the best-performing RoBIn variant surpasses traditional machine learning and LLM-based approaches, achieving an ROC AUC of 0.83. Conclusion: Based on the evidence extracted from clinical trial reports, RoBIn performs a binary classification to decide whether the trial is at a low RoB or a high/unclear RoB. We found that both RoBInGen and RoBInExt are robust and have the best results in many settings.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Abel Corr\u00eaa Dias et al.",
      "keywords": "Transformer; Inference; Computer science; Comprehension; Reading comprehension; Artificial intelligence; Reading (process); Machine learning; Engineering; Linguistics; Programming language; Electrical engineering; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.21495",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4417313621",
      "doi": "10.48550/arxiv.2502.07794",
      "title": "Regulatory Science Innovation for Generative AI and Large Language Models in Health and Medicine: A Global Call for Action",
      "abstract": "The integration of generative AI (GenAI) and large language models (LLMs) in healthcare presents both unprecedented opportunities and challenges, necessitating innovative regulatory approaches. GenAI and LLMs offer broad applications, from automating clinical workflows to personalizing diagnostics. However, the non-deterministic outputs, broad functionalities and complex integration of GenAI and LLMs challenge existing medical device regulatory frameworks, including the total product life cycle (TPLC) approach. Here we discuss the constraints of the TPLC approach to GenAI and LLM-based medical device regulation, and advocate for global collaboration in regulatory science research. This serves as the foundation for developing innovative approaches including adaptive policies and regulatory sandboxes, to test and refine governance in real-world settings. International harmonization, as seen with the International Medical Device Regulators Forum, is essential to manage implications of LLM on global health, including risks of widening health inequities driven by inherent model biases. By engaging multidisciplinary expertise, prioritizing iterative, data-driven approaches, and focusing on the needs of diverse populations, global regulatory science research enables the responsible and equitable advancement of LLM innovations in healthcare.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Jasmine Chiat Ling Ong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2502.07794",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4417123792",
      "doi": "10.48550/arxiv.2510.09162",
      "title": "Dr. Bias: Social Disparities in AI-Powered Medical Guidance",
      "abstract": "With the rapid progress of Large Language Models (LLMs), the general public now has easy and affordable access to applications capable of answering most health-related questions in a personalized manner. These LLMs are increasingly proving to be competitive, and now even surpass professionals in some medical capabilities. They hold particular promise in low-resource settings, considering they provide the possibility of widely accessible, quasi-free healthcare support. However, evaluations that fuel these motivations highly lack insights into the social nature of healthcare, oblivious to health disparities between social groups and to how bias may translate into LLM-generated medical advice and impact users. We provide an exploratory analysis of LLM answers to a series of medical questions spanning key clinical domains, where we simulate these questions being asked by several patient profiles that vary in sex, age range, and ethnicity. By comparing natural language features of the generated responses, we show that, when LLMs are used for medical advice generation, they generate responses that systematically differ between social groups. In particular, Indigenous and intersex patients receive advice that is less readable and more complex. We observe these trends amplify when intersectional groups are considered. Considering the increasing trust individuals place in these models, we argue for higher AI literacy and for the urgent need for investigation and mitigation by AI developers to ensure these systemic differences are diminished and do not translate to unjust patient support. Our code is publicly available on GitHub.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Emma Kondrup et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2510.09162",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4294753117",
      "doi": "10.48550/arxiv.2209.00858",
      "title": "A Discussion of Discrimination and Fairness in Insurance Pricing",
      "abstract": "Indirect discrimination is an issue of major concern in algorithmic models. This is particularly the case in insurance pricing where protected policyholder characteristics are not allowed to be used for insurance pricing. Simply disregarding protected policyholder information is not an appropriate solution because this still allows for the possibility of inferring the protected characteristics from the non-protected ones. This leads to so-called proxy or indirect discrimination. Though proxy discrimination is qualitatively different from the group fairness concepts in machine learning, these group fairness concepts are proposed to 'smooth out' the impact of protected characteristics in the calculation of insurance prices. The purpose of this note is to share some thoughts about group fairness concepts in the light of insurance pricing and to discuss their implications. We present a statistical model that is free of proxy discrimination, thus, unproblematic from an insurance pricing point of view. However, we find that the canonical price in this statistical model does not satisfy any of the three most popular group fairness axioms. This seems puzzling and we welcome feedback on our example and on the usefulness of these group fairness axioms for non-discriminatory insurance pricing.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Mathias Lindholm et al.",
      "keywords": "Axiom; Proxy (statistics); Actuarial science; Point (geometry); Group (periodic table); Economics; Mathematical economics; Computer science; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.00858",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W2344877013",
      "doi": "10.48550/arxiv.1604.07180",
      "title": "Observing and Recommending from a Social Web with Biases",
      "abstract": "The research question this report addresses is: how, and to what extent, those directly involved with the design, development and employment of a specific black box algorithm can be certain that it is not unlawfully discriminating (directly and/or indirectly) against particular persons with protected characteristics (e.g. gender, race and ethnicity)?",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Steffen Staab et al.",
      "keywords": "Ethnic group; Race (biology); Black box; World Wide Web; Computer science; Internet privacy; Social psychology; Psychology; Data science; Information retrieval; Political science; Sociology; Gender studies; Artificial intelligence; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1604.07180",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4287080082",
      "doi": "10.48550/arxiv.2107.05704",
      "title": "How Could Equality and Data Protection Law Shape AI Fairness for People\\n with Disabilities?",
      "abstract": "This article examines the concept of 'AI fairness' for people with\\ndisabilities from the perspective of data protection and equality law. This\\nexamination demonstrates that there is a need for a distinctive approach to AI\\nfairness that is fundamentally different to that used for other protected\\ncharacteristics, due to the different ways in which discrimination and data\\nprotection law applies in respect of Disability. We articulate this new agenda\\nfor AI fairness for people with disabilities, explaining how combining data\\nprotection and equality law creates new opportunities for disabled people's\\norganisations and assistive technology researchers alike to shape the use of\\nAI, as well as to challenge potential harmful uses.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Reuben Binns et al.",
      "keywords": "Perspective (graphical); Data Protection Act 1998; Law and economics; Political science; Sociology; Law; Psychology; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2107.05704",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392822317",
      "doi": "10.48550/arxiv.2403.08115",
      "title": "Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies",
      "abstract": "Privacy policies are expected to inform data subjects about their data protection rights and should explain the data controller's data management practices. Privacy policies only fulfill their purpose, if they are correctly interpreted, understood, and trusted by the data subject. This implies that a privacy policy is written in a fair way, e.g., it does not use polarizing terms, does not require a certain education, or does not assume a particular social background. We outline our approach to assessing fairness in privacy policies. We identify from fundamental legal sources and fairness research, how the dimensions informational fairness, representational fairness and ethics / morality are related to privacy policies. We propose options to automatically assess policies in these fairness dimensions, based on text statistics, linguistic methods and artificial intelligence. We conduct initial experiments with German privacy policies to provide evidence that our approach is applicable. Our experiments indicate that there are issues in all three dimensions of fairness. This is important, as future privacy policies may be used in a corpus for legal artificial intelligence models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Vincent Freiberger et al.",
      "keywords": "Internet privacy; Business; Privacy policy; Privacy rights; Computer security; Information privacy; Law and economics; Computer science; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.08115",
      "cited_by_count": 0,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    }
  ],
  "ta_excluded": [
    {
      "openalex_id": "https://openalex.org/W4383605161",
      "doi": "10.48550/arxiv.2307.03109",
      "title": "A Survey on Evaluation of Large Language Models",
      "abstract": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yupeng Chang et al.",
      "keywords": "Popularity; Engineering ethics; Psychology; Engineering; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.03109",
      "cited_by_count": 193,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288076238",
      "doi": "10.1145/3442188.3445881",
      "title": "Leveraging Administrative Data for Bias Audits: Assessing Disparate Coverage with Mobility Data for COVID-19 Policy",
      "abstract": "Anonymized smartphone-based mobility data has been widely adopted in devising and evaluating COVID-19 response strategies such as the targeting of public health resources. Yet little attention has been paid to measurement validity and demographic bias, due in part to the lack of documentation about which users are represented as well as the challenge of obtaining ground truth data on unique visits and demographics. We illustrate how linking large-scale administrative data can enable auditing mobility data for bias in the absence of demographic information and ground truth labels. More precisely, we show that linking voter roll data -- containing individual-level voter turnout for specific voting locations along with race and age -- can facilitate the construction of rigorous bias and reliability tests. These tests illuminate a sampling bias that is particularly noteworthy in the pandemic context: older and non-white voters are less likely to be captured by mobility data. We show that allocating public health resources based on such mobility data could disproportionately harm high-risk elderly and minority groups.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Amanda Coston et al.",
      "keywords": "Audit; Computer science; Accounting; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3442188.3445881",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2778434186",
      "doi": "10.48550/arxiv.1712.08238",
      "title": "Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment",
      "abstract": "Actuarial risk assessments might be unduly perceived as a neutral way to counteract implicit bias and increase the fairness of decisions made at almost every juncture of the criminal justice system, from pretrial release to sentencing, parole and probation. In recent times these assessments have come under increased scrutiny, as critics claim that the statistical techniques underlying them might reproduce existing patterns of discrimination and historical biases that are reflected in the data. Much of this debate is centered around competing notions of fairness and predictive accuracy, resting on the contested use of variables that act as \"proxies\" for characteristics legally protected against discrimination, such as race and gender. We argue that a core ethical debate surrounding the use of regression in risk assessments is not simply one of bias or accuracy. Rather, it's one of purpose. If machine learning is operationalized merely in the service of predicting individual future crime, then it becomes difficult to break cycles of criminalization that are driven by the iatrogenic effects of the criminal justice system itself. We posit that machine learning should not be used for prediction, but rather to surface covariates that are fed into a causal model for understanding the social, structural and psychological drivers of crime. We propose an alternative application of machine learning and causal inference away from predicting risk scores to risk mitigation.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Chelsea Barabas et al.",
      "keywords": "Cognitive reframing; Psychological intervention; Actuarial science; Risk assessment; Economics; Psychology; Political science; Public economics; Social psychology; Psychiatry; Management",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1712.08238",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391555522",
      "doi": "10.48550/arxiv.2402.00888",
      "title": "Security and Privacy Challenges of Large Language Models: A Survey",
      "abstract": "Large Language Models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Nowadays, LLM is becoming a very popular tool in computerized language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant and appropriate responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and Personally Identifiable Information (PII) leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs for both training data and users, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks for LLMs, and review the potential defense mechanisms. Additionally, the survey outlines existing research gaps in this domain and highlights future research directions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Badhan Chandra Das et al.",
      "keywords": "Internet privacy; Computer security; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.00888",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287775015",
      "doi": "10.48550/arxiv.2005.13249",
      "title": "CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and\\n Patients",
      "abstract": "The healthcare industry generates troves of unlabelled physiological data.\\nThis data can be exploited via contrastive learning, a self-supervised\\npre-training method that encourages representations of instances to be similar\\nto one another. We propose a family of contrastive learning methods, CLOCS,\\nthat encourages representations across space, time, \\\\textit{and} patients to be\\nsimilar to one another. We show that CLOCS consistently outperforms the\\nstate-of-the-art methods, BYOL and SimCLR, when performing a linear evaluation\\nof, and fine-tuning on, downstream tasks. We also show that CLOCS achieves\\nstrong generalization performance with only 25\\\\% of labelled training data.\\nFurthermore, our training procedure naturally generates patient-specific\\nrepresentations that can be used to quantify patient-similarity.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Dani Kiyasseh et al.",
      "keywords": "Generalization; Similarity (geometry); Space (punctuation); Computer science; Artificial intelligence; Training set; Machine learning; Natural language processing; Mathematics; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2005.13249",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4200630839",
      "doi": "10.48550/arxiv.2112.06459",
      "title": "Machine Learning-Based Heart Disease Diagnosis: A Systematic Literature Review",
      "abstract": "Heart disease is one of the significant challenges in today's world and one of the leading causes of many deaths worldwide. Recent advancement of machine learning (ML) application demonstrates that using electrocardiogram (ECG) and patient data, detecting heart disease during the early stage is feasible. However, both ECG and patient data are often imbalanced, which ultimately raises a challenge for the traditional ML to perform unbiasedly. Over the years, several data level and algorithm level solutions have been exposed by many researchers and practitioners. To provide a broader view of the existing literature, this study takes a systematic literature review (SLR) approach to uncover the challenges associated with imbalanced data in heart diseases predictions. Before that, we conducted a meta-analysis using 451 referenced literature acquired from the reputed journals between 2012 and November 15, 2021. For in-depth analysis, 49 referenced literature has been considered and studied, taking into account the following factors: heart disease type, algorithms, applications, and solutions. Our SLR study revealed that the current approaches encounter various open problems/issues when dealing with imbalanced data, eventually hindering their practical applicability and functionality.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Md Manjurul Ahsan et al.",
      "keywords": "Systematic review; Heart disease; Computer science; Disease; Machine learning; Artificial intelligence; Data science; Intensive care medicine; MEDLINE; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.06459",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4311559656",
      "doi": "10.48550/arxiv.2212.06823",
      "title": "Explanations Can Reduce Overreliance on AI Systems During Decision-Making",
      "abstract": "Prior work has identified a resilient phenomenon that threatens the performance of human-AI decision-making teams: overreliance, when people agree with an AI, even when it is incorrect. Surprisingly, overreliance does not reduce when the AI produces explanations for its predictions, compared to only providing predictions. Some have argued that overreliance results from cognitive biases or uncalibrated trust, attributing overreliance to an inevitability of human cognition. By contrast, our paper argues that people strategically choose whether or not to engage with an AI explanation, demonstrating empirically that there are scenarios where AI explanations reduce overreliance. To achieve this, we formalize this strategic choice in a cost-benefit framework, where the costs and benefits of engaging with the task are weighed against the costs and benefits of relying on the AI. We manipulate the costs and benefits in a maze task, where participants collaborate with a simulated AI to find the exit of a maze. Through 5 studies (N = 731), we find that costs such as task difficulty (Study 1), explanation difficulty (Study 2, 3), and benefits such as monetary compensation (Study 4) affect overreliance. Finally, Study 5 adapts the Cognitive Effort Discounting paradigm to quantify the utility of different explanations, providing further support for our framework. Our results suggest that some of the null effects found in literature could be due in part to the explanation not sufficiently reducing the costs of verifying the AI's prediction.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Helena Vasconcelos et al.",
      "keywords": "Task (project management); Cognition; Temporal discounting; Discounting; Affect (linguistics); Risk analysis (engineering); Cognitive psychology; Psychology; Computer science; Economics; Business; Management",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.06823",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4385001873",
      "doi": "10.48550/arxiv.2307.10616",
      "title": "Heterogeneous Federated Learning: State-of-the-art and Research Challenges",
      "abstract": "Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications. Existing federated learning works mainly focus on model homogeneous settings. However, practical federated learning typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients. Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex. Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential. In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges. In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons. We classify existing methods from three different levels according to the HFL procedure: data-level, model-level, and server-level. Finally, several critical and promising future research directions in HFL are discussed, which may facilitate further developments in this field. A periodically updated collection on HFL is available at https://github.com/marswhu/HFL_Survey.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Mang Ye et al.",
      "keywords": "Computer science; Homogeneous; Federated learning; Data science; Field (mathematics); Scale (ratio); Data collection; State (computer science); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.10616",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4293824115",
      "doi": "10.48550/arxiv.2208.13501",
      "title": "When Internet of Things meets Metaverse: Convergence of Physical and Cyber Worlds",
      "abstract": "In recent years, the Internet of Things (IoT) is studied in the context of the Metaverse to provide users immersive cyber-virtual experiences in mixed reality environments. This survey introduces six typical IoT applications in the Metaverse, including collaborative healthcare, education, smart city, entertainment, real estate, and socialization. In the IoT-inspired Metaverse, we also comprehensively survey four pillar technologies that enable augmented reality (AR) and virtual reality (VR), namely, responsible artificial intelligence (AI), high-speed data communications, cost-effective mobile edge computing (MEC), and digital twins. According to the physical-world demands, we outline the current industrial efforts and seven key requirements for building the IoT-inspired Metaverse: immersion, variety, economy, civility, interactivity, authenticity, and independence. In addition, this survey describes the open issues in the IoT-inspired Metaverse, which need to be addressed to eventually achieve the convergence of physical and cyber worlds.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Kai Li et al.",
      "keywords": "Metaverse; Computer science; Interactivity; Augmented reality; Context (archaeology); Internet of Things; Virtual reality; Variety (cybernetics); Human\u2013computer interaction; World Wide Web; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.13501",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3121574534",
      "doi": "10.17863/cam.70020",
      "title": "Clairvoyance: A Pipeline Toolkit for Medical Time Series",
      "abstract": "Time-series learning is the bread and butter of data-driven *clinical decision support*, and the recent explosion in ML research has demonstrated great potential in various healthcare settings. At the same time, medical time-series problems in the wild are challenging due to their highly *composite* nature: They entail design choices and interactions among components that preprocess data, impute missing values, select features, issue predictions, estimate uncertainty, and interpret models. Despite exponential growth in electronic patient data, there is a remarkable gap between the potential and realized utilization of ML for clinical research and decision support. In particular, orchestrating a real-world project lifecycle poses challenges in engineering (i.e. hard to build), evaluation (i.e. hard to assess), and efficiency (i.e. hard to optimize). Designed to address these issues simultaneously, Clairvoyance proposes a unified, end-to-end, autoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical standard, and (iii) interface for optimization. Our ultimate goal lies in facilitating transparent and reproducible experimentation with complex inference workflows, providing integrated pathways for (1) personalized prediction, (2) treatment-effect estimation, and (3) information acquisition. Through illustrative examples on real-world data in outpatient, general wards, and intensive-care settings, we illustrate the applicability of the pipeline paradigm on core tasks in the healthcare journey. To the best of our knowledge, Clairvoyance is the first to demonstrate viability of a comprehensive and automatable pipeline for clinical time-series ML.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Daniel Jarrett et al.",
      "keywords": "Pipeline (software); Computer science; Workflow; Inference; Data science; Time series; Software; Data mining; Machine learning; Artificial intelligence; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.17863/cam.70020",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288043212",
      "doi": "10.48550/arxiv.2207.10991",
      "title": "Algorithmic Fairness in Business Analytics: Directions for Research and Practice",
      "abstract": "The extensive adoption of business analytics (BA) has brought financial gains and increased efficiencies. However, these advances have simultaneously drawn attention to rising legal and ethical challenges when BA inform decisions with fairness implications. As a response to these concerns, the emerging study of algorithmic fairness deals with algorithmic outputs that may result in disparate outcomes or other forms of injustices for subgroups of the population, especially those who have been historically marginalized. Fairness is relevant on the basis of legal compliance, social responsibility, and utility; if not adequately and systematically addressed, unfair BA systems may lead to societal harms and may also threaten an organization's own survival, its competitiveness, and overall performance. This paper offers a forward-looking, BA-focused review of algorithmic fairness. We first review the state-of-the-art research on sources and measures of bias, as well as bias mitigation algorithms. We then provide a detailed discussion of the utility-fairness relationship, emphasizing that the frequent assumption of a trade-off between these two constructs is often mistaken or short-sighted. Finally, we chart a path forward by identifying opportunities for business scholars to address impactful, open challenges that are key to the effective and responsible deployment of BA.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Maria De\u2010Arteaga et al.",
      "keywords": "Analytics; Software deployment; Key (lock); Population; Computer science; Management science; Business; Data science; Economics; Sociology; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2207.10991",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4379474637",
      "doi": "10.48550/arxiv.2306.01603",
      "title": "Decentralized Federated Learning: A Survey and Perspective",
      "abstract": "Federated learning (FL) has been gaining attention for its ability to share knowledge while maintaining user data, protecting privacy, increasing learning efficiency, and reducing communication overhead. Decentralized FL (DFL) is a decentralized network architecture that eliminates the need for a central server in contrast to centralized FL (CFL). DFL enables direct communication between clients, resulting in significant savings in communication resources. In this paper, a comprehensive survey and profound perspective are provided for DFL. First, a review of the methodology, challenges, and variants of CFL is conducted, laying the background of DFL. Then, a systematic and detailed perspective on DFL is introduced, including iteration order, communication protocols, network topologies, paradigm proposals, and temporal variability. Next, based on the definition of DFL, several extended variants and categorizations are proposed with state-of-the-art (SOTA) technologies. Lastly, in addition to summarizing the current challenges in the DFL, some possible solutions and future research directions are also discussed.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Liangqi Yuan et al.",
      "keywords": "Overhead (engineering); Computer science; Perspective (graphical); Federated learning; Network topology; Order (exchange); State (computer science); Telecommunications network; Distributed computing; Data science; Telecommunications; Artificial intelligence; Computer network; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.01603",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287204861",
      "doi": "10.48550/arxiv.2104.09957",
      "title": "Evaluating Deep Neural Networks Trained on Clinical Images in\\n Dermatology with the Fitzpatrick 17k Dataset",
      "abstract": "How does the accuracy of deep neural network models trained to classify\\nclinical images of skin conditions vary across skin color? While recent studies\\ndemonstrate computer vision models can serve as a useful decision support tool\\nin healthcare and provide dermatologist-level classification on a number of\\nspecific tasks, darker skin is underrepresented in the data. Most publicly\\navailable data sets do not include Fitzpatrick skin type labels. We annotate\\n16,577 clinical images sourced from two dermatology atlases with Fitzpatrick\\nskin type labels and open-source these annotations. Based on these labels, we\\nfind that there are significantly more images of light skin types than dark\\nskin types in this dataset. We train a deep neural network model to classify\\n114 skin conditions and find that the model is most accurate on skin types\\nsimilar to those it was trained on. In addition, we evaluate how an algorithmic\\napproach to identifying skin tones, individual typology angle, compares with\\nFitzpatrick skin type labels annotated by a team of human labelers.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Matthew Groh et al.",
      "keywords": "Artificial intelligence; Computer science; Artificial neural network; Skin type; Deep learning; Deep neural networks; Pattern recognition (psychology); Skin lesion; Clinical Practice; Machine learning; Dermatology; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2104.09957",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295539003",
      "doi": "10.48550/arxiv.1811.11839",
      "title": "A Multidisciplinary Survey and Framework for Design and Evaluation of\\n Explainable AI Systems",
      "abstract": "The need for interpretable and accountable intelligent systems grows along\\nwith the prevalence of artificial intelligence applications used in everyday\\nlife. Explainable intelligent systems are designed to self-explain the\\nreasoning behind system decisions and predictions, and researchers from\\ndifferent disciplines work together to define, design, and evaluate\\ninterpretable systems. However, scholars from different disciplines focus on\\ndifferent objectives and fairly independent topics of interpretable machine\\nlearning research, which poses challenges for identifying appropriate design\\nand evaluation methodology and consolidating knowledge across efforts. To this\\nend, this paper presents a survey and framework intended to share knowledge and\\nexperiences of XAI design and evaluation methods across multiple disciplines.\\nAiming to support diverse design goals and evaluation methods in XAI research,\\nafter a thorough review of XAI related papers in the fields of machine\\nlearning, visualization, and human-computer interaction, we present a\\ncategorization of interpretable machine learning design goals and evaluation\\nmethods to show a mapping between design goals for different XAI user groups\\nand their evaluation methods. From our findings, we develop a framework with\\nstep-by-step design guidelines paired with evaluation methods to close the\\niterative design and evaluation cycles in multidisciplinary XAI teams. Further,\\nwe provide summarized ready-to-use tables of evaluation methods and\\nrecommendations for different goals in XAI research.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Sina Mohseni et al.",
      "keywords": "Multidisciplinary approach; Computer science; Categorization; Management science; Artificial intelligence; Knowledge management; Data science; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1811.11839",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4367189496",
      "doi": "10.48550/arxiv.2304.13081",
      "title": "Organizational Governance of Emerging Technologies: AI Adoption in Healthcare",
      "abstract": "Private and public sector structures and norms refine how emerging technology is used in practice. In healthcare, despite a proliferation of AI adoption, the organizational governance surrounding its use and integration is often poorly understood. What the Health AI Partnership (HAIP) aims to do in this research is to better define the requirements for adequate organizational governance of AI systems in healthcare settings and support health system leaders to make more informed decisions around AI adoption. To work towards this understanding, we first identify how the standards for the AI adoption in healthcare may be designed to be used easily and efficiently. Then, we map out the precise decision points involved in the practical institutional adoption of AI technology within specific health systems. Practically, we achieve this through a multi-organizational collaboration with leaders from major health systems across the United States and key informants from related fields. Working with the consultancy IDEO [dot] org, we were able to conduct usability-testing sessions with healthcare and AI ethics professionals. Usability analysis revealed a prototype structured around mock key decision points that align with how organizational leaders approach technology adoption. Concurrently, we conducted semi-structured interviews with 89 professionals in healthcare and other relevant fields. Using a modified grounded theory approach, we were able to identify 8 key decision points and comprehensive procedures throughout the AI adoption lifecycle. This is one of the most detailed qualitative analyses to date of the current governance structures and processes involved in AI adoption by health systems in the United States. We hope these findings can inform future efforts to build capabilities to promote the safe, effective, and responsible adoption of emerging technologies in healthcare.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jee Young Kim et al.",
      "keywords": "Usability; Health care; Knowledge management; Corporate governance; General partnership; Business; Public relations; Political science; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.13081",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4307206576",
      "doi": "10.48550/arxiv.2210.12007",
      "title": "Ethics for Digital Medicine: A Path for Ethical Emerging Medical IoT Design",
      "abstract": "The dawn of the digital medicine era, ushered in by increasingly powerful embedded systems and Internet of Things (IoT) computing devices, is creating new therapies and biomedical solutions that promise to positively transform our quality of life. However, the digital medicine revolution also creates unforeseen and complex ethical, regulatory, and societal issues. In this article, we reflect on the ethical challenges facing digital medicine. We discuss the perils of ethical oversights in medical devices, and the role of professional codes and regulatory oversight towards the ethical design, deployment, and operation of digital medicine devices that safely and effectively meet the needs of patients. We advocate for an ensemble approach of intensive education, programmable ethical behaviors, and ethical analysis frameworks, to prevent mishaps and sustain ethical innovation, design, and lifecycle management of emerging digital medicine devices.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Sudeep Pasricha",
      "keywords": "Engineering ethics; Digital Revolution; Software deployment; Ethical issues; Internet of Things; Business; Computer science; Engineering; Internet privacy; Telecommunications",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.12007",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2753780685",
      "doi": "10.48550/arxiv.1708.08994",
      "title": "Clustering Patients with Tensor Decomposition",
      "abstract": "In this paper we present a method for the unsupervised clustering of high-dimensional binary data, with a special focus on electronic healthcare records. We present a robust and efficient heuristic to face this problem using tensor decomposition. We present the reasons why this approach is preferable for tasks such as clustering patient records, to more commonly used distance-based methods. We run the algorithm on two datasets of healthcare records, obtaining clinically meaningful results.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Matteo Ruffini et al.",
      "keywords": "Cluster analysis; Computer science; Focus (optics); Heuristic; Tensor decomposition; Decomposition; Tensor (intrinsic definition); Health records; Face (sociological concept); Data mining; Artificial intelligence; Health care; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1708.08994",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309048392",
      "doi": "10.48550/arxiv.2211.06346",
      "title": "AI Ethics in Smart Healthcare",
      "abstract": "This article reviews the landscape of ethical challenges of integrating artificial intelligence (AI) into smart healthcare products, including medical electronic devices. Differences between traditional ethics in the medical domain and emerging ethical challenges with AI-driven healthcare are presented, particularly as they relate to transparency, bias, privacy, safety, responsibility, justice, and autonomy. Open challenges and recommendations are outlined to enable the integration of ethical principles into the design, validation, clinical trials, deployment, monitoring, repair, and retirement of AI-based smart healthcare products.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Sudeep Pasricha",
      "keywords": "Transparency (behavior); Autonomy; Health care; Software deployment; Economic Justice; Engineering ethics; Medical ethics; Business; Knowledge management; Computer science; Political science; Engineering; Computer security; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2211.06346",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287684786",
      "doi": "10.48550/arxiv.2008.11600",
      "title": "Estimating Example Difficulty Using Variance of Gradients",
      "abstract": "In machine learning, a question of great interest is understanding what examples are challenging for a model to classify. Identifying atypical examples ensures the safe deployment of models, isolates samples that require further human inspection and provides interpretability into model behavior. In this work, we propose Variance of Gradients (VoG) as a valuable and efficient metric to rank data by difficulty and to surface a tractable subset of the most challenging examples for human-in-the-loop auditing. We show that data points with high VoG scores are far more difficult for the model to learn and over-index on corrupted or memorized examples. Further, restricting the evaluation to the test set instances with the lowest VoG improves the model's generalization performance. Finally, we show that VoG is a valuable and efficient ranking for out-of-distribution detection.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Chirag Agarwal et al.",
      "keywords": "Interpretability; Generalization; Ranking (information retrieval); Variance (accounting); Computer science; Metric (unit); Rank (graph theory); Artificial intelligence; Set (abstract data type); Machine learning; Software deployment; Training set; Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2008.11600",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393213647",
      "doi": "10.48550/arxiv.2403.16812",
      "title": "Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making",
      "abstract": "In AI-assisted decision-making, humans often passively review AI's suggestion and decide whether to accept or reject it as a whole. In such a paradigm, humans are found to rarely trigger analytical thinking and face difficulties in communicating the nuances of conflicting opinions to the AI when disagreements occur. To tackle this challenge, we propose Human-AI Deliberation, a novel framework to promote human reflection and discussion on conflicting human-AI opinions in decision-making. Based on theories in human deliberation, this framework engages humans and AI in dimension-level opinion elicitation, deliberative discussion, and decision updates. To empower AI with deliberative capabilities, we designed Deliberative AI, which leverages large language models (LLMs) as a bridge between humans and domain-specific models to enable flexible conversational interactions and faithful information provision. An exploratory evaluation on a graduate admissions task shows that Deliberative AI outperforms conventional explainable AI (XAI) assistants in improving humans' appropriate reliance and task performance. Based on a mixed-methods analysis of participant behavior, perception, user experience, and open-ended feedback, we draw implications for future AI-assisted decision tool design.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuai Ma et al.",
      "keywords": "Deliberation; Computer science; Management science; Political science; Psychology; Knowledge management; Engineering; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.16812",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287752385",
      "doi": "10.48550/arxiv.2006.14779",
      "title": "Does the Whole Exceed its Parts? The Effect of AI Explanations on\\n Complementary Team Performance",
      "abstract": "Many researchers motivate explainable AI with studies showing that human-AI\\nteam performance on decision-making tasks improves when the AI explains its\\nrecommendations. However, prior studies observed improvements from explanations\\nonly when the AI, alone, outperformed both the human and the best team. Can\\nexplanations help lead to complementary performance, where team accuracy is\\nhigher than either the human or the AI working solo? We conduct mixed-method\\nuser studies on three datasets, where an AI with accuracy comparable to humans\\nhelps participants solve a task (explaining itself in some conditions). While\\nwe observed complementary improvements from AI augmentation, they were not\\nincreased by explanations. Rather, explanations increased the chance that\\nhumans will accept the AI's recommendation, regardless of its correctness. Our\\nresult poses new challenges for human-centered AI: Can we develop explanatory\\napproaches that encourage appropriate trust in AI, and therefore help generate\\n(or improve) complementary performance?\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Gagan Bansal et al.",
      "keywords": "Task (project management); Computer science; Correctness; Artificial intelligence; Machine learning; Knowledge management; Management",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2006.14779",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4310997200",
      "doi": "10.48550/arxiv.2212.03954",
      "title": "Going Beyond XAI: A Systematic Survey for Explanation-Guided Learning",
      "abstract": "As the societal impact of Deep Neural Networks (DNNs) grows, the goals for advancing DNNs become more complex and diverse, ranging from improving a conventional model accuracy metric to infusing advanced human virtues such as fairness, accountability, transparency (FaccT), and unbiasedness. Recently, techniques in Explainable Artificial Intelligence (XAI) are attracting considerable attention, and have tremendously helped Machine Learning (ML) engineers in understanding AI models. However, at the same time, we started to witness the emerging need beyond XAI among AI communities; based on the insights learned from XAI, how can we better empower ML engineers in steering their DNNs so that the model's reasonableness and performance can be improved as intended? This article provides a timely and extensive literature overview of the field Explanation-Guided Learning (EGL), a domain of techniques that steer the DNNs' reasoning process by adding regularization, supervision, or intervention on model explanations. In doing so, we first provide a formal definition of EGL and its general learning paradigm. Secondly, an overview of the key factors for EGL evaluation, as well as summarization and categorization of existing evaluation procedures and metrics for EGL are provided. Finally, the current and potential future application areas and directions of EGL are discussed, and an extensive experimental study is presented aiming at providing comprehensive comparative studies among existing EGL models in various popular application domains, such as Computer Vision (CV) and Natural Language Processing (NLP) domains.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuyang Gao et al.",
      "keywords": "Computer science; Transparency (behavior); Artificial intelligence; Automatic summarization; Accountability; Process (computing); Data science; Field (mathematics); Domain (mathematical analysis); Machine learning; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.03954",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4315925340",
      "doi": "10.48550/arxiv.2301.04558",
      "title": "Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing",
      "abstract": "Self-supervised learning in vision-language processing exploits semantic alignment between imaging and text modalities. Prior work in biomedical VLP has mostly relied on the alignment of single image and report pairs even though clinical notes commonly refer to prior images. This does not only introduce poor alignment between the modalities but also a missed opportunity to exploit rich self-supervision through existing temporal content in the data. In this work, we explicitly account for prior images and reports when available during both training and fine-tuning. Our approach, named BioViL-T, uses a CNN-Transformer hybrid multi-image encoder trained jointly with a text model. It is designed to be versatile to arising challenges such as pose variations and missing input images across time. The resulting model excels on downstream tasks both in single- and multi-image setups, achieving state-of-the-art performance on (I) progression classification, (II) phrase grounding, and (III) report generation, whilst offering consistent improvements on disease classification and sentence-similarity tasks. We release a novel multi-modal temporal benchmark dataset, MS-CXR-T, to quantify the quality of vision-language representations in terms of temporal semantics. Our experimental results show the advantages of incorporating prior images and reports to make most use of the data.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shruthi Bannur et al.",
      "keywords": "Exploit; Computer science; Artificial intelligence; Encoder; Phrase; Transformer; Modalities; Natural language processing; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2301.04558",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394007316",
      "doi": "10.48550/arxiv.2404.03264",
      "title": "Foundation Model for Advancing Healthcare: Challenges, Opportunities, and Future Directions",
      "abstract": "Foundation model, which is pre-trained on broad data and is able to adapt to a wide range of tasks, is advancing healthcare. It promotes the development of healthcare artificial intelligence (AI) models, breaking the contradiction between limited AI models and diverse healthcare practices. Much more widespread healthcare scenarios will benefit from the development of a healthcare foundation model (HFM), improving their advanced intelligent healthcare services. Despite the impending widespread deployment of HFMs, there is currently a lack of clear understanding about how they work in the healthcare field, their current challenges, and where they are headed in the future. To answer these questions, a comprehensive and deep survey of the challenges, opportunities, and future directions of HFMs is presented in this survey. It first conducted a comprehensive overview of the HFM including the methods, data, and applications for a quick grasp of the current progress. Then, it made an in-depth exploration of the challenges present in data, algorithms, and computing infrastructures for constructing and widespread application of foundation models in healthcare. This survey also identifies emerging and promising directions in this field for future development. We believe that this survey will enhance the community's comprehension of the current progress of HFM and serve as a valuable source of guidance for future development in this field. The latest HFM papers and related resources are maintained on our website: https://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuting He et al.",
      "keywords": "Foundation (evidence); Health care; Political science; Engineering ethics; Business; Engineering; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.03264",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226088704",
      "doi": "10.48550/arxiv.2112.14233",
      "title": "Multitask Learning and Bandits via Robust Statistics",
      "abstract": "Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bounds in the feature dimension $d$ relative to commonly-employed estimators; this improvement is exponential for \"data-poor\" instances, which benefit the most from multitask learning. We illustrate the utility of these results for online learning by embedding our multitask estimator within simultaneous contextual bandit algorithms. We specify a dynamic calibration of our estimator to appropriately balance the bias-variance tradeoff over time, improving the resulting regret bounds in the context dimension $d$. Finally, we illustrate the value of our approach on synthetic and real datasets.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Kan Xu et al.",
      "keywords": "Computer science; Estimator; Regret; Lasso (programming language); Context (archaeology); Machine learning; Bootstrapping (finance); Variance (accounting); Feature (linguistics); Artificial intelligence; Exploit; Mathematics; Econometrics; Statistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.14233",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4353007511",
      "doi": "10.48550/arxiv.2303.11196",
      "title": "Bridging the Global Divide in AI Regulation: A Proposal for a Contextual, Coherent, and Commensurable Framework",
      "abstract": "As debates on potential societal harm from artificial intelligence (AI) culminate in legislation and international norms, a global divide is emerging in both AI regulatory frameworks and international governance structures. In terms of local regulatory frameworks, the European Union (E.U.), Canada, and Brazil follow a horizontal or lateral approach that postulates the homogeneity of AI, seeks to identify common causes of harm, and demands uniform human interventions. In contrast, the United States (U.S.), the United Kingdom (U.K.), Israel, and Switzerland (and potentially China) have pursued a context-specific or modular approach, tailoring regulations to the specific use cases of AI systems. This paper argues for a context-specific approach to effectively address evolving risks in diverse mission-critical domains, while avoiding social costs associated with one-size-fits-all approaches. However, to enhance the systematicity and interoperability of international norms and accelerate global harmonization, this paper proposes an alternative contextual, coherent, and commensurable (3C) framework. To ensure contextuality, the framework (i) bifurcates the AI life cycle into two phases: learning and deployment for specific tasks, instead of defining foundation or general-purpose models; and (ii) categorizes these tasks based on their application and interaction with humans as follows: autonomous, discriminative (allocative, punitive, and cognitive), and generative AI. To ensure coherency, each category is assigned specific regulatory objectives replacing 2010s vintage AI ethics. To ensure commensurability, the framework promotes the adoption of international standards for measuring and mitigating risks.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Sang-Chul Park",
      "keywords": "Proportionality (law); Bridging (networking); Context (archaeology); Punitive damages; Law and economics; Political science; Computer science; Economics; Law; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.11196",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386908241",
      "doi": "10.48550/arxiv.2309.10780",
      "title": "Towards affective computing that works for everyone",
      "abstract": "Missing diversity, equity, and inclusion elements in affective computing datasets directly affect the accuracy and fairness of emotion recognition algorithms across different groups. A literature review reveals how affective computing systems may work differently for different groups due to, for instance, mental health conditions impacting facial expressions and speech or age-related changes in facial appearance and health. Our work analyzes existing affective computing datasets and highlights a disconcerting lack of diversity in current affective computing datasets regarding race, sex/gender, age, and (mental) health representation. By emphasizing the need for more inclusive sampling strategies and standardized documentation of demographic factors in datasets, this paper provides recommendations and calls for greater attention to inclusivity and consideration of societal consequences in affective computing research to promote ethical and accurate outcomes in this emerging field.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Tessa Verhoef et al.",
      "keywords": "Affective computing; Affect (linguistics); Documentation; Diversity (politics); Mental health; Representation (politics); Emotion recognition; Inclusion (mineral); Computer science; Field (mathematics); Equity (law); Race (biology); Cognitive computing; Psychology; Data science; Cognitive psychology; Social psychology; Artificial intelligence; Political science; Cognition; Politics; Mathematics; Sociology; Psychotherapist; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.10780",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4317437681",
      "doi": "10.48550/arxiv.2301.05809",
      "title": "Who Should I Trust: AI or Myself? Leveraging Human and AI Correctness Likelihood to Promote Appropriate Trust in AI-Assisted Decision-Making",
      "abstract": "In AI-assisted decision-making, it is critical for human decision-makers to know when to trust AI and when to trust themselves. However, prior studies calibrated human trust only based on AI confidence indicating AI's correctness likelihood (CL) but ignored humans' CL, hindering optimal team decision-making. To mitigate this gap, we proposed to promote humans' appropriate trust based on the CL of both sides at a task-instance level. We first modeled humans' CL by approximating their decision-making models and computing their potential performance in similar instances. We demonstrated the feasibility and effectiveness of our model via two preliminary studies. Then, we proposed three CL exploitation strategies to calibrate users' trust explicitly/implicitly in the AI-assisted decision-making process. Results from a between-subjects experiment (N=293) showed that our CL exploitation strategies promoted more appropriate human trust in AI, compared with only using AI confidence. We further provided practical implications for more human-compatible AI-assisted decision-making.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuai Ma et al.",
      "keywords": "Correctness; Computer science; Task (project management); Artificial intelligence; Decision-making; Process (computing); Decision model; Machine learning; Engineering; Algorithm",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2301.05809",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391334966",
      "doi": "10.48550/arxiv.2401.14462",
      "title": "AI auditing: The Broken Bus on the Road to AI Accountability",
      "abstract": "One of the most concrete measures to take towards meaningful AI accountability is to consequentially assess and report the systems' performance and impact. However, the practical nature of the \"AI audit\" ecosystem is muddled and imprecise, making it difficult to work through various concepts and map out the stakeholders involved in the practice. First, we taxonomize current AI audit practices as completed by regulators, law firms, civil society, journalism, academia, consulting agencies. Next, we assess the impact of audits done by stakeholders within each domain. We find that only a subset of AI audit studies translate to desired accountability outcomes. We thus assess and isolate practices necessary for effective AI audit results, articulating the observed connections between AI audit design, methodology and institutional context on its effectiveness as a meaningful mechanism for accountability.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Abeba Birhane et al.",
      "keywords": "Accountability; Audit; Business; Computer security; Computer science; Transport engineering; Accounting; Engineering; Political science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.14462",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4385750047",
      "doi": "10.48550/arxiv.2308.04696",
      "title": "Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects",
      "abstract": "While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Soheyla Amirian et al.",
      "keywords": "Interpretability; Transparency (behavior); Health care; Data science; Medicine; Computer science; Knowledge management; Political science; Artificial intelligence; Computer security; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.04696",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4302012756",
      "doi": "10.48550/arxiv.2210.00859",
      "title": "Requirements Engineering for Machine Learning: A Review and Reflection",
      "abstract": "Today, many industrial processes are undergoing digital transformation, which often requires the integration of well-understood domain models and state-of-the-art machine learning technology in business processes. However, requirements elicitation and design decision making about when, where and how to embed various domain models and end-to-end machine learning techniques properly into a given business workflow requires further exploration. This paper aims to provide an overview of the requirements engineering process for machine learning applications in terms of cross domain collaborations. We first review the literature on requirements engineering for machine learning, and then go through the collaborative requirements analysis process step-by-step. An example case of industrial data-driven intelligence applications is also discussed in relation to the aforementioned steps.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhongyi Pei et al.",
      "keywords": "Computer science; Workflow; Domain (mathematical analysis); Business process; Software engineering; Process (computing); Artificial intelligence; Systems engineering; Engineering; Work in process; Database; Programming language",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2210.00859",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387723631",
      "doi": "10.48550/arxiv.2310.09457",
      "title": "UCM-Net: A Lightweight and Efficient Solution for Skin Lesion Segmentation using MLP and CNN",
      "abstract": "Skin cancer poses a significant public health challenge, necessitating efficient diagnostic tools. We introduce UCM-Net, a novel skin lesion segmentation model combining Multi-Layer Perceptrons (MLP) and Convolutional Neural Networks (CNN). This lightweight, efficient architecture, deviating from traditional UNet designs, dramatically reduces computational demands, making it ideal for mobile health applications. Evaluated on PH2, ISIC 2017, and ISIC 2018 datasets, UCM-Net demonstrates robust performance with fewer than 50KB parameters and requires less than 0.05 Giga Operations Per Second (GLOPs). Moreover, its minimal memory requirement is just 1.19MB in CPU environment positions. It is a potential benchmark for efficiency in skin lesion segmentation, suitable for deployment in resource-constrained settings. In order to facilitate accessibility and further research in the field, the UCM-Net source code is https://github.com/chunyuyuan/UCM-Net.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Chunyu Yuan et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Convolutional neural network; Block (permutation group theory); Noise (video); Skin lesion; Deep learning; Pattern recognition (psychology); Overhead (engineering); Market segmentation; Computer-aided diagnosis; Code (set theory); Machine learning; Computer vision; Image (mathematics); Medicine; Pathology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.09457",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288336093",
      "doi": "10.48550/arxiv.1906.01998",
      "title": "The Secrets of Machine Learning: Ten Things You Wish You Had Known Earlier to be More Effective at Data Analysis",
      "abstract": "Despite the widespread usage of machine learning throughout organizations, there are some key principles that are commonly missed. In particular: 1) There are at least four main families for supervised learning: logical modeling methods, linear combination methods, case-based reasoning methods, and iterative summarization methods. 2) For many application domains, almost all machine learning methods perform similarly (with some caveats). Deep learning methods, which are the leading technique for computer vision problems, do not maintain an edge over other methods for most problems (and there are reasons why). 3) Neural networks are hard to train and weird stuff often happens when you try to train them. 4) If you don't use an interpretable model, you can make bad mistakes. 5) Explanations can be misleading and you can't trust them. 6) You can pretty much always find an accurate-yet-interpretable model, even for deep neural networks. 7) Special properties such as decision making or robustness must be built in, they don't happen on their own. 8) Causal inference is different than prediction (correlation is not causation). 9) There is a method to the madness of deep neural architectures, but not always. 10) It is a myth that artificial intelligence can do anything.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Cynthia Rudin et al.",
      "keywords": "Artificial intelligence; Computer science; Machine learning; Artificial neural network; Deep learning; Causal inference; Causation; Robustness (evolution); Automatic summarization; Inference; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1906.01998",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4361019429",
      "doi": "10.48550/arxiv.2303.13524",
      "title": "Talking Abortion (Mis)information with ChatGPT on TikTok",
      "abstract": "In this study, we tested users' perception of accuracy and engagement with TikTok videos in which ChatGPT responded to prompts about \"at-home\" abortion remedies. The chatbot's responses, though somewhat vague and confusing, nonetheless recommended consulting with health professionals before attempting an \"at-home\" abortion. We used ChatGPT to create two TikTok video variants - one where users can see ChatGPT explicitly typing back a response, and one where the text response is presented without any notion to the chatbot. We randomly exposed 100 participants to each variant and found that the group of participants unaware of ChatGPT's text synthetization was more inclined to believe the responses were misinformation. Under the same impression, TikTok itself attached misinformation warning labels (\"Get the facts about abortion\") to all videos after we collected our initial results. We then decided to test the videos again with another set of 50 participants and found that the labels did not affect the perceptions of abortion misinformation except in the case where ChatGPT explicitly responded to a prompt for a lyrical output. We also found that more than 60% of the participants expressed negative or hesitant opinions about chatbots as sources of credible health information.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Filipo Sharevski et al.",
      "keywords": "Misinformation; Abortion; Chatbot; Perception; Internet privacy; Psychology; Affect (linguistics); Set (abstract data type); Social psychology; Medicine; Computer science; World Wide Web; Communication; Pregnancy; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.13524",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4223634546",
      "doi": "10.48550/arxiv.2204.03742",
      "title": "Mitosis domain generalization in histopathology images -- The MIDOG challenge",
      "abstract": "The density of mitotic figures within tumor tissue is known to be highly correlated with tumor proliferation and thus is an important marker in tumor grading. Recognition of mitotic figures by pathologists is known to be subject to a strong inter-rater bias, which limits the prognostic value. State-of-the-art deep learning methods can support the expert in this assessment but are known to strongly deteriorate when applied in a different clinical environment than was used for training. One decisive component in the underlying domain shift has been identified as the variability caused by using different whole slide scanners. The goal of the MICCAI MIDOG 2021 challenge has been to propose and evaluate methods that counter this domain shift and derive scanner-agnostic mitosis detection algorithms. The challenge used a training set of 200 cases, split across four scanning systems. As a test set, an additional 100 cases split across four scanning systems, including two previously unseen scanners, were given. The best approaches performed on an expert level, with the winning algorithm yielding an F_1 score of 0.748 (CI95: 0.704-0.781). In this paper, we evaluate and compare the approaches that were submitted to the challenge and identify methodological factors contributing to better performance.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Marc Aubreville et al.",
      "keywords": "Computer science; Grading (engineering); Artificial intelligence; Generalization; Domain (mathematical analysis); Set (abstract data type); Pattern recognition (psychology); Mitosis; Machine learning; Mathematics; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.03742",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4330336728",
      "doi": "10.48550/arxiv.2303.10215",
      "title": "Statistical inference for association studies in the presence of binary outcome misclassification",
      "abstract": "In biomedical and public health association studies, binary outcome variables may be subject to misclassification, resulting in substantial bias in effect estimates. The feasibility of addressing binary outcome misclassification in regression models is often hindered by model identifiability issues. In this paper, we characterize the identifiability problems in this class of models as a specific case of ''label switching'' and leverage a pattern in the resulting parameter estimates to solve the permutation invariance of the complete data log-likelihood. Our proposed algorithm in binary outcome misclassification models does not require gold standard labels and relies only on the assumption that the sum of the sensitivity and specificity exceeds 1. A label switching correction is applied within estimation methods to recover unbiased effect estimates and to estimate misclassification rates. Open source software is provided to implement the proposed methods. We give a detailed simulation study for our proposed methodology and apply these methods to data from the 2020 Medical Expenditure Panel Survey (MEPS).",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Kimberly A. Hochstedler et al.",
      "keywords": "Inference; Association (psychology); Outcome (game theory); Statistical inference; Binary number; Statistics; Econometrics; Computer science; Mathematics; Artificial intelligence; Psychology; Mathematical economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.10215",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393026865",
      "doi": "10.48550/arxiv.2403.10779",
      "title": "LLM-based Conversational AI Therapist for Daily Functioning Screening and Psychotherapeutic Intervention via Everyday Smart Devices",
      "abstract": "Despite the global mental health crisis, access to screenings, professionals, and treatments remains high. In collaboration with licensed psychotherapists, we propose a Conversational AI Therapist with psychotherapeutic Interventions (CaiTI), a platform that leverages large language models (LLM)s and smart devices to enable better mental health self-care. CaiTI can screen the day-to-day functioning using natural and psychotherapeutic conversations. CaiTI leverages reinforcement learning to provide personalized conversation flow. CaiTI can accurately understand and interpret user responses. When the user needs further attention during the conversation, CaiTI can provide conversational psychotherapeutic interventions, including cognitive behavioral therapy (CBT) and motivational interviewing (MI). Leveraging the datasets prepared by the licensed psychotherapists, we experiment and microbenchmark various LLMs' performance in tasks along CaiTI's conversation flow and discuss their strengths and weaknesses. With the psychotherapists, we implement CaiTI and conduct 14-day and 24-week studies. The study results, validated by therapists, demonstrate that CaiTI can converse with users naturally, accurately understand and interpret user responses, and provide psychotherapeutic interventions appropriately and effectively. We showcase the potential of CaiTI LLMs to assist the mental therapy diagnosis and treatment and improve day-to-day functioning screening and precautionary psychotherapeutic intervention systems.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jingping Nie et al.",
      "keywords": "Intervention (counseling); Psychotherapist; Psychology; Everyday life; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.10779",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221165921",
      "doi": "10.48550/arxiv.2202.07448",
      "title": "Towards a Unified Pandemic Management Architecture: Survey, Challenges and Future Directions",
      "abstract": "The pandemic caused by SARS-CoV-2 has left an unprecedented impact on health, economy and society worldwide. Emerging strains are making pandemic management increasingly challenging. There is an urge to collect epidemiological, clinical, and physiological data to make an informed decision on mitigation measures. Advances in the Internet of Things (IoT) and edge computing provide solutions for pandemic management through data collection and intelligent computation. While existing data-driven architectures attempt to automate decision-making, they do not capture the multifaceted interaction among computational models, communication infrastructure, and the generated data. In this paper, we perform a survey of the existing approaches for pandemic management, including online data repositories and contact-tracing applications. We then envision a unified pandemic management architecture that leverages the IoT and edge computing to automate recommendations on vaccine distribution, dynamic lockdown, mobility scheduling and pandemic prediction. We elucidate the flow of data among the layers of the architecture, namely, cloud, edge and end device layers. Moreover, we address the privacy implications, threats, regulations, and existing solutions that may be adapted to optimize the utility of health data with security guarantees. The paper ends with a lowdown on the limitations of the architecture and research directions to enhance its practicality.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Satyaki Roy et al.",
      "keywords": "Cloud computing; Computer science; Architecture; Edge computing; Data science; Pandemic; Scheduling (production processes); Data management; Computer security; Tracing; Big data; Distributed computing; Risk analysis (engineering); Internet of Things; Coronavirus disease 2019 (COVID-19); Engineering; Data mining; Business; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.07448",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4396786610",
      "doi": "10.48550/arxiv.2405.03636",
      "title": "The Federation Strikes Back: A Survey of Federated Learning Privacy Attacks, Defenses, Applications, and Policy Landscape",
      "abstract": "Deep learning has shown incredible potential across a wide array of tasks, and accompanied by this growth has been an insatiable appetite for data. However, a large amount of data needed for enabling deep learning is stored on personal devices, and recent concerns on privacy have further highlighted challenges for accessing such data. As a result, federated learning (FL) has emerged as an important privacy-preserving technology that enables collaborative training of machine learning models without the need to send the raw, potentially sensitive, data to a central server. However, the fundamental premise that sending model updates to a server is privacy-preserving only holds if the updates cannot be \"reverse engineered\" to infer information about the private training data. It has been shown under a wide variety of settings that this privacy premise does not hold. In this survey paper, we provide a comprehensive literature review of the different privacy attacks and defense methods in FL. We identify the current limitations of these attacks and highlight the settings in which the privacy of an FL client can be broken. We further dissect some of the successful industry applications of FL and draw lessons for future successful adoption. We survey the emerging landscape of privacy regulation for FL and conclude with future directions for taking FL toward the cherished goal of generating accurate models while preserving the privacy of the data from its participants.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Joshua C. Zhao et al.",
      "keywords": "Internet privacy; Privacy policy; Computer security; Business; Information privacy; Policy learning; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.03636",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4376122682",
      "doi": "10.48550/arxiv.2305.05105",
      "title": "TinyML Design Contest for Life-Threatening Ventricular Arrhythmia Detection",
      "abstract": "The first ACM/IEEE TinyML Design Contest (TDC) held at the 41st International Conference on Computer-Aided Design (ICCAD) in 2022 is a challenging, multi-month, research and development competition. TDC'22 focuses on real-world medical problems that require the innovation and implementation of artificial intelligence/machine learning (AI/ML) algorithms on implantable devices. The challenge problem of TDC'22 is to develop a novel AI/ML-based real-time detection algorithm for life-threatening ventricular arrhythmia over low-power microcontrollers utilized in Implantable Cardioverter-Defibrillators (ICDs). The dataset contains more than 38,000 5-second intracardiac electrograms (IEGMs) segments over 8 different types of rhythm from 90 subjects. The dedicated hardware platform is NUCLEO-L432KC manufactured by STMicroelectronics. TDC'22, which is open to multi-person teams world-wide, attracted more than 150 teams from over 50 organizations. This paper first presents the medical problem, dataset, and evaluation procedure in detail. It further demonstrates and discusses the designs developed by the leading teams as well as representative results. This paper concludes with the direction of improvement for the future TinyML design for health monitoring applications.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhenge Jia et al.",
      "keywords": "CONTEST; Computer science; Heart Rhythm; Intracardiac injection; Microcontroller; Artificial intelligence; Machine learning; Computer architecture; Embedded system; Medicine; Cardiology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.05105",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4224329779",
      "doi": "10.48550/arxiv.2204.05737",
      "title": "LifeLonger: A Benchmark for Continual Disease Classification",
      "abstract": "Deep learning models have shown a great effectiveness in recognition of findings in medical images. However, they cannot handle the ever-changing clinical environment, bringing newly annotated medical data from different sources. To exploit the incoming streams of data, these models would benefit largely from sequentially learning from new samples, without forgetting the previously obtained knowledge. In this paper we introduce LifeLonger, a benchmark for continual disease classification on the MedMNIST collection, by applying existing state-of-the-art continual learning methods. In particular, we consider three continual learning scenarios, namely, task and class incremental learning and the newly defined cross-domain incremental learning. Task and class incremental learning of diseases address the issue of classifying new samples without re-training the models from scratch, while cross-domain incremental learning addresses the issue of dealing with datasets originating from different institutions while retaining the previously obtained knowledge. We perform a thorough analysis of the performance and examine how the well-known challenges of continual learning, such as the catastrophic forgetting exhibit themselves in this setting. The encouraging results demonstrate that continual learning has a major potential to advance disease classification and to produce a more robust and efficient learning framework for clinical settings. The code repository, data partitions and baseline results for the complete benchmark will be made publicly available.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Mohammad Mahdi Derakhshani et al.",
      "keywords": "Forgetting; Benchmark (surveying); Computer science; Machine learning; Artificial intelligence; Exploit; Task (project management); Class (philosophy); Domain (mathematical analysis); Baseline (sea); Deep learning; Active learning (machine learning); Multi-task learning; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.05737",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395482906",
      "doi": "10.48550/arxiv.2404.15381",
      "title": "Advances and Open Challenges in Federated Foundation Models",
      "abstract": "The integration of Foundation Models (FMs) with Federated Learning (FL) presents a transformative paradigm in Artificial Intelligence (AI). This integration offers enhanced capabilities, while addressing concerns of privacy, data decentralization and computational efficiency. This paper provides a comprehensive survey of the emerging field of Federated Foundation Models (FedFM), elucidating their synergistic relationship and exploring novel methodologies, challenges, and future directions that the FL research field needs to focus on in order to thrive in the age of FMs. A systematic multi-tiered taxonomy is proposed, categorizing existing FedFM approaches for model training, aggregation, trustworthiness, and incentivization. Key challenges, including how to enable FL to deal with high complexity of computational demands, privacy considerations, contribution evaluation, and communication efficiency, are thoroughly discussed. Moreover, this paper explores the intricate challenges of communication, scalability and security inherent in training/fine-tuning FMs via FL. It highlights the potential of quantum computing to revolutionize the processes of training, inference, optimization and security. This survey also introduces the implementation requirement of FedFM and some practical FedFM applications. It highlights lessons learned with a clear understanding of our findings for FedFM. Finally, this survey not only provides insights into the current state and challenges of FedFM, but also offers a blueprint for future research directions, emphasizing the need for developing trustworthy solutions. It serves as a foundational guide for researchers and practitioners interested in contributing to this interdisciplinary and rapidly advancing field.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Chao Ren et al.",
      "keywords": "Foundation (evidence); Federated learning; Computer science; Political science; Artificial intelligence; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.15381",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4377086514",
      "doi": "10.48550/arxiv.2305.09675",
      "title": "Spatial Computing Opportunities in Biomedical Decision Support: The Atlas-EHR Vision",
      "abstract": "We consider the problem of reducing the time needed by healthcare professionals to understand patient medical history via the next generation of biomedical decision support. This problem is societally important because it has the potential to improve healthcare quality and patient outcomes. However, navigating electronic health records is challenging due to the high patient-doctor ratios, potentially long medical histories, the urgency of treatment for some medical conditions, and patient variability. The current electronic health record systems provides only a longitudinal view of patient medical history, which is time-consuming to browse, and doctors often need to engage nurses, residents, and others for initial analysis. To overcome this limitation, we envision an alternative spatial representation of patients' histories (e.g., electronic health records (EHRs)) and other biomedical data in the form of Atlas-EHR. Just like Google Maps allows a global, national, regional, and local view, the Atlas-EHR may start with an overview of the patient's anatomy and history before drilling down to spatially anatomical sub-systems, their individual components, or sub-components. Atlas-EHR presents a compelling opportunity for spatial computing since healthcare is almost a fifth of the US economy. However, the traditional spatial computing designed for geographic use cases (e.g., navigation, land-surveys, mapping) faces many hurdles in the biomedical domain. This paper presents a number of open research questions under this theme in five broad areas of spatial computing.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Majid Farhadloo et al.",
      "keywords": "Data science; Atlas (anatomy); Task (project management); Health care; Decision support system; Computer science; Medicine; Artificial intelligence; Engineering; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.09675",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3035217479",
      "doi": "10.48550/arxiv.2006.06466",
      "title": "How Interpretable and Trustworthy are GAMs?",
      "abstract": "Generalized additive models (GAMs) have become a leading modelclass for interpretable machine learning. However, there are many algorithms for training GAMs, and these can learn different or even contradictory models, while being equally accurate. Which GAM should we trust? In this paper, we quantitatively and qualitatively investigate a variety of GAM algorithms on real and simulated datasets. We find that GAMs with high feature sparsity (only using afew variables to make predictions) can miss patterns in the data and be unfair to rare subpopulations. Our results suggest that inductive bias plays a crucial role in what interpretable models learn and that tree-based GAMs represent the best balance of sparsity, fidelity and accuracy and thus appear to be the most trustworthy GAM.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Chun\u2010Hao Chang et al.",
      "keywords": "Trustworthiness; Fidelity; Generalized additive model; Feature (linguistics); Computer science; Tree (set theory); Variety (cybernetics); Machine learning; Artificial intelligence; Mathematics; Linguistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2006.06466",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2983402352",
      "doi": "10.48550/arxiv.1911.03764",
      "title": "Optimal Experimental Design for Staggered Rollouts",
      "abstract": "In this paper, we study the design and analysis of experiments conducted on a set of units over multiple time periods where the starting time of the treatment may vary by unit. The design problem involves selecting an initial treatment time for each unit in order to most precisely estimate both the instantaneous and cumulative effects of the treatment. We first consider non-adaptive experiments, where all treatment assignment decisions are made prior to the start of the experiment. For this case, we show that the optimization problem is generally NP-hard, and we propose a near-optimal solution. Under this solution, the fraction entering treatment each period is initially low, then high, and finally low again. Next, we study an adaptive experimental design problem, where both the decision to continue the experiment and treatment assignment decisions are updated after each period's data is collected. For the adaptive case, we propose a new algorithm, the Precision-Guided Adaptive Experiment (PGAE) algorithm, that addresses the challenges at both the design stage and at the stage of estimating treatment effects, ensuring valid post-experiment inference accounting for the adaptive nature of the design. Using realistic settings, we demonstrate that our proposed solutions can reduce the opportunity cost of the experiments by over 50%, compared to static design benchmarks.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Ruoxuan Xiong et al.",
      "keywords": "Computer science; Mathematical optimization; Set (abstract data type); Sequential analysis; Design of experiments; Inference; Fraction (chemistry); Adaptive design; Adaptive strategies; Optimal design; Machine learning; Mathematics; Statistics; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1911.03764",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287274268",
      "doi": "10.48550/arxiv.2103.06076",
      "title": "Designing Disaggregated Evaluations of AI Systems: Choices,\\n Considerations, and Tradeoffs",
      "abstract": "Disaggregated evaluations of AI systems, in which system performance is\\nassessed and reported separately for different groups of people, are\\nconceptually simple. However, their design involves a variety of choices. Some\\nof these choices influence the results that will be obtained, and thus the\\nconclusions that can be drawn; others influence the impacts -- both beneficial\\nand harmful -- that a disaggregated evaluation will have on people, including\\nthe people whose data is used to conduct the evaluation. We argue that a deeper\\nunderstanding of these choices will enable researchers and practitioners to\\ndesign careful and conclusive disaggregated evaluations. We also argue that\\nbetter documentation of these choices, along with the underlying considerations\\nand tradeoffs that have been made, will help others when interpreting an\\nevaluation's results and conclusions.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Solon Barocas et al.",
      "keywords": "Variety (cybernetics); Documentation; Simple (philosophy); Computer science; Management science; Data science; Risk analysis (engineering); Artificial intelligence; Economics; Business; Epistemology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2103.06076",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225407841",
      "doi": "10.48550/arxiv.2205.01037",
      "title": "Data Justice in Practice: A Guide for Developers",
      "abstract": "The Advancing Data Justice Research and Practice project aims to broaden understanding of the social, historical, cultural, political, and economic forces that contribute to discrimination and inequity in contemporary ecologies of data collection, governance, and use. This is the consultation draft of a guide for developers and organisations, which are producing, procuring, or using data-intensive technologies.In the first section, we introduce the field of data justice, from its early discussions to more recent proposals to relocate understandings of what data justice means. This section includes a description of the six pillars of data justice around which this guidance revolves. Next, to support developers in designing, developing, and deploying responsible and equitable data-intensive and AI/ML systems, we outline the AI/ML project lifecycle through a sociotechnical lens. To support the operationalisation data justice throughout the entirety of the AI/ML lifecycle and within data innovation ecosystems, we then present five overarching principles of responsible, equitable, and trustworthy data research and innovation practices, the SAFE-D principles-Safety, Accountability, Fairness, Explainability, and Data Quality, Integrity, Protection, and Privacy. The final section presents guiding questions that will help developers both address data justice issues throughout the AI/ML lifecycle and engage in reflective innovation practices that ensure the design, development, and deployment of responsible and equitable data-intensive and AI/ML systems.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "David Leslie et al.",
      "keywords": "Accountability; Economic Justice; Data governance; Engineering ethics; Software deployment; Data quality; Corporate governance; Public relations; Knowledge management; Sociology; Business; Political science; Engineering; Computer science; Marketing; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.01037",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4303673372",
      "doi": "10.48550/arxiv.2002.03595",
      "title": "Representation Learning on Variable Length and Incomplete Wearable-Sensory Time Series",
      "abstract": "The prevalence of wearable sensors (e.g., smart wristband) is creating unprecedented opportunities to not only inform health and wellness states of individuals, but also assess and infer personal attributes, including demographic and personality attributes. However, the data captured from wearables, such as heart rate or number of steps, present two key challenges: 1) the time series is often of variable-length and incomplete due to different data collection periods (e.g., wearing behavior varies by person); and 2) inter-individual variability to external factors like stress and environment. This paper addresses these challenges and brings us closer to the potential of personalized insights about an individual, taking the leap from quantified self to qualified self. Specifically, HeartSpace proposed in this paper encodes time series data with variable-length and missing values via the integration of a time series encoding module and a pattern aggregation network. Additionally, HeartSpace implements a Siamese-triplet network to optimize representations by jointly capturing intra- and inter-series correlations during the embedding learning process. The empirical evaluation over two different real-world data presents significant performance gains overstate-of-the-art baselines in a variety of applications, including personality prediction, demographics inference, and user identification.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Xian Wu et al.",
      "keywords": "Wearable computer; Computer science; Inference; Variable (mathematics); Wearable technology; Embedding; Series (stratigraphy); Machine learning; Representation (politics); Identification (biology); Time series; Data mining; Smartwatch; Encoding (memory); Artificial intelligence; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2002.03595",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388685547",
      "doi": "10.48550/arxiv.2311.07370",
      "title": "Classification of developmental and brain disorders via graph convolutional aggregation",
      "abstract": "While graph convolution based methods have become the de-facto standard for graph representation learning, their applications to disease prediction tasks remain quite limited, particularly in the classification of neurodevelopmental and neurodegenerative brain disorders. In this paper, we introduce an aggregator normalization graph convolutional network by leveraging aggregation in graph sampling, as well as skip connections and identity mapping. The proposed model learns discriminative graph node representations by incorporating both imaging and non-imaging features into the graph nodes and edges, respectively, with the aim of augmenting predictive capabilities and providing a holistic perspective on the underlying mechanisms of brain disorders. Skip connections enable the direct flow of information from the input features to later layers of the network, while identity mapping helps maintain the structural information of the graph during feature learning. We benchmark our model against several recent baseline methods on two large datasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease Neuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder and Alzheimer's disease, respectively. Experimental results demonstrate the competitive performance of our approach in comparison with recent baselines in terms of several evaluation metrics, achieving relative improvements of 50% and 13.56% in classification accuracy over graph convolutional networks on ABIDE and ADNI, respectively.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ibrahim Salim et al.",
      "keywords": "Computer science; Graph; Discriminative model; Neuroimaging; Artificial intelligence; Feature learning; Convolutional neural network; Autism; Machine learning; Theoretical computer science; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.07370",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3120219680",
      "doi": "10.13140/rg.2.2.33097.98403",
      "title": "The Medical Authority of AI: A Study of AI-enabled Consumer-facing Health Technology",
      "abstract": "Recently, consumer-facing health technologies such as Artificial Intelligence (AI)-based symptom checkers (AISCs) have sprung up in everyday healthcare practice. AISCs solicit symptom information from users and provide medical suggestions and possible diagnoses, a responsibility that people usually entrust with real-person authorities such as physicians and expert patients. Thus, the advent of AISCs begs a question of whether and how they transform the notion of medical authority in everyday healthcare practice. To answer this question, we conducted an interview study with thirty AISC users. We found that users assess the medical authority of AISCs using various factors including automated decisions and interaction design patterns of AISC apps, associations with established medical authorities like hospitals, and comparisons with other health technologies. We reveal how AISCs are used in healthcare delivery, discuss how AI transforms conventional understandings of medical authority, and derive implications for designing AI-enabled health technology.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Yue You et al.",
      "keywords": "Health care; Medical diagnosis; Medical practice; Everyday life; Health technology; Public relations; Psychology; Medical education; Medicine; Political science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.13140/rg.2.2.33097.98403",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390722657",
      "doi": "10.48550/arxiv.2401.02985",
      "title": "Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education",
      "abstract": "The rapid evolution of artificial intelligence (AI), especially in the domain of Large Language Models (LLMs) and generative AI, has opened new avenues for application across various fields, yet its role in business education remains underexplored. This study introduces the first benchmark to assess the performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models (Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission process for graduate business programs. Our analysis shows that most LLMs outperform human candidates, with GPT-4 Turbo not only outperforming the other models but also surpassing the average scores of graduate students at top business schools. Through a case study, this research examines GPT-4 Turbo's ability to explain answers, evaluate responses, identify errors, tailor instructions, and generate alternative scenarios. The latest LLM versions, GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in reasoning tasks compared to their predecessors, underscoring their potential for complex problem-solving. While AI's promise in education, assessment, and tutoring is clear, challenges remain. Our study not only sheds light on LLMs' academic potential but also emphasizes the need for careful development and application of AI in education. As AI technology advances, it is imperative to establish frameworks and protocols for AI interaction, verify the accuracy of AI-generated content, ensure worldwide access for diverse learners, and create an educational environment where AI supports human expertise. This research sets the stage for further exploration into the responsible use of AI to enrich educational experiences and improve exam preparation and assessment methods.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Vahid Ashrafimoghari et al.",
      "keywords": "Benchmark (surveying); Computer science; Turbo; Process (computing); Artificial intelligence; Mathematics education; Psychology; Engineering; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.02985",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396821863",
      "doi": "10.48550/arxiv.2405.05299",
      "title": "Challenges for Responsible AI Design and Workflow Integration in Healthcare: A Case Study of Automatic Feeding Tube Qualification in Radiology",
      "abstract": "Nasogastric tubes (NGTs) are feeding tubes that are inserted through the nose into the stomach to deliver nutrition or medication. If not placed correctly, they can cause serious harm, even death to patients. Recent AI developments demonstrate the feasibility of robustly detecting NGT placement from Chest X-ray images to reduce risks of sub-optimally or critically placed NGTs being missed or delayed in their detection, but gaps remain in clinical practice integration. In this study, we present a human-centered approach to the problem and describe insights derived following contextual inquiry and in-depth interviews with 15 clinical stakeholders. The interviews helped understand challenges in existing workflows, and how best to align technical capabilities with user needs and expectations. We discovered the trade-offs and complexities that need consideration when choosing suitable workflow stages, target users, and design configurations for different AI proposals. We explored how to balance AI benefits and risks for healthcare staff and patients within broader organizational and medical-legal constraints. We also identified data issues related to edge cases and data biases that affect model training and evaluation; how data documentation practices influence data preparation and labelling; and how to measure relevant AI outcomes reliably in future evaluations. We discuss how our work informs design and development of AI applications that are clinically useful, ethical, and acceptable in real-world healthcare services.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Anja Thieme et al.",
      "keywords": "Workflow; Health care; Tube (container); Medicine; Radiology; Medical physics; Knowledge management; Business; Computer science; Process management; Software engineering; Engineering; Political science; Mechanical engineering; Database",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.05299",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4414587923",
      "doi": "10.48550/arxiv.2505.20020",
      "title": "Ontology- and LLM-based Data Harmonization for Federated Learning in Healthcare",
      "abstract": "The rise of electronic health records (EHRs) has unlocked new opportunities for medical research, but privacy regulations and data heterogeneity remain key barriers to large-scale machine learning. Federated learning (FL) enables collaborative modeling without sharing raw data, yet faces challenges in harmonizing diverse clinical datasets. This paper presents a two-step data alignment strategy integrating ontologies and large language models (LLMs) to support secure, privacy-preserving FL in healthcare, demonstrating its effectiveness in a real-world project involving semantic mapping of EHR data.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Natallia Kokash et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.20020",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399794359",
      "doi": "10.48550/arxiv.2406.10563",
      "title": "Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data",
      "abstract": "In the realm of healthcare where decentralized facilities are prevalent, machine learning faces two major challenges concerning the protection of data and models. The data-level challenge concerns the data privacy leakage when centralizing data with sensitive personal information. While the model-level challenge arises from the heterogeneity of local models, which need to be collaboratively trained while ensuring their confidentiality to address intellectual property concerns. To tackle these challenges, we propose a new framework termed Abstention-Aware Federated Voting (AAFV) that can collaboratively and confidentially train heterogeneous local models while simultaneously protecting the data privacy. This is achieved by integrating a novel abstention-aware voting mechanism and a differential privacy mechanism onto local models' predictions. In particular, the proposed abstention-aware voting mechanism exploits a threshold-based abstention method to select high-confidence votes from heterogeneous local models, which not only enhances the learning utility but also protects model confidentiality. Furthermore, we implement AAFV on two practical prediction tasks of diabetes and in-hospital patient mortality. The experiments demonstrate the effectiveness and confidentiality of AAFV in testing accuracy and privacy protection.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yukai Xu et al.",
      "keywords": "Federated learning; Computer science; Health care; Internet privacy; Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.10563",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4302011556",
      "doi": "10.48550/arxiv.2210.00572",
      "title": "Risk-graded Safety for Handling Medical Queries in Conversational AI",
      "abstract": "Conversational AI systems can engage in unsafe behaviour when handling users' medical queries that can have severe consequences and could even lead to deaths. Systems therefore need to be capable of both recognising the seriousness of medical inputs and producing responses with appropriate levels of risk. We create a corpus of human written English language medical queries and the responses of different types of systems. We label these with both crowdsourced and expert annotations. While individual crowdworkers may be unreliable at grading the seriousness of the prompts, their aggregated labels tend to agree with professional opinion to a greater extent on identifying the medical queries and recognising the risk types posed by the responses. Results of classification experiments suggest that, while these tasks can be automated, caution should be exercised, as errors can potentially be very serious.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Gavin Abercrombie et al.",
      "keywords": "Seriousness; Computer science; Grading (engineering); Medical information; Natural language processing; Human\u2013computer interaction; Information retrieval; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.00572",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3176038277",
      "doi": "10.48550/arxiv.2106.03468",
      "title": "On Healthcare Robots: Concepts, definitions, and considerations for healthcare robot governance",
      "abstract": "Although healthcare is a remarkably sensitive domain of application, and systems that exert direct control over the world can cause harm in a way that humans cannot necessarily correct or oversee, it is still unclear whether and how healthcare robots are currently regulated or should be regulated. Existing regulations are primarily unprepared to provide guidance for such a rapidly evolving field and accommodate devices that rely on machine learning and AI. Moreover, the field of healthcare robotics is very rich and extensive, but it is still very much scattered and unclear in terms of definitions, medical and technical classifications, product characteristics, purpose, and intended use. As a result, these devices often navigate between the medical device regulation or other non-medical norms, such as the ISO personal care standard. Before regulating the field of healthcare robots, it is therefore essential to map the major state-of-the-art developments in healthcare robotics, their capabilities and applications, and the challenges we face as a result of their integration within the healthcare environment. This contribution fills in this gap and lack of clarity currently experienced within healthcare robotics and its governance by providing a structured overview of and further elaboration on the main categories now established, their intended purpose, use, and main characteristics. We explicitly focus on surgical, assistive, and service robots to rightfully match the definition of healthcare as the organized provision of medical care to individuals, including efforts to maintain, treat, or restore physical, mental, or emotional well-being. We complement these findings with policy recommendations to help policymakers unravel an optimal regulatory framing for healthcare robot technologies",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Eduard Fosch\u2010Villaronga et al.",
      "keywords": "Health care; CLARITY; Robot; Robotics; Corporate governance; Harm; Artificial intelligence; Computer science; Field (mathematics); Knowledge management; Human\u2013computer interaction; Psychology; Business; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.03468",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392866638",
      "doi": "10.48550/arxiv.2403.08495",
      "title": "Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in human interactions, yet their application within the medical field remains insufficiently explored. Previous works mainly focus on the performance of medical knowledge with examinations, which is far from the realistic scenarios, falling short in assessing the abilities of LLMs on clinical tasks. In the quest to enhance the application of Large Language Models (LLMs) in healthcare, this paper introduces the Automated Interactive Evaluation (AIE) framework and the State-Aware Patient Simulator (SAPS), targeting the gap between traditional LLM evaluations and the nuanced demands of clinical practice. Unlike prior methods that rely on static medical knowledge assessments, AIE and SAPS provide a dynamic, realistic platform for assessing LLMs through multi-turn doctor-patient simulations. This approach offers a closer approximation to real clinical scenarios and allows for a detailed analysis of LLM behaviors in response to complex patient interactions. Our extensive experimental validation demonstrates the effectiveness of the AIE framework, with outcomes that align well with human evaluations, underscoring its potential to revolutionize medical LLM testing for improved healthcare delivery.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yusheng Liao et al.",
      "keywords": "Computer science; State (computer science); Simulation; Computer architecture simulator; Human\u2013computer interaction; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.08495",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312097187",
      "doi": "10.48550/arxiv.2107.06641",
      "title": "Trustworthy AI: A Computational Perspective",
      "abstract": "In the past few decades, artificial intelligence (AI) technology has experienced swift developments, changing everyone's daily life and profoundly altering the course of human society. The intention of developing AI is to benefit humans, by reducing human labor, bringing everyday convenience to human lives, and promoting social good. However, recent research and AI applications show that AI can cause unintentional harm to humans, such as making unreliable decisions in safety-critical scenarios or undermining fairness by inadvertently discriminating against one group. Thus, trustworthy AI has attracted immense attention recently, which requires careful consideration to avoid the adverse effects that AI may bring to humans, so that humans can fully trust and live in harmony with AI technologies. Recent years have witnessed a tremendous amount of research on trustworthy AI. In this survey, we present a comprehensive survey of trustworthy AI from a computational perspective, to help readers understand the latest technologies for achieving trustworthy AI. Trustworthy AI is a large and complex area, involving various dimensions. In this work, we focus on six of the most crucial dimensions in achieving trustworthy AI: (i) Safety &amp; Robustness, (ii) Non-discrimination &amp; Fairness, (iii) Explainability, (iv) Privacy, (v) Accountability &amp; Auditability, and (vi) Environmental Well-Being. For each dimension, we review the recent related technologies according to a taxonomy and summarize their applications in real-world systems. We also discuss the accordant and conflicting interactions among different dimensions and discuss potential aspects for trustworthy AI to investigate in the future.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Haochen Liu et al.",
      "keywords": "Trustworthiness; Harm; Computer science; Accountability; Emerging technologies; Data science; Everyday life; Internet privacy; Artificial intelligence; Computer security; Knowledge management; Engineering ethics; Psychology; Political science; Social psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2107.06641",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403444052",
      "doi": "10.48550/arxiv.2410.08327",
      "title": "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains",
      "abstract": "The difficulty of anonymizing text data hinders the development and deployment of NLP in high-stakes domains that involve private data, such as healthcare and social services. Poorly anonymized sensitive data cannot be easily shared with annotators or external researchers, nor can it be used to train public models. In this work, we explore the feasibility of using synthetic data generated from differentially private language models in place of real data to facilitate the development of NLP in these domains without compromising privacy. In contrast to prior work, we generate synthetic data for real high-stakes domains, and we propose and conduct use-inspired evaluations to assess data quality. Our results show that prior simplistic evaluations have failed to highlight utility, privacy, and fairness issues in the synthetic data. Overall, our work underscores the need for further improvements to synthetic data generation for it to be a viable way to enable privacy-preserving data sharing.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Krithika Ramesh et al.",
      "keywords": "Business; Synthetic data; Data science; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.08327",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415037462",
      "doi": "10.48550/arxiv.2505.21418",
      "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery",
      "abstract": "Focused Ultrasound Ablation Surgery (FUAS) has emerged as a promising non-invasive therapeutic modality, valued for its safety and precision. Nevertheless, its clinical implementation entails intricate tasks such as multimodal image interpretation, personalized dose planning, and real-time intraoperative decision-making processes that demand intelligent assistance to improve efficiency and reliability. We introduce FUAS-Agents, an autonomous agent system that leverages the multimodal understanding and tool-using capabilities of large language models (LLMs). By integrating patient profiles and MRI data, FUAS-Agents orchestrates a suite of specialized medical AI tools, including segmentation, treatment dose prediction, and clinical guideline retrieval, to generate personalized treatment plans comprising MRI image, dose parameters, and therapeutic strategies. We evaluate the system in a uterine fibroid treatment scenario. Human assessment by four senior FUAS experts indicates that 82.5%, 82.5%, 87.5%, and 97.5% of the generated plans were rated 4 or above (on a 5-point scale) in terms of completeness, accuracy, fluency, and clinical compliance, respectively. These results demonstrate the potential of LLM-driven agents in enhancing decision-making across complex clinical workflows, and exemplify a translational paradigm that combines general-purpose models with specialized expert systems to solve practical challenges in vertical healthcare domains.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Lina Zhao et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.21418",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313958184",
      "doi": "10.48550/arxiv.2301.02589",
      "title": "Causal Categorization of Mental Health Posts using Transformers",
      "abstract": "With recent developments in digitization of clinical psychology, NLP research community has revolutionized the field of mental health detection on social media. Existing research in mental health analysis revolves around the cross-sectional studies to classify users' intent on social media. For in-depth analysis, we investigate existing classifiers to solve the problem of causal categorization which suggests the inefficiency of learning based methods due to limited training samples. To handle this challenge, we use transformer models and demonstrate the efficacy of a pre-trained transfer learning on \"CAMS\" dataset. The experimental result improves the accuracy and depicts the importance of identifying cause-and-effect relationships in the underlying text.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Muskan Garg et al.",
      "keywords": "Categorization; Inefficiency; Digitization; Mental health; Computer science; Social media; Transfer of learning; Data science; Machine learning; Transformer; Artificial intelligence; Psychology; World Wide Web; Psychiatry; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2301.02589",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366559953",
      "doi": "10.48550/arxiv.2304.09572",
      "title": "An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap",
      "abstract": "This paper presents an ecosystem for personal knowledge graphs (PKGs), commonly defined as resources of structured information about entities related to an individual, their attributes, and the relations between them. PKGs are a key enabler of secure and sophisticated personal data management and personalized services. However, there are challenges that need to be addressed before PKGs can achieve widespread adoption. One of the fundamental challenges is the very definition of what constitutes a PKG, as there are multiple interpretations of the term. We propose our own definition of a PKG, emphasizing the aspects of (1) data ownership by a single individual and (2) the delivery of personalized services as the primary purpose. We further argue that a holistic view of PKGs is needed to unlock their full potential, and propose a unified framework for PKGs, where the PKG is a part of a larger ecosystem with clear interfaces towards data services and data sources. A comprehensive survey and synthesis of existing work is conducted, with a mapping of the surveyed work into the proposed unified ecosystem. Finally, we identify open challenges and research opportunities for the ecosystem as a whole, as well as for the specific aspects of PKGs, which include population, representation and management, and utilization.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Martin G. Skj\u00e6veland et al.",
      "keywords": "Ecosystem; Knowledge graph; Business; Knowledge management; Computer science; Data science; Environmental resource management; Environmental science; Ecology; Information retrieval; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.09572",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388092129",
      "doi": "10.48550/arxiv.2310.17944",
      "title": "A Survey on Trustworthy Edge Intelligence: From Security and Reliability To Transparency and Sustainability",
      "abstract": "Edge Intelligence (EI) integrates Edge Computing (EC) and Artificial Intelligence (AI) to push the capabilities of AI to the network edge for real-time, efficient and secure intelligent decision-making and computation. However, EI faces various challenges due to resource constraints, heterogeneous network environments, and diverse service requirements of different applications, which together affect the trustworthiness of EI in the eyes of stakeholders. This survey comprehensively summarizes the characteristics, architecture, technologies, and solutions of trustworthy EI. Specifically, we first emphasize the need for trustworthy EI in the context of the trend toward large models. We then provide an initial definition of trustworthy EI, explore its key characteristics and give a multi-layered architecture for trustworthy EI. Then, we summarize several important issues that hinder the achievement of trustworthy EI. Subsequently, we present enabling technologies for trustworthy EI systems and provide an in-depth literature review of the state-of-the-art solutions for realizing the trustworthiness of EI. Finally, we discuss the corresponding research challenges and open issues.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiaojie Wang et al.",
      "keywords": "Trustworthiness; Transparency (behavior); Computer science; Context (archaeology); Enhanced Data Rates for GSM Evolution; Reliability (semiconductor); Architecture; Data science; Knowledge management; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.17944",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393212046",
      "doi": "10.5281/zenodo.10679891",
      "title": "AI Ethics and Governance in Practice: An Introduction",
      "abstract": "AI systems may have transformative and long-term effects on individuals and society. To manage these impacts responsibly and direct the development of AI systems toward optimal public benefit, considerations of AI ethics and governance must be a first priority. In this workbook, we introduce and describe our PBG Framework, a multi-tiered governance model that enables project teams to integrate ethical values and practical principles into their innovation practices and to have clear mechanisms for demonstrating and documenting this.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "David Leslie et al.",
      "keywords": "Corporate governance; Political science; Engineering ethics; Sociology; Management; Economics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.5281/zenodo.10679891",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4307536358",
      "doi": "10.48550/arxiv.2210.15261",
      "title": "A knowledge-driven vowel-based approach of depression classification from speech using data augmentation",
      "abstract": "We propose a novel explainable machine learning (ML) model that identifies depression from speech, by modeling the temporal dependencies across utterances and utilizing the spectrotemporal information at the vowel level. Our method first models the variable-length utterances at the local-level into a fixed-size vowel-based embedding using a convolutional neural network with a spatial pyramid pooling layer (\"vowel CNN\"). Following that, the depression is classified at the global-level from a group of vowel CNN embeddings that serve as the input of another 1D CNN (\"depression CNN\"). Different data augmentation methods are designed for both the training of vowel CNN and depression CNN. We investigate the performance of the proposed system at various temporal granularities when modeling short, medium, and long analysis windows, corresponding to 10, 21, and 42 utterances, respectively. The proposed method reaches comparable performance with previous state-of-the-art approaches and depicts explainable properties with respect to the depression outcome. The findings from this work may benefit clinicians by providing additional intuitions during joint human-ML decision-making tasks.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Kexin Feng et al.",
      "keywords": "Vowel; Convolutional neural network; Computer science; Pooling; Speech recognition; Embedding; Artificial intelligence; Natural language processing; Depression (economics); Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.15261",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399354140",
      "doi": "10.48550/arxiv.2406.00062",
      "title": "Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study",
      "abstract": "Automated clinical text anonymization has the potential to unlock the widespread sharing of textual health data for secondary usage while assuring patient privacy and safety. Despite the proposal of many complex and theoretically successful anonymization solutions in literature, these techniques remain flawed. As such, clinical institutions are still reluctant to apply them for open access to their data. Recent advances in developing Large Language Models (LLMs) pose a promising opportunity to further the field, given their capability to perform various tasks. This paper proposes six new evaluation metrics tailored to the challenges of generative anonymization with LLMs. Moreover, we present a comparative study of LLM-based methods, testing them against two baseline techniques. Our results establish LLM-based models as a reliable alternative to common approaches, paving the way toward trustworthy anonymization of clinical text.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "David Pissarra et al.",
      "keywords": "Computer science; Data anonymization; Natural language processing; Data science; Internet privacy; Information privacy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.00062",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4321392955",
      "doi": "10.48550/arxiv.2302.08976",
      "title": "Welfare and Fairness Dynamics in Federated Learning: A Client Selection Perspective",
      "abstract": "Federated learning (FL) is a privacy-preserving learning technique that enables distributed computing devices to train shared learning models across data silos collaboratively. Existing FL works mostly focus on designing advanced FL algorithms to improve the model performance. However, the economic considerations of the clients, such as fairness and incentive, are yet to be fully explored. Without such considerations, self-motivated clients may lose interest and leave the federation. To address this problem, we designed a novel incentive mechanism that involves a client selection process to remove low-quality clients and a money transfer process to ensure a fair reward distribution. Our experimental results strongly demonstrate that the proposed incentive mechanism can effectively improve the duration and fairness of the federation.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yash Travadi et al.",
      "keywords": "Incentive; Computer science; Process (computing); Perspective (graphical); Selection (genetic algorithm); Quality (philosophy); Welfare; Federated learning; Mechanism (biology); Knowledge management; Microeconomics; Artificial intelligence; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.08976",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387725492",
      "doi": "10.48550/arxiv.2310.10549",
      "title": "Applications of Distributed Machine Learning for the Internet-of-Things: A Comprehensive Survey",
      "abstract": "The emergence of new services and applications in emerging wireless networks (e.g., beyond 5G and 6G) has shown a growing demand for the usage of artificial intelligence (AI) in the Internet of Things (IoT). However, the proliferation of massive IoT connections and the availability of computing resources distributed across future IoT systems have strongly demanded the development of distributed AI for better IoT services and applications. Therefore, existing AI-enabled IoT systems can be enhanced by implementing distributed machine learning (aka distributed learning) approaches. This work aims to provide a comprehensive survey on distributed learning for IoT services and applications in emerging networks. In particular, we first provide a background of machine learning and present a preliminary to typical distributed learning approaches, such as federated learning, multi-agent reinforcement learning, and distributed inference. Then, we provide an extensive review of distributed learning for critical IoT services (e.g., data sharing and computation offloading, localization, mobile crowdsensing, and security and privacy) and IoT applications (e.g., smart healthcare, smart grid, autonomous vehicle, aerial IoT networks, and smart industry). From the reviewed literature, we also present critical challenges of distributed learning for IoT and propose several promising solutions and research directions in this emerging area.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Mai Le et al.",
      "keywords": "Computer science; Distributed computing; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.10549",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4224928110",
      "doi": "10.48550/arxiv.2204.11374",
      "title": "Stochastic Optimization Approaches for an Operating Room and Anesthesiologist Scheduling Problem",
      "abstract": "We propose combined allocation, assignment, sequencing, and scheduling problems under uncertainty involving multiple operation rooms (ORs), anesthesiologists, and surgeries, as well as methodologies for solving such problems. Specifically, given sets of ORs, regular anesthesiologists, on-call anesthesiologists, and surgeries, our methodologies solve the following decision-making problems simultaneously: (1) an allocation problem that decides which ORs to open and which on-call anesthesiologists to call in, (2) an assignment problem that assigns an OR and an anesthesiologist to each surgery, and (3) a sequencing and scheduling problem that determines the order of surgeries and their scheduled start times in each OR. To address uncertainty of each surgery's duration, we propose and analyze stochastic programming (SP) and distributionally robust optimization (DRO) models with both risk-neutral and risk-averse objectives. We obtain near-optimal solutions of our SP models using sample average approximation and propose a computationally efficient column-and-constraint generation method to solve our DRO models. In addition, we derive symmetry-breaking constraints that improve the models' solvability. Using real-world, publicly available surgery data and a case study from a health system in New York, we conduct extensive computational experiments comparing the proposed methodologies empirically and theoretically, demonstrating where significant performance improvements can be gained. Additionally, we derive several managerial insights relevant to practice.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Man Yiu et al.",
      "keywords": "Mathematical optimization; Scheduling (production processes); Computer science; Column generation; Robust optimization; Stochastic programming; Constraint (computer-aided design); Job shop scheduling; Operations research; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.11374",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4300597891",
      "doi": "10.48550/arxiv.2108.00588",
      "title": "Measuring User Experience Inclusivity in Human-AI Interaction via Five User Problem-Solving Styles",
      "abstract": "Motivations: Recent research has emerged on generally how to improve AI product user experiences, but relatively little is known about an AI product's inclusivity. For example, what kinds of users does it support well, and who does it leave out? And what changes in the product would make it more inclusive? Objectives: Our overall objective is to help fill this gap, investigating what kinds of diverse users an AI product leaves out, and how to act upon that knowledge. To bring actionability to our findings, we focus on users' diversity of problem-solving attributes. Thus, our specific objectives were: (1) to reveal whether participants with diverse problem-solving styles were left behind in a set of AI products; and (2) to relate participants' problem-solving diversity to their demographic diversity, specifically, gender and age. Methods: We performed 18 experiments, discarding two that failed manipulation checks. Each experiment was a 2x2 factorial experiment with online participants. Each experiment compared two AI products: one deliberately violating an HAI guideline and the other applying the guideline. For our first objective, we analyzed how much each AI product gained/lost inclusivity compared to its counterpart, where inclusivity was supportiveness to participants with particular problem-solving styles. For our second objective, we analyzed how participants' problem-solving styles aligned with their demographics, namely their genders and ages. Results &amp; Implications: Participants' diverse problem-solving styles revealed six types of inclusivity results: (1) the AI products that followed an HAI guideline were almost always more inclusive across diversity of problem-solving styles than the products that did not follow that guideline-but the \"who\" that got most of the inclusivity varied widely by guideline and by problem-solving style...",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "A. W. Anderson et al.",
      "keywords": "Style (visual arts); Cognitive science; Cognition; Psychology; Cognitive psychology; Computer science; Neuroscience; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2108.00588",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391272065",
      "doi": "10.48550/arxiv.2401.13699",
      "title": "Generative AI-Driven Human Digital Twin in IoT-Healthcare: A Comprehensive Survey",
      "abstract": "The Internet of things (IoT) can significantly enhance the quality of human life, specifically in healthcare, attracting extensive attentions to IoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as an innovative paradigm that can comprehensively characterize the replication of the individual human body in the digital world and reflect its physical status in real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the application of healthcare monitoring by acting as a versatile and vivid human digital testbed, simulating the outcomes and guiding the practical treatments. However, successfully establishing HDT requires high-fidelity virtual modeling and strong information interactions but possibly with scarce, biased and noisy data. Fortunately, a recent popular technology called generative artificial intelligence (GAI) may be a promising solution because it can leverage advanced AI algorithms to automatically create, manipulate, and modify valuable while diverse data. This survey particularly focuses on the implementation of GAI-driven HDT in IoT-healthcare. We start by introducing the background of IoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the fundamental techniques and present the overall framework of GAI-driven HDT. After that, we explore the realization of GAI-driven HDT in detail, including GAI-enabled data acquisition, communication, data management, digital modeling, and data analysis. Besides, we discuss typical IoT-healthcare applications that can be revolutionized by GAI-driven HDT, namely personalized health monitoring and diagnosis, personalized prescription, and personalized rehabilitation. Finally, we conclude this survey by highlighting some future research directions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiayuan Chen et al.",
      "keywords": "Computer science; Health care; Data sharing; Data science; Leverage (statistics); Internet of Things; Generative grammar; Artificial intelligence; Human\u2013computer interaction; Computer security; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.13699",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4401202544",
      "doi": "10.48550/arxiv.2407.20181",
      "title": "Blockchain for Large Language Model Security and Safety: A Holistic Survey",
      "abstract": "With the growing development and deployment of large language models (LLMs) in both industrial and academic fields, their security and safety concerns have become increasingly critical. However, recent studies indicate that LLMs face numerous vulnerabilities, including data poisoning, prompt injections, and unauthorized data exposure, which conventional methods have struggled to address fully. In parallel, blockchain technology, known for its data immutability and decentralized structure, offers a promising foundation for safeguarding LLMs. In this survey, we aim to comprehensively assess how to leverage blockchain technology to enhance LLMs' security and safety. Besides, we propose a new taxonomy of blockchain for large language models (BC4LLMs) to systematically categorize related works in this emerging field. Our analysis includes novel frameworks and definitions to delineate security and safety in the context of BC4LLMs, highlighting potential research directions and challenges at this intersection. Through this study, we aim to stimulate targeted advancements in blockchain-integrated LLM security.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Caleb Geren et al.",
      "keywords": "Blockchain; Computer security; Computer science; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.20181",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386907339",
      "doi": "10.48550/arxiv.2309.10283",
      "title": "FRAMU: Attention-based Machine Unlearning using Federated Reinforcement Learning",
      "abstract": "Machine Unlearning is an emerging field that addresses data privacy issues by enabling the removal of private or irrelevant data from the Machine Learning process. Challenges related to privacy and model efficiency arise from the use of outdated, private, and irrelevant data. These issues compromise both the accuracy and the computational efficiency of models in both Machine Learning and Unlearning. To mitigate these challenges, we introduce a novel framework, Attention-based Machine Unlearning using Federated Reinforcement Learning (FRAMU). This framework incorporates adaptive learning mechanisms, privacy preservation techniques, and optimization strategies, making it a well-rounded solution for handling various data sources, either single-modality or multi-modality, while maintaining accuracy and privacy. FRAMU's strength lies in its adaptability to fluctuating data landscapes, its ability to unlearn outdated, private, or irrelevant data, and its support for continual model evolution without compromising privacy. Our experiments, conducted on both single-modality and multi-modality datasets, revealed that FRAMU significantly outperformed baseline models. Additional assessments of convergence behavior and optimization strategies further validate the framework's utility in federated learning applications. Overall, FRAMU advances Machine Unlearning by offering a robust, privacy-preserving solution that optimizes model performance while also addressing key challenges in dynamic data environments.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Thanveer Shaik et al.",
      "keywords": "Computer science; Reinforcement learning; Artificial intelligence; Machine learning; Modality (human\u2013computer interaction); Compromise; Information privacy; Adaptability; Process (computing); Field (mathematics); Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.10283",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392271351",
      "doi": "10.48550/arxiv.2402.17502",
      "title": "FedLPPA: Learning Personalized Prompt and Aggregation for Federated Weakly-supervised Medical Image Segmentation",
      "abstract": "Federated learning (FL) effectively mitigates the data silo challenge brought about by policies and privacy concerns, implicitly harnessing more data for deep model training. However, traditional centralized FL models grapple with diverse multi-center data, especially in the face of significant data heterogeneity, notably in medical contexts. In the realm of medical image segmentation, the growing imperative to curtail annotation costs has amplified the importance of weakly-supervised techniques which utilize sparse annotations such as points, scribbles, etc. A pragmatic FL paradigm shall accommodate diverse annotation formats across different sites, which research topic remains under-investigated. In such context, we propose a novel personalized FL framework with learnable prompt and aggregation (FedLPPA) to uniformly leverage heterogeneous weak supervision for medical image segmentation. In FedLPPA, a learnable universal knowledge prompt is maintained, complemented by multiple learnable personalized data distribution prompts and prompts representing the supervision sparsity. Integrated with sample features through a dual-attention mechanism, those prompts empower each local task decoder to adeptly adjust to both the local distribution and the supervision form. Concurrently, a dual-decoder strategy, predicated on prompt similarity, is introduced for enhancing the generation of pseudo-labels in weakly-supervised learning, alleviating overfitting and noise accumulation inherent to local data, while an adaptable aggregation method is employed to customize the task decoder on a parameter-wise basis. Extensive experiments on four distinct medical image segmentation tasks involving different modalities underscore the superiority of FedLPPA, with its efficacy closely parallels that of fully supervised centralized training. Our code and data will be available.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Li Lin et al.",
      "keywords": "Segmentation; Computer science; Artificial intelligence; Image (mathematics); Federated learning; Pattern recognition (psychology); Information retrieval",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.17502",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400064792",
      "doi": "10.48550/arxiv.2406.17181",
      "title": "FacePsy: An Open-Source Affective Mobile Sensing System -- Analyzing Facial Behavior and Head Gesture for Depression Detection in Naturalistic Settings",
      "abstract": "Depression, a prevalent and complex mental health issue affecting millions worldwide, presents significant challenges for detection and monitoring. While facial expressions have shown promise in laboratory settings for identifying depression, their potential in real-world applications remains largely unexplored due to the difficulties in developing efficient mobile systems. In this study, we aim to introduce FacePsy, an open-source mobile sensing system designed to capture affective inferences by analyzing sophisticated features and generating real-time data on facial behavior landmarks, eye movements, and head gestures -- all within the naturalistic context of smartphone usage with 25 participants. Through rigorous development, testing, and optimization, we identified eye-open states, head gestures, smile expressions, and specific Action Units (2, 6, 7, 12, 15, and 17) as significant indicators of depressive episodes (AUROC=81%). Our regression model predicting PHQ-9 scores achieved moderate accuracy, with a Mean Absolute Error of 3.08. Our findings offer valuable insights and implications for enhancing deployable and usable mobile affective sensing systems, ultimately improving mental health monitoring, prediction, and just-in-time adaptive interventions for researchers and developers in healthcare.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Rahul Islam et al.",
      "keywords": "Gesture; Open source; Facial expression; Computer science; Head (geology); Depression (economics); Psychology; Computer vision; Human\u2013computer interaction; Communication; Cognitive psychology; Artificial intelligence; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.17181",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286890870",
      "doi": "10.48550/arxiv.2110.15087",
      "title": "MOOMIN: Deep Molecular Omics Network for Anti-Cancer Drug Combination Therapy",
      "abstract": "We propose the molecular omics network (MOOMIN) a multimodal graph neural network used by AstraZeneca oncologists to predict the synergy of drug combinations for cancer treatment. Our model learns drug representations at multiple scales based on a drug-protein interaction network and metadata. Structural properties of compounds and proteins are encoded to create vertex features for a message-passing scheme that operates on the bipartite interaction graph. Propagated messages form multi-resolution drug representations which we utilized to create drug pair descriptors. By conditioning the drug combination representations on the cancer cell type we define a synergy scoring function that can inductively score unseen pairs of drugs. Experimental results on the synergy scoring task demonstrate that MOOMIN outperforms state-of-the-art graph fingerprinting, proximity preserving node embedding, and existing deep learning approaches. Further results establish that the predictive performance of our model is robust to hyperparameter changes. We demonstrate that the model makes high-quality predictions over a wide range of cancer cell line tissues, out-of-sample predictions can be validated with external synergy databases, and that the proposed model is data efficient at learning.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Benedek R\u00f3zemberczki et al.",
      "keywords": "Bipartite graph; Computer science; Hyperparameter; Metadata; Artificial intelligence; Graph; Machine learning; Embedding; Graph embedding; Artificial neural network; Node (physics); Cancer drugs; Drug; Theoretical computer science; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.15087",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4292216206",
      "doi": "10.48550/arxiv.2208.07626",
      "title": "Algorithmic Assistance with Recommendation-Dependent Preferences",
      "abstract": "When an algorithm provides risk assessments, we typically think of them as helpful inputs to human decisions, such as when risk scores are presented to judges or doctors. However, a decision-maker may react not only to the information provided by the algorithm. The decision-maker may also view the algorithmic recommendation as a default action, making it costly for them to deviate, such as when a judge is reluctant to overrule a high-risk assessment for a defendant or a doctor fears the consequences of deviating from recommended procedures. To address such unintended consequences of algorithmic assistance, we propose a model of joint human-machine decision-making. Within this model, we consider the effect and design of algorithmic recommendations when they affect choices not just by shifting beliefs, but also by altering preferences. We motivate this assumption from institutional factors, such as a desire to avoid audits, as well as from well-established models in behavioral science that predict loss aversion relative to a reference point. We show that recommendation-dependent preferences create inefficiencies where the decision-maker is overly responsive to the recommendation. As a remedy, we discuss algorithms that strategically withhold recommendations and show how they can improve the quality of final decisions. Concretely, we prove that an intuitive algorithm achieves minimax optimality by sending recommendations only when it is confident that their implementation would improve over an unassisted baseline decision.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Bryce McLaughlin et al.",
      "keywords": "Computer science; Decision maker; Set (abstract data type); Audit; Action (physics); Affect (linguistics); Quality (philosophy); Point (geometry); Unintended consequences; Risk aversion (psychology); Risk analysis (engineering); Actuarial science; Operations research; Psychology; Management science; Expected utility hypothesis; Economics; Business; Mathematical economics; Mathematics; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.07626",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4360819153",
      "doi": "10.48550/arxiv.2303.12206",
      "title": "Policy Optimization for Personalized Interventions in Behavioral Health",
      "abstract": "Behavioral health interventions, delivered through digital platforms, have the potential to significantly improve health outcomes, through education, motivation, reminders, and outreach. We study the problem of optimizing personalized interventions for patients to maximize a long-term outcome, where interventions are costly and capacity-constrained. We assume we have access to a historical dataset collected from an initial pilot study. We present a new approach for this problem that we dub DecompPI, which decomposes the state space for a system of patients to the individual level and then approximates one step of policy iteration. Implementing DecompPI simply consists of a prediction task using the dataset, alleviating the need for online experimentation. DecompPI is a generic model-free algorithm that can be used irrespective of the underlying patient behavior model. We derive theoretical guarantees on a simple, special case of the model that is representative of our problem setting. When the initial policy used to collect the data is randomized, we establish an approximation guarantee for DecompPI with respect to the improvement beyond a null policy that does not allocate interventions. We show that this guarantee is robust to estimation errors. We then conduct a rigorous empirical case study using real-world data from a mobile health platform for improving treatment adherence for tuberculosis. Using a validated simulation model, we demonstrate that DecompPI can provide the same efficacy as the status quo approach with approximately half the capacity of interventions. DecompPI is simple and easy to implement for an organization aiming to improve long-term behavior through targeted interventions, and this paper demonstrates its strong performance both theoretically and empirically, particularly in resource-limited settings.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jackie Baek et al.",
      "keywords": "Psychological intervention; Leverage (statistics); Computer science; Mathematical optimization; Baseline (sea); Intervention (counseling); Machine learning; Medicine; Nursing; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.12206",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400433789",
      "doi": "10.48550/arxiv.2407.03545",
      "title": "On Evaluating Explanation Utility for Human-AI Decision Making in NLP",
      "abstract": "Is explainability a false promise? This debate has emerged from the insufficient evidence that explanations help people in situations they are introduced for. More human-centered, application-grounded evaluations of explanations are needed to settle this. Yet, with no established guidelines for such studies in NLP, researchers accustomed to standardized proxy evaluations must discover appropriate measurements, tasks, datasets, and sensible models for human-AI teams in their studies. To aid with this, we first review existing metrics suitable for application-grounded evaluation. We then establish criteria to select appropriate datasets, and using them, we find that only 4 out of over 50 datasets available for explainability research in NLP meet them. We then demonstrate the importance of reassessing the state of the art to form and study human-AI teams: teaming people with models for certain tasks might only now start to make sense, and for others, it remains unsound. Finally, we present the exemplar studies of human-AI decision-making for one of the identified tasks -- verifying the correctness of a legal claim given a contract. Our results show that providing AI predictions, with or without explanations, does not cause decision makers to speed up their work without compromising performance. We argue for revisiting the setup of human-AI teams and improving automatic deferral of instances to AI, where explanations could play a useful role.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Fateme Hashemi Chaleshtori et al.",
      "keywords": "Artificial intelligence; Natural language processing; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.03545",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414896346",
      "doi": "10.48550/arxiv.2506.01364",
      "title": "Unraveling Spatio-Temporal Foundation Models via the Pipeline Lens: A Comprehensive Review",
      "abstract": "Spatio-temporal deep learning models aims to utilize useful patterns in such data to support tasks like prediction. However, previous deep learning models designed for specific tasks typically require separate training for each use case, leading to increased computational and storage costs. To address this issue, spatio-temporal foundation models have emerged, offering a unified framework capable of solving multiple spatio-temporal tasks. These foundation models achieve remarkable success by learning general knowledge with spatio-temporal data or transferring the general capabilities of pre-trained language models. While previous surveys have explored spatio-temporal data and methodologies separately, they have ignored a comprehensive examination of how foundation models are designed, selected, pre-trained, and adapted. As a result, the overall pipeline for spatio-temporal foundation models remains unclear. To bridge this gap, we innovatively provide an up-to-date review of previous spatio-temporal foundation models from the pipeline perspective. The pipeline begins with an introduction to different types of spatio-temporal data, followed by details of data preprocessing and embedding techniques. The pipeline then presents a novel data property taxonomy to divide existing methods according to data sources and dependencies, providing efficient and effective model design and selection for researchers. On this basis, we further illustrate the training objectives of primitive models, as well as the adaptation techniques of transferred models. Overall, our survey provides a clear and structured pipeline to understand the connection between core elements of spatio-temporal foundation models while guiding researchers to get started quickly. Additionally, we introduce emerging opportunities such as multi-objective training in the field of spatio-temporal foundation models.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuchen Fang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01364",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387356343",
      "doi": "10.48550/arxiv.2310.02174",
      "title": "Ask Again, Then Fail: Large Language Models' Vacillations in Judgment",
      "abstract": "We observe that current conversational language models often waver in their judgments when faced with follow-up questions, even if the original judgment was correct. This wavering presents a significant challenge for generating reliable responses and building user trust. To comprehensively assess this issue, we introduce a \\textsc{Follow-up Questioning Mechanism} along with two metrics to quantify this inconsistency, confirming its widespread presence in current language models. To mitigate this issue, we explore various prompting strategies for closed-source models; moreover, we develop a training-based framework \\textsc{Unwavering-FQ} that teaches language models to maintain their originally correct judgments through synthesized high-quality preference data. Our experimental results confirm the effectiveness of our framework and its ability to enhance the general capabilities of models.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Qiming Xie et al.",
      "keywords": "Judgement; Ask price; Computer science; Preference; Quality (philosophy); Language model; Mechanism (biology); Econometrics; Epistemology; Artificial intelligence; Mathematics; Statistics; Economics; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.02174",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2935782201",
      "doi": "10.48550/arxiv.1904.09525",
      "title": "Recovery of the fetal electrocardiogram for morphological analysis from two trans-abdominal channels via optimal shrinkage",
      "abstract": "We propose a novel algorithm to recover fetal electrocardiogram (ECG) for both the fetal heart rate analysis and morphological analysis of its waveform from two or three trans-abdominal maternal ECG channels. We design an algorithm based on the optimal-shrinkage and the nonlocal Euclidean median under the wave-shape manifold model. For the fetal heart rate analysis, the algorithm is evaluated on publicly available database, 2013 PhyioNet/Computing in Cardiology Challenge, set A. For the morphological analysis, we propose to simulate semi-real databases by mixing the MIT-BIH Normal Sinus Rhythm Database and MITDB Arrhythmia Database. For the fetal R peak detection, the proposed algorithm outperforms all algorithms under comparison. For the morphological analysis, the algorithm provides an encouraging result in recovery of the fetal ECG waveform, including PR, QT and ST intervals, even when the fetus has arrhythmia. To the best of our knowledge, this is the first work focusing on recovering the fetal ECG for morphological analysis from two or three channels with an algorithm potentially applicable for continuous fetal electrocardiographic monitoring, which creates the potential for long term monitoring purpose.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Pei-Chun Su et al.",
      "keywords": "Waveform; Fetus; Normal Sinus Rhythm; Algorithm; Computer science; Fetal heart rate; Shrinkage; Electrocardiography; Pattern recognition (psychology); Cardiology; Internal medicine; Artificial intelligence; Medicine; Heart rate; Machine learning; Pregnancy; Atrial fibrillation",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1904.09525",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400375220",
      "doi": "10.48550/arxiv.2407.02397",
      "title": "Learning to Refine with Fine-Grained Natural Language Feedback",
      "abstract": "Recent work has explored the capability of large language models (LLMs) to identify and correct errors in LLM-generated responses. These refinement approaches frequently evaluate what sizes of models are able to do refinement for what problems, but less attention is paid to what effective feedback for refinement looks like. In this work, we propose looking at refinement with feedback as a composition of three distinct LLM competencies: (1) detection of bad generations; (2) fine-grained natural language critique generation; (3) refining with fine-grained feedback. The first step can be implemented with a high-performing discriminative model and steps 2 and 3 can be implemented either via prompted or fine-tuned LLMs. A key property of the proposed Detect, Critique, Refine (\"DCR\") method is that the step 2 critique model can give fine-grained feedback about errors, made possible by offloading the discrimination to a separate model in step 1. We show that models of different capabilities benefit from refining with DCR on the task of improving factual consistency of document grounded summaries. Overall, DCR consistently outperforms existing end-to-end refinement approaches and current trained models not fine-tuned for factuality critiquing.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Manya Wadhwa et al.",
      "keywords": "Natural (archaeology); Computer science; Natural language processing; Artificial intelligence; Geology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.02397",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4295992348",
      "doi": "10.48550/arxiv.2209.06378",
      "title": "RMExplorer: A Visual Analytics Approach to Explore the Performance and the Fairness of Disease Risk Models on Population Subgroups",
      "abstract": "Disease risk models can identify high-risk patients and help clinicians provide more personalized care. However, risk models developed on one dataset may not generalize across diverse subpopulations of patients in different datasets and may have unexpected performance. It is challenging for clinical researchers to inspect risk models across different subgroups without any tools. Therefore, we developed an interactive visualization system called RMExplorer (Risk Model Explorer) to enable interactive risk model assessment. Specifically, the system allows users to define subgroups of patients by selecting clinical, demographic, or other characteristics, to explore the performance and fairness of risk models on the subgroups, and to understand the feature contributions to risk scores. To demonstrate the usefulness of the tool, we conduct a case study, where we use RMExplorer to explore three atrial fibrillation risk models by applying them to the UK Biobank dataset of 445,329 individuals. RMExplorer can help researchers to evaluate the performance and biases of risk models on subpopulations of interest in their data.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Bum Chul Kwon et al.",
      "keywords": "Biobank; Visual analytics; Computer science; Disease; Population; Visualization; Risk assessment; Data science; Risk analysis (engineering); Data mining; Medicine; Bioinformatics; Pathology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.06378",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403813925",
      "doi": "10.48550/arxiv.2409.19756",
      "title": "Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System",
      "abstract": "The concept of a learning healthcare system (LHS) envisions a self-improving network where multimodal data from patient care are continuously analyzed to enhance future healthcare outcomes. However, realizing this vision faces significant challenges in data sharing and privacy protection. Privacy-Preserving Federated Learning (PPFL) is a transformative and promising approach that has the potential to address these challenges by enabling collaborative learning from decentralized data while safeguarding patient privacy. This paper proposes a vision for integrating PPFL into the healthcare ecosystem to achieve a truly LHS as defined by the Institute of Medicine (IOM) Roundtable.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ravi Madduri et al.",
      "keywords": "Federated learning; Computer science; Health care; Healthcare system; Internet privacy; Information privacy; Computer security; Artificial intelligence; Political science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.19756",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312107683",
      "doi": "10.48550/arxiv.2212.10839",
      "title": "Consistent Range Approximation for Fair Predictive Modeling",
      "abstract": "This paper proposes a novel framework for certifying the fairness of predictive models trained on biased data. It draws from query answering for incomplete and inconsistent databases to formulate the problem of consistent range approximation (CRA) of fairness queries for a predictive model on a target population. The framework employs background knowledge of the data collection process and biased data, working with or without limited statistics about the target population, to compute a range of answers for fairness queries. Using CRA, the framework builds predictive models that are certifiably fair on the target population, regardless of the availability of external data during training. The framework's efficacy is demonstrated through evaluations on real data, showing substantial improvement over existing state-of-the-art methods.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiongli Zhu et al.",
      "keywords": "Computer science; Range (aeronautics); Population; Process (computing); Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.10839",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415065933",
      "doi": "10.48550/arxiv.2504.16504",
      "title": "Intelligent Depression Prevention via LLM-Based Dialogue Analysis: Overcoming the Limitations of Scale-Dependent Diagnosis through Precise Emotional Pattern Recognition",
      "abstract": "Existing depression screening predominantly relies on standardized questionnaires (e.g., PHQ-9, BDI), which suffer from high misdiagnosis rates (18-34% in clinical studies) due to their static, symptom-counting nature and susceptibility to patient recall bias. This paper presents an AI-powered depression prevention system that leverages large language models (LLMs) to analyze real-time conversational cues--including subtle emotional expressions (e.g., micro-sentiment shifts, self-referential language patterns)--for more accurate and dynamic mental state assessment. Our system achieves three key innovations: (1) Continuous monitoring through natural dialogue, detecting depression-indicative linguistic features (anhedonia markers, hopelessness semantics) with 89% precision (vs. 72% for PHQ-9); (2) Adaptive risk stratification that updates severity levels based on conversational context, reducing false positives by 41% compared to scale-based thresholds; and (3) Personalized intervention strategies tailored to users' emotional granularity, demonstrating 2.3x higher adherence rates than generic advice. Clinical validation with 450 participants shows the system identifies 92% of at-risk cases missed by traditional scales, while its explainable AI interface bridges the gap between automated analysis and clinician judgment. This work establishes conversational AI as a paradigm shift from episodic scale-dependent diagnosis to continuous, emotionally intelligent mental health monitoring.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhang Zhong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.16504",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395444199",
      "doi": "10.48550/arxiv.2404.14563",
      "title": "Exploring Algorithmic Explainability: Generating Explainable AI Insights for Personalized Clinical Decision Support Focused on Cannabis Intoxication in Young Adults",
      "abstract": "This study explores the possibility of facilitating algorithmic decision-making by combining interpretable artificial intelligence (XAI) techniques with sensor data, with the aim of providing researchers and clinicians with personalized analyses of cannabis intoxication behavior. SHAP analyzes the importance and quantifies the impact of specific factors such as environmental noise or heart rate, enabling clinicians to pinpoint influential behaviors and environmental conditions. SkopeRules simplify the understanding of cannabis use for a specific activity or environmental use. Decision trees provide a clear visualization of how factors interact to influence cannabis consumption. Counterfactual models help identify key changes in behaviors or conditions that may alter cannabis use outcomes, to guide effective individualized intervention strategies. This multidimensional analytical approach not only unveils changes in behavioral and physiological states after cannabis use, such as frequent fluctuations in activity states, nontraditional sleep patterns, and specific use habits at different times and places, but also highlights the significance of individual differences in responses to cannabis use. These insights carry profound implications for clinicians seeking to gain a deeper understanding of the diverse needs of their patients and for tailoring precisely targeted intervention strategies. Furthermore, our findings highlight the pivotal role that XAI technologies could play in enhancing the transparency and interpretability of Clinical Decision Support Systems (CDSS), with a particular focus on substance misuse treatment. This research significantly contributes to ongoing initiatives aimed at advancing clinical practices that aim to prevent and reduce cannabis-related harms to health, positioning XAI as a supportive tool for clinicians and researchers alike.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Tongze Zhang et al.",
      "keywords": "Cannabis; Psychology; Computer science; Medicine; Artificial intelligence; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.14563",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4381587804",
      "doi": "10.48550/arxiv.2306.10043",
      "title": "Unraveling the Interconnected Axes of Heterogeneity in Machine Learning for Democratic and Inclusive Advancements",
      "abstract": "The growing utilization of machine learning (ML) in decision-making processes raises questions about its benefits to society. In this study, we identify and analyze three axes of heterogeneity that significantly influence the trajectory of ML products. These axes are i) values, culture and regulations, ii) data composition, and iii) resource and infrastructure capacity. We demonstrate how these axes are interdependent and mutually influence one another, emphasizing the need to consider and address them jointly. Unfortunately, the current research landscape falls short in this regard, often failing to adopt a holistic approach. We examine the prevalent practices and methodologies that skew these axes in favor of a selected few, resulting in power concentration, homogenized control, and increased dependency. We discuss how this fragmented study of the three axes poses a significant challenge, leading to an impractical solution space that lacks reflection of real-world scenarios. Addressing these issues is crucial to ensure a more comprehensive understanding of the interconnected nature of society and to foster the democratic and inclusive development of ML systems that are more aligned with real-world complexities and its diverse requirements.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Maryam Molamohammadi et al.",
      "keywords": "Interdependence; Democracy; Resource (disambiguation); Skew; Computer science; Space (punctuation); Control (management); Dependency (UML); Process management; Management science; Political science; Artificial intelligence; Business; Sociology; Engineering; Social science; Politics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.10043",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416608678",
      "doi": "10.48550/arxiv.2505.23030",
      "title": "Can Modern NLP Systems Reliably Annotate Chest Radiography Exams? A Pre-Purchase Evaluation and Comparative Study of Solutions from AWS, Google, Azure, John Snow Labs, and Open-Source Models on an Independent Pediatric Dataset",
      "abstract": "General-purpose clinical natural language processing (NLP) tools are increasingly used for the automatic labeling of clinical reports. However, independent evaluations for specific tasks, such as pediatric chest radiograph (CXR) report labeling, are limited. This study compares four commercial clinical NLP systems - Amazon Comprehend Medical (AWS), Google Healthcare NLP (GC), Azure Clinical NLP (AZ), and SparkNLP (SP) - for entity extraction and assertion detection in pediatric CXR reports. Additionally, CheXpert and CheXbert, two dedicated chest radiograph report labelers, were evaluated on the same task using CheXpert-defined labels. We analyzed 95,008 pediatric CXR reports from a large academic pediatric hospital. Entities and assertion statuses (positive, negative, uncertain) from the findings and impression sections were extracted by the NLP systems, with impression section entities mapped to 12 disease categories and a No Findings category. CheXpert and CheXbert extracted the same 13 categories. Outputs were compared using Fleiss Kappa and accuracy against a consensus pseudo-ground truth. Significant differences were found in the number of extracted entities and assertion distributions across NLP systems. SP extracted 49,688 unique entities, GC 16,477, AZ 31,543, and AWS 27,216. Assertion accuracy across models averaged around 62%, with SP highest (76%) and AWS lowest (50%). CheXpert and CheXbert achieved 56% accuracy. Considerable variability in performance highlights the need for careful validation and review before deploying NLP tools for clinical report labeling.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Shruti Hegde et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23030",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416610428",
      "doi": "10.48550/arxiv.2505.23334",
      "title": "X2Graph for Cancer Subtyping Prediction on Biological Tabular Data",
      "abstract": "Despite the transformative impact of deep learning on text, audio, and image datasets, its dominance in tabular data, especially in the medical domain where data are often scarce, remains less clear. In this paper, we propose X2Graph, a novel deep learning method that achieves strong performance on small biological tabular datasets. X2Graph leverages external knowledge about the relationships between table columns, such as gene interactions, to convert each sample into a graph structure. This transformation enables the application of standard message passing algorithms for graph modeling. Our X2Graph method demonstrates superior performance compared to existing tree-based and deep learning methods across three cancer subtyping datasets.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Tu Bui et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23334",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416526775",
      "doi": "10.48550/arxiv.2504.04717",
      "title": "Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models",
      "abstract": "Recent advancements in large language models (LLMs) have revolutionized their ability to handle single-turn tasks, yet real-world applications demand sophisticated multi-turn interactions. This survey provides a comprehensive review of recent advancements in evaluating and enhancing multi-turn interactions in LLMs. Focusing on task-specific scenarios, from instruction following in diverse domains such as math and coding to complex conversational engagements in roleplay, healthcare, education, and even adversarial jailbreak settings, we systematically examine the challenges of maintaining context, coherence, fairness, and responsiveness over prolonged dialogues. The paper organizes current benchmarks and datasets into coherent categories that reflect the evolving landscape of multi-turn dialogue evaluation. In addition, we review a range of enhancement methodologies under multi-turn settings, including model-centric strategies (contextual learning, supervised fine-tuning, reinforcement learning, and new architectures), external integration approaches (memory-augmented, retrieval-based methods, and knowledge graph), and agent-based techniques for collaborative interactions. Finally, we discuss open challenges and propose future directions for research to further advance the robustness and effectiveness of multi-turn interactions in LLMs. Related resources and papers are available at https://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Y. X. Li et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.04717",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402705627",
      "doi": "10.48550/arxiv.2408.15244",
      "title": "Misrepresented Technological Solutions in Imagined Futures: The Origins and Dangers of AI Hype in the Research Community",
      "abstract": "Technology does not exist in a vacuum; technological development, media representation, public perception, and governmental regulation cyclically influence each other to produce the collective understanding of a technology's capabilities, utilities, and risks. When these capabilities are overestimated, there is an enhanced risk of subjecting the public to dangerous or harmful technology, artificially restricting research and development directions, and enabling misguided or detrimental policy. The dangers of technological hype are particularly relevant in the rapidly evolving space of AI. Centering the research community as a key player in the development and proliferation of hype, we examine the origins and risks of AI hype to the research community and society more broadly and propose a set of measures that researchers, regulators, and the public can take to mitigate these risks and reduce the prevalence of unfounded claims about the technology.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Savannah Thais",
      "keywords": "Futures contract; Sociology; Political science; Media studies; Economics; Financial economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.15244",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287990760",
      "doi": "10.48550/arxiv.1912.10552",
      "title": "Hierarchical Target-Attentive Diagnosis Prediction in Heterogeneous\\n Information Networks",
      "abstract": "We introduce HTAD, a novel model for diagnosis prediction using Electronic\\nHealth Records (EHR) represented as Heterogeneous Information Networks. Recent\\nstudies on modeling EHR have shown success in automatically learning\\nrepresentations of the clinical records in order to avoid the need for manual\\nfeature selection. However, these representations are often learned and\\naggregated without specificity for the different possible targets being\\npredicted. Our model introduces a target-aware hierarchical attention mechanism\\nthat allows it to learn to attend to the most important clinical records when\\naggregating their representations for prediction of a diagnosis.\\n We evaluate our model using a publicly available benchmark dataset and\\ndemonstrate that the use of target-aware attention significantly improves\\nperformance compared to the current state of the art. Additionally, we propose\\na method for incorporating non-categorical data into our predictions and\\ndemonstrate that this technique leads to further performance improvements.\\nLastly, we demonstrate that the predictions made by our proposed model are\\neasily interpretable.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Anahita Hosseini et al.",
      "keywords": "Computer science; Categorical variable; Benchmark (surveying); Health records; Machine learning; Artificial intelligence; Feature selection; Data mining; Feature (linguistics); Selection (genetic algorithm)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1912.10552",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415024667",
      "doi": "10.48550/arxiv.2505.14659",
      "title": "Explainable AI for Securing Healthcare in IoT-Integrated 6G Wireless Networks",
      "abstract": "As healthcare systems increasingly adopt advanced wireless networks and connected devices, securing medical applications has become critical. The integration of Internet of Medical Things devices, such as robotic surgical tools, intensive care systems, and wearable monitors has enhanced patient care but introduced serious security risks. Cyberattacks on these devices can lead to life threatening consequences, including surgical errors, equipment failure, and data breaches. While the ITU IMT 2030 vision highlights 6G's transformative role in healthcare through AI and cloud integration, it also raises new security concerns. This paper explores how explainable AI techniques like SHAP, LIME, and DiCE can uncover vulnerabilities, strengthen defenses, and improve trust and transparency in 6G enabled healthcare. We support our approach with experimental analysis and highlight promising results.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Navneet Kaur et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.14659",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389650261",
      "doi": "10.48550/arxiv.2312.05585",
      "title": "Enhancing Medical Specialty Assignment to Patients using NLP Techniques",
      "abstract": "The introduction of Large Language Models (LLMs), and the vast volume of publicly available medical data, amplified the application of NLP to the medical domain. However, LLMs are pretrained on data that are not explicitly relevant to the domain that are applied to and are often biased towards the original data they were pretrained upon. Even when pretrained on domainspecific data, these models typically require time-consuming fine-tuning to achieve good performance for a specific task. To address these limitations, we propose an alternative approach that achieves superior performance while being computationally efficient. Specifically, we utilize keywords to train a deep learning architecture that outperforms a language model pretrained on a large corpus of text. Our proposal does not require pretraining nor fine-tuning and can be applied directly to a specific setting for performing multi-label classification. Our objective is to automatically assign a new patient to the specialty of the medical professional they require, using a dataset that contains medical transcriptions and relevant keywords. To this end, we fine-tune the PubMedBERT model on this dataset, which serves as the baseline for our experiments. We then twice train/fine-tune a DNN and the RoBERTa language model, using both the keywords and the full transcriptions as input. We compare the performance of these approaches using relevant metrics. Our results demonstrate that utilizing keywords for text classification significantly improves classification performance, for both a basic DL architecture and a large language model. Our approach represents a promising and efficient alternative to traditional methods for finetuning language models on domain-specific data and has potential applications in various medical domains",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Chris Solomou",
      "keywords": "Computer science; Task (project management); Language model; Artificial intelligence; Labeled data; Baseline (sea); Machine learning; Domain (mathematical analysis); Natural language processing; Architecture; Deep learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2312.05585",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414588059",
      "doi": "10.48550/arxiv.2505.20085",
      "title": "Explanation User Interfaces: A Systematic Literature Review",
      "abstract": "Artificial Intelligence (AI) is one of the major technological advancements of this century, bearing incredible potential for users through AI-powered applications and tools in numerous domains. Being often black-box (i.e., its decision-making process is unintelligible), developers typically resort to eXplainable Artificial Intelligence (XAI) techniques to interpret the behaviour of AI models to produce systems that are transparent, fair, reliable, and trustworthy. However, presenting explanations to the user is not trivial and is often left as a secondary aspect of the system's design process, leading to AI systems that are not useful to end-users. This paper presents a Systematic Literature Review on Explanation User Interfaces (XUIs) to gain a deeper understanding of the solutions and design guidelines employed in the academic literature to effectively present explanations to users. To improve the contribution and real-world impact of this survey, we also present a framework for Human-cEnteRed developMent of Explainable user interfaceS (HERMES) to guide practitioners and academics in the design and evaluation of XUIs.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Eleonora Cappuccio et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.20085",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391462596",
      "doi": "10.48550/arxiv.2401.17542",
      "title": "A Medical Data-Effective Learning Benchmark for Highly Efficient Pre-training of Foundation Models",
      "abstract": "Foundation models, pre-trained on massive datasets, have achieved unprecedented generalizability. However, is it truly necessary to involve such vast amounts of data in pre-training, consuming extensive computational resources? This paper introduces data-effective learning, aiming to use data in the most impactful way to pre-train foundation models. This involves strategies that focus on data quality rather than quantity, ensuring the data used for training has high informational value. Data-effective learning plays a profound role in accelerating foundation model training, reducing computational costs, and saving data storage, which is very important as the volume of medical data in recent years has grown beyond many people's expectations. However, due to the lack of standards and comprehensive benchmarks, research on medical data-effective learning is poorly studied. To address this gap, our paper introduces a comprehensive benchmark specifically for evaluating data-effective learning in the medical field. This benchmark includes a dataset with millions of data samples from 31 medical centers (DataDEL), a baseline method for comparison (MedDEL), and a new evaluation metric (NormDEL) to objectively measure data-effective learning performance. Our extensive experimental results show the baseline MedDEL can achieve performance comparable to the original large dataset with only 5% of the data. Establishing such an open data-effective learning benchmark is crucial for the medical foundation model research community because it facilitates efficient data use, promotes collaborative breakthroughs, and fosters the development of cost-effective, scalable, and impactful healthcare solutions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Wenxuan Yang et al.",
      "keywords": "Benchmark (surveying); Computer science; Artificial intelligence; Machine learning; Data science; Geography; Cartography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.17542",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414897501",
      "doi": "10.48550/arxiv.2506.01584",
      "title": "VirnyFlow: A Design Space for Responsible Model Development",
      "abstract": "Developing machine learning (ML) models requires a deep understanding of real-world problems, which are inherently multi-objective. In this paper, we present VirnyFlow, the first design space for responsible model development, designed to assist data scientists in building ML pipelines that are tailored to the specific context of their problem. Unlike conventional AutoML frameworks, VirnyFlow enables users to define customized optimization criteria, perform comprehensive experimentation across pipeline stages, and iteratively refine models in alignment with real-world constraints. Our system integrates evaluation protocol definition, multi-objective Bayesian optimization, cost-aware multi-armed bandits, query optimization, and distributed parallelism into a unified architecture. We show that VirnyFlow significantly outperforms state-of-the-art AutoML systems in both optimization quality and scalability across five real-world benchmarks, offering a flexible, efficient, and responsible alternative to black-box automation in ML development.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Denys Herasymuk et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01584",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4377864593",
      "doi": "10.48550/arxiv.2305.12671",
      "title": "Transferring Fairness using Multi-Task Learning with Limited Demographic Information",
      "abstract": "Training supervised machine learning systems with a fairness loss can improve prediction fairness across different demographic groups. However, doing so requires demographic annotations for training data, without which we cannot produce debiased classifiers for most tasks. Drawing inspiration from transfer learning methods, we investigate whether we can utilize demographic data from a related task to improve the fairness of a target task. We adapt a single-task fairness loss to a multi-task setting to exploit demographic labels from a related task in debiasing a target task and demonstrate that demographic fairness objectives transfer fairness within a multi-task framework. Additionally, we show that this approach enables intersectional fairness by transferring between two datasets with different single-axis demographics. We explore different data domains to show how our loss can improve fairness domains and tasks.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Carlos Aguirre et al.",
      "keywords": "Debiasing; Task (project management); Computer science; Demographics; Exploit; Multi-task learning; Transfer of learning; Machine learning; Artificial intelligence; Task analysis; Cognitive psychology; Psychology; Social psychology; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.12671",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390961149",
      "doi": "10.48550/arxiv.2401.06804",
      "title": "ChatGPT, Let us Chat Sign Language: Experiments, Architectural Elements, Challenges and Research Directions",
      "abstract": "ChatGPT is a language model based on Generative AI. Existing research work on ChatGPT focused on its use in various domains. However, its potential for Sign Language Translation (SLT) is yet to be explored. This paper addresses this void. Therefore, we present GPT's evolution aiming a retrospective analysis of the improvements to its architecture for SLT. We explore ChatGPT's capabilities in translating different sign languages in paving the way to better accessibility for deaf and hard-of-hearing community. Our experimental results indicate that ChatGPT can accurately translate from English to American (ASL), Australian (AUSLAN), and British (BSL) sign languages and from Arabic Sign Language (ArSL) to English with only one prompt iteration. However, the model failed to translate from Arabic to ArSL and ASL, AUSLAN, and BSL to Arabic. Consequently, we present challenges and derive insights for future research directions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Nada Shahin et al.",
      "keywords": "Sign language; Computer science; Generative grammar; Linguistics; Sign (mathematics); American Sign Language; Arabic; Architecture; Natural language processing; Artificial intelligence; History",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.06804",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415065731",
      "doi": "10.48550/arxiv.2504.16394",
      "title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs",
      "abstract": "Unstructured clinical data can serve as a unique and rich source of information that can meaningfully inform clinical practice. Extracting the most pertinent context from such data is critical for exploiting its true potential toward optimal and timely decision-making in patient care. While prior research has explored various methods for clinical text summarization, most prior studies either process all input tokens uniformly or rely on heuristic-based filters, which can overlook nuanced clinical cues and fail to prioritize information critical for decision-making. In this study, we propose Contextual, a novel framework that integrates a Context-Preserving Token Filtering method with a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By preserving context-specific important tokens and enriching them with structured knowledge, ConTextual improves both linguistic coherence and clinical fidelity. Our extensive empirical evaluations on two public benchmark datasets demonstrate that ConTextual consistently outperforms other baselines. Our proposed approach highlights the complementary role of token-level filtering and structured retrieval in enhancing both linguistic and clinical integrity, as well as offering a scalable solution for improving precision in clinical text generation.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Fahmida Liza Piya et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.16394",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226435470",
      "doi": "10.48550/arxiv.2202.01319",
      "title": "Deep Learning for Epidemiologists: An Introduction to Neural Networks",
      "abstract": "Deep learning methods are increasingly being applied to problems in medicine and healthcare. However, few epidemiologists have received formal training in these methods. To bridge this gap, this article introduces to the fundamentals of deep learning from an epidemiological perspective. Specifically, this article reviews core concepts in machine learning (overfitting, regularization, hyperparameters), explains several fundamental deep learning architectures (convolutional neural networks, recurrent neural networks), and summarizes training, evaluation, and deployment of models. We aim to enable the reader to engage with and critically evaluate medical applications of deep learning, facilitating a dialogue between computer scientists and epidemiologists that will improve the safety and efficacy of applications of this technology.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Stylianos Serghiou et al.",
      "keywords": "Deep learning; Artificial intelligence; Computer science; Overfitting; Machine learning; Convolutional neural network; Hyperparameter; Data science; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.01319",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403624380",
      "doi": "10.48550/arxiv.2409.06585",
      "title": "Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records",
      "abstract": "Background: Hip replacement procedures improve patient lives by relieving pain and restoring mobility. Predicting hip replacement in advance could reduce pain by enabling timely interventions, prioritising individuals for surgery or rehabilitation, and utilising physiotherapy to potentially delay the need for joint replacement. This study predicts hip replacement a year in advance to enhance quality of life and health service efficiency. Methods: Adapting previous work using Temporal Graph Convolutional Neural Network (TG-CNN) models, we construct temporal graphs from primary care medical event codes, sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip replacement risk. We match hip replacement cases to controls by age, sex, and Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187 controls, predicts hip replacement one year in advance. We validate the model on two unseen datasets, recalibrating for class imbalance. Additionally, we conduct an ablation study and compare against four baseline models. Results: Our best model predicts hip replacement risk one year in advance with an AUROC of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209), achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after recalibration. Conclusions: The TG-CNN model effectively predicts hip replacement risk by identifying patterns in patient trajectories, potentially improving understanding and management of hip-related conditions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zoe Hancox et al.",
      "keywords": "Convolutional neural network; Computer science; Health records; Graph; Artificial intelligence; Health care; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.06585",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414897597",
      "doi": "10.48550/arxiv.2506.01662",
      "title": "Explainable AI Systems Must Be Contestable: Here's How to Make It Happen",
      "abstract": "As AI regulations around the world intensify their focus on system safety, contestability has become a mandatory, yet ill-defined, safeguard. In XAI, \"contestability\" remains an empty promise: no formal definition exists, no algorithm guarantees it, and practitioners lack concrete guidance to satisfy regulatory requirements. Grounded in a systematic literature review, this paper presents the first rigorous formal definition of contestability in explainable AI, directly aligned with stakeholder requirements and regulatory mandates. We introduce a modular framework of by-design and post-hoc mechanisms spanning human-centered interfaces, technical architectures, legal processes, and organizational workflows. To operationalize our framework, we propose the Contestability Assessment Scale, a composite metric built on more than twenty quantitative criteria. Through multiple case studies across diverse application domains, we reveal where state-of-the-art systems fall short and show how our framework drives targeted improvements. By converting contestability from regulatory theory into a practical framework, our work equips practitioners with the tools to embed genuine recourse and accountability into AI systems.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Catarina Moreira et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01662",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417516765",
      "doi": "10.48550/arxiv.2505.07393",
      "title": "AI in Money Matters",
      "abstract": "In November 2022, Europe and the world by and large were stunned by the birth of a new large language model : ChatGPT. Ever since then, both academic and populist discussions have taken place in various public spheres such as LinkedIn and X(formerly known as Twitter) with the view to both understand the tool and its benefits for the society. The views of real actors in professional spaces, especially in regulated industries such as finance and law have been largely missing. We aim to begin to close this gap by presenting results from an empirical investigation conducted through interviews with professional actors in the Fintech industry. The paper asks the question, how and to what extent are large language models in general and ChatGPT in particular being adopted and used in the Fintech industry? The results show that while the fintech experts we spoke with see a potential in using large language models in the future, a lot of questions marks remain concerning how they are policed and therefore might be adopted in a regulated industry such as Fintech. This paper aims to add to the existing academic discussing around large language models, with a contribution to our understanding of professional viewpoints.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Nadine Sandjo Tchatchoua et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07393",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415312666",
      "doi": "10.48550/arxiv.2506.14652",
      "title": "Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor",
      "abstract": "In AI research and practice, rigor remains largely understood in terms of methodological rigor -- such as whether mathematical, statistical, or computational methods are correctly applied. We argue that this narrow conception of rigor has contributed to the concerns raised by the responsible AI community, including overblown claims about the capabilities of AI systems. Our position is that a broader conception of what rigorous AI research and practice should entail is needed. We believe such a conception -- in addition to a more expansive understanding of (1) methodological rigor -- should include aspects related to (2) what background knowledge informs what to work on (epistemic rigor); (3) how disciplinary, community, or personal norms, standards, or beliefs influence the work (normative rigor); (4) how clearly articulated the theoretical constructs under use are (conceptual rigor); (5) what is reported and how (reporting rigor); and (6) how well-supported the inferences from existing evidence are (interpretative rigor). In doing so, we also provide useful language and a framework for much-needed dialogue about the AI community's work by researchers, policymakers, journalists, and other stakeholders.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Alexandra Olteanu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.14652",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4405173905",
      "doi": "10.48550/arxiv.2412.04999",
      "title": "'Debunk-It-Yourself': Health Professionals' Strategies for Responding to Misinformation on TikTok",
      "abstract": "Misinformation is \"sticky\" in nature, requiring a considerable effort to undo its influence. One such effort is debunking or exposing the falsity of information. As an abundance of misinformation is on social media, platforms do bear some debunking responsibility in order to preserve their trustworthiness as information providers. A subject of interpretation, platforms poorly meet this responsibility and allow dangerous health misinformation to influence many of their users. This open route to harm did not sit well with health professional users, who recently decided to take the debunking into their own hands. To study this individual debunking effort - which we call 'Debunk-It-Yourself (DIY)' - we conducted an exploratory survey n=14 health professionals who wage a misinformation counter-influence campaign through videos on TikTok. We focused on two topics, nutrition and mental health, which are the ones most often subjected to misinformation on the platform. Our thematic analysis reveals that the counterinfluence follows a common process of initiation, selection, creation, and \"stitching\" or duetting a debunking video with a misinformation video. The 'Debunk-It-Yourself' effort was underpinned by three unique aspects: (i) it targets trending misinformation claims perceived to be of direct harm to people's health; (ii) it offers a symmetric response to the misinformation; and (iii) it is strictly based on scientific evidence and claimed clinical experience. Contrasting the 'Debunk-It-Yourself' effort with the one TikTok and other platforms (reluctantly) put in moderation, we offer recommendations for a structured response against the misinformation's influence by the users themselves.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Filipo Sharevski et al.",
      "keywords": "Misinformation; Health professionals; Psychology; Business; Internet privacy; Health care; Political science; Computer science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.04999",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417517359",
      "doi": "10.48550/arxiv.2505.07772",
      "title": "The Value of Disagreement in AI Design, Evaluation, and Alignment",
      "abstract": "Disagreements are widespread across the design, evaluation, and alignment pipelines of artificial intelligence (AI) systems. Yet, standard practices in AI development often obscure or eliminate disagreement, resulting in an engineered homogenization that can be epistemically and ethically harmful, particularly for marginalized groups. In this paper, we characterize this risk, and develop a normative framework to guide practical reasoning about disagreement in the AI lifecycle. Our contributions are two-fold. First, we introduce the notion of perspectival homogenization, characterizing it as a coupled ethical-epistemic risk that arises when an aspect of an AI system's development unjustifiably suppresses disagreement and diversity of perspectives. We argue that perspectival homogenization is best understood as a procedural risk, which calls for targeted interventions throughout the AI development pipeline. Second, we propose a normative framework to guide such interventions, grounded in lines of research that explain why disagreement can be epistemically beneficial, and how its benefits can be realized in practice. We apply this framework to key design questions across three stages of AI development tasks: when disagreement is epistemically valuable; whose perspectives should be included and preserved; how to structure tasks and navigate trade-offs; and how disagreement should be documented and communicated. In doing so, we challenge common assumptions in AI practice, offer a principled foundation for emerging participatory and pluralistic approaches, and identify actionable pathways for future work in AI design and governance.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Sina Fazelpour et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07772",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400481999",
      "doi": "10.48550/arxiv.2407.05870",
      "title": "Cervical Auscultation Machine Learning for Dysphagia Assessment",
      "abstract": "This study evaluates the use of machine learning, specifically the Random Forest Classifier, to differentiate normal and pathological swallowing sounds. Employing a commercially available wearable stethoscope, we recorded swallows from both healthy adults and patients with dysphagia. The analysis revealed statistically significant differences in acoustic features, such as spectral crest, and zero-crossing rate between normal and pathological swallows, while no discriminating differences were demonstrated between different fluidand diet consistencies. The system demonstrated fair sensitivity (mean plus or minus SD: 74% plus or minus 8%) and specificity (89% plus or minus 6%) for dysphagic swallows. The model attained an overall accuracy of 83% plus or minus 3%, and F1 score of 78% plus or minus 5%. These results demonstrate that machine learning can be a valuable tool in non-invasive dysphagia assessment, although challenges such as sampling rate limitations and variability in sensitivity and specificity in discriminating between normal and pathological sounds are noted. The study underscores the need for further research to optimize these techniques for clinical use.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "An An Chia et al.",
      "keywords": "Auscultation; Dysphagia; Medicine; Physical therapy; Radiology; Medical physics; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.05870",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416123535",
      "doi": "10.48550/arxiv.2504.02694",
      "title": "Semiparametric Counterfactual Regression",
      "abstract": "We study counterfactual regression, which aims to map input features to outcomes under hypothetical scenarios that differ from those observed in the data. This is particularly useful for decision-making when adapting to sudden shifts in treatment patterns is essential. We propose a doubly robust-style estimator for counterfactual regression within a generalizable framework that accommodates a broad class of risk functions and flexible constraints, drawing on tools from semiparametric theory and stochastic optimization. Our approach uses incremental interventions to enhance adaptability while maintaining consistency with standard methods. We formulate the target estimand as the optimal solution to a stochastic optimization problem and develop an efficient estimation strategy, where we can leverage rapid development of modern optimization algorithms. We go on to analyze the rates of convergence and characterize the asymptotic distributions. Our analysis shows that the proposed estimators can achieve $\\sqrt{n}$-consistency and asymptotic normality for a broad class of problems. Numerical illustrations highlight their effectiveness in adapting to unseen counterfactual scenarios while maintaining parametric convergence rates.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Kwang\u2010Ho Kim",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.02694",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402698534",
      "doi": "10.48550/arxiv.2408.09224",
      "title": "Neuro-Symbolic AI for Military Applications",
      "abstract": "Artificial Intelligence (AI) plays a significant role in enhancing the capabilities of defense systems, revolutionizing strategic decision-making, and shaping the future landscape of military operations. Neuro-Symbolic AI is an emerging approach that leverages and augments the strengths of neural networks and symbolic reasoning. These systems have the potential to be more impactful and flexible than traditional AI systems, making them well-suited for military applications. This paper comprehensively explores the diverse dimensions and capabilities of Neuro-Symbolic AI, aiming to shed light on its potential applications in military contexts. We investigate its capacity to improve decision-making, automate complex intelligence analysis, and strengthen autonomous systems. We further explore its potential to solve complex tasks in various domains, in addition to its applications in military contexts. Through this exploration, we address ethical, strategic, and technical considerations crucial to the development and deployment of Neuro-Symbolic AI in military and civilian applications. Contributing to the growing body of research, this study represents a comprehensive exploration of the extensive possibilities offered by Neuro-Symbolic AI.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Desta Haileselassie Hagos et al.",
      "keywords": "Computer science; Artificial intelligence; Cognitive science; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.09224",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287829669",
      "doi": "10.48550/arxiv.2003.00662",
      "title": "Uncertainty-Aware Variational-Recurrent Imputation Network for Clinical\\n Time Series",
      "abstract": "Electronic health records (EHR) consist of longitudinal clinical observations\\nportrayed with sparsity, irregularity, and high-dimensionality, which become\\nmajor obstacles in drawing reliable downstream clinical outcomes. Although\\nthere exist great numbers of imputation methods to tackle these issues, most of\\nthem ignore correlated features, temporal dynamics and entirely set aside the\\nuncertainty. Since the missing value estimates involve the risk of being\\ninaccurate, it is appropriate for the method to handle the less certain\\ninformation differently than the reliable data. In that regard, we can use the\\nuncertainties in estimating the missing values as the fidelity score to be\\nfurther utilized to alleviate the risk of biased missing value estimates. In\\nthis work, we propose a novel variational-recurrent imputation network, which\\nunifies an imputation and a prediction network by taking into account the\\ncorrelated features, temporal dynamics, as well as the uncertainty.\\nSpecifically, we leverage the deep generative model in the imputation, which is\\nbased on the distribution among variables, and a recurrent imputation network\\nto exploit the temporal relations, in conjunction with utilization of the\\nuncertainty. We validated the effectiveness of our proposed model on two\\npublicly available real-world EHR datasets: PhysioNet Challenge 2012 and\\nMIMIC-III, and compared the results with other competing state-of-the-art\\nmethods in the literature.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Ahmad Wisnu Mulyadi et al.",
      "keywords": "Imputation (statistics); Missing data; Leverage (statistics); Computer science; Data mining; Exploit; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2003.00662",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400519206",
      "doi": "10.48550/arxiv.2407.07054",
      "title": "A Differentially Private Blockchain-Based Approach for Vertical Federated Learning",
      "abstract": "We present the Differentially Private Blockchain-Based Vertical Federal Learning (DP-BBVFL) algorithm that provides verifiability and privacy guarantees for decentralized applications. DP-BBVFL uses a smart contract to aggregate the feature representations, i.e., the embeddings, from clients transparently. We apply local differential privacy to provide privacy for embeddings stored on a blockchain, hence protecting the original data. We provide the first prototype application of differential privacy with blockchain for vertical federated learning. Our experiments with medical data show that DP-BBVFL achieves high accuracy with a tradeoff in training time due to on-chain aggregation. This innovative fusion of differential privacy and blockchain technology in DP-BBVFL could herald a new era of collaborative and trustworthy machine learning applications across several decentralized application domains.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Linh Tran et al.",
      "keywords": "Blockchain; Computer science; Federated learning; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.07054",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385889692",
      "doi": "10.48550/arxiv.2308.06546",
      "title": "MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction",
      "abstract": "Extracting meaningful drug-related information chunks, such as adverse drug events (ADE), is crucial for preventing morbidity and saving many lives. Most ADEs are reported via an unstructured conversation with the medical context, so applying a general entity recognition approach is not sufficient enough. In this paper, we propose a new multi-aspect cross-integration framework for drug entity/event detection by capturing and aligning different context/language/knowledge properties from drug-related documents. We first construct multi-aspect encoders to describe semantic, syntactic, and medical document contextual information by conducting those slot tagging tasks, main drug entity/event detection, part-of-speech tagging, and general medical named entity recognition. Then, each encoder conducts cross-integration with other contextual information in three ways: the key-value cross, attention cross, and feedforward cross, so the multi-encoders are integrated in depth. Our model outperforms all SOTA on two widely used tasks, flat entity detection and discontinuous event extraction.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie Yang et al.",
      "keywords": "Computer science; Event (particle physics); Encoder; Context (archaeology); Conversation; Construct (python library); Information extraction; Natural language processing; Named-entity recognition; Key (lock); Entity linking; Artificial intelligence; Information retrieval; Knowledge base; Task (project management); Engineering; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.06546",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394947757",
      "doi": "10.48550/arxiv.2404.11428",
      "title": "Explainable Lung Disease Classification from Chest X-Ray Images Utilizing Deep Learning and XAI",
      "abstract": "Lung diseases remain a critical global health concern, and it's crucial to have accurate and quick ways to diagnose them. This work focuses on classifying different lung diseases into five groups: viral pneumonia, bacterial pneumonia, COVID, tuberculosis, and normal lungs. Employing advanced deep learning techniques, we explore a diverse range of models including CNN, hybrid models, ensembles, transformers, and Big Transfer. The research encompasses comprehensive methodologies such as hyperparameter tuning, stratified k-fold cross-validation, and transfer learning with fine-tuning.Remarkably, our findings reveal that the Xception model, fine-tuned through 5-fold cross-validation, achieves the highest accuracy of 96.21\\%. This success shows that our methods work well in accurately identifying different lung diseases. The exploration of explainable artificial intelligence (XAI) methodologies further enhances our understanding of the decision-making processes employed by these models, contributing to increased trust in their clinical applications.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Tanzina Taher Ifty et al.",
      "keywords": "Artificial intelligence; Lung; Medicine; Radiology; Chest pain; Computer science; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.11428",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417523337",
      "doi": "10.48550/arxiv.2504.21464",
      "title": "VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep Network for Diabetic Retinopathy Classification",
      "abstract": "Diabetic retinopathy is a severe eye condition caused by diabetes where the retinal blood vessels get damaged and can lead to vision loss and blindness if not treated. Early and accurate detection is key to intervention and stopping the disease progressing. For addressing this disease properly, this paper presents a comprehensive approach for automated diabetic retinopathy detection by proposing a new hybrid deep learning model called VR-FuseNet. Diabetic retinopathy is a major eye disease and leading cause of blindness especially among diabetic patients so accurate and efficient automated detection methods are required. To address the limitations of existing methods including dataset imbalance, diversity and generalization issues this paper presents a hybrid dataset created from five publicly available diabetic retinopathy datasets. Essential preprocessing techniques such as SMOTE for class balancing and CLAHE for image enhancement are applied systematically to the dataset to improve the robustness and generalizability of the dataset. The proposed VR-FuseNet model combines the strengths of two state-of-the-art convolutional neural networks, VGG19 which captures fine-grained spatial features and ResNet50V2 which is known for its deep hierarchical feature extraction. This fusion improves the diagnostic performance and achieves an accuracy of 91.824%. The model outperforms individual architectures on all performance metrics demonstrating the effectiveness of hybrid feature extraction in Diabetic Retinopathy classification tasks. To make the proposed model more clinically useful and interpretable this paper incorporates multiple XAI techniques. These techniques generate visual explanations that clearly indicate the retinal features affecting the model's prediction such as microaneurysms, hemorrhages and exudates so that clinicians can interpret and validate.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Shamim Rahim Refat et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.21464",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384807778",
      "doi": "10.48550/arxiv.2307.08919",
      "title": "Systematic comparison of semi-supervised and self-supervised learning for medical image classification",
      "abstract": "In typical medical image classification problems, labeled data is scarce while unlabeled data is more available. Semi-supervised learning and self-supervised learning are two different research directions that can improve accuracy by learning from extra unlabeled data. Recent methods from both directions have reported significant gains on traditional benchmarks. Yet past benchmarks do not focus on medical tasks and rarely compare self- and semi- methods together on an equal footing. Furthermore, past benchmarks often handle hyperparameter tuning suboptimally. First, they may not tune hyperparameters at all, leading to underfitting. Second, when tuning does occur, it often unrealistically uses a labeled validation set that is much larger than the training set. Therefore currently published rankings might not always corroborate with their practical utility This study contributes a systematic evaluation of self- and semi- methods with a unified experimental protocol intended to guide a practitioner with scarce overall labeled data and a limited compute budget. We answer two key questions: Can hyperparameter tuning be effective with realistic-sized validation sets? If so, when all methods are tuned well, which self- or semi-supervised methods achieve the best accuracy? Our study compares 13 representative semi- and self-supervised methods to strong labeled-set-only baselines on 4 medical datasets. From 20000+ GPU hours of computation, we provide valuable best practices to resource-constrained practitioners: hyperparameter tuning is effective, and the semi-supervised method known as MixMatch delivers the most reliable gains across 4 datasets.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhe Huang et al.",
      "keywords": "Artificial intelligence; Supervised learning; Computer science; Machine learning; Image (mathematics); Pattern recognition (psychology); Semi-supervised learning; Contextual image classification; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.08919",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4317832414",
      "doi": "10.48550/arxiv.2301.08439",
      "title": "Schr\u00f6dinger Spectrum based Continuous Cuff-less Blood Pressure Estimation using Clinically Relevant Features from PPG Signal and its Second Derivative",
      "abstract": "The presented study aims to estimate blood pressure (BP) using photoplethysmogram (PPG) signals while employing multiple machine learning models. The study proposes a novel algorithm for signal reconstruction, which utilizes the semi-classical signal analysis (SCSA) technique. The proposed algorithm optimises the semi-classical constant and eliminates the trade-off between complexity and accuracy in reconstruction. The reconstructed signals' spectral features are extracted and incorporated with clinically relevant PPG and its second derivative's (SDPPG) morphological features. The developed method was assessed using a publicly available virtual in-silico dataset with more than 4000 subjects, and the Multi-Parameter Intelligent Monitoring in Intensive Care Units dataset. Results showed that the method attained a mean absolute error of 5.37 and 2.96 mmHg for systolic and diastolic BP, respectively, using the CatBoost supervisory algorithm. This approach met the standards set by the Advancement of Medical Instrumentation, and achieved Grade A for all BP categories in the British Hypertension Society protocol. The proposed framework performs well even when applied to a combined database of the MIMIC-III and the Queensland dataset. This study also evaluates the proposed method's performance in a non-clinical setting with noisy and deformed PPG signals, to validate the efficacy of the SCSA method. The noise stress tests showed that the algorithm maintained its key feature detection, signal reconstruction capability, and estimation accuracy up to a 10 dB SNR ratio. It is believed that the proposed cuff-less BP estimation technique has the potential to perform well on resource-constrained settings due to its straightforward implementation approach.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Aayushman Ghosh et al.",
      "keywords": "Photoplethysmogram; SIGNAL (programming language); Computer science; Pattern recognition (psychology); Artificial intelligence; Signal reconstruction; Signal-to-noise ratio (imaging); Feature (linguistics); Cuff; Signal processing; Algorithm; Computer vision; Medicine; Digital signal processing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2301.08439",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4379087057",
      "doi": "10.48550/arxiv.2305.19373",
      "title": "Mining Themes in Clinical Notes to Identify Phenotypes and to Predict Length of Stay in Patients admitted with Heart Failure",
      "abstract": "Heart failure is a syndrome which occurs when the heart is not able to pump blood and oxygen to support other organs in the body. Identifying the underlying themes in the diagnostic codes and procedure reports of patients admitted for heart failure could reveal the clinical phenotypes associated with heart failure and to group patients based on their similar characteristics which could also help in predicting patient outcomes like length of stay. These clinical phenotypes usually have a probabilistic latent structure and hence, as there has been no previous work on identifying phenotypes in clinical notes of heart failure patients using a probabilistic framework and to predict length of stay of these patients using data-driven artificial intelligence-based methods, we apply natural language processing technique, topic modeling, to identify the themes present in diagnostic codes and in procedure reports of 1,200 patients admitted for heart failure at the University of Illinois Hospital and Health Sciences System (UI Health). Topic modeling identified twelve themes each in diagnostic codes and procedure reports which revealed information about different phenotypes related to various perspectives about heart failure, to study patients' profiles and to discover new relationships among medical concepts. Each theme had a set of keywords and each clinical note was labeled with two themes - one corresponding to its diagnostic code and the other corresponding to its procedure reports along with their percentage contribution. We used these themes and their percentage contribution to predict length of stay. We found that the themes discovered in diagnostic codes and procedure reports using topic modeling together were able to predict length of stay of the patients with an accuracy of 61.1% and an Area under the Receiver Operating Characteristic Curve (ROC AUC) value of 0.828.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ankita Agarwal et al.",
      "keywords": "Heart failure; Set (abstract data type); Diagnosis code; Medicine; Probabilistic logic; Medical diagnosis; Intensive care medicine; Psychology; Artificial intelligence; Computer science; Internal medicine; Pathology; Population",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.19373",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221162934",
      "doi": "10.48550/arxiv.2201.09280",
      "title": "SpiroMask: Measuring Lung Function Using Consumer-Grade Masks",
      "abstract": "According to the World Health Organisation (WHO), 235 million people suffer from respiratory illnesses and four million people die annually due to air pollution. Regular lung health monitoring can lead to prognoses about deteriorating lung health conditions. This paper presents our system SpiroMask that retrofits a microphone in consumer-grade masks (N95 and cloth masks) for continuous lung health monitoring. We evaluate our approach on 48 participants (including 14 with lung health issues) and find that we can estimate parameters such as lung volume and respiration rate within the approved error range by the American Thoracic Society (ATS). Further, we show that our approach is robust to sensor placement inside the mask.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Rishiraj Adhikary et al.",
      "keywords": "Lung function; Lung; Lung volumes; Medicine; Environmental health; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2201.09280",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287905095",
      "doi": "10.48550/arxiv.2001.04051",
      "title": "An Adversarial Approach for the Robust Classification of Pneumonia from\\n Chest Radiographs",
      "abstract": "While deep learning has shown promise in the domain of disease classification\\nfrom medical images, models based on state-of-the-art convolutional neural\\nnetwork architectures often exhibit performance loss due to dataset shift.\\nModels trained using data from one hospital system achieve high predictive\\nperformance when tested on data from the same hospital, but perform\\nsignificantly worse when they are tested in different hospital systems.\\nFurthermore, even within a given hospital system, deep learning models have\\nbeen shown to depend on hospital- and patient-level confounders rather than\\nmeaningful pathology to make classifications. In order for these models to be\\nsafely deployed, we would like to ensure that they do not use confounding\\nvariables to make their classification, and that they will work well even when\\ntested on images from hospitals that were not included in the training data. We\\nattempt to address this problem in the context of pneumonia classification from\\nchest radiographs. We propose an approach based on adversarial optimization,\\nwhich allows us to learn more robust models that do not depend on confounders.\\nSpecifically, we demonstrate improved out-of-hospital generalization\\nperformance of a pneumonia classifier by training a model that is invariant to\\nthe view position of chest radiographs (anterior-posterior vs.\\nposterior-anterior). Our approach leads to better predictive performance on\\nexternal hospital data than both a standard baseline and previously proposed\\nmethods to handle confounding, and also suggests a method for identifying\\nmodels that may rely on confounders. Code available at\\nhttps://github.com/suinleelab/cxr_adv.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Joseph D. Janizek et al.",
      "keywords": "Confounding; Classifier (UML); Computer science; Artificial intelligence; Radiography; Machine learning; Deep learning; Convolutional neural network; Context (archaeology); Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2001.04051",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391421181",
      "doi": "10.48550/arxiv.2401.16796",
      "title": "Learnable Prompt as Pseudo-Imputation: Rethinking the Necessity of Traditional EHR Data Imputation in Downstream Clinical Prediction",
      "abstract": "Analyzing the health status of patients based on Electronic Health Records (EHR) is a fundamental research problem in medical informatics. The presence of extensive missing values in EHR makes it challenging for deep neural networks (DNNs) to directly model the patient's health status. Existing DNNs training protocols, including Impute-then-Regress Procedure and Jointly Optimizing of Impute-n-Regress Procedure, require the additional imputation models to reconstruction missing values. However, Impute-then-Regress Procedure introduces the risk of injecting imputed, non-real data into downstream clinical prediction tasks, resulting in power loss, biased estimation, and poorly performing models, while Jointly Optimizing of Impute-n-Regress Procedure is also difficult to generalize due to the complex optimization space and demanding data requirements. Inspired by the recent advanced literature of learnable prompt in the fields of NLP and CV, in this work, we rethought the necessity of the imputation model in downstream clinical tasks, and proposed Learnable Prompt as Pseudo-Imputation (PAI) as a new training protocol to assist EHR analysis. PAI no longer introduces any imputed data but constructs a learnable prompt to model the implicit preferences of the downstream model for missing values, resulting in a significant performance improvement for all state-of-the-arts EHR analysis models on four real-world datasets across two clinical prediction tasks. Further experimental analysis indicates that PAI exhibits higher robustness in situations of data insufficiency and high missing rates. More importantly, as a plug-and-play protocol, PAI can be easily integrated into any existing or even imperceptible future EHR analysis models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Weibin Liao et al.",
      "keywords": "Imputation (statistics); Downstream (manufacturing); Computer science; Data mining; Econometrics; Statistics; Missing data; Mathematics; Machine learning; Engineering; Operations management",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.16796",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2949159381",
      "doi": "10.48550/arxiv.1812.02793",
      "title": "Generation of Synthetic Electronic Medical Record Text",
      "abstract": "Machine learning (ML) and Natural Language Processing (NLP) have achieved remarkable success in many fields and have brought new opportunities and high expectation in the analyses of medical data. The most common type of medical data is the massive free-text electronic medical records (EMR). It is widely regarded that mining such massive data can bring up important information for improving medical practices as well as for possible new discoveries on complex diseases. However, the free EMR texts are lacking consistent standards, rich of private information, and limited in availability. Also, as they are accumulated from everyday practices, it is often hard to have a balanced number of samples for the types of diseases under study. These problems hinder the development of ML and NLP methods for EMR data analysis. To tackle these problems, we developed a model to generate synthetic text of EMRs called Medical Text Generative Adversarial Network or mtGAN. It is based on the GAN framework and is trained by the REINFORCE algorithm. It takes disease features as inputs and generates synthetic texts as EMRs for the corresponding diseases. We evaluate the model from micro-level, macro-level and application-level on a Chinese EMR text dataset. The results show that the method has a good capacity to fit real data and can generate realistic and diverse EMR samples. This provides a novel way to avoid potential leakage of patient privacy while still supply sufficient well-controlled cohort data for developing downstream ML and NLP methods. It can also be used as a data augmentation method to assist studies based on real EMR data.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiaqi Guan et al.",
      "keywords": "Computer science; Adversarial system; Electronic medical record; Artificial intelligence; Data science; Deep learning; Generative adversarial network; Data-driven; Generative grammar; Macro; Medical record; Machine learning; Natural language processing; Information retrieval; Medicine; Internet privacy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1812.02793",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416052273",
      "doi": "10.48550/arxiv.2504.10918",
      "title": "Adaptive Human-Agent Teaming: A Review of Empirical Studies from the Process Dynamics Perspective",
      "abstract": "The rapid advancement of AI, including Large Language Models, has propelled autonomous agents forward, accelerating the human-agent teaming (HAT) paradigm to leverage complementary strengths. However, HAT research remains fragmented, often focusing on isolated team development phases or specific challenges like trust calibration while overlooking the real-world need for adaptability. Addressing these gaps, a process dynamics perspective is adopted to systematically review HAT using the T$^4$ framework: Team Formation, Task and Role Development, Team Development, and Team Improvement. Each phase is examined in terms of its goals, actions, and evaluation metrics, emphasizing the co-evolution of task and team dynamics. Special focus is given to the second and third phases, highlighting key factors such as team roles, shared mental model, and backup behaviors. This holistic perspective identifies future research directions for advancing long-term adaptive HAT.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mengyao Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2504.10918",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416118784",
      "doi": "10.48550/arxiv.2504.05238",
      "title": "Federated Learning for Medical Image Classification: A Comprehensive Benchmark",
      "abstract": "The federated learning paradigm is wellsuited for the field of medical image analysis, as it can effectively cope with machine learning on isolated multicenter data while protecting the privacy of participating parties. However, current research on optimization algorithms in federated learning often focuses on limited datasets and scenarios, primarily centered around natural images, with insufficient comparative experiments in medical contexts. In this work, we conduct a comprehensive evaluation of several state-of-the-art federated learning algorithms in the context of medical imaging. We conduct a fair comparison of classification models trained using various federated learning algorithms across multiple medical imaging datasets. Additionally, we evaluate system performance metrics, such as communication cost and computational efficiency, while considering different federated learning architectures. Our findings show that medical imaging datasets pose substantial challenges for current federated learning optimization algorithms. No single algorithm consistently delivers optimal performance across all medical federated learning scenarios, and many optimization algorithms may underperform when applied to these datasets. Our experiments provide a benchmark and guidance for future research and application of federated learning in medical imaging contexts. Furthermore, we propose an efficient and robust method that combines generative techniques using denoising diffusion probabilistic models with label smoothing to augment datasets, widely enhancing the performance of federated learning on classification tasks across various medical imaging datasets. Our code will be released on GitHub, offering a reliable and comprehensive benchmark for future federated learning studies in medical imaging.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Ziheng Zhou et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.05238",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4296405796",
      "doi": "10.48550/arxiv.2205.13705",
      "title": "Heterogeneous Collaborative Learning for Personalized Healthcare Analytics via Messenger Distillation",
      "abstract": "In this paper, we propose a Similarity-Quality-based Messenger Distillation (SQMD) framework for heterogeneous asynchronous on-device healthcare analytics. By introducing a preloaded reference dataset, SQMD enables all participant devices to distill knowledge from peers via messengers (i.e., the soft labels of the reference dataset generated by clients) without assuming the same model architecture. Furthermore, the messengers also carry important auxiliary information to calculate the similarity between clients and evaluate the quality of each client model, based on which the central server creates and maintains a dynamic collaboration graph (communication graph) to improve the personalization and reliability of SQMD under asynchronous conditions. Extensive experiments on three real-life datasets show that SQMD achieves superior performance.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Guanhua Ye et al.",
      "keywords": "Computer science; Asynchronous communication; Personalization; Analytics; Similarity (geometry); Graph; Machine learning; Data mining; Artificial intelligence; Theoretical computer science; World Wide Web; Computer network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.13705",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417062153",
      "doi": "10.48550/arxiv.2504.07471",
      "title": "Traversal Learning: A Lossless And Efficient Distributed Learning Framework",
      "abstract": "In this paper, we introduce Traversal Learning (TL), a novel approach designed to address the problem of decreased quality encountered in popular distributed learning (DL) paradigms such as Federated Learning (FL), Split Learning (SL), and SplitFed Learning (SFL). Traditional FL experiences from an accuracy drop during aggregation due to its averaging function, while SL and SFL face increased loss due to the independent gradient updates on each split network. TL adopts a unique strategy where the model traverses the nodes during forward propagation (FP) and performs backward propagation (BP) on the orchestrator, effectively implementing centralized learning (CL) principles within a distributed environment. The orchestrator is tasked with generating virtual batches and planning the sequential node visits of the model during FP, aligning them with the ordered index of the data within these batches. We conducted experiments on six datasets representing diverse characteristics across various domains. Our evaluation demonstrates that TL is on par with classic CL approaches in terms of accurate inference, thereby offering a viable and robust solution for DL tasks. TL outperformed other DL methods and improved accuracy by 7.85% for independent and identically distributed (IID) datasets, macro F1-score by 1.06% for non-IID datasets, accuracy by 2.60% for text classification, and AUC by 3.88% and 4.54% for medical and financial datasets, respectively. By effectively preserving data privacy while maintaining performance, TL represents a significant advancement in DL methodologies. The implementation of TL is available at https://github.com/neouly-inc/Traversal-Learning",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Erdenebileg Batbaatar et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.07471",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417077291",
      "doi": "10.48550/arxiv.2505.23027",
      "title": "Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift",
      "abstract": "The subpopulationtion shift, characterized by a disparity in subpopulation distributibetween theween the training and target datasets, can significantly degrade the performance of machine learning models. Current solutions to subpopulation shift involve modifying empirical risk minimization with re-weighting strategies to improve generalization. This strategy relies on assumptions about the number and nature of subpopulations and annotations on group membership, which are unavailable for many real-world datasets. Instead, we propose using an ensemble of diverse classifiers to adaptively capture risk associated with subpopulations. Given a feature extractor network, we replace its standard linear classification layer with a mixture of prototypical classifiers, where each member is trained to classify the data while focusing on different features and samples from other members. In empirical evaluation on nine real-world datasets, covering diverse domains and kinds of subpopulation shift, our method of Diverse Prototypical Ensembles (DPEs) often outperforms the prior state-of-the-art in worst-group accuracy. The code is available at https://github.com/minhto2802/dpe4subpop",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Minh Nguyen Nhat To et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23027",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416075024",
      "doi": "10.48550/arxiv.2506.04049",
      "title": "WANDER: An Explainable Decision-Support Framework for HPC",
      "abstract": "High-performance computing (HPC) systems expose many interdependent configuration knobs that impact runtime, resource usage, power, and variability. Existing predictive tools model these outcomes, but do not support structured exploration, explanation, or guided reconfiguration. We present WANDER, a decision-support framework that synthesizes alternate configurations using counterfactual analysis aligned with user goals and constraints. We introduce a composite trade-off score that ranks suggestions based on prediction uncertainty, consistency between feature-target relationships using causal models, and similarity between feature distributions against historical data. To our knowledge, WANDER is the first such system to unify prediction, exploration, and explanation for HPC tuning under a common query interface. Across multiple datasets WANDER generates interpretable and trustworthy, human-readable alternatives that guide users to achieve their performance objectives.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Ankur Lahiry et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.04049",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287080737",
      "doi": "10.48550/arxiv.2107.14052",
      "title": "The Role of Social Movements, Coalitions, and Workers in Resisting\\n Harmful Artificial Intelligence and Contributing to the Development of\\n Responsible AI",
      "abstract": "There is mounting public concern over the influence that AI based systems has\\nin our society. Coalitions in all sectors are acting worldwide to resist hamful\\napplications of AI. From indigenous people addressing the lack of reliable\\ndata, to smart city stakeholders, to students protesting the academic\\nrelationships with sex trafficker and MIT donor Jeffery Epstein, the\\nquestionable ethics and values of those heavily investing in and profiting from\\nAI are under global scrutiny. There are biased, wrongful, and disturbing\\nassumptions embedded in AI algorithms that could get locked in without\\nintervention. Our best human judgment is needed to contain AI's harmful impact.\\nPerhaps one of the greatest contributions of AI will be to make us ultimately\\nunderstand how important human wisdom truly is in life on earth.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Susan von Struensee",
      "keywords": "Scrutiny; Indigenous; Intervention (counseling); Environmental ethics; Political science; Engineering ethics; Public relations; Law and economics; Business; Sociology; Psychology; Law; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2107.14052",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320343050",
      "doi": "10.48550/arxiv.2010.08155",
      "title": "Guided Data Discovery in Interactive Visualizations via Active Search",
      "abstract": "Recent advances in visual analytics have enabled us to learn from user interactions and uncover analytic goals. These innovations set the foundation for actively guiding users during data exploration. Providing such guidance will become more critical as datasets grow in size and complexity, precluding exhaustive investigation. Meanwhile, the machine learning community also struggles with datasets growing in size and complexity, precluding exhaustive labeling. Active learning is a broad family of algorithms developed for actively guiding models during training. We will consider the intersection of these analogous research thrusts. First, we discuss the nuances of matching the choice of an active learning algorithm to the task at hand. This is critical for performance, a fact we demonstrate in a simulation study. We then present results of a user study for the particular task of data discovery guided by an active learning algorithm specifically designed for this task.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Shayan Monadjemi et al.",
      "keywords": "Computer science; Intersection (aeronautics); Task (project management); Active learning (machine learning); Set (abstract data type); Matching (statistics); Visual analytics; Analytics; Machine learning; Data science; Human\u2013computer interaction; Visualization; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2010.08155",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288263228",
      "doi": "10.48550/arxiv.1908.04674",
      "title": "Requirements Engineering for Machine Learning: Perspectives from Data\\n Scientists",
      "abstract": "Machine learning (ML) is used increasingly in real-world applications. In\\nthis paper, we describe our ongoing endeavor to define characteristics and\\nchallenges unique to Requirements Engineering (RE) for ML-based systems. As a\\nfirst step, we interviewed four data scientists to understand how ML experts\\napproach elicitation, specification, and assurance of requirements and\\nexpectations. The results show that changes in the development paradigm, i.e.,\\nfrom coding to training, also demands changes in RE. We conclude that\\ndevelopment of ML systems demands requirements engineers to: (1) understand ML\\nperformance measures to state good functional requirements, (2) be aware of new\\nquality requirements such as explainability, freedom from discrimination, or\\nspecific legal requirements, and (3) integrate ML specifics in the RE process.\\nOur study provides a first contribution towards an RE methodology for ML\\nsystems.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Andreas Vogelsang et al.",
      "keywords": "Requirements elicitation; Requirements engineering; Computer science; Requirements analysis; Requirements management; Quality assurance; Coding (social sciences); Process (computing); Non-functional requirement; Functional requirement; Software engineering; Engineering management; Artificial intelligence; Engineering; Operations management; Software development",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1908.04674",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404345177",
      "doi": "10.48550/arxiv.2411.00173",
      "title": "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning",
      "abstract": "Medical coding, the translation of unstructured clinical text into standardized medical codes, is a crucial but time-consuming healthcare practice. Though large language models (LLM) could automate the coding process and improve the efficiency of such tasks, interpretability remains paramount for maintaining patient trust. Current efforts in interpretability of medical coding applications rely heavily on label attention mechanisms, which often leads to the highlighting of extraneous tokens irrelevant to the ICD code. To facilitate accurate interpretability in medical language models, this paper leverages dictionary learning that can efficiently extract sparsely activated representations from dense language model embeddings in superposition. Compared with common label attention mechanisms, our model goes beyond token-level representations by building an interpretable dictionary which enhances the mechanistic-based explanations for each ICD code prediction, even when the highlighted tokens are medically irrelevant. We show that dictionary features can steer model behavior, elucidate the hidden meanings of upwards of 90% of medically irrelevant tokens, and are human interpretable.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "John Wu et al.",
      "keywords": "Transparency (behavior); Computer science; Coding (social sciences); Natural language processing; Artificial intelligence; Language model; Machine learning; Computer security; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.00173",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415023058",
      "doi": "10.48550/arxiv.2505.14312",
      "title": "MultiTab: A Comprehensive Benchmark Suite for Multi-Dimensional Evaluation in Tabular Domains",
      "abstract": "Despite the widespread use of tabular data in real-world applications, most benchmarks rely on average-case metrics, which fail to reveal how model behavior varies across diverse data regimes. To address this, we propose MultiTab, a benchmark suite and evaluation framework for multi-dimensional, data-aware analysis of tabular learning algorithms. Rather than comparing models only in aggregate, MultiTab categorizes 196 publicly available datasets along key data characteristics, including sample size, label imbalance, and feature interaction, and evaluates 13 representative models spanning a range of inductive biases. Our analysis shows that model performance is highly sensitive to such regimes: for example, models using sample-level similarity excel on datasets with large sample sizes or high inter-feature correlation, while models encoding inter-feature dependencies perform best with weakly correlated features. These findings reveal that inductive biases do not always behave as intended, and that regime-aware evaluation is essential for understanding and improving model behavior. MultiTab enables more principled model design and offers practical guidance for selecting models tailored to specific data characteristics. All datasets, code, and optimization logs are publicly available at https://huggingface.co/datasets/LGAI-DILab/Multitab.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Kyung\u2010Eun Lee et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.14312",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390961848",
      "doi": "10.48550/arxiv.2401.07058",
      "title": "Does More Advice Help? The Effects of Second Opinions in AI-Assisted Decision Making",
      "abstract": "AI assistance in decision-making has become popular, yet people's inappropriate reliance on AI often leads to unsatisfactory human-AI collaboration performance. In this paper, through three pre-registered, randomized human subject experiments, we explore whether and how the provision of {second opinions} may affect decision-makers' behavior and performance in AI-assisted decision-making. We find that if both the AI model's decision recommendation and a second opinion are always presented together, decision-makers reduce their over-reliance on AI while increase their under-reliance on AI, regardless whether the second opinion is generated by a peer or another AI model. However, if decision-makers have the control to decide when to solicit a peer's second opinion, we find that their active solicitations of second opinions have the potential to mitigate over-reliance on AI without inducing increased under-reliance in some cases. We conclude by discussing the implications of our findings for promoting effective human-AI collaborations in decision-making.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhuoran Lu et al.",
      "keywords": "Advice (programming); Affect (linguistics); Control (management); Popular opinion; Subject (documents); Public opinion; Psychology; Computer science; Public relations; Artificial intelligence; Political science; Sociology; Law; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.07058",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416091757",
      "doi": "10.48550/arxiv.2505.05396",
      "title": "A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods",
      "abstract": "From the original abstract: This thesis initially aims to study the pain assessment process from a clinical-theoretical perspective while exploring and examining existing automatic approaches. Building on this foundation, the primary objective of this Ph.D. project is to develop innovative computational methods for automatic pain assessment that achieve high performance and are applicable in real clinical settings. A primary goal is to thoroughly investigate and assess significant factors, including demographic elements that impact pain perception, as recognized in pain research, through a computational standpoint. Within the limits of the available data in this research area, our goal was to design, develop, propose, and offer automatic pain assessment pipelines for unimodal and multimodal configurations that are applicable to the specific requirements of different scenarios. The studies published in this Ph.D. thesis showcased the effectiveness of the proposed methods, achieving state-of-the-art results. Additionally, they paved the way for exploring new approaches in artificial intelligence, foundation models, and generative artificial intelligence.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Stefanos Gkikas",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.05396",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402698537",
      "doi": "10.48550/arxiv.2408.09607",
      "title": "Experimental Design For Causal Inference Through An Optimization Lens",
      "abstract": "The study of experimental design offers tremendous benefits for answering causal questions across a wide range of applications, including agricultural experiments, clinical trials, industrial experiments, social experiments, and digital experiments. Although valuable in such applications, the costs of experiments often drive experimenters to seek more efficient designs. Recently, experimenters have started to examine such efficiency questions from an optimization perspective, as experimental design problems are fundamentally decision-making problems. This perspective offers a lot of flexibility in leveraging various existing optimization tools to study experimental design problems. This manuscript thus aims to examine the foundations of experimental design problems in the context of causal inference as viewed through an optimization lens.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jinglong Zhao",
      "keywords": "Causal inference; Inference; Through-the-lens metering; Lens (geology); Computer science; Artificial intelligence; Econometrics; Economics; Optics; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.09607",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4223592771",
      "doi": "10.48550/arxiv.2204.03500",
      "title": "Multi-Task Distributed Learning using Vision Transformer with Random Patch Permutation",
      "abstract": "The widespread application of artificial intelligence in health research is currently hampered by limitations in data availability. Distributed learning methods such as federated learning (FL) and shared learning (SL) are introduced to solve this problem as well as data management and ownership issues with their different strengths and weaknesses. The recent proposal of federated split task-agnostic (FeSTA) learning tries to reconcile the distinct merits of FL and SL by enabling the multi-task collaboration between participants through Vision Transformer (ViT) architecture, but they suffer from higher communication overhead. To address this, here we present a multi-task distributed learning using ViT with random patch permutation. Instead of using a CNN based head as in FeSTA, p-FeSTA adopts a randomly permuting simple patch embedder, improving the multi-task learning performance without sacrificing privacy. Experimental results confirm that the proposed method significantly enhances the benefit of multi-task collaboration, communication efficiency, and privacy preservation, shedding light on practical multi-task distributed learning in the field of medical imaging.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Sang Joon Park et al.",
      "keywords": "Computer science; Task (project management); Multi-task learning; Distributed learning; Artificial intelligence; Transformer; Machine learning; Overhead (engineering); Permutation (music)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.03500",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387964058",
      "doi": "10.48550/arxiv.2310.16677",
      "title": "Machine Learning Approaches for Fine-Grained Symptom Estimation in Schizophrenia: A Comprehensive Review",
      "abstract": "Schizophrenia is a severe yet treatable mental disorder, it is diagnosed using a multitude of primary and secondary symptoms. Diagnosis and treatment for each individual depends on the severity of the symptoms, therefore there is a need for accurate, personalised assessments. However, the process can be both time-consuming and subjective; hence, there is a motivation to explore automated methods that can offer consistent diagnosis and precise symptom assessments, thereby complementing the work of healthcare practitioners. Machine Learning has demonstrated impressive capabilities across numerous domains, including medicine; the use of Machine Learning in patient assessment holds great promise for healthcare professionals and patients alike, as it can lead to more consistent and accurate symptom estimation.This survey aims to review methodologies that utilise Machine Learning for diagnosis and assessment of schizophrenia. Contrary to previous reviews that primarily focused on binary classification, this work recognises the complexity of the condition and instead, offers an overview of Machine Learning methods designed for fine-grained symptom estimation. We cover multiple modalities, namely Medical Imaging, Electroencephalograms and Audio-Visual, as the illness symptoms can manifest themselves both in a patient's pathology and behaviour. Finally, we analyse the datasets and methodologies used in the studies and identify trends, gaps as well as opportunities for future research.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Niki Maria Foteinopoulou et al.",
      "keywords": "Modalities; Schizophrenia (object-oriented programming); Artificial intelligence; Machine learning; Health care; Estimation; Medical diagnosis; Process (computing); Computer science; Data science; Psychology; Medicine; Psychiatry; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2310.16677",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389362509",
      "doi": "10.48550/arxiv.2312.00817",
      "title": "TimelyGPT: Extrapolatable Transformer Pre-training for Long-term Time-Series Forecasting in Healthcare",
      "abstract": "Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success in Natural Language Processing and Computer Vision domains. However, the development of PTMs on healthcare time-series data is lagging behind.This underscores the limitations of the existing transformer-based architectures, particularly their scalability to handle large-scale time series and ability to capture long-term temporal dependencies. In this study, we present Timely Generative Pre-trained Transformer (TimelyGPT). TimelyGPT employs an extrapolatable position (xPos) embedding to encode trend and periodic patterns into time-series representations. It also integrates recurrent attention and temporal convolution modules to effectively capture global-local temporal dependencies. We evaluated TimelyGPT on two large-scale healthcare time series datasets corresponding to continuous biosignals and irregularly-sampled time series, respectively. Our experiments show that during pre-training, TimelyGPT excels in learning time-series representations from continuously monitored biosignals and irregularly-sampled time series data commonly observed in longitudinal electronic health records (EHRs). In forecasting continuous biosignals, TimelyGPT achieves accurate extrapolation up to 6,000 timesteps of body temperature during the sleep stage transition, given a short look-up window (i.e., prompt) containing only 2,000 timesteps. For irregularly-sampled time series, TimelyGPT with a proposed time-specific inference demonstrates high top recall scores in predicting future diagnoses using early diagnostic records, effectively handling irregular intervals between clinical records. Together, we envision TimelyGPT to be useful in a broad spectrum of health domains, including long-term patient health state forecasting and patient risk trajectory prediction.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ziyang Song et al.",
      "keywords": "Extrapolation; Computer science; Scalability; Recurrent neural network; Transformer; Deep learning; Artificial intelligence; Time series; Machine learning; Data mining; Artificial neural network; Database; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2312.00817",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415311636",
      "doi": "10.48550/arxiv.2506.14203",
      "title": "Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation",
      "abstract": "In this study, we investigate the potential of language models (LMs) in aiding patients experiencing anomia, a difficulty identifying the names of items. Identifying the intended target item from patient's circumlocution involves the two challenges of term failure and error: (1) The terms relevant to identifying the item remain unseen. (2) What makes the challenge unique is inherent perturbed terms by semantic paraphasia, which are not exactly related to the target item, hindering the identification process. To address each, we propose robustifying the model from semantically paraphasic errors and enhancing the model with unseen terms with gradient-based selective augmentation. Specifically, the gradient value controls augmented data quality amid semantic errors, while the gradient variance guides the inclusion of unseen but relevant terms. Due to limited domain-specific datasets, we evaluate the model on the Tip-of-the-Tongue dataset as an intermediary task and then apply our findings to real patient data from AphasiaBank. Our results demonstrate strong performance against baselines, aiding anomia patients by addressing the outlined challenges.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Jongho Kim et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.14203",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417071111",
      "doi": "10.48550/arxiv.2505.14588",
      "title": "Generative AI at the Crossroads: Light Bulb, Dynamo, or Microscope?",
      "abstract": "With the advent of generative AI (genAI), the potential scope of artificial intelligence has increased dramatically, but the future effect of genAI on productivity remains uncertain. The effect of the technology on the innovation process is a crucial open question. Some inventions, such as the light bulb, temporarily raise productivity growth as adoption spreads, but the effect fades when the market is saturated; that is, the level of output per hour is permanently higher but the growth rate is not. In contrast, two types of technologies stand out as having longer-lived effects on productivity growth. First, there are technologies known as general-purpose technologies (GPTs). GPTs (1) are widely adopted, (2) spur abundant knock-on innovations (new goods and services, process efficiencies, and business reorganization), and (3) show continual improvement, refreshing this innovation cycle; the electric dynamo is an example. Second, there are inventions of methods of invention (IMIs). IMIs increase the efficiency of the research and development process via improvements to observation, analysis, communication, or organization; the compound microscope is an example. We show that GenAI has the characteristics of both a GPT and an IMI -- an encouraging sign that genAI will raise the \\textit{level} of productivity. Even so, genAI's contribution to productivity \\textit{growth} will depend on the speed with which that level is attained and, historically, integrating revolutionary technologies into the economy is a protracted process.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Martin Neil Baily et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.14588",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390690415",
      "doi": "10.48550/arxiv.2401.02717",
      "title": "Complementary Information Mutual Learning for Multimodality Medical Image Segmentation",
      "abstract": "Radiologists must utilize multiple modal images for tumor segmentation and diagnosis due to the limitations of medical imaging and the diversity of tumor signals. This leads to the development of multimodal learning in segmentation. However, the redundancy among modalities creates challenges for existing subtraction-based joint learning methods, such as misjudging the importance of modalities, ignoring specific modal information, and increasing cognitive load. These thorny issues ultimately decrease segmentation accuracy and increase the risk of overfitting. This paper presents the complementary information mutual learning (CIML) framework, which can mathematically model and address the negative impact of inter-modal redundant information. CIML adopts the idea of addition and removes inter-modal redundant information through inductive bias-driven task decomposition and message passing-based redundancy filtering. CIML first decomposes the multimodal segmentation task into multiple subtasks based on expert prior knowledge, minimizing the information dependence between modalities. Furthermore, CIML introduces a scheme in which each modality can extract information from other modalities additively through message passing. To achieve non-redundancy of extracted information, the redundant filtering is transformed into complementary information learning inspired by the variational information bottleneck. The complementary information learning procedure can be efficiently solved by variational inference and cross-modal spatial attention. Numerical results from the verification task and standard benchmarks indicate that CIML efficiently removes redundant information between modalities, outperforming SOTA methods regarding validation accuracy and segmentation effect.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Chuyun Shen et al.",
      "keywords": "Computer science; Modalities; Segmentation; Artificial intelligence; Redundancy (engineering); Information bottleneck method; Mutual information; Multi-task learning; Machine learning; Inference; Modal; Image segmentation; Pattern recognition (psychology); Task (project management)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.02717",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404311464",
      "doi": "10.48550/arxiv.2410.19279",
      "title": "UbiHR: Resource-efficient Long-range Heart Rate Sensing on Ubiquitous Devices",
      "abstract": "Ubiquitous on-device heart rate sensing is vital for high-stress individuals and chronic patients. Non-contact sensing, compared to contact-based tools, allows for natural user monitoring, potentially enabling more accurate and holistic data collection. However, in open and uncontrolled mobile environments, user movement and lighting introduce. Existing methods, such as curve-based or short-range deep learning recognition based on adjacent frames, strike the optimal balance between real-time performance and accuracy, especially under limited device resources. In this paper, we present UbiHR, a ubiquitous device-based heart rate sensing system. Key to UbiHR is a real-time long-range spatio-temporal model enabling noise-independent heart rate recognition and display on commodity mobile devices, along with a set of mechanisms for prompt and energy-efficient sampling and preprocessing. Diverse experiments and user studies involving four devices, four tasks, and 80 participants demonstrate UbiHR's superior performance, enhancing accuracy by up to 74.2\\% and reducing latency by 51.2\\%.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Hailong Bian et al.",
      "keywords": "Range (aeronautics); Resource (disambiguation); Computer science; Ubiquitous computing; Computer network; Materials science; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.19279",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403661828",
      "doi": "10.48550/arxiv.2409.08501",
      "title": "PSTNet: Enhanced Polyp Segmentation with Multi-scale Alignment and Frequency Domain Integration",
      "abstract": "Accurate segmentation of colorectal polyps in colonoscopy images is crucial for effective diagnosis and management of colorectal cancer (CRC). However, current deep learning-based methods primarily rely on fusing RGB information across multiple scales, leading to limitations in accurately identifying polyps due to restricted RGB domain information and challenges in feature misalignment during multi-scale aggregation. To address these limitations, we propose the Polyp Segmentation Network with Shunted Transformer (PSTNet), a novel approach that integrates both RGB and frequency domain cues present in the images. PSTNet comprises three key modules: the Frequency Characterization Attention Module (FCAM) for extracting frequency cues and capturing polyp characteristics, the Feature Supplementary Alignment Module (FSAM) for aligning semantic information and reducing misalignment noise, and the Cross Perception localization Module (CPM) for synergizing frequency cues with high-level semantics to achieve efficient polyp segmentation. Extensive experiments on challenging datasets demonstrate PSTNet's significant improvement in polyp segmentation accuracy across various metrics, consistently outperforming state-of-the-art methods. The integration of frequency domain cues and the novel architectural design of PSTNet contribute to advancing computer-assisted polyp segmentation, facilitating more accurate diagnosis and management of CRC.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Wenhao Xu et al.",
      "keywords": "Scale (ratio); Segmentation; Domain (mathematical analysis); Computer science; Artificial intelligence; Mathematics; Geography; Cartography; Mathematical analysis",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.08501",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4401594470",
      "doi": "10.48550/arxiv.2407.14651",
      "title": "Improving Representation of High-frequency Components for Medical Visual Foundation Models",
      "abstract": "Foundation models have recently attracted significant attention for their impressive generalizability across diverse downstream tasks. However, these models are demonstrated to exhibit great limitations in representing high-frequency components and fine-grained details. In many medical imaging tasks, the precise representation of such information is crucial due to the inherently intricate anatomical structures, sub-visual features, and complex boundaries involved. Consequently, the limited representation of prevalent foundation models can result in significant performance degradation or even failure in these tasks. To address these challenges, we propose a novel pretraining strategy, named Frequency-advanced Representation Autoencoder (Frepa). Through high-frequency masking and low-frequency perturbation combined with adversarial learning, Frepa encourages the encoder to effectively represent and preserve high-frequency components in the image embeddings. Additionally, we introduce an innovative histogram-equalized image masking strategy, extending the Masked Autoencoder approach beyond ViT to other architectures such as Swin Transformer and convolutional networks. We develop Frepa across nine medical modalities and validate it on 32 downstream tasks for both 2D images and 3D volume data. Without fine-tuning, Frepa can outperform other self-supervised pretraining methods and, in some cases, even surpasses task-specific trained models. This improvement is particularly significant for tasks involving fine-grained details, such as achieving up to a +15% increase in DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule detection. Further experiments quantitatively reveal that Frepa enables superior high-frequency representations and preservation in the embeddings, underscoring its potential for developing more generalized and universal medical image foundation models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuetan Chu et al.",
      "keywords": "Foundation (evidence); Representation (politics); Computer science; Political science; History; Archaeology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.14651",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392822545",
      "doi": "10.48550/arxiv.2403.08352",
      "title": "Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods",
      "abstract": "Data augmentation is arguably the most important regularization technique commonly used to improve generalization performance of machine learning models. It primarily involves the application of appropriate data transformation operations to create new data samples with desired properties. Despite its effectiveness, the process is often challenging because of the time-consuming trial and error procedures for creating and testing different candidate augmentations and their hyperparameters manually. State-of-the-art approaches are increasingly relying on automated machine learning (AutoML) principles. This work presents a comprehensive survey of AutoML-based data augmentation techniques. We discuss various approaches for accomplishing data augmentation with AutoML, including data manipulation, data integration and data synthesis techniques. The focus of this work is on image data augmentation methods. Nonetheless, we cover other data modalities, especially in cases where the specific data augmentations techniques being discussed are more suitable for these other modalities. For instance, since automated data integration methods are more suitable for tabular data, we cover tabular data in the discussion of data integration methods. The work also presents extensive discussion of techniques for accomplishing each of the major subtasks of the image data augmentation process: search space design, hyperparameter optimization and model evaluation. Finally, we carried out an extensive comparison and analysis of the performance of automated data augmentation techniques and state-of-the-art methods based on classical augmentation approaches. The results show that AutoML methods for data augmentation currently outperform state-of-the-art techniques based on conventional approaches.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Alhassan Mumuni et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.08352",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386651415",
      "doi": "10.48550/arxiv.2309.05238",
      "title": "Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation",
      "abstract": "Screening prioritisation in medical systematic reviews aims to rank the set of documents retrieved by complex Boolean queries. Prioritising the most important documents ensures that subsequent review steps can be carried out more efficiently and effectively. The current state of the art uses the final title of the review as a query to rank the documents using BERT-based neural rankers. However, the final title is only formulated at the end of the review process, which makes this approach impractical as it relies on ex post facto information. At the time of screening, only a rough working title is available, with which the BERT-based ranker performs significantly worse than with the final title. In this paper, we explore alternative sources of queries for prioritising screening, such as the Boolean query used to retrieve the documents to be screened and queries generated by instruction-based generative large-scale language models such as ChatGPT and Alpaca. Our best approach is not only viable based on the information available at the time of screening, but also has similar effectiveness to the final title.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuai Wang et al.",
      "keywords": "Computer science; Rank (graph theory); Information retrieval; Set (abstract data type); De facto; Process (computing); Data mining; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.05238",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400267156",
      "doi": "10.48550/arxiv.2407.00191",
      "title": "MetaKP: On-Demand Keyphrase Generation",
      "abstract": "Traditional keyphrase prediction methods predict a single set of keyphrases per document, failing to cater to the diverse needs of users and downstream applications. To bridge the gap, we introduce on-demand keyphrase generation, a novel paradigm that requires keyphrases that conform to specific high-level goals or intents. For this task, we present MetaKP, a large-scale benchmark comprising four datasets, 7500 documents, and 3760 goals across news and biomedical domains with human-annotated keyphrases. Leveraging MetaKP, we design both supervised and unsupervised methods, including a multi-task fine-tuning approach and a self-consistency prompting method with large language models. The results highlight the challenges of supervised fine-tuning, whose performance is not robust to distribution shifts. By contrast, the proposed self-consistency prompting approach greatly improves the performance of large language models, enabling GPT-4o to achieve 0.548 SemF1, surpassing the performance of a fully fine-tuned BART-base model. Finally, we demonstrate the potential of our method to serve as a general NLP infrastructure, exemplified by its application in epidemic event detection from social media.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Di Wu et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.00191",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297794453",
      "doi": "10.48550/arxiv.2209.04418",
      "title": "Trustworthy Federated Learning via Blockchain",
      "abstract": "The safety-critical scenarios of artificial intelligence (AI), such as autonomous driving, Internet of Things, smart healthcare, etc., have raised critical requirements of trustworthy AI to guarantee the privacy and security with reliable decisions. As a nascent branch for trustworthy AI, federated learning (FL) has been regarded as a promising privacy preserving framework for training a global AI model over collaborative devices. However, security challenges still exist in the FL framework, e.g., Byzantine attacks from malicious devices, and model tampering attacks from malicious server, which will degrade or destroy the accuracy of trained global AI model. In this paper, we shall propose a decentralized blockchain based FL (B-FL) architecture by using a secure global aggregation algorithm to resist malicious devices, and deploying practical Byzantine fault tolerance consensus protocol with high effectiveness and low energy consumption among multiple edge servers to prevent model tampering from the malicious server. However, to implement B-FL system at the network edge, multiple rounds of cross-validation in blockchain consensus protocol will induce long training latency. We thus formulate a network optimization problem that jointly considers bandwidth and power allocation for the minimization of long-term average training latency consisting of progressive learning rounds. We further propose to transform the network optimization problem as a Markov decision process and leverage the deep reinforcement learning based algorithm to provide high system performance with low computational complexity. Simulation results demonstrate that B-FL can resist malicious attacks from edge devices and servers, and the training latency of B-FL can be significantly reduced by deep reinforcement learning based algorithm compared with baseline algorithms.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhanpeng Yang et al.",
      "keywords": "Computer science; Byzantine fault tolerance; Server; Reinforcement learning; Blockchain; Computer security; Edge device; Deep learning; Distributed computing; Leverage (statistics); Artificial intelligence; Computer network; Fault tolerance; Cloud computing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.04418",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387210362",
      "doi": "10.48550/arxiv.2309.15979",
      "title": "Clinical Trial Recommendations Using Semantics-Based Inductive Inference and Knowledge Graph Embeddings",
      "abstract": "Designing a new clinical trial entails many decisions, such as defining a cohort and setting the study objectives to name a few, and therefore can benefit from recommendations based on exhaustive mining of past clinical trial records. Here, we propose a novel recommendation methodology, based on neural embeddings trained on a first-of-a-kind knowledge graph of clinical trials. We addressed several important research questions in this context, including designing a knowledge graph (KG) for clinical trial data, effectiveness of various KG embedding (KGE) methods for it, a novel inductive inference using KGE, and its use in generating recommendations for clinical trial design. We used publicly available data from clinicaltrials.gov for the study. Results show that our recommendations approach achieves relevance scores of 70%-83%, measured as the text similarity to actual clinical trial elements, and the most relevant recommendation can be found near the top of list. Our study also suggests potential improvement in training KGE using node semantics.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Murthy Devarakonda et al.",
      "keywords": "Inference; Computer science; Clinical trial; Graph; Context (archaeology); Relevance (law); Semantics (computer science); Artificial intelligence; Information retrieval; Natural language processing; Machine learning; Medicine; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.15979",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404648168",
      "doi": "10.48550/arxiv.2411.11641",
      "title": "TSINR: Capturing Temporal Continuity via Implicit Neural Representations for Time Series Anomaly Detection",
      "abstract": "Time series anomaly detection aims to identify unusual patterns in data or deviations from systems' expected behavior. The reconstruction-based methods are the mainstream in this task, which learn point-wise representation via unsupervised learning. However, the unlabeled anomaly points in training data may cause these reconstruction-based methods to learn and reconstruct anomalous data, resulting in the challenge of capturing normal patterns. In this paper, we propose a time series anomaly detection method based on implicit neural representation (INR) reconstruction, named TSINR, to address this challenge. Due to the property of spectral bias, TSINR enables prioritizing low-frequency signals and exhibiting poorer performance on high-frequency abnormal data. Specifically, we adopt INR to parameterize time series data as a continuous function and employ a transformer-based architecture to predict the INR of given data. As a result, the proposed TSINR method achieves the advantage of capturing the temporal continuity and thus is more sensitive to discontinuous anomaly data. In addition, we further design a novel form of INR continuous function to learn inter- and intra-channel information, and leverage a pre-trained large language model to amplify the intense fluctuations in anomalies. Extensive experiments demonstrate that TSINR achieves superior overall performance on both univariate and multivariate time series anomaly detection benchmarks compared to other state-of-the-art reconstruction-based methods. Our codes are available.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Mengxuan Li et al.",
      "keywords": "Anomaly detection; Series (stratigraphy); Anomaly (physics); Computer science; Time series; Artificial intelligence; Pattern recognition (psychology); Machine learning; Geology; Physics; Paleontology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.11641",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4286224687",
      "doi": "10.48550/arxiv.2207.09389",
      "title": "Image Synthesis with Disentangled Attributes for Chest X-Ray Nodule Augmentation and Detection",
      "abstract": "Lung nodule detection in chest X-ray (CXR) images is common to early screening of lung cancers. Deep-learning-based Computer-Assisted Diagnosis (CAD) systems can support radiologists for nodule screening in CXR. However, it requires large-scale and diverse medical data with high-quality annotations to train such robust and accurate CADs. To alleviate the limited availability of such datasets, lung nodule synthesis methods are proposed for the sake of data augmentation. Nevertheless, previous methods lack the ability to generate nodules that are realistic with the size attribute desired by the detector. To address this issue, we introduce a novel lung nodule synthesis framework in this paper, which decomposes nodule attributes into three main aspects including shape, size, and texture, respectively. A GAN-based Shape Generator firstly models nodule shapes by generating diverse shape masks. The following Size Modulation then enables quantitative control on the diameters of the generated nodule shapes in pixel-level granularity. A coarse-to-fine gated convolutional Texture Generator finally synthesizes visually plausible nodule textures conditioned on the modulated shape masks. Moreover, we propose to synthesize nodule CXR images by controlling the disentangled nodule attributes for data augmentation, in order to better compensate for the nodules that are easily missed in the detection task. Our experiments demonstrate the enhanced image quality, diversity, and controllability of the proposed lung nodule synthesis framework. We also validate the effectiveness of our data augmentation on greatly improving nodule detection performance.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhenrong Shen et al.",
      "keywords": "Nodule (geology); Computer science; Artificial intelligence; Pattern recognition (psychology); Computer vision; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2207.09389",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415247850",
      "doi": "10.48550/arxiv.2505.03401",
      "title": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation",
      "abstract": "Radiology Report Generation (RRG) automates the creation of radiology reports from medical imaging, enhancing the efficiency of the reporting process. Longitudinal Radiology Report Generation (LRRG) extends RRG by incorporating the ability to compare current and prior exams, facilitating the tracking of temporal changes in clinical findings. Existing LRRG approaches only extract features from prior and current images using a visual pre-trained encoder, which are then concatenated to generate the final report. However, these methods struggle to effectively capture both spatial and temporal correlations during the feature extraction process. Consequently, the extracted features inadequately capture the information of difference across exams and thus underrepresent the expected progressions, leading to sub-optimal performance in LRRG. To address this, we develop a novel dynamic difference-aware temporal residual network (DDaTR). In DDaTR, we introduce two modules at each stage of the visual encoder to capture multi-level spatial correlations. The Dynamic Feature Alignment Module (DFAM) is designed to align prior features across modalities for the integrity of prior clinical information. Prompted by the enriched prior features, the dynamic difference-aware module (DDAM) captures favorable difference information by identifying relationships across exams. Furthermore, our DDaTR employs the dynamic residual network to unidirectionally transmit longitudinal information, effectively modelling temporal correlations. Extensive experiments demonstrated superior performance over existing methods on three benchmarks, proving its efficacy in both RRG and LRRG tasks.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Shanshan Song et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.03401",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4404306488",
      "doi": "10.48550/arxiv.2410.18393",
      "title": "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness",
      "abstract": "Social media is often the first place where communities discuss the latest societal trends. Prior works have utilized this platform to extract epidemic-related information (e.g. infections, preventive measures) to provide early warnings for epidemic prediction. However, these works only focused on English posts, while epidemics can occur anywhere in the world, and early discussions are often in the local, non-English languages. In this work, we introduce the first multilingual Event Extraction (EE) framework SPEED++ for extracting epidemic event information for a wide range of diseases and languages. To this end, we extend a previous epidemic ontology with 20 argument roles; and curate our multilingual EE dataset SPEED++ comprising 5.1K tweets in four languages for four diseases. Annotating data in every language is infeasible; thus we develop zero-shot cross-lingual cross-disease models (i.e., training only on English COVID data) utilizing multilingual pre-training and show their efficacy in extracting epidemic-related events for 65 diverse languages across different diseases. Experiments demonstrate that our framework can provide epidemic warnings for COVID-19 in its earliest stages in Dec 2019 (3 weeks before global discussions) from Chinese Weibo posts without any training in Chinese. Furthermore, we exploit our framework's argument extraction capabilities to aggregate community epidemic discussions like symptoms and cure measures, aiding misinformation detection and public attention monitoring. Overall, we lay a strong foundation for multilingual epidemic preparedness.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Tanmay Parekh et al.",
      "keywords": "Preparedness; Event (particle physics); Extraction (chemistry); Computer science; Artificial intelligence; Political science; Chromatography; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.18393",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4229073015",
      "doi": "10.48550/arxiv.2205.02007",
      "title": "A Computational Inflection for Scientific Discovery",
      "abstract": "We stand at the foot of a significant inflection in the trajectory of scientific discovery. As society continues on its fast-paced digital transformation, so does humankind's collective scientific knowledge and discourse. We now read and write papers in digitized form, and a great deal of the formal and informal processes of science are captured digitally -- including papers, preprints and books, code and datasets, conference presentations, and interactions in social networks and collaboration and communication platforms. The transition has led to the creation and growth of a tremendous amount of information -- much of which is available for public access -- opening exciting opportunities for computational models and systems that analyze and harness it. In parallel, exponential growth in data processing power has fueled remarkable advances in artificial intelligence, including large neural language models capable of learning powerful representations from unstructured text. Dramatic changes in scientific communication -- such as the advent of the first scientific journal in the 17th century -- have historically catalyzed revolutions in scientific thought. The confluence of societal and computational trends suggests that computer science is poised to ignite a revolution in the scientific process itself.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Tom Hope et al.",
      "keywords": "Inflection; Computer science; Scientific discovery; Process (computing); Data science; Scientific communication; Science communication; Computational sociology; Scientific revolution; Social media; Sociology of scientific knowledge; Scientific progress; Cognitive science; Artificial intelligence; World Wide Web; Sociology; Social science; Epistemology; Science education",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.02007",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387323615",
      "doi": "10.48550/arxiv.2310.00347",
      "title": "Unlocking Bias Detection: Leveraging Transformer-Based Models for Content Analysis",
      "abstract": "Bias detection in text is crucial for combating the spread of negative stereotypes, misinformation, and biased decision-making. Traditional language models frequently face challenges in generalizing beyond their training data and are typically designed for a single task, often focusing on bias detection at the sentence level. To address this, we present the Contextualized Bi-Directional Dual Transformer (CBDT) \\textcolor{green}{\\faLeaf} classifier. This model combines two complementary transformer networks: the Context Transformer and the Entity Transformer, with a focus on improving bias detection capabilities. We have prepared a dataset specifically for training these models to identify and locate biases in texts. Our evaluations across various datasets demonstrate CBDT \\textcolor{green} effectiveness in distinguishing biased narratives from neutral ones and identifying specific biased terms. This work paves the way for applying the CBDT \\textcolor{green} model in various linguistic and cultural contexts, enhancing its utility in bias detection efforts. We also make the annotated dataset available for research purposes.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shaina Raza et al.",
      "keywords": "Transformer; Computer science; Classifier (UML); Language model; Machine learning; Artificial intelligence; Natural language processing; Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.00347",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4381713065",
      "doi": "10.48550/arxiv.2306.11892",
      "title": "Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications",
      "abstract": "This paper explores new frontiers in agricultural natural language processing by investigating the effectiveness of using food-related text corpora for pretraining transformer-based language models. In particular, we focus on the task of semantic matching, which involves establishing mappings between food descriptions and nutrition data. To accomplish this, we fine-tune a pre-trained transformer-based language model, AgriBERT, on this task, utilizing an external source of knowledge, such as the FoodOn ontology. To advance the field of agricultural NLP, we propose two new avenues of exploration: (1) utilizing GPT-based models as a baseline and (2) leveraging ChatGPT as an external source of knowledge. ChatGPT has shown to be a strong baseline in many NLP tasks, and we believe it has the potential to improve our model in the task of semantic matching and enhance our model's understanding of food-related concepts and relationships. Additionally, we experiment with other applications, such as cuisine prediction based on food ingredients, and expand the scope of our research to include other NLP tasks beyond semantic matching. Overall, this paper provides promising avenues for future research in this field, with potential implications for improving the performance of agricultural NLP applications.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Saed Rezayi et al.",
      "keywords": "Computer science; Transformer; Artificial intelligence; Natural language processing; Baseline (sea); Task (project management); Scope (computer science); Matching (statistics); Field (mathematics); Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.11892",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403322216",
      "doi": "10.48550/arxiv.2410.03884",
      "title": "KidLM: Advancing Language Models for Children -- Early Insights and Future Directions",
      "abstract": "Recent studies highlight the potential of large language models in creating educational tools for children, yet significant challenges remain in maintaining key child-specific properties such as linguistic nuances, cognitive needs, and safety standards. In this paper, we explore foundational steps toward the development of child-specific language models, emphasizing the necessity of high-quality pre-training data. We introduce a novel user-centric data collection pipeline that involves gathering and validating a corpus specifically written for and sometimes by children. Additionally, we propose a new training objective, Stratified Masking, which dynamically adjusts masking probabilities based on our domain-specific child language data, enabling models to prioritize vocabulary and concepts more suitable for children. Experimental evaluations demonstrate that our model excels in understanding lower grade-level text, maintains safety by avoiding stereotypes, and captures children's unique preferences. Furthermore, we provide actionable insights for future research and development in child-specific language modeling.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Mir Tafseer Nayeem et al.",
      "keywords": "Computer science; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.03884",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287374070",
      "doi": "10.48550/arxiv.2101.07714",
      "title": "Towards Facilitating Empathic Conversations in Online Mental Health\\n Support: A Reinforcement Learning Approach",
      "abstract": "Online peer-to-peer support platforms enable conversations between millions\\nof people who seek and provide mental health support. If successful, web-based\\nmental health conversations could improve access to treatment and reduce the\\nglobal disease burden. Psychologists have repeatedly demonstrated that empathy,\\nthe ability to understand and feel the emotions and experiences of others, is a\\nkey component leading to positive outcomes in supportive conversations.\\nHowever, recent studies have shown that highly empathic conversations are rare\\nin online mental health platforms.\\n In this paper, we work towards improving empathy in online mental health\\nsupport conversations. We introduce a new task of empathic rewriting which aims\\nto transform low-empathy conversational posts to higher empathy. Learning such\\ntransformations is challenging and requires a deep understanding of empathy\\nwhile maintaining conversation quality through text fluency and specificity to\\nthe conversational context. Here we propose PARTNER, a deep reinforcement\\nlearning agent that learns to make sentence-level edits to posts in order to\\nincrease the expressed level of empathy while maintaining conversation quality.\\nOur RL agent leverages a policy network, based on a transformer language model\\nadapted from GPT-2, which performs the dual task of generating candidate\\nempathic sentences and adding those sentences at appropriate positions. During\\ntraining, we reward transformations that increase empathy in posts while\\nmaintaining text fluency, context specificity and diversity. Through a\\ncombination of automatic and human evaluation, we demonstrate that PARTNER\\nsuccessfully generates more empathic, specific, and diverse responses and\\noutperforms NLP methods from related tasks like style transfer and empathic\\ndialogue generation. Our work has direct implications for facilitating empathic\\nconversations on web-based platforms.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Ashish Sharma et al.",
      "keywords": "Empathy; Conversation; Computer science; Mental health; Context (archaeology); Fluency; Psychology; Cognitive psychology; Social psychology; Communication; Psychotherapist",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2101.07714",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414534826",
      "doi": "10.48550/arxiv.2506.04194",
      "title": "What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness",
      "abstract": "Most of the widely used estimators of the average treatment effect (ATE) in causal inference rely on the assumptions of unconfoundedness and overlap. Unconfoundedness requires that the observed covariates account for all correlations between the outcome and treatment. Overlap requires the existence of randomness in treatment decisions for all individuals. Nevertheless, many types of studies frequently violate unconfoundedness or overlap, for instance, observational studies with deterministic treatment decisions - popularly known as Regression Discontinuity designs - violate overlap. In this paper, we initiate the study of general conditions that enable the identification of the average treatment effect, extending beyond unconfoundedness and overlap. In particular, following the paradigm of statistical learning theory, we provide an interpretable condition that is sufficient and necessary for the identification of ATE. Moreover, this condition also characterizes the identification of the average treatment effect on the treated (ATT) and can be used to characterize other treatment effects as well. To illustrate the utility of our condition, we present several well-studied scenarios where our condition is satisfied and, hence, we prove that ATE can be identified in regimes that prior works could not capture. For example, under mild assumptions on the data distributions, this holds for the models proposed by Tan (2006) and Rosenbaum (2002), and the Regression Discontinuity design model introduced by Thistlethwaite and Campbell (1960). For each of these scenarios, we also show that, under natural additional assumptions, ATE can be estimated from finite samples. We believe these findings open new avenues for bridging learning-theoretic insights and causal inference methodologies, particularly in observational studies with complex treatment mechanisms.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yong Cai et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.04194",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415160690",
      "doi": "10.48550/arxiv.2504.10359",
      "title": "DICE: A Framework for Dimensional and Contextual Evaluation of Language Models",
      "abstract": "Language models (LMs) are increasingly being integrated into a wide range of applications, yet the modern evaluation paradigm does not sufficiently reflect how they are actually being used. Current evaluations rely on benchmarks that often lack direct applicability to the real-world contexts in which LMs are being deployed. To address this gap, we propose Dimensional and Contextual Evaluation (DICE), an approach that evaluates LMs on granular, context-dependent dimensions. In this position paper, we begin by examining the insufficiency of existing LM benchmarks, highlighting their limited applicability to real-world use cases. Next, we propose a set of granular evaluation parameters that capture dimensions of LM behavior that are more meaningful to stakeholders across a variety of application domains. Specifically, we introduce the concept of context-agnostic parameters - such as robustness, coherence, and epistemic honesty - and context-specific parameters that must be tailored to the specific contextual constraints and demands of stakeholders choosing to deploy LMs into a particular setting. We then discuss potential approaches to operationalize this evaluation framework, finishing with the opportunities and challenges DICE presents to the LM evaluation landscape. Ultimately, this work serves as a practical and approachable starting point for context-specific and stakeholder-relevant evaluation of LMs.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Ajay Kumar Shrivastava et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10359",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416048539",
      "doi": "10.48550/arxiv.2505.22483",
      "title": "A Closer Look at Multimodal Representation Collapse",
      "abstract": "We aim to develop a fundamental understanding of modality collapse, a recently observed empirical phenomenon wherein models trained for multimodal fusion tend to rely only on a subset of the modalities, ignoring the rest. We show that modality collapse happens when noisy features from one modality are entangled, via a shared set of neurons in the fusion head, with predictive features from another, effectively masking out positive contributions from the predictive features of the former modality and leading to its collapse. We further prove that cross-modal knowledge distillation implicitly disentangles such representations by freeing up rank bottlenecks in the student encoder, denoising the fusion-head outputs without negatively impacting the predictive features from either modality. Based on the above findings, we propose an algorithm that prevents modality collapse through explicit basis reallocation, with applications in dealing with missing modalities. Extensive experiments on multiple multimodal benchmarks validate our theoretical claims. Project page: https://abhrac.github.io/mmcollapse/.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Abhra Chaudhuri et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.22483",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W46659105",
      "doi": "10.48550/arxiv.2010.16061",
      "title": "Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation",
      "abstract": "Commonly used evaluation measures including Recall, Precision, F-Measure and Rand Accuracy are biased and should not be used without clear understanding of the biases, and corresponding identification of chance or base case levels of the statistic. Using these measures a system that performs worse in the objective sense of Informedness, can appear to perform better under any of these commonly used measures. We discuss several concepts and measures that reflect the probability that prediction is informed versus chance. Informedness and introduce Markedness as a dual measure for the probability that prediction is marked versus chance. Finally we demonstrate elegant connections between the concepts of Informedness, Markedness, Correlation and Significance as well as their intuitive relationships with Recall and Precision, and outline the extension from the dichotomous case to the general multi-class case.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "David Powers",
      "keywords": "Markedness; Measure (data warehouse); Recall; Computer science; Statistic; Correlation; Natural language processing; Artificial intelligence; Class (philosophy); Extension (predicate logic); Statistics; Mathematics; Psychology; Linguistics; Data mining; Cognitive psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2010.16061",
      "cited_by_count": 4425,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392931894",
      "doi": "10.48550/arxiv.2403.10250",
      "title": "Interpretable Machine Learning for Survival Analysis",
      "abstract": "With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade. This is particularly relevant for survival analysis, where the adoption of IML techniques promotes transparency, accountability and fairness in sensitive areas, such as clinical decision making processes, the development of targeted therapies, interventions or in other medical or healthcare related contexts. More specifically, explainability can uncover a survival model's potential biases and limitations and provide more mathematically sound ways to understand how and which features are influential for prediction or constitute risk factors. However, the lack of readily available IML methods may have deterred medical practitioners and policy makers in public health from leveraging the full potential of machine learning for predicting time-to-event data. We present a comprehensive review of the limited existing amount of work on IML methods for survival analysis within the context of the general IML taxonomy. In addition, we formally detail how commonly used IML methods, such as such as individual conditional expectation (ICE), partial dependence plots (PDP), accumulated local effects (ALE), different feature importance measures or Friedman's H-interaction statistics can be adapted to survival outcomes. An application of several IML methods to real data on data on under-5 year mortality of Ghanaian children from the Demographic and Health Surveys (DHS) Program serves as a tutorial or guide for researchers, on how to utilize the techniques in practice to facilitate understanding of model decisions or predictions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "S. Langbein et al.",
      "keywords": "Artificial intelligence; Machine learning; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.10250",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2954855426",
      "doi": "10.48550/arxiv.1906.10742",
      "title": "Machine Learning Testing: Survey, Landscapes and Horizons",
      "abstract": "This paper provides a comprehensive survey of Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie M. Zhang et al.",
      "keywords": "Workflow; Correctness; Computer science; Robustness (evolution); Machine learning; Robustness testing; Test (biology); Artificial intelligence; Data science; Database; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1906.10742",
      "cited_by_count": 108,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2983035142",
      "doi": "10.48550/arxiv.1911.07524",
      "title": "The Devil is in the Details: Delving into Unbiased Data Processing for Human Pose Estimation",
      "abstract": "Being a fundamental component in training and inference, data processing has not been systematically considered in human pose estimation community, to the best of our knowledge. In this paper, we focus on this problem and find that the devil of human pose estimation evolution is in the biased data processing. Specifically, by investigating the standard data processing in state-of-the-art approaches mainly including coordinate system transformation and keypoint format transformation (i.e., encoding and decoding), we find that the results obtained by common flipping strategy are unaligned with the original ones in inference. Moreover, there is a statistical error in some keypoint format transformation methods. Two problems couple together, significantly degrade the pose estimation performance and thus lay a trap for the research community. This trap has given bone to many suboptimal remedies, which are always unreported, confusing but influential. By causing failure in reproduction and unfair in comparison, the unreported remedies seriously impedes the technological development. To tackle this dilemma from the source, we propose Unbiased Data Processing (UDP) consist of two technique aspect for the two aforementioned problems respectively (i.e., unbiased coordinate system transformation and unbiased keypoint format transformation). As a model-agnostic approach and a superior solution, UDP successfully pushes the performance boundary of human pose estimation and offers a higher and more reliable baseline for research community. Code is public available in https://github.com/HuangJunJie2017/UDP-Pose",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Junjie Huang et al.",
      "keywords": "Computer science; Transformation (genetics); Inference; Pose; Encoding (memory); Dilemma; Coordinate system; Code (set theory); Decoding methods; Statistical inference; Artificial intelligence; Focus (optics); Data mining; Machine learning; Data science; Algorithm; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1911.07524",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4362631702",
      "doi": "10.48550/arxiv.2304.00416",
      "title": "Towards Healthy AI: Large Language Models Need Therapists Too",
      "abstract": "Recent advances in large language models (LLMs) have led to the development of powerful AI chatbots capable of engaging in natural and human-like conversations. However, these chatbots can be potentially harmful, exhibiting manipulative, gaslighting, and narcissistic behaviors. We define Healthy AI to be safe, trustworthy and ethical. To create healthy AI systems, we present the SafeguardGPT framework that uses psychotherapy to correct for these harmful behaviors in AI chatbots. The framework involves four types of AI agents: a Chatbot, a \"User,\" a \"Therapist,\" and a \"Critic.\" We demonstrate the effectiveness of SafeguardGPT through a working example of simulating a social conversation. Our results show that the framework can improve the quality of conversations between AI chatbots and humans. Although there are still several challenges and directions to be addressed in the future, SafeguardGPT provides a promising approach to improving the alignment between AI chatbots and human values. By incorporating psychotherapy and reinforcement learning techniques, the framework enables AI chatbots to learn and adapt to human preferences and values in a safe and ethical way, contributing to the development of a more human-centric and responsible AI.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Baihan Lin et al.",
      "keywords": "Chatbot; Conversation; Computer science; Quality (philosophy); Trustworthiness; Artificial intelligence; Psychology; Cognitive science; Human\u2013computer interaction; Communication; Epistemology; Internet privacy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.00416",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2951319200",
      "doi": "10.48550/arxiv.1505.06236",
      "title": "A Bottom-up Approach for Pancreas Segmentation using Cascaded Superpixels and (Deep) Image Patch Labeling",
      "abstract": "Robust automated organ segmentation is a prerequisite for computer-aided diagnosis (CAD), quantitative imaging analysis and surgical assistance. For high-variability organs such as the pancreas, previous approaches report undesirably low accuracies. We present a bottom-up approach for pancreas segmentation in abdominal CT scans that is based on a hierarchy of information propagation by classifying image patches at different resolutions; and cascading superpixels. There are four stages: 1) decomposing CT slice images as a set of disjoint boundary-preserving superpixels; 2) computing pancreas class probability maps via dense patch labeling; 3) classifying superpixels by pooling both intensity and probability features to form empirical statistics in cascaded random forest frameworks; and 4) simple connectivity based post-processing. The dense image patch labeling are conducted by: efficient random forest classifier on image histogram, location and texture features; and more expensive (but with better specificity) deep convolutional neural network classification on larger image windows (with more spatial contexts). Evaluation of the approach is performed on a database of 80 manually segmented CT volumes in six-fold cross-validation (CV). Our achieved results are comparable, or better than the state-of-the-art methods (evaluated by \"leave-one-patient-out\"), with Dice 70.7% and Jaccard 57.9%. The computational efficiency has been drastically improved in the order of 6~8 minutes, comparing with others of ~10 hours per case. Finally, we implement a multi-atlas label fusion (MALF) approach for pancreas segmentation using the same datasets. Under six-fold CV, our bottom-up segmentation method significantly outperforms its MALF counterpart: (70.7 +/- 13.0%) versus (52.5 +/- 20.8%) in Dice. Deep CNN patch labeling confidences offer more numerical stability, reflected by smaller standard deviations.",
      "year": "2015",
      "journal": "arXiv (Cornell University)",
      "authors": "Amal Farag et al.",
      "keywords": "Random forest; Artificial intelligence; Segmentation; Computer science; Pattern recognition (psychology); Jaccard index; Convolutional neural network; Histogram; Image segmentation; Computer vision; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1505.06236",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285597974",
      "doi": "10.48550/arxiv.2207.06509",
      "title": "One Model to Unite Them All: Personalized Federated Learning of Multi-Contrast MRI Synthesis",
      "abstract": "Multi-institutional collaborations are key for learning generalizable MRI synthesis models that translate source- onto target-contrast images. To facilitate collaboration, federated learning (FL) adopts decentralized training and mitigates privacy concerns by avoiding sharing of imaging data. However, FL-trained synthesis models can be impaired by the inherent heterogeneity in the data distribution, with domain shifts evident when common or variable translation tasks are prescribed across sites. Here we introduce the first personalized FL method for MRI Synthesis (pFLSynth) to improve reliability against domain shifts. pFLSynth is based on an adversarial model that produces latents specific to individual sites and source-target contrasts, and leverages novel personalization blocks to adaptively tune the statistics and weighting of feature maps across the generator stages given latents. To further promote site specificity, partial model aggregation is employed over downstream layers of the generator while upstream layers are retained locally. As such, pFLSynth enables training of a unified synthesis model that can reliably generalize across multiple sites and translation tasks. Comprehensive experiments on multi-site datasets clearly demonstrate the enhanced performance of pFLSynth against prior federated methods in multi-contrast MRI synthesis.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Onat Dalmaz et al.",
      "keywords": "Computer science; Personalization; Weighting; Contrast (vision); Generator (circuit theory); Domain (mathematical analysis); Translation (biology); Artificial intelligence; Key (lock); Feature (linguistics); Reliability (semiconductor); Data mining; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2207.06509",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3014514837",
      "doi": "10.48550/arxiv.2004.00053",
      "title": "Information Leakage in Embedding Models",
      "abstract": "Embeddings are functions that map raw input data to low-dimensional vector representations, while preserving important semantic information about the inputs. Pre-training embeddings on a large amount of unlabeled data and fine-tuning them for downstream tasks is now a de facto standard in achieving state of the art learning in many domains. We demonstrate that embeddings, in addition to encoding generic semantics, often also present a vector that leaks sensitive information about the input data. We develop three classes of attacks to systematically study information that might be leaked by embeddings. First, embedding vectors can be inverted to partially recover some of the input data. As an example, we show that our attacks on popular sentence embeddings recover between 50\\%--70\\% of the input words (F1 scores of 0.5--0.7). Second, embeddings may reveal sensitive attributes inherent in inputs and independent of the underlying semantic task at hand. Attributes such as authorship of text can be easily extracted by training an inference model on just a handful of labeled embedding vectors. Third, embedding models leak moderate amount of membership information for infrequent training data inputs. We extensively evaluate our attacks on various state-of-the-art embedding models in the text domain. We also propose and evaluate defenses that can prevent the leakage to some extent at a minor cost in utility.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Congzheng Song et al.",
      "keywords": "Embedding; Computer science; Inference; Sentence; Information leakage; Encoding (memory); Task (project management); Artificial intelligence; Theoretical computer science; Data mining; Natural language processing; Pattern recognition (psychology); Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2004.00053",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4225550260",
      "doi": "10.48550/arxiv.2204.02779",
      "title": "A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation",
      "abstract": "Deep learning models for medical image segmentation can fail unexpectedly and spectacularly for pathological cases and images acquired at different centers than training images, with labeling errors that violate expert knowledge. Such errors undermine the trustworthiness of deep learning models for medical image segmentation. Mechanisms for detecting and correcting such failures are essential for safely translating this technology into clinics and are likely to be a requirement of future regulations on artificial intelligence (AI). In this work, we propose a trustworthy AI theoretical framework and a practical system that can augment any backbone AI system using a fallback method and a fail-safe mechanism based on Dempster-Shafer theory. Our approach relies on an actionable definition of trustworthy AI. Our method automatically discards the voxel-level labeling predicted by the backbone AI that violate expert knowledge and relies on a fallback for those voxels. We demonstrate the effectiveness of the proposed trustworthy AI approach on the largest reported annotated dataset of fetal MRI consisting of 540 manually annotated fetal brain 3D T2w MRIs from 13 centers. Our trustworthy AI method improves the robustness of a state-of-the-art backbone AI for fetal brain MRIs acquired across various centers and for fetuses with various brain abnormalities.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Lucas Fidon et al.",
      "keywords": "Artificial intelligence; Computer science; Robustness (evolution); Segmentation; Voxel; Trustworthiness; Dempster\u2013Shafer theory; Deep learning; Machine learning; Pattern recognition (psychology); Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.02779",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388717680",
      "doi": "10.48550/arxiv.2311.07594",
      "title": "How to Bridge the Gap between Modalities: Survey on Multimodal Large Language Model",
      "abstract": "We explore Multimodal Large Language Models (MLLMs), which integrate LLMs like GPT-4 to handle multimodal data, including text, images, audio, and more. MLLMs demonstrate capabilities such as generating image captions and answering image-based questions, bridging the gap towards real-world human-computer interactions and hinting at a potential pathway to artificial general intelligence. However, MLLMs still face challenges in addressing the semantic gap in multimodal data, which may lead to erroneous outputs, posing potential risks to society. Selecting the appropriate modality alignment method is crucial, as improper methods might require more parameters without significant performance improvements. This paper aims to explore modality alignment methods for LLMs and their current capabilities. Implementing effective modality alignment can help LLMs address environmental issues and enhance accessibility. The study surveys existing modality alignment methods for MLLMs, categorizing them into four groups: (1) Multimodal Converter, which transforms data into a format that LLMs can understand; (2) Multimodal Perceiver, which improves how LLMs percieve different types of data; (3) Tool Learning, which leverages external tools to convert data into a common format, usually text; and (4) Data-Driven Method, which teaches LLMs to understand specific data types within datasets.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shezheng Song et al.",
      "keywords": "Multimodality; Modalities; Computer science; Modality (human\u2013computer interaction); Bridging (networking); Data science; Bridge (graph theory); Artificial intelligence; Human\u2013computer interaction; World Wide Web; Sociology; Medicine; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.07594",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385774780",
      "doi": "10.48550/arxiv.2308.05342",
      "title": "Metacognitive Prompting Improves Understanding in Large Language Models",
      "abstract": "In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. Recent advancements in prompting have enhanced reasoning in logic-intensive tasks for LLMs, yet the nuanced understanding abilities of these models, crucial for processing and interpreting complex information, remain underexplored. In this study, we introduce Metacognitive Prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. We conduct extensive experiments on four prevalent LLMs: Llama2, PaLM2, GPT-3.5, and GPT-4, across ten natural language understanding (NLU) datasets from GLUE, SuperGLUE, BLUE, and LexGLUE benchmarks. Additionally, we compare our method with chain-of-thought prompting and its advanced versions. The results show that GPT-4 consistently excels across all tasks, while other models have shown significant progress in some tasks when used in conjunction with MP. Furthermore, MP consistently outperforms existing prompting methods in both general and domain-specific NLU tasks. This study underscores the potential to amplify the understanding abilities of LLMs and highlights the benefits of mirroring human introspective reasoning in NLU tasks.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuqing Wang et al.",
      "keywords": "Metacognition; Introspection; Mirroring; Task (project management); Cognitive psychology; Computer science; Natural language understanding; Psychology; Cognitive science; Cognition; Artificial intelligence; Natural language; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.05342",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3033385487",
      "doi": "10.48550/arxiv.2006.03796",
      "title": "Deep Mining External Imperfect Data for Chest X-ray Disease Screening",
      "abstract": "Deep learning approaches have demonstrated remarkable progress in automatic Chest X-ray analysis. The data-driven feature of deep models requires training data to cover a large distribution. Therefore, it is substantial to integrate knowledge from multiple datasets, especially for medical images. However, learning a disease classification model with extra Chest X-ray (CXR) data is yet challenging. Recent researches have demonstrated that performance bottleneck exists in joint training on different CXR datasets, and few made efforts to address the obstacle. In this paper, we argue that incorporating an external CXR dataset leads to imperfect training data, which raises the challenges. Specifically, the imperfect data is in two folds: domain discrepancy, as the image appearances vary across datasets; and label discrepancy, as different datasets are partially labeled. To this end, we formulate the multi-label thoracic disease classification problem as weighted independent binary tasks according to the categories. For common categories shared across domains, we adopt task-specific adversarial training to alleviate the feature differences. For categories existing in a single dataset, we present uncertainty-aware temporal ensembling of model predictions to mine the information from the missing labels further. In this way, our framework simultaneously models and tackles the domain and label discrepancies, enabling superior knowledge mining ability. We conduct extensive experiments on three datasets with more than 360,000 Chest X-ray images. Our method outperforms other competing models and sets state-of-the-art performance on the official NIH test set with 0.8349 AUC, demonstrating its effectiveness of utilizing the external dataset to improve the internal classification.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Luyang Luo et al.",
      "keywords": "Computer science; Bottleneck; Artificial intelligence; Feature (linguistics); Deep learning; Machine learning; Domain (mathematical analysis); Imperfect; Set (abstract data type); Data mining; Binary classification; Domain knowledge; Pattern recognition (psychology); Support vector machine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2006.03796",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4224944790",
      "doi": "10.48550/arxiv.2204.10817",
      "title": "Reward Reports for Reinforcement Learning",
      "abstract": "Building systems that are good for society in the face of complex societal effects requires a dynamic approach. Recent approaches to machine learning (ML) documentation have demonstrated the promise of discursive frameworks for deliberation about these complexities. However, these developments have been grounded in a static ML paradigm, leaving the role of feedback and post-deployment performance unexamined. Meanwhile, recent work in reinforcement learning has shown that the effects of feedback and optimization objectives on system behavior can be wide-ranging and unpredictable. In this paper we sketch a framework for documenting deployed and iteratively updated learning systems, which we call Reward Reports. Taking inspiration from various contributions to the technical literature on reinforcement learning, we outline Reward Reports as living documents that track updates to design choices and assumptions behind what a particular automated system is optimizing for. They are intended to track dynamic phenomena arising from system deployment, rather than merely static properties of models or data. After presenting the elements of a Reward Report, we discuss a concrete example: Meta's BlenderBot 3 chatbot. Several others for game-playing (DeepMind's MuZero), content recommendation (MovieLens), and traffic control (Project Flow) are included in the appendix.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Thomas Krendl Gilbert et al.",
      "keywords": "Reinforcement learning; Computer science; Software deployment; Sketch; Documentation; Chatbot; Human\u2013computer interaction; Deliberation; Artificial intelligence; Data science; Software engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.10817",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4321853906",
      "doi": "10.48550/arxiv.2302.11703",
      "title": "fAIlureNotes: Supporting Designers in Understanding the Limits of AI Models for Computer Vision Tasks",
      "abstract": "To design with AI models, user experience (UX) designers must assess the fit between the model and user needs. Based on user research, they need to contextualize the model's behavior and potential failures within their product-specific data instances and user scenarios. However, our formative interviews with ten UX professionals revealed that such a proactive discovery of model limitations is challenging and time-intensive. Furthermore, designers often lack technical knowledge of AI and accessible exploration tools, which challenges their understanding of model capabilities and limitations. In this work, we introduced a failure-driven design approach to AI, a workflow that encourages designers to explore model behavior and failure patterns early in the design process. The implementation of fAIlureNotes, a designer-centered failure exploration and analysis tool, supports designers in evaluating models and identifying failures across diverse user groups and scenarios. Our evaluation with UX practitioners shows that fAIlureNotes outperforms today's interactive model cards in assessing context-specific model performance.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Steven A. Moore et al.",
      "keywords": "Workflow; Computer science; Formative assessment; Context (archaeology); Process (computing); Human\u2013computer interaction; User experience design; Software engineering; Data science; Database",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.11703",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226257674",
      "doi": "10.48550/arxiv.2112.15072",
      "title": "Empirical Evaluation of Deep Learning Models for Knowledge Tracing: Of Hyperparameters and Metrics on Performance and Replicability",
      "abstract": "New knowledge tracing models are continuously being proposed, even at a pace where state-of-theart<br> models cannot be compared with each other at the time of publication. This leads to a situation<br> where ranking models is hard, and the underlying reasons of the models\u2019 performance \u2013 be it architectural<br> choices, hyperparameter tuning, performance metrics, or data \u2013 is often underexplored. In this<br> work, we review and evaluate a body of deep learning knowledge tracing (DLKT) models with openly<br> available and widely-used data sets, and with a novel data set of students learning to program. The<br> evaluated knowledge tracing models include Vanilla-DKT, two Long Short-Term Memory Deep Knowledge<br> Tracing (LSTM-DKT) variants, two Dynamic Key-Value Memory Network (DKVMN) variants,<br> and Self-Attentive Knowledge Tracing (SAKT). As baselines, we evaluate simple non-learning models,<br> logistic regression and Bayesian Knowledge Tracing (BKT). To evaluate how different aspects of DLKT<br> models influence model performance, we test input and output layer variations found in the compared<br> models that are independent of the main architectures. We study maximum attempt count options, including<br> filtering out long attempt sequences, that have been implicitly and explicitly used in prior studies.<br> We contrast the observed performance variations against variations from non-model properties such as<br> randomness and hardware. Performance of models is assessed using multiple metrics, whereby we also<br> contrast the impact of the choice of metric on model performance. The key contributions of this work are<br> the following: Evidence that DLKT models generally outperform more traditional models, but not necessarily<br> by much and not always; Evidence that even simple baselines with little to no predictive value<br> may outperform DLKT models, especially in terms of accuracy \u2013 highlighting importance of selecting<br> proper baselines for comparison; Disambiguation of properties that lead to better performance in DLKT<br> models including metric choice, input and output layer variations, common hyperparameters, random<br> seeding and hardware; Discussion of issues in replicability when evaluating DLKT models, including<br> discrepancies in prior reported results and methodology. Model implementations, evaluation code, and<br> data are published as a part of this work.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Sami Sarsa et al.",
      "keywords": "Computer science; Hyperparameter; Machine learning; Tracing; Artificial intelligence; Contrast (vision); Metric (unit); Deep learning; Randomness; Performance metric; Set (abstract data type); Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.15072",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390723544",
      "doi": "10.48550/arxiv.2401.03002",
      "title": "Prompt-driven Latent Domain Generalization for Medical Image Classification",
      "abstract": "Deep learning models for medical image analysis easily suffer from distribution shifts caused by dataset artifacts bias, camera variations, differences in the imaging station, etc., leading to unreliable diagnoses in real-world clinical settings. Domain generalization (DG) methods, which aim to train models on multiple domains to perform well on unseen domains, offer a promising direction to solve the problem. However, existing DG methods assume domain labels of each image are available and accurate, which is typically feasible for only a limited number of medical datasets. To address these challenges, we propose a novel DG framework for medical image classification without relying on domain labels, called Prompt-driven Latent Domain Generalization (PLDG). PLDG consists of unsupervised domain discovery and prompt learning. This framework first discovers pseudo domain labels by clustering the bias-associated style features, then leverages collaborative domain prompts to guide a Vision Transformer to learn knowledge from discovered diverse domains. To facilitate cross-domain knowledge learning between different prompts, we introduce a domain prompt generator that enables knowledge sharing between domain prompts and a shared prompt. A domain mixup strategy is additionally employed for more flexible decision margins and mitigates the risk of incorrect domain assignments. Extensive experiments on three medical image classification tasks and one debiasing task demonstrate that our method can achieve comparable or even superior performance than conventional DG algorithms without relying on domain labels. Our code will be publicly available upon the paper is accepted.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "S. Yan et al.",
      "keywords": "Computer science; Artificial intelligence; Domain (mathematical analysis); Medical diagnosis; Generalization; Image (mathematics); Machine learning; Contextual image classification; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.03002",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400103780",
      "doi": "10.48550/arxiv.2406.18071",
      "title": "Documenting Ethical Considerations in Open Source AI Models",
      "abstract": "Background: The development of AI-enabled software heavily depends on AI model documentation, such as model cards, due to different domain expertise between software engineers and model developers. From an ethical standpoint, AI model documentation conveys critical information on ethical considerations along with mitigation strategies for downstream developers to ensure the delivery of ethically compliant software. However, knowledge on such documentation practice remains scarce. Aims: The objective of our study is to investigate how developers document ethical aspects of open source AI models in practice, aiming at providing recommendations for future documentation endeavours. Method: We selected three sources of documentation on GitHub and Hugging Face, and developed a keyword set to identify ethics-related documents systematically. After filtering an initial set of 2,347 documents, we identified 265 relevant ones and performed thematic analysis to derive the themes of ethical considerations. Results: Six themes emerge, with the three largest ones being model behavioural risks, model use cases, and model risk mitigation. Conclusions: Our findings reveal that open source AI model documentation focuses on articulating ethical problem statements and use case restrictions. We further provide suggestions to various stakeholders for improving documentation practice regarding ethical considerations.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Haoyu Gao et al.",
      "keywords": "Open source; Engineering ethics; Computer science; Epistemology; Psychology; Philosophy; Engineering; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.18071",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391833798",
      "doi": "10.48550/arxiv.2402.08466",
      "title": "Taking Training Seriously: Human Guidance and Management-Based Regulation of Artificial Intelligence",
      "abstract": "Fervent calls for more robust governance of the harms associated with artificial intelligence (AI) are leading to the adoption around the world of what regulatory scholars have called a management-based approach to regulation. Recent initiatives in the United States and Europe, as well as the adoption of major self-regulatory standards by the International Organization for Standardization, share in common a core management-based paradigm. These management-based initiatives seek to motivate an increase in human oversight of how AI tools are trained and developed. Refinements and systematization of human-guided training techniques will thus be needed to fit within this emerging era of management-based regulatory paradigm. If taken seriously, human-guided training can alleviate some of the technical and ethical pressures on AI, boosting AI performance with human intuition as well as better addressing the needs for fairness and effective explainability. In this paper, we discuss the connection between the emerging management-based regulatory frameworks governing AI and the need for human oversight during training. We broadly cover some of the technical components involved in human-guided training and then argue that the kinds of high-stakes use cases for AI that appear of most concern to regulators should lean more on human-guided training than on data-only training. We hope to foster a discussion between legal scholars and computer scientists involving how to govern a domain of technology that is vast, heterogenous, and dynamic in its applications and risks.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Cary Coglianese et al.",
      "keywords": "Training (meteorology); Artificial intelligence; Computer science; Engineering management; Knowledge management; Process management; Business; Engineering; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.08466",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4303649073",
      "doi": "10.48550/arxiv.2210.02943",
      "title": "On Explaining Confounding Bias",
      "abstract": "When analyzing large datasets, analysts are often interested in the explanations for surprising or unexpected results produced by their queries. In this work, we focus on aggregate SQL queries that expose correlations in the data. A major challenge that hinders the interpretation of such queries is confounding bias, which can lead to an unexpected correlation. We generate explanations in terms of a set of confounding variables that explain the unexpected correlation observed in a query. We propose to mine candidate confounding variables from external sources since, in many real-life scenarios, the explanations are not solely contained in the input data. We present an efficient algorithm that finds the optimal subset of attributes (mined from external sources and the input dataset) that explain the unexpected correlation. This algorithm is embodied in a system called MESA. We demonstrate experimentally over multiple real-life datasets and through a user study that our approach generates insightful explanations, outperforming existing methods that search for explanations only in the input data. We further demonstrate the robustness of our system to missing data and the ability of MESA to handle input datasets containing millions of tuples and an extensive search space of candidate confounding attributes.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Brit Youngmann et al.",
      "keywords": "Confounding; Computer science; Robustness (evolution); Tuple; Correlation; Data mining; Aggregate (composite); Set (abstract data type); Machine learning; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.02943",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387433467",
      "doi": "10.48550/arxiv.2310.03559",
      "title": "MedSyn: Text-guided Anatomy-aware Synthesis of High-Fidelity 3D CT Images",
      "abstract": "This paper introduces an innovative methodology for producing high-quality 3D lung CT images guided by textual information. While diffusion-based generative models are increasingly used in medical imaging, current state-of-the-art approaches are limited to low-resolution outputs and underutilize radiology reports' abundant information. The radiology reports can enhance the generation process by providing additional guidance and offering fine-grained control over the synthesis of images. Nevertheless, expanding text-guided generation to high-resolution 3D images poses significant memory and anatomical detail-preserving challenges. Addressing the memory issue, we introduce a hierarchical scheme that uses a modified UNet architecture. We start by synthesizing low-resolution images conditioned on the text, serving as a foundation for subsequent generators for complete volumetric data. To ensure the anatomical plausibility of the generated samples, we provide further guidance by generating vascular, airway, and lobular segmentation masks in conjunction with the CT images. The model demonstrates the capability to use textual input and segmentation tasks to generate synthesized images. The results of comparative assessments indicate that our approach exhibits superior performance compared to the most advanced models based on GAN and diffusion techniques, especially in accurately retaining crucial anatomical features such as fissure lines, airways, and vascular structures. This innovation introduces novel possibilities. This study focuses on two main objectives: (1) the development of a method for creating images based on textual prompts and anatomical components, and (2) the capability to generate new images conditioning on anatomical elements. The advancements in image generation can be applied to enhance numerous downstream tasks.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yanwu Xu et al.",
      "keywords": "Computer science; Segmentation; Process (computing); Artificial intelligence; Fidelity; Computer vision",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.03559",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4302438568",
      "doi": "10.48550/arxiv.1710.11216",
      "title": "Deep Learning and Conditional Random Fields-based Depth Estimation and\\n Topographical Reconstruction from Conventional Endoscopy",
      "abstract": "Colorectal cancer is the fourth leading cause of cancer deaths worldwide and\\nthe second leading cause in the United States. The risk of colorectal cancer\\ncan be mitigated by the identification and removal of premalignant lesions\\nthrough optical colonoscopy. Unfortunately, conventional colonoscopy misses\\nmore than 20% of the polyps that should be removed, due in part to poor\\ncontrast of lesion topography. Imaging tissue topography during a colonoscopy\\nis difficult because of the size constraints of the endoscope and the deforming\\nmucosa. Most existing methods make geometric assumptions or incorporate a\\npriori information, which limits accuracy and sensitivity. In this paper, we\\npresent a method that avoids these restrictions, using a joint deep\\nconvolutional neural network-conditional random field (CNN-CRF) framework.\\nEstimated depth is used to reconstruct the topography of the surface of the\\ncolon from a single image. We train the unary and pairwise potential functions\\nof a CRF in a CNN on synthetic data, generated by developing an endoscope\\ncamera model and rendering over 100,000 images of an anatomically-realistic\\ncolon. We validate our approach with real endoscopy images from a porcine\\ncolon, transferred to a synthetic-like domain, with ground truth from\\nregistered computed tomography measurements. The CNN-CRF approach estimates\\ndepths with a relative error of 0.152 for synthetic endoscopy images and 0.242\\nfor real endoscopy images. We show that the estimated depth maps can be used\\nfor reconstructing the topography of the mucosa from conventional colonoscopy\\nimages. This approach can easily be integrated into existing endoscopy systems\\nand provides a foundation for improving computer-aided detection algorithms for\\ndetection, segmentation and classification of lesions.\\n",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Faisal Mahmood et al.",
      "keywords": "Conditional random field; Artificial intelligence; Endoscope; Colonoscopy; Ground truth; Computer vision; Computer science; Endoscopy; Convolutional neural network; Pairwise comparison; Segmentation; Deep learning; Colorectal cancer; Pattern recognition (psychology); Medicine; Radiology; Cancer; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1710.11216",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384643946",
      "doi": "10.48550/arxiv.2307.07829",
      "title": "HQG-Net: Unpaired Medical Image Enhancement with High-Quality Guidance",
      "abstract": "Unpaired Medical Image Enhancement (UMIE) aims to transform a low-quality (LQ) medical image into a high-quality (HQ) one without relying on paired images for training. While most existing approaches are based on Pix2Pix/CycleGAN and are effective to some extent, they fail to explicitly use HQ information to guide the enhancement process, which can lead to undesired artifacts and structural distortions. In this paper, we propose a novel UMIE approach that avoids the above limitation of existing methods by directly encoding HQ cues into the LQ enhancement process in a variational fashion and thus model the UMIE task under the joint distribution between the LQ and HQ domains. Specifically, we extract features from an HQ image and explicitly insert the features, which are expected to encode HQ cues, into the enhancement network to guide the LQ enhancement with the variational normalization module. We train the enhancement network adversarially with a discriminator to ensure the generated HQ image falls into the HQ domain. We further propose a content-aware loss to guide the enhancement process with wavelet-based pixel-level and multi-encoder-based feature-level constraints. Additionally, as a key motivation for performing image enhancement is to make the enhanced images serve better for downstream tasks, we propose a bi-level learning scheme to optimize the UMIE task and downstream tasks cooperatively, helping generate HQ images both visually appealing and favorable for downstream tasks. Experiments on three medical datasets, including two newly collected datasets, verify that the proposed method outperforms existing techniques in terms of both enhancement quality and downstream task performance. We will make the code and the newly collected datasets publicly available for community study.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Chunming He et al.",
      "keywords": "Computer science; Discriminator; Artificial intelligence; Image (mathematics); Process (computing); Feature (linguistics); Encoding (memory); Encoder; Pattern recognition (psychology); Image quality; ENCODE; Task (project management); Normalization (sociology); Computer vision",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.07829",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289286732",
      "doi": "10.48550/arxiv.1811.06747",
      "title": "Machine Decisions and Human Consequences",
      "abstract": "As we increasingly delegate decision-making to algorithms, whether directly or indirectly, important questions emerge in circumstances where those decisions have direct consequences for individual rights and personal opportunities, as well as for the collective good. A key problem for policymakers is that the social implications of these new methods can only be grasped if there is an adequate comprehension of their general technical underpinnings. The discussion here focuses primarily on the case of enforcement decisions in the criminal justice system, but draws on similar situations emerging from other algorithms utilised in controlling access to opportunities, to explain how machine learning works and, as a result, how decisions are made by modern intelligent algorithms or 'classifiers'. It examines the key aspects of the performance of classifiers, including how classifiers learn, the fact that they operate on the basis of correlation rather than causation, and that the term 'bias' in machine learning has a different meaning to common usage. An example of a real world 'classifier', the Harm Assessment Risk Tool (HART), is examined, through identification of its technical features: the classification method, the training data and the test data, the features and the labels, validation and performance measures. Four normative benchmarks are then considered by reference to HART: (a) prediction accuracy (b) fairness and equality before the law (c) transparency and accountability (d) informational privacy and freedom of expression, in order to demonstrate how its technical features have important normative dimensions that bear directly on the extent to which the system can be regarded as a viable and legitimate support for, or even alternative to, existing human decision-makers.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Teresa Scantamburlo et al.",
      "keywords": "Computer science; Artificial intelligence; Normative; Accountability; Machine learning; Delegate; Transparency (behavior); Harm; Identification (biology); Causation; Political science; Psychology; Social psychology; Computer security; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1811.06747",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4323651041",
      "doi": "10.48550/arxiv.2303.03886",
      "title": "AI Usage Cards: Responsibly Reporting AI-generated Content",
      "abstract": "Given AI systems like ChatGPT can generate content that is indistinguishable from human-made work, the responsible use of this technology is a growing concern. Although understanding the benefits and harms of using AI systems requires more time, their rapid and indiscriminate adoption in practice is a reality. Currently, we lack a common framework and language to define and report the responsible use of AI for content generation. Prior work proposed guidelines for using AI in specific scenarios (e.g., robotics or medicine) which are not transferable to conducting and reporting scientific research. Our work makes two contributions: First, we propose a three-dimensional model consisting of transparency, integrity, and accountability to define the responsible use of AI. Second, we introduce ``AI Usage Cards'', a standardized way to report the use of AI in scientific research. Our model and cards allow users to reflect on key principles of responsible AI usage. They also help the research community trace, compare, and question various forms of AI usage and support the development of accepted community norms. The proposed framework and reporting system aims to promote the ethical and responsible use of AI in scientific research and provide a standardized approach for reporting AI usage across different research fields. We also provide a free service to easily generate AI Usage Cards for scientific work via a questionnaire and export them in various machine-readable formats for inclusion in different work products at https://ai-cards.org.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jan Philip Wahle et al.",
      "keywords": "Computer science; Transparency (behavior); Accountability; Work (physics); Inclusion (mineral); TRACE (psycholinguistics); Key (lock); Artificial intelligence; Robotics; Data science; Computer security; Robot; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.03886",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3014808298",
      "doi": "10.48550/arxiv.2004.00204",
      "title": "Ontology-based Interpretable Machine Learning for Textual Data",
      "abstract": "In this paper, we introduce a novel interpreting framework that learns an interpretable model based on an ontology-based sampling technique to explain agnostic prediction models. Different from existing approaches, our algorithm considers contextual correlation among words, described in domain knowledge ontologies, to generate semantic explanations. To narrow down the search space for explanations, which is a major problem of long and complicated text data, we design a learnable anchor algorithm, to better extract explanations locally. A set of regulations is further introduced, regarding combining learned interpretable representations with anchors to generate comprehensible semantic explanations. An extensive experiment conducted on two real-world datasets shows that our approach generates more precise and insightful explanations compared with baseline approaches.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Phung Lai et al.",
      "keywords": "Computer science; Ontology; Baseline (sea); Artificial intelligence; Set (abstract data type); Machine learning; Space (punctuation); Natural language processing; Domain (mathematical analysis); Sampling (signal processing); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2004.00204",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394780433",
      "doi": "10.48550/arxiv.2404.06859",
      "title": "Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark",
      "abstract": "Despite the critical importance of the medical domain in Deep Learning, most of the research in this area solely focuses on training models in static environments. It is only in recent years that research has begun to address dynamic environments and tackle the Catastrophic Forgetting problem through Continual Learning (CL) techniques. Previous studies have primarily focused on scenarios such as Domain Incremental Learning and Class Incremental Learning, which do not fully capture the complexity of real-world applications. Therefore, in this work, we propose a novel benchmark combining the challenges of new class arrivals and domain shifts in a single framework, by considering the New Instances and New Classes (NIC) scenario. This benchmark aims to model a realistic CL setting for the multi-label classification problem in medical imaging. Additionally, it encompasses a greater number of tasks compared to previously tested scenarios. Specifically, our benchmark consists of two datasets (NIH and CXP), nineteen classes, and seven tasks, a stream longer than the previously tested ones. To solve common challenges (e.g., the task inference problem) found in the CIL and NIC scenarios, we propose a novel approach called Replay Consolidation with Label Propagation (RCLP). Our method surpasses existing approaches, exhibiting superior performance with minimal forgetting.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Marina Ceccon et al.",
      "keywords": "Computer science; Benchmark (surveying); Forgetting; Domain (mathematical analysis); Class (philosophy); Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.06859",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287685598",
      "doi": "10.48550/arxiv.2008.10726",
      "title": "Unsupervised Multi-Modal Representation Learning for Affective Computing\\n with Multi-Corpus Wearable Data",
      "abstract": "With recent developments in smart technologies, there has been a growing\\nfocus on the use of artificial intelligence and machine learning for affective\\ncomputing to further enhance the user experience through emotion recognition.\\nTypically, machine learning models used for affective computing are trained\\nusing manually extracted features from biological signals. Such features may\\nnot generalize well for large datasets and may be sub-optimal in capturing the\\ninformation from the raw input data. One approach to address this issue is to\\nuse fully supervised deep learning methods to learn latent representations of\\nthe biosignals. However, this method requires human supervision to label the\\ndata, which may be unavailable or difficult to obtain. In this work we propose\\nan unsupervised framework reduce the reliance on human supervision. The\\nproposed framework utilizes two stacked convolutional autoencoders to learn\\nlatent representations from wearable electrocardiogram (ECG) and electrodermal\\nactivity (EDA) signals. These representations are utilized within a random\\nforest model for binary arousal classification. This approach reduces human\\nsupervision and enables the aggregation of datasets allowing for higher\\ngeneralizability. To validate this framework, an aggregated dataset comprised\\nof the AMIGOS, ASCERTAIN, CLEAS, and MAHNOB-HCI datasets is created. The\\nresults of our proposed method are compared with using convolutional neural\\nnetworks, as well as methods that employ manual extraction of hand-crafted\\nfeatures. The methodology used for fusing the two modalities is also\\ninvestigated. Lastly, we show that our method outperforms current\\nstate-of-the-art results that have performed arousal detection on the same\\ndatasets using ECG and EDA biosignals. The results show the wide-spread\\napplicability for stacked convolutional autoencoders to be used with machine\\nlearning for affective computing.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Kyle Ross et al.",
      "keywords": "Computer science; Artificial intelligence; Generalizability theory; Convolutional neural network; Machine learning; Wearable computer; Deep learning; Representation (politics); Feature learning; Wearable technology; Focus (optics); Modalities; Unsupervised learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2008.10726",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2798112314",
      "doi": "10.48550/arxiv.1804.05373",
      "title": "A Semiparametric Approach to Model Effect Modification",
      "abstract": "One fundamental statistical question for research areas such as precision medicine and health disparity is about discovering effect modification of treatment or exposure by observed covariates. We propose a semiparametric framework for identifying such effect modification. Instead of using the traditional outcome models, we directly posit semiparametric models on contrasts, or expected differences of the outcome under different treatment choices or exposures. Through semiparametric estimation theory, all valid estimating equations, including the efficient scores, are derived. Besides doubly robust loss functions, our approach also enables dimension reduction in presence of many covariates. The asymptotic and non-asymptotic properties of the proposed methods are explored via a unified statistical and algorithmic analysis. Comparison with existing methods in both simulation and real data analysis demonstrates the superiority of our estimators especially for an efficiency improved version. Supplementary materials for this article are available online.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Muxuan Liang et al.",
      "keywords": "Covariate; Estimator; Semiparametric regression; Outcome (game theory); Semiparametric model; Dimension (graph theory); Econometrics; Computer science; Asymptotic analysis; Dimensionality reduction; Effect modification; Mathematical optimization; Mathematics; Statistics; Machine learning; Mathematical economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1804.05373",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365601231",
      "doi": "10.48550/arxiv.2304.06496",
      "title": "EEGMatch: Learning with Incomplete Labels for Semi-Supervised EEG-based Cross-Subject Emotion Recognition",
      "abstract": "Electroencephalography (EEG) is an objective tool for emotion recognition and shows promising performance. However, the label scarcity problem is a main challenge in this field, which limits the wide application of EEG-based emotion recognition. In this paper, we propose a novel semi-supervised learning framework (EEGMatch) to leverage both labeled and unlabeled EEG data. First, an EEG-Mixup based data augmentation method is developed to generate more valid samples for model learning. Second, a semi-supervised two-step pairwise learning method is proposed to bridge prototype-wise and instance-wise pairwise learning, where the prototype-wise pairwise learning measures the global relationship between EEG data and the prototypical representation of each emotion class and the instance-wise pairwise learning captures the local intrinsic relationship among EEG data. Third, a semi-supervised multi-domain adaptation is introduced to align the data representation among multiple domains (labeled source domain, unlabeled source domain, and target domain), where the distribution mismatch is alleviated. Extensive experiments are conducted on two benchmark databases (SEED and SEED-IV) under a cross-subject leave-one-subject-out cross-validation evaluation protocol. The results show the proposed EEGmatch performs better than the state-of-the-art methods under different incomplete label conditions (with 6.89% improvement on SEED and 1.44% improvement on SEED-IV), which demonstrates the effectiveness of the proposed EEGMatch in dealing with the label scarcity problem in emotion recognition using EEG signals. The source code is available at https://github.com/KAZABANA/EEGMatch.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Rushuang Zhou et al.",
      "keywords": "Pairwise comparison; Computer science; Artificial intelligence; Electroencephalography; Leverage (statistics); Machine learning; Pattern recognition (psychology); Transfer of learning; Labeled data; Benchmark (surveying); Emotion recognition; Speech recognition; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.06496",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388787637",
      "doi": "10.48550/arxiv.2311.09538",
      "title": "Reducing Privacy Risks in Online Self-Disclosures with Language Models",
      "abstract": "Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure categories and curate a large corpus consisting of 4.8K annotated disclosure spans. We then fine-tune a language model for detection, achieving over 65% partial span F$_1$. We further conduct an HCI user study, with 82% of participants viewing the model positively, highlighting its real-world applicability. Motivated by the user feedback, we introduce the task of self-disclosure abstraction, which is rephrasing disclosures into less specific terms while preserving their utility, e.g., \"Im 16F\" to \"I'm a teenage girl\". We explore various fine-tuning strategies, and our best model can generate diverse abstractions that moderately reduce privacy risks while maintaining high utility according to human evaluation. To help users in deciding which disclosures to abstract, we present a task of rating their importance for context understanding. Our fine-tuned model achieves 80% accuracy, on-par with GPT-3.5. Given safety and privacy considerations, we will only release our corpus and models to researcher who agree to the ethical guidelines outlined in Ethics Statement.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yao Dou et al.",
      "keywords": "Internet privacy; Business; Actuarial science; Computer security; Psychology; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.09538",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4402698591",
      "doi": "10.48550/arxiv.2408.11787",
      "title": "NuSegDG: Integration of Heterogeneous Space and Gaussian Kernel for Domain-Generalized Nuclei Segmentation",
      "abstract": "Domain-generalized nuclei segmentation refers to the generalizability of models to unseen domains based on knowledge learned from source domains and is challenged by various image conditions, cell types, and stain strategies. Recently, the Segment Anything Model (SAM) has made great success in universal image segmentation by interactive prompt modes (e.g., point and box). Despite its strengths, the original SAM presents limited adaptation to medical images. Moreover, SAM requires providing manual bounding box prompts for each object to produce satisfactory segmentation masks, so it is laborious in nuclei segmentation scenarios. To address these limitations, we propose a domain-generalizable framework for nuclei image segmentation, abbreviated to NuSegDG. Specifically, we first devise a Heterogeneous Space Adapter (HS-Adapter) to learn multi-dimensional feature representations of different nuclei domains by injecting a small number of trainable parameters into the image encoder of SAM. To alleviate the labor-intensive requirement of manual prompts, we introduce a Gaussian-Kernel Prompt Encoder (GKP-Encoder) to generate density maps driven by a single point, which guides segmentation predictions by mixing position prompts and semantic prompts. Furthermore, we present a Two-Stage Mask Decoder (TSM-Decoder) to effectively convert semantic masks to instance maps without the manual demand for morphological shape refinement. Based on our experimental evaluations, the proposed NuSegDG demonstrates state-of-the-art performance in nuclei instance segmentation, exhibiting superior domain generalization capabilities. The source code is available at https://github.com/xq141839/NuSegDG.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhenye Lou et al.",
      "keywords": "Kernel (algebra); Domain (mathematical analysis); Segmentation; Space (punctuation); Computer science; Gaussian; Artificial intelligence; Mathematics; Pure mathematics; Physics; Mathematical analysis",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.11787",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4303648734",
      "doi": "10.48550/arxiv.2210.02527",
      "title": "Toward Knowledge-Driven Speech-Based Models of Depression: Leveraging Spectrotemporal Variations in Speech Vowels",
      "abstract": "Psychomotor retardation associated with depression has been linked with tangible differences in vowel production. This paper investigates a knowledge-driven machine learning (ML) method that integrates spectrotemporal information of speech at the vowel-level to identify the depression. Low-level speech descriptors are learned by a convolutional neural network (CNN) that is trained for vowel classification. The temporal evolution of those low-level descriptors is modeled at the high-level within and across utterances via a long short-term memory (LSTM) model that takes the final depression decision. A modified version of the Local Interpretable Model-agnostic Explanations (LIME) is further used to identify the impact of the low-level spectrotemporal vowel variation on the decisions and observe the high-level temporal change of the depression likelihood. The proposed method outperforms baselines that model the spectrotemporal information in speech without integrating the vowel-based information, as well as ML models trained with conventional prosodic and spectrotemporal features. The conducted explainability analysis indicates that spectrotemporal information corresponding to non-vowel segments less important than the vowel-based information. Explainability of the high-level information capturing the segment-by-segment decisions is further inspected for participants with and without depression. The findings from this work can provide the foundation toward knowledge-driven interpretable decision-support systems that can assist clinicians to better understand fine-grain temporal changes in speech data, ultimately augmenting mental health diagnosis and care.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Kexin Feng et al.",
      "keywords": "Vowel; Computer science; Speech recognition; Convolutional neural network; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.02527",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287828362",
      "doi": "10.48550/arxiv.2003.03541",
      "title": "A Human-Centered Review of the Algorithms used within the U.S. Child\\n Welfare System",
      "abstract": "The U.S. Child Welfare System (CWS) is charged with improving outcomes for\\nfoster youth; yet, they are overburdened and underfunded. To overcome this\\nlimitation, several states have turned towards algorithmic decision-making\\nsystems to reduce costs and determine better processes for improving CWS\\noutcomes. Using a human-centered algorithmic design approach, we synthesize 50\\npeer-reviewed publications on computational systems used in CWS to assess how\\nthey were being developed, common characteristics of predictors used, as well\\nas the target outcomes. We found that most of the literature has focused on\\nrisk assessment models but does not consider theoretical approaches (e.g.,\\nchild-foster parent matching) nor the perspectives of caseworkers (e.g., case\\nnotes). Therefore, future algorithms should strive to be context-aware and\\ntheoretically robust by incorporating salient factors identified by past\\nresearch. We provide the HCI community with research avenues for developing\\nhuman-centered algorithms that redirect attention towards more equitable\\noutcomes for CWS.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Devansh Saxena et al.",
      "keywords": "Salient; Welfare; Context (archaeology); Matching (statistics); Computer science; Welfare system; Human welfare; Machine learning; Psychology; Artificial intelligence; Algorithm; Political science; Medicine; Law",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2003.03541",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387963700",
      "doi": "10.48550/arxiv.2310.16273",
      "title": "Deep Learning for Plant Identification and Disease Classification from Leaf Images: Multi-prediction Approaches",
      "abstract": "Deep learning plays an important role in modern agriculture, especially in plant pathology using leaf images where convolutional neural networks (CNN) are attracting a lot of attention. While numerous reviews have explored the applications of deep learning within this research domain, there remains a notable absence of an empirical study to offer insightful comparisons due to the employment of varied datasets in the evaluation. Furthermore, a majority of these approaches tend to address the problem as a singular prediction task, overlooking the multifaceted nature of predicting various aspects of plant species and disease types. Lastly, there is an evident need for a more profound consideration of the semantic relationships that underlie plant species and disease types. In this paper, we start our study by surveying current deep learning approaches for plant identification and disease classification. We categorise the approaches into multi-model, multi-label, multi-output, and multi-task, in which different backbone CNNs can be employed. Furthermore, based on the survey of existing approaches in plant pathology and the study of available approaches in machine learning, we propose a new model named Generalised Stacking Multi-output CNN (GSMo-CNN). To investigate the effectiveness of different backbone CNNs and learning approaches, we conduct an intensive experiment on three benchmark datasets Plant Village, Plant Leaves, and PlantDoc. The experimental results demonstrate that InceptionV3 can be a good choice for a backbone CNN as its performance is better than AlexNet, VGG16, ResNet101, EfficientNet, MobileNet, and a custom CNN developed by us. Interestingly, empirical results support the hypothesis that using a single model can be comparable or better than using two models. Finally, we show that the proposed GSMo-CNN achieves state-of-the-art performance on three benchmark datasets.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jianping Yao et al.",
      "keywords": "Convolutional neural network; Artificial intelligence; Computer science; Benchmark (surveying); Deep learning; Machine learning; Identification (biology); Plant disease; Plant identification; Task (project management); Empirical research; Contextual image classification; Multi-task learning; Image (mathematics); Mathematics; Engineering; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.16273",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293791265",
      "doi": "10.48550/arxiv.2208.12812",
      "title": "Speech Emotion Recognition using Supervised Deep Recurrent System for Mental Health Monitoring",
      "abstract": "Understanding human behavior and monitoring mental health are essential to maintaining the community and society's safety. As there has been an increase in mental health problems during the COVID-19 pandemic due to uncontrolled mental health, early detection of mental issues is crucial. Nowadays, the usage of Intelligent Virtual Personal Assistants (IVA) has increased worldwide. Individuals use their voices to control these devices to fulfill requests and acquire different services. This paper proposes a novel deep learning model based on the gated recurrent neural network and convolution neural network to understand human emotion from speech to improve their IVA services and monitor their mental health.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Nelly Elsayed et al.",
      "keywords": "Mental health; Deep learning; Convolutional neural network; Computer science; Control (management); Artificial neural network; Psychology; Applied psychology; Artificial intelligence; Human\u2013computer interaction; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.12812",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226045921",
      "doi": "10.48550/arxiv.2202.08063",
      "title": "Information Extraction in Low-Resource Scenarios: Survey and Perspective",
      "abstract": "Information Extraction (IE) seeks to derive structured information from unstructured texts, often facing challenges in low-resource scenarios due to data scarcity and unseen classes. This paper presents a review of neural approaches to low-resource IE from \\emph{traditional} and \\emph{LLM-based} perspectives, systematically categorizing them into a fine-grained taxonomy. Then we conduct empirical study on LLM-based methods compared with previous state-of-the-art models, and discover that (1) well-tuned LMs are still predominant; (2) tuning open-resource LLMs and ICL with GPT family is promising in general; (3) the optimal LLM-based technical solution for low-resource IE can be task-dependent. In addition, we discuss low-resource IE with LLMs, highlight promising applications, and outline potential research directions. This survey aims to foster understanding of this field, inspire new ideas, and encourage widespread applications in both academia and industry.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Shumin Deng et al.",
      "keywords": "Perspective (graphical); Resource (disambiguation); Scarcity; Computer science; Information extraction; Field (mathematics); Task (project management); Knowledge management; Data science; Resource scarcity; Management science; Artificial intelligence; Engineering; Management; Economics; Natural resource economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.08063",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393404423",
      "doi": "10.48550/arxiv.2403.19807",
      "title": "Protocols for Observational Studies: Methods and Open Problems",
      "abstract": "For learning about the causal effect of a treatment, a randomized controlled trial (RCT) is considered the gold standard. However, randomizing treatment is sometimes unethical or infeasible, and instead an observational study may be conducted. While some aspects of a well designed RCT cannot be replicated in an observational study, one aspect that can is to have a protocol with prespecified hypotheses about prespecified outcomes and a prespecified analysis. We illustrate the value of protocols for observational studies in three applications -- the effect of playing high school football on later life mental functioning, the effect of police seizing a gun when arresting a domestic violence suspect on future domestic violence and the effect of mountaintop mining on health. We then discuss methodologies for observational study protocols. We discuss considerations for protocols that are similar between observational studies and RCTs, and considerations that are different. The considerations that are different include (i) whether the protocol should be specified before treatment assignment is known or after; (ii) how multiple outcomes should be incorporated into the planned analysis and (iii) how subgroups should be incorporated into the planned analysis. We conclude with discussion of a few open problems in the methodology of observational study protocols.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Dylan S. Small",
      "keywords": "Observational study; Computer science; Mathematics; Statistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.19807",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3158551809",
      "doi": "10.48550/arxiv.2104.11436",
      "title": "Learning from Ambiguous Labels for Lung Nodule Malignancy Prediction",
      "abstract": "Lung nodule malignancy prediction is an essential step in the early diagnosis of lung cancer. Besides the difficulties commonly discussed, the challenges of this task also come from the ambiguous labels provided by annotators, since deep learning models may learn, even amplify, the bias embedded in them. In this paper, we propose a multi-view \"divide-and-rule\" (MV-DAR) model to learn from both reliable and ambiguous annotations for lung nodule malignancy prediction. According to the consistency and reliability of their annotations, we divide nodules into three sets: a consistent and reliable set (CR-Set), an inconsistent set (IC-Set), and a low reliable set (LR-Set). The nodule in IC-Set is annotated by multiple radiologists inconsistently, and the nodule in LR-Set is annotated by only one radiologist. The proposed MV-DAR contains three DAR submodels to characterize a lung nodule from three orthographic views. Each DAR consists of a prediction network (Prd-Net), a counterfactual network (CF-Net), and a low reliable network (LR-Net), learning on CR-Set, IC-Set, and LR-Set, respectively. The image representation ability learned by CF-Net and LR-Net is then transferred to Prd-Net by negative-attention module (NA-Module) and consistent-attention module (CA-Module), aiming to boost the prediction ability of Prd-Net. The MV-DAR model has been evaluated on the LIDC-IDRI dataset and LUNGx dataset. Our results indicate not only the effectiveness of the proposed MV-DAR model in learning from ambiguous labels but also its superiority over present noisy label-learning models in lung nodule malignancy prediction.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Zehui Liao et al.",
      "keywords": "Set (abstract data type); Computer science; Artificial intelligence; Nodule (geology); Test set; Malignancy; Consistency (knowledge bases); Pattern recognition (psychology); Medicine; Pathology; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2104.11436",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205416813",
      "doi": "10.48550/arxiv.2205.04723",
      "title": "Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training",
      "abstract": "Deep neural networks have achieved remarkable success in a wide variety of natural image and medical image computing tasks. However, these achievements indispensably rely on accurately annotated training data. If encountering some noisy-labeled images, the network training procedure would suffer from difficulties, leading to a sub-optimal classifier. This problem is even more severe in the medical image analysis field, as the annotation quality of medical images heavily relies on the expertise and experience of annotators. In this paper, we propose a novel collaborative training paradigm with global and local representation learning for robust medical image classification from noisy-labeled data to combat the lack of high quality annotated medical data. Specifically, we employ the self-ensemble model with a noisy label filter to efficiently select the clean and noisy samples. Then, the clean samples are trained by a collaborative training strategy to eliminate the disturbance from imperfect labeled samples. Notably, we further design a novel global and local representation learning scheme to implicitly regularize the networks to utilize noisy samples in a self-supervised manner. We evaluated our proposed robust learning strategy on four public medical image classification datasets with three types of label noise,ie,random noise, computer-generated label noise, and inter-observer variability noise. Our method outperforms other learning from noisy label methods and we also conducted extensive experiments to analyze each component of our method.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Cheng Xue et al.",
      "keywords": "Computer science; Artificial intelligence; Noise (video); Classifier (UML); Machine learning; Pattern recognition (psychology); Robustness (evolution); Annotation; Deep learning; Artificial neural network; Data mining; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.04723",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221148885",
      "doi": "10.48550/arxiv.2202.04175",
      "title": "Federated Learning of Generative Image Priors for MRI Reconstruction",
      "abstract": "Multi-institutional efforts can facilitate training of deep MRI reconstruction models, albeit privacy risks arise during cross-site sharing of imaging data. Federated learning (FL) has recently been introduced to address privacy concerns by enabling distributed training without transfer of imaging data. Existing FL methods for MRI reconstruction employ conditional models to map from undersampled to fully-sampled acquisitions via explicit knowledge of the imaging operator. Since conditional models generalize poorly across different acceleration rates or sampling densities, imaging operators must be fixed between training and testing, and they are typically matched across sites. To improve generalization and flexibility in multi-institutional collaborations, here we introduce a novel method for MRI reconstruction based on Federated learning of Generative IMage Priors (FedGIMP). FedGIMP leverages a two-stage approach: cross-site learning of a generative MRI prior, and subject-specific injection of the imaging operator. The global MRI prior is learned via an unconditional adversarial model that synthesizes high-quality MR images based on latent variables. Specificity in the prior is preserved via a mapper subnetwork that produces site-specific latents. During inference, the prior is combined with subject-specific imaging operators to enable reconstruction, and further adapted to individual test samples by minimizing data-consistency loss. Comprehensive experiments on multi-institutional datasets clearly demonstrate enhanced generalization performance of FedGIMP against site-specific and federated methods based on conditional models, as well as traditional reconstruction methods.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Gokberk Elmas et al.",
      "keywords": "Prior probability; Computer science; Inference; Artificial intelligence; Generative model; Generalization; Machine learning; Iterative reconstruction; Consistency (knowledge bases); Flexibility (engineering); Generative grammar; Bayesian probability; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.04175",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4395444168",
      "doi": "10.48550/arxiv.2404.14590",
      "title": "PupilSense: Detection of Depressive Episodes Through Pupillary Response in the Wild",
      "abstract": "Early detection of depressive episodes is crucial in managing mental health disorders such as Major Depressive Disorder (MDD) and Bipolar Disorder. However, existing methods often necessitate active participation or are confined to clinical settings. Addressing this gap, we introduce PupilSense, a novel, deep learning-driven mobile system designed to discreetly track pupillary responses as users interact with their smartphones in their daily lives. This study presents a proof-of-concept exploration of PupilSense's capabilities, where we captured real-time pupillary data from users in naturalistic settings. Our findings indicate that PupilSense can effectively and passively monitor indicators of depressive episodes, offering a promising tool for continuous mental health assessment outside laboratory environments. This advancement heralds a significant step in leveraging ubiquitous mobile technology for proactive mental health care, potentially transforming how depressive episodes are detected and managed in everyday contexts.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Rahul Islam et al.",
      "keywords": "Pupillary response; Psychology; Environmental science; Pupil; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.14590",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4306886663",
      "doi": "10.48550/arxiv.2210.09430",
      "title": "Evaluating Search System Explainability with Psychometrics and Crowdsourcing",
      "abstract": "As information retrieval (IR) systems, such as search engines and conversational agents, become ubiquitous in various domains, the need for transparent and explainable systems grows to ensure accountability, fairness, and unbiased results. Despite recent advances in explainable AI and IR techniques, there is no consensus on the definition of explainability. Existing approaches often treat it as a singular notion, disregarding the multidimensional definition postulated in the literature. In this paper, we use psychometrics and crowdsourcing to identify human-centered factors of explainability in Web search systems and introduce SSE (Search System Explainability), an evaluation metric for explainable IR (XIR) search systems. In a crowdsourced user study, we demonstrate SSE's ability to distinguish between explainable and non-explainable systems, showing that systems with higher scores indeed indicate greater interpretability. We hope that aside from these concrete contributions to XIR, this line of work will serve as a blueprint for similar explainability evaluation efforts in other domains of machine learning and natural language processing.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Catherine Chen et al.",
      "keywords": "Crowdsourcing; Recreation; Computer science; Recommender system; Psychometrics; Data science; World Wide Web; Psychology; Clinical psychology; Biology; Ecology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.09430",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383605192",
      "doi": "10.48550/arxiv.2307.03068",
      "title": "A Hybrid End-to-End Spatio-Temporal Attention Neural Network with Graph-Smooth Signals for EEG Emotion Recognition",
      "abstract": "Recently, physiological data such as electroencephalography (EEG) signals have attracted significant attention in affective computing. In this context, the main goal is to design an automated model that can assess emotional states. Lately, deep neural networks have shown promising performance in emotion recognition tasks. However, designing a deep architecture that can extract practical information from raw data is still a challenge. Here, we introduce a deep neural network that acquires interpretable physiological representations by a hybrid structure of spatio-temporal encoding and recurrent attention network blocks. Furthermore, a preprocessing step is applied to the raw data using graph signal processing tools to perform graph smoothing in the spatial domain. We demonstrate that our proposed architecture exceeds state-of-the-art results for emotion classification on the publicly available DEAP dataset. To explore the generality of the learned model, we also evaluate the performance of our architecture towards transfer learning (TL) by transferring the model parameters from a specific source to other target domains. Using DEAP as the source dataset, we demonstrate the effectiveness of our model in performing cross-modality TL and improving emotion classification accuracy on DREAMER and the Emotional English Word (EEWD) datasets, which involve EEG-based emotion classification tasks with different stimuli.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shadi Sartipi et al.",
      "keywords": "Computer science; Preprocessor; Artificial intelligence; Electroencephalography; Smoothing; Graph; Deep learning; Artificial neural network; Attention network; Pattern recognition (psychology); Context (archaeology); Speech recognition; Machine learning; Computer vision; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.03068",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3047494720",
      "doi": "10.48550/arxiv.2008.02218",
      "title": "BATS: A Spectral Biclustering Approach to Single Document Topic Modeling and Segmentation",
      "abstract": "Existing topic modeling and text segmentation methodologies generally require large datasets for training, limiting their capabilities when only small collections of text are available. In this work, we reexamine the inter-related problems of \"topic identification\" and \"text segmentation\" for sparse document learning, when there is a single new text of interest. In developing a methodology to handle single documents, we face two major challenges. First is sparse information: with access to only one document, we cannot train traditional topic models or deep learning algorithms. Second is significant noise: a considerable portion of words in any single document will produce only noise and not help discern topics or segments. To tackle these issues, we design an unsupervised, computationally efficient methodology called BATS: Biclustering Approach to Topic modeling and Segmentation. BATS leverages three key ideas to simultaneously identify topics and segment text: (i) a new mechanism that uses word order information to reduce sample complexity, (ii) a statistically sound graph-based biclustering technique that identifies latent structures of words and sentences, and (iii) a collection of effective heuristics that remove noise words and award important words to further improve performance. Experiments on four datasets show that our approach outperforms several state-of-the-art baselines when considering topic coherence, topic diversity, segmentation, and runtime comparison metrics.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Qiong Wu et al.",
      "keywords": "Computer science; Segmentation; Heuristics; Topic model; Artificial intelligence; Information retrieval; Biclustering; Cluster analysis; Machine learning; Pattern recognition (psychology); Data mining; Natural language processing; Fuzzy clustering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2008.02218",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4289704090",
      "doi": "10.48550/arxiv.1808.02531",
      "title": "SchiNet: Automatic Estimation of Symptoms of Schizophrenia from Facial\\n Behaviour Analysis",
      "abstract": "Patients with schizophrenia often display impairments in the expression of\\nemotion and speech and those are observed in their facial behaviour. Automatic\\nanalysis of patients' facial expressions that is aimed at estimating symptoms\\nof schizophrenia has received attention recently. However, the datasets that\\nare typically used for training and evaluating the developed methods, contain\\nonly a small number of patients (4-34) and are recorded while the subjects were\\nperforming controlled tasks such as listening to life vignettes, or answering\\nemotional questions. In this paper, we use videos of professional-patient\\ninterviews, in which symptoms were assessed in a standardised way as they\\nshould/may be assessed in practice, and which were recorded in realistic\\nconditions (i.e. varying illumination levels and camera viewpoints) at the\\npatients' homes or at mental health services. We automatically analyse the\\nfacial behaviour of 91 out-patients - this is almost 3 times the number of\\npatients in other studies - and propose SchiNet, a novel neural network\\narchitecture that estimates expression-related symptoms in two different\\nassessment interviews. We evaluate the proposed SchiNet for patient-independent\\nprediction of symptoms of schizophrenia. Experimental results show that some\\nautomatically detected facial expressions are significantly correlated to\\nsymptoms of schizophrenia, and that the proposed network for estimating symptom\\nseverity delivers promising results.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Mina Bishay et al.",
      "keywords": "Schizophrenia (object-oriented programming); Viewpoints; Facial expression; Active listening; Psychology; Expression (computer science); Estimation; Medicine; Clinical psychology; Audiology; Computer science; Psychiatry; Psychotherapist; Communication",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1808.02531",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4401671460",
      "doi": "10.48550/arxiv.2407.11371",
      "title": "Estimating Agreement by Chance for Sequence Annotation",
      "abstract": "In the field of natural language processing, correction of performance assessment for chance agreement plays a crucial role in evaluating the reliability of annotations. However, there is a notable dearth of research focusing on chance correction for assessing the reliability of sequence annotation tasks, despite their widespread prevalence in the field. To address this gap, this paper introduces a novel model for generating random annotations, which serves as the foundation for estimating chance agreement in sequence annotation tasks. Utilizing the proposed randomization model and a related comparison approach, we successfully derive the analytical form of the distribution, enabling the computation of the probable location of each annotated text segment and subsequent chance agreement estimation. Through a combination simulation and corpus-based evaluation, we successfully assess its applicability and validate its accuracy and efficacy.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Diya Li et al.",
      "keywords": "Annotation; Sequence (biology); Agreement; Computer science; Natural language processing; Econometrics; Artificial intelligence; Mathematics; Linguistics; Biology; Philosophy; Genetics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.11371",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2527769015",
      "doi": "10.48550/arxiv.1610.01526",
      "title": "Marginally Interpretable Generalized Linear Mixed Models",
      "abstract": "Two popular approaches for relating correlated measurements of a non-Gaussian response variable to a set of predictors are to fit a marginal model using generalized estimating equations and to fit a generalized linear mixed model by introducing latent random variables. The first approach is effective for parameter estimation, but leaves one without a formal model for the data with which to assess quality of fit or make predictions for future observations. The second approach overcomes the deficiencies of the first, but leads to parameter estimates that must be interpreted conditional on the latent variables. Further complicating matters, obtaining marginal summaries from a generalized linear mixed model often requires evaluation of an analytically intractable integral or use of attenuation factors that are not exact. We define a class of marginally interpretable generalized linear mixed models that lead to parameter estimates with a marginal interpretation while maintaining the desirable statistical properties of a conditionally-specified model. We discuss the form of these models under various common link functions and also address computational issues associated with these models. For logistic mixed effects models, we introduce an accurate and efficient method for evaluating the logistic-normal integral.",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Jeffrey J. Gory et al.",
      "keywords": "Generalized linear model; Marginal model; Generalized linear mixed model; Mathematics; Hierarchical generalized linear model; Generalized additive model; Applied mathematics; Latent variable; Marginal distribution; Set (abstract data type); Gaussian; Linear model; Estimation theory; Generalized estimating equation; Mixed model; Mathematical optimization; Random variable; Computer science; Statistics; Regression analysis",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1610.01526",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4400668520",
      "doi": "10.48550/arxiv.2407.09429",
      "title": "Open (Clinical) LLMs are Sensitive to Instruction Phrasings",
      "abstract": "Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as clinicians are unlikely to be experienced prompt engineers and the potential consequences of inaccurate outputs are heightened in this domain. This raises a practical question: How robust are instruction-tuned LLMs to natural variations in the instructions provided for clinical NLP tasks? We collect prompts from medical doctors across a range of tasks and quantify the sensitivity of seven LLMs -- some general, others specialized -- to natural (i.e., non-adversarial) instruction phrasings. We find that performance varies substantially across all models, and that -- perhaps surprisingly -- domain-specific models explicitly trained on clinical data are especially brittle, compared to their general domain counterparts. Further, arbitrary phrasing differences can affect fairness, e.g., valid but distinct instructions for mortality prediction yield a range both in overall performance, and in terms of differences between demographic groups.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Alberto Mario Ceballos Arroyo et al.",
      "keywords": "Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.09429",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404341836",
      "doi": "10.48550/arxiv.2410.22312",
      "title": "Effective Guidance for Model Attention with Simple Yes-no Annotations",
      "abstract": "Modern deep learning models often make predictions by focusing on irrelevant areas, leading to biased performance and limited generalization. Existing methods aimed at rectifying model attention require explicit labels for irrelevant areas or complex pixel-wise ground truth attention maps. We present CRAYON (Correcting Reasoning with Annotations of Yes Or No), offering effective, scalable, and practical solutions to rectify model attention using simple yes-no annotations. CRAYON empowers classical and modern model interpretation techniques to identify and guide model reasoning: CRAYON-ATTENTION directs classic interpretations based on saliency maps to focus on relevant image regions, while CRAYON-PRUNING removes irrelevant neurons identified by modern concept-based methods to mitigate their influence. Through extensive experiments with both quantitative and human evaluation, we showcase CRAYON's effectiveness, scalability, and practicality in refining model attention. CRAYON achieves state-of-the-art performance, outperforming 12 methods across 3 benchmark datasets, surpassing approaches that require more complex annotations.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Seongmin Lee et al.",
      "keywords": "Simple (philosophy); Computer science; Philosophy; Epistemology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.22312",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415066985",
      "doi": "10.48550/arxiv.2504.16778",
      "title": "Evaluation Framework for AI Systems in \"the Wild\"",
      "abstract": "Generative AI (GenAI) models have become vital across industries, yet current evaluation methods have not adapted to their widespread use. Traditional evaluations often rely on benchmarks and fixed datasets, frequently failing to reflect real-world performance, which creates a gap between lab-tested outcomes and practical applications. This white paper proposes a comprehensive framework for how we should evaluate real-world GenAI systems, emphasizing diverse, evolving inputs and holistic, dynamic, and ongoing assessment approaches. The paper offers guidance for practitioners on how to design evaluation methods that accurately reflect real-time capabilities, and provides policymakers with recommendations for crafting GenAI policies focused on societal impacts, rather than fixed performance numbers or parameter sizes. We advocate for holistic frameworks that integrate performance, fairness, and ethics and the use of continuous, outcome-oriented methods that combine human and automated assessments while also being transparent to foster trust among stakeholders. Implementing these strategies ensures GenAI models are not only technically proficient but also ethically responsible and impactful.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Sarah Jabbour et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.16778",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3149607116",
      "doi": "10.48550/arxiv.2104.00137",
      "title": "Achieving Transparency Report Privacy in Linear Time",
      "abstract": "An accountable algorithmic transparency report (ATR) should ideally investigate the (a) transparency of the underlying algorithm, and (b) fairness of the algorithmic decisions, and at the same time preserve data subjects' privacy. However, a provably formal study of the impact to data subjects' privacy caused by the utility of releasing an ATR (that investigates transparency and fairness), is yet to be addressed in the literature. The far-fetched benefit of such a study lies in the methodical characterization of privacy-utility trade-offs for release of ATRs in public, and their consequential application-specific impact on the dimensions of society, politics, and economics. In this paper, we first investigate and demonstrate potential privacy hazards brought on by the deployment of transparency and fairness measures in released ATRs. To preserve data subjects' privacy, we then propose a linear-time optimal-privacy scheme, built upon standard linear fractional programming (LFP) theory, for announcing ATRs, subject to constraints controlling the tolerance of privacy perturbation on the utility of transparency schemes. Subsequently, we quantify the privacy-utility trade-offs induced by our scheme, and analyze the impact of privacy perturbation on fairness measures in ATRs. To the best of our knowledge, this is the first analytical work that simultaneously addresses trade-offs between the triad of privacy, utility, and fairness, applicable to algorithmic transparency reports.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Chien\u2010Lun Chen et al.",
      "keywords": "Transparency (behavior); Computer science; Information privacy; Internet privacy; Privacy by Design; Computer security; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2104.00137",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396814725",
      "doi": "10.48550/arxiv.2405.04295",
      "title": "Semi-Supervised Disease Classification based on Limited Medical Image Data",
      "abstract": "In recent years, significant progress has been made in the field of learning from positive and unlabeled examples (PU learning), particularly in the context of advancing image and text classification tasks. However, applying PU learning to semi-supervised disease classification remains a formidable challenge, primarily due to the limited availability of labeled medical images. In the realm of medical image-aided diagnosis algorithms, numerous theoretical and practical obstacles persist. The research on PU learning for medical image-assisted diagnosis holds substantial importance, as it aims to reduce the time spent by professional experts in classifying images. Unlike natural images, medical images are typically accompanied by a scarcity of annotated data, while an abundance of unlabeled cases exists. Addressing these challenges, this paper introduces a novel generative model inspired by H\u00f6lder divergence, specifically designed for semi-supervised disease classification using positive and unlabeled medical image data. In this paper, we present a comprehensive formulation of the problem and establish its theoretical feasibility through rigorous mathematical analysis. To evaluate the effectiveness of our proposed approach, we conduct extensive experiments on five benchmark datasets commonly used in PU medical learning: BreastMNIST, PneumoniaMNIST, BloodMNIST, OCTMNIST, and AMD. The experimental results clearly demonstrate the superiority of our method over existing approaches based on KL divergence. Notably, our approach achieves state-of-the-art performance on all five disease classification benchmarks. By addressing the limitations imposed by limited labeled data and harnessing the untapped potential of unlabeled medical images, our novel generative model presents a promising direction for enhancing semi-supervised disease classification in the field of medical image analysis.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yan Zhang et al.",
      "keywords": "Computer science; Image (mathematics); Artificial intelligence; Contextual image classification; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.04295",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4364382972",
      "doi": "10.48550/arxiv.2304.04057",
      "title": "How Does Imperfect Automatic Indexing Affect Semantic Search Performance?",
      "abstract": "Documents in the health domain are often annotated with semantic concepts (i.e., terms) from controlled vocabularies. As the volume of these documents gets large, the annotation work is increasingly done by algorithms. Compared to humans, automatic indexing algorithms are imperfect and may assign wrong terms to documents, which affect subsequent search tasks where queries contain these terms. In this work, we aim to understand the performance impact of using imperfectly assigned terms in Boolean semantic searches. We used MeSH terms and biomedical literature search as a case study. We implemented multiple automatic indexing algorithms on real-world Boolean queries that consist of MeSH terms, and found that (1) probabilistic logic can handle inaccurately assigned terms better than traditional Boolean logic, (2) query-level performance is mostly limited by lowest-performing terms in a query, and (3) mixing a small amount of human indexing with automatic indexing can regain excellent query-level performance. These findings provide important implications for future work on automatic indexing.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Mengtian Guo et al.",
      "keywords": "Search engine indexing; Computer science; Information retrieval; Automatic indexing; Probabilistic logic; Domain (mathematical analysis); Data mining; Artificial intelligence; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.04057",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286858401",
      "doi": "10.48550/arxiv.2111.06773",
      "title": "Explainability and the Fourth AI Revolution",
      "abstract": "This chapter discusses AI from the prism of an automated process for the organization of data, and exemplifies the role that explainability has to play in moving from the current generation of AI systems to the next one, where the role of humans is lifted from that of data annotators working for the AI systems to that of collaborators working with the AI systems.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Loizos Michael",
      "keywords": "Process (computing); Prism; Computer science; Artificial intelligence; Data science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2111.06773",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4403666702",
      "doi": "10.48550/arxiv.2409.09194",
      "title": "Hierarchical Hypercomplex Network for Multimodal Emotion Recognition",
      "abstract": "Emotion recognition is relevant in various domains, ranging from healthcare to human-computer interaction. Physiological signals, being beyond voluntary control, offer reliable information for this purpose, unlike speech and facial expressions which can be controlled at will. They reflect genuine emotional responses, devoid of conscious manipulation, thereby enhancing the credibility of emotion recognition systems. Nonetheless, multimodal emotion recognition with deep learning models remains a relatively unexplored field. In this paper, we introduce a fully hypercomplex network with a hierarchical learning structure to fully capture correlations. Specifically, at the encoder level, the model learns intra-modal relations among the different channels of each input signal. Then, a hypercomplex fusion module learns inter-modal relations among the embeddings of the different modalities. The main novelty is in exploiting intra-modal relations by endowing the encoders with parameterized hypercomplex convolutions (PHCs) that thanks to hypercomplex algebra can capture inter-channel interactions within single modalities. Instead, the fusion module comprises parameterized hypercomplex multiplications (PHMs) that can model inter-modal correlations. The proposed architecture surpasses state-of-the-art models on the MAHNOB-HCI dataset for emotion recognition, specifically in classifying valence and arousal from electroencephalograms (EEGs) and peripheral physiological signals. The code of this study is available at https://github.com/ispamm/MHyEEG.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Eleonora Lopez et al.",
      "keywords": "Hypercomplex number; Psychology; Computer science; Cognitive psychology; Artificial intelligence; Mathematics; Quaternion; Geometry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.09194",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414897091",
      "doi": "10.48550/arxiv.2506.01533",
      "title": "A Diffusion-Based Method for Learning the Multi-Outcome Distribution of Medical Treatments",
      "abstract": "In medicine, treatments often influence multiple, interdependent outcomes, such as primary endpoints, complications, adverse events, or other secondary endpoints. Hence, to make optimal treatment decisions, clinicians are interested in learning the distribution of multi-dimensional treatment outcomes. However, the vast majority of machine learning methods for predicting treatment effects focus on single-outcome settings, despite the fact that medical data often include multiple, interdependent outcomes. To address this limitation, we propose a novel diffusion-based method called DIME to learn the joint distribution of multiple outcomes of medical treatments. We addresses three challenges relevant in medical practice: (i)it is tailored to learn the joint interventional distribution of multiple medical outcomes, which enables reliable decision-making with uncertainty quantification rather than relying solely on point estimates; (ii)it explicitly captures the dependence structure between outcomes; (iii)it can handle outcomes of mixed type, including binary, categorical, and continuous variables. In DIME, we take into account the fundamental problem of causal inference through causal masking. For training, our method decomposes the joint distribution into a series of conditional distributions with a customized conditional masking to account for the dependence structure across outcomes. For inference, our method auto-regressively generates predictions. This allows our method to move beyond point estimates of causal quantities and thus learn the joint interventional distribution. To the best of our knowledge, DIME is the first neural method tailored to learn the joint, multi-outcome distribution of medical treatments. Across various experiments, we demonstrate that our method effectively learns the joint distribution and captures shared information among multiple outcomes.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuchen Ma et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01533",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387430714",
      "doi": "10.48550/arxiv.2310.03432",
      "title": "Mitigating the Influence of Domain Shift in Skin Lesion Classification: A Benchmark Study of Unsupervised Domain Adaptation Methods on Dermoscopic Images",
      "abstract": "The potential of deep neural networks in skin lesion classification has already been demonstrated to be on-par if not superior to the dermatologists diagnosis. However, the performance of these models usually deteriorates when the test data differs significantly from the training data (i.e. domain shift). This concerning limitation for models intended to be used in real-world skin lesion classification tasks poses a risk to patients. For example, different image acquisition systems or previously unseen anatomical sites on the patient can suffice to cause such domain shifts. Mitigating the negative effect of such shifts is therefore crucial, but developing effective methods to address domain shift has proven to be challenging. In this study, we carry out an in-depth analysis of eight different unsupervised domain adaptation methods to analyze their effectiveness in improving generalization for dermoscopic datasets. To ensure robustness of our findings, we test each method on a total of ten distinct datasets, thereby covering a variety of possible domain shifts. In addition, we investigated which factors in the domain shifted datasets have an impact on the effectiveness of domain adaptation methods. Our findings show that all of the eight domain adaptation methods result in improved AUPRC for the majority of analyzed datasets. Altogether, these results indicate that unsupervised domain adaptations generally lead to performance improvements for the binary melanoma-nevus classification task regardless of the nature of the domain shift. However, small or heavily imbalanced datasets lead to a reduced conformity of the results due to the influence of these factors on the methods performance.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Sireesha Chamarthi et al.",
      "keywords": "Computer science; Artificial intelligence; Benchmark (surveying); Pattern recognition (psychology); Robustness (evolution); Domain (mathematical analysis); Machine learning; Domain adaptation; Classifier (UML); Mathematics; Biology; Cartography; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.03432",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3174580367",
      "doi": "10.48550/arxiv.2106.14384",
      "title": "Towards Model-informed Precision Dosing with Expert-in-the-loop Machine Learning",
      "abstract": "Machine Learning (ML) and its applications have been transforming our lives but it is also creating issues related to the development of fair, accountable, transparent, and ethical Artificial Intelligence. As the ML models are not fully comprehensible yet, it is obvious that we still need humans to be part of algorithmic decision-making processes. In this paper, we consider a ML framework that may accelerate model learning and improve its interpretability by incorporating human experts into the model learning loop. We propose a novel human-in-the-loop ML framework aimed at dealing with learning problems that the cost of data annotation is high and the lack of appropriate data to model the association between the target tasks and the input features. With an application to precision dosing, our experimental results show that the approach can learn interpretable rules from data and may potentially lower experts' workload by replacing data annotation with rule representation editing. The approach may also help remove algorithmic bias by introducing experts' feedback into the iterative model learning process.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Yihuang Kang et al.",
      "keywords": "Interpretability; Computer science; Machine learning; Artificial intelligence; Annotation; Process (computing); Representation (politics); Workload; Human-in-the-loop; Iterative and incremental development; Software engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.14384",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4221162329",
      "doi": "10.48550/arxiv.2203.06823",
      "title": "SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense Image Labels for Quantitative Clinical Evaluation",
      "abstract": "Magnetic resonance imaging (MRI) is a cornerstone of modern medical imaging. However, long image acquisition times, the need for qualitative expert analysis, and the lack of (and difficulty extracting) quantitative indicators that are sensitive to tissue health have curtailed widespread clinical and research studies. While recent machine learning methods for MRI reconstruction and analysis have shown promise for reducing this burden, these techniques are primarily validated with imperfect image quality metrics, which are discordant with clinically-relevant measures that ultimately hamper clinical deployment and clinician trust. To mitigate this challenge, we present the Stanford Knee MRI with Multi-Task Evaluation (SKM-TEA) dataset, a collection of quantitative knee MRI (qMRI) scans that enables end-to-end, clinically-relevant evaluation of MRI reconstruction and analysis tools. This 1.6TB dataset consists of raw-data measurements of ~25,000 slices (155 patients) of anonymized patient MRI scans, the corresponding scanner-generated DICOM images, manual segmentations of four tissues, and bounding box annotations for sixteen clinically relevant pathologies. We provide a framework for using qMRI parameter maps, along with image reconstructions and dense image labels, for measuring the quality of qMRI biomarker estimates extracted from MRI reconstruction, segmentation, and detection techniques. Finally, we use this framework to benchmark state-of-the-art baselines on this dataset. We hope our SKM-TEA dataset and code can enable a broad spectrum of research for modular image reconstruction and image analysis in a clinically informed manner. Dataset access, code, and benchmarks are available at https://github.com/StanfordMIMI/skm-tea.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Arjun Desai et al.",
      "keywords": "Computer science; Benchmark (surveying); Artificial intelligence; Segmentation; Image quality; Modular design; Magnetic resonance imaging; Toolbox; Medical imaging; DICOM; Computer vision; Image (mathematics); Data mining; Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.06823",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286906959",
      "doi": "10.48550/arxiv.2110.04902",
      "title": "Synthetic Data for Multi-Parameter Camera-Based Physiological Sensing",
      "abstract": "Synthetic data is a powerful tool in training data hungry deep learning algorithms. However, to date, camera-based physiological sensing has not taken full advantage of these techniques. In this work, we leverage a high-fidelity synthetics pipeline for generating videos of faces with faithful blood flow and breathing patterns. We present systematic experiments showing how physiologically-grounded synthetic data can be used in training camera-based multi-parameter cardiopulmonary sensing. We provide empirical evidence that heart and breathing rate measurement accuracy increases with the number of synthetic avatars in the training set. Furthermore, training with avatars with darker skin types leads to better overall performance than training with avatars with lighter skin types. Finally, we discuss the opportunities that synthetics present in the domain of camera-based physiological sensing and limitations that need to be overcome.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Daniel McDuff et al.",
      "keywords": "Leverage (statistics); Computer science; Fidelity; Synthetic data; Artificial intelligence; Training set; Deep learning; Pipeline (software); Computer vision; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.04902",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4401201777",
      "doi": "10.48550/arxiv.2407.19540",
      "title": "Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Curriculum Data Erasing Guided Knowledge Distillation",
      "abstract": "In this paper, we present NECHO v2, a novel framework designed to enhance the predictive accuracy of multimodal sequential patient diagnoses under uncertain missing visit sequences, a common challenge in real clinical settings. Firstly, we modify NECHO, designed in a diagnosis code-centric fashion, to handle uncertain modality representation dominance under the imperfect data. Secondly, we develop a systematic knowledge distillation by employing the modified NECHO as both teacher and student. It encompasses a modality-wise contrastive and hierarchical distillation, transformer representation random distillation, along with other distillations to align representations between teacher and student tightly and effectively. We also propose curriculum learning guided random data erasing within sequences during both training and distillation of the teacher to lightly simulate scenario with missing visit information, thereby fostering effective knowledge transfer. As a result, NECHO v2 verifies itself by showing robust superiority in multimodal sequential diagnosis prediction under both balanced and imbalanced incomplete settings on multimodal healthcare data.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Heejoon Koo",
      "keywords": "Computer science; Distillation; Artificial intelligence; Machine learning; Chemistry; Chromatography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.19540",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402346396",
      "doi": "10.48550/arxiv.2407.13768",
      "title": "Addressing Imbalance for Class Incremental Learning in Medical Image Classification",
      "abstract": "Deep convolutional neural networks have made significant breakthroughs in medical image classification, under the assumption that training samples from all classes are simultaneously available. However, in real-world medical scenarios, there's a common need to continuously learn about new diseases, leading to the emerging field of class incremental learning (CIL) in the medical domain. Typically, CIL suffers from catastrophic forgetting when trained on new classes. This phenomenon is mainly caused by the imbalance between old and new classes, and it becomes even more challenging with imbalanced medical datasets. In this work, we introduce two simple yet effective plug-in methods to mitigate the adverse effects of the imbalance. First, we propose a CIL-balanced classification loss to mitigate the classifier bias toward majority classes via logit adjustment. Second, we propose a distribution margin loss that not only alleviates the inter-class overlap in embedding space but also enforces the intra-class compactness. We evaluate the effectiveness of our method with extensive experiments on three benchmark datasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our approach outperforms state-of-the-art methods.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Xuze Hao et al.",
      "keywords": "Class (philosophy); Image (mathematics); Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.13768",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392736013",
      "doi": "10.48550/arxiv.2403.06498",
      "title": "Incorporating Improved Sinusoidal Threshold-based Semi-supervised Method and Diffusion Models for Osteoporosis Diagnosis",
      "abstract": "Osteoporosis is a common skeletal disease that seriously affects patients' quality of life. Traditional osteoporosis diagnosis methods are expensive and complex. The semi-supervised model based on diffusion model and class threshold sinusoidal decay proposed in this paper can automatically diagnose osteoporosis based on patient's imaging data, which has the advantages of convenience, accuracy, and low cost. Unlike previous semi-supervised models, all the unlabeled data used in this paper are generated by the diffusion model. Compared with real unlabeled data, synthetic data generated by the diffusion model show better performance. In addition, this paper proposes a novel pseudo-label threshold adjustment mechanism, Sinusoidal Threshold Decay, which can make the semi-supervised model converge more quickly and improve its performance. Specifically, the method is tested on a dataset including 749 dental panoramic images, and its achieved leading detect performance and produces a 80.10% accuracy.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Wenchi Ke",
      "keywords": "Osteoporosis; Diffusion; Computer science; Medicine; Mathematics; Artificial intelligence; Physics; Pathology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.06498",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399555129",
      "doi": "10.48550/arxiv.2406.05786",
      "title": "CAMS: Convolution and Attention-Free Mamba-based Cardiac Image Segmentation",
      "abstract": "Convolutional Neural Networks (CNNs) and Transformer-based self-attention models have become the standard for medical image segmentation. This paper demonstrates that convolution and self-attention, while widely used, are not the only effective methods for segmentation. Breaking with convention, we present a Convolution and self-Attention-free Mamba-based semantic Segmentation Network named CAMS-Net. Specifically, we design Mamba-based Channel Aggregator and Spatial Aggregator, which are applied independently in each encoder-decoder stage. The Channel Aggregator extracts information across different channels, and the Spatial Aggregator learns features across different spatial locations. We also propose a Linearly Interconnected Factorized Mamba (LIFM) block to reduce the computational complexity of a Mamba block and to enhance its decision function by introducing a non-linearity between two factorized Mamba blocks. Our model outperforms the existing state-of-the-art CNN, self-attention, and Mamba-based methods on CMR and M&amp;Ms-2 Cardiac segmentation datasets, showing how this innovative, convolution, and self-attention-free method can inspire further research beyond CNN and Transformer paradigms, achieving linear complexity and reducing the number of parameters. Source code and pre-trained models are available at: https://github.com/kabbas570/CAMS-Net.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Abbas Khan et al.",
      "keywords": "Convolution (computer science); Segmentation; Image (mathematics); Computer science; Artificial intelligence; Mathematics; Computer vision",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.05786",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387075853",
      "doi": "10.48550/arxiv.2309.13817",
      "title": "MMA-Net: Multiple Morphology-Aware Network for Automated Cobb Angle Measurement",
      "abstract": "Scoliosis diagnosis and assessment depend largely on the measurement of the Cobb angle in spine X-ray images. With the emergence of deep learning techniques that employ landmark detection, tilt prediction, and spine segmentation, automated Cobb angle measurement has become increasingly popular. However, these methods encounter difficulties such as high noise sensitivity, intricate computational procedures, and exclusive reliance on a single type of morphological information. In this paper, we introduce the Multiple Morphology-Aware Network (MMA-Net), a novel framework that improves Cobb angle measurement accuracy by integrating multiple spine morphology as attention information. In the MMA-Net, we first feed spine X-ray images into the segmentation network to produce multiple morphological information (spine region, centerline, and boundary) and then concatenate the original X-ray image with the resulting segmentation maps as input for the regression module to perform precise Cobb angle measurement. Furthermore, we devise joint loss functions for our segmentation and regression network training, respectively. We evaluate our method on the AASCE challenge dataset and achieve superior performance with the SMAPE of 7.28% and the MAE of 3.18\u00b0, indicating a strong competitiveness compared to other outstanding methods. Consequently, we can offer clinicians automated, efficient, and reliable Cobb angle measurement.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhengxuan Qiu et al.",
      "keywords": "CobB; Segmentation; Artificial intelligence; Cobb angle; Tilt (camera); Computer science; Computer vision; Noise (video); Boundary (topology); Pattern recognition (psychology); Scoliosis; Image (mathematics); Mathematics; Geometry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.13817",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415021895",
      "doi": "10.48550/arxiv.2505.14113",
      "title": "CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition",
      "abstract": "Most machine learning-based image segmentation models produce pixel-wise confidence scores that represent the model's predicted probability for each class label at every pixel. While this information can be particularly valuable in high-stakes domains such as medical imaging, these scores are heuristic in nature and do not constitute rigorous quantitative uncertainty estimates. Conformal prediction (CP) provides a principled framework for transforming heuristic confidence scores into statistically valid uncertainty estimates. However, applying CP directly to image segmentation ignores the spatial correlations between pixels, a fundamental characteristic of image data. This can result in overly conservative and less interpretable uncertainty estimates. To address this, we propose CONSIGN (Conformal Segmentation Informed by Spatial Groupings via Decomposition), a CP-based method that incorporates spatial correlations to improve uncertainty quantification in image segmentation. Our method generates meaningful prediction sets that come with user-specified, high-probability error guarantees. It is compatible with any pre-trained segmentation model capable of generating multiple sample outputs. We evaluate CONSIGN against two CP baselines across three medical imaging datasets and two COCO dataset subsets, using three different pre-trained segmentation models. Results demonstrate that accounting for spatial structure significantly improves performance across multiple metrics and enhances the quality of uncertainty estimates.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Bruno Viti et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.14113",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293322895",
      "doi": "10.48550/arxiv.2107.11045",
      "title": "Ensemble of Convolution Neural Networks on Heterogeneous Signals for Sleep Stage Scoring",
      "abstract": "Over the years, several approaches have tried to tackle the problem of performing an automatic scoring of the sleeping stages. Although any polysomnography usually collects over a dozen of different signals, this particular problem has been mainly tackled by using only the Electroencephalograms presented in those records. On the other hand, the other recorded signals have been mainly ignored by most works. This paper explores and compares the convenience of using additional signals apart from electroencephalograms. More specifically, this work uses the SHHS-1 dataset with 5,804 patients containing an electromyogram recorded simultaneously as two electroencephalograms. To compare the results, first, the same architecture has been evaluated with different input signals and all their possible combinations. These tests show how, using more than one signal especially if they are from different sources, improves the results of the classification. Additionally, the best models obtained for each combination of one or more signals have been used in ensemble models and, its performance has been compared showing the convenience of using these multi-signal models to improve the classification. The best overall model, an ensemble of Depth-wise Separational Convolutional Neural Networks, has achieved an accuracy of 86.06\\% with a Cohen's Kappa of 0.80 and a $F_{1}$ of 0.77. Up to date, those are the best results on the complete dataset and it shows a significant improvement in the precision and recall for the most uncommon class in the dataset.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Enrique Fern\u00e1ndez-Blanco et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Pattern recognition (psychology); Convolution (computer science); SIGNAL (programming language); Polysomnography; Recall; Precision and recall; Artificial neural network; Machine learning; Speech recognition; Electroencephalography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2107.11045",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283217348",
      "doi": "10.48550/arxiv.2206.08524",
      "title": "CDNet: Contrastive Disentangled Network for Fine-Grained Image Categorization of Ocular B-Scan Ultrasound",
      "abstract": "Precise and rapid categorization of images in the B-scan ultrasound modality is vital for diagnosing ocular diseases. Nevertheless, distinguishing various diseases in ultrasound still challenges experienced ophthalmologists. Thus a novel contrastive disentangled network (CDNet) is developed in this work, aiming to tackle the fine-grained image categorization (FGIC) challenges of ocular abnormalities in ultrasound images, including intraocular tumor (IOT), retinal detachment (RD), posterior scleral staphyloma (PSS), and vitreous hemorrhage (VH). Three essential components of CDNet are the weakly-supervised lesion localization module (WSLL), contrastive multi-zoom (CMZ) strategy, and hyperspherical contrastive disentangled loss (HCD-Loss), respectively. These components facilitate feature disentanglement for fine-grained recognition in both the input and output aspects. The proposed CDNet is validated on our ZJU Ocular Ultrasound Dataset (ZJUOUSD), consisting of 5213 samples. Furthermore, the generalization ability of CDNet is validated on two public and widely-used chest X-ray FGIC benchmarks. Quantitative and qualitative results demonstrate the efficacy of our proposed CDNet, which achieves state-of-the-art performance in the FGIC task. Code is available at: https://github.com/ZeroOneGame/CDNet-for-OUS-FGIC .",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Ruilong Dan et al.",
      "keywords": "Computer science; Categorization; Feature (linguistics); Artificial intelligence; Generalization; Ultrasound; Modality (human\u2013computer interaction); Image (mathematics); Pattern recognition (psychology); Radiology; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.08524",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403709861",
      "doi": "10.48550/arxiv.2409.11534",
      "title": "Unsupervised Hybrid framework for ANomaly Detection (HAND) -- applied to Screening Mammogram",
      "abstract": "Out-of-distribution (OOD) detection is crucial for enhancing the generalization of AI models used in mammogram screening. Given the challenge of limited prior knowledge about OOD samples in external datasets, unsupervised generative learning is a preferable solution which trains the model to discern the normal characteristics of in-distribution (ID) data. The hypothesis is that during inference, the model aims to reconstruct ID samples accurately, while OOD samples exhibit poorer reconstruction due to their divergence from normality. Inspired by state-of-the-art (SOTA) hybrid architectures combining CNNs and transformers, we developed a novel backbone - HAND, for detecting OOD from large-scale digital screening mammogram studies. To boost the learning efficiency, we incorporated synthetic OOD samples and a parallel discriminator in the latent space to distinguish between ID and OOD samples. Gradient reversal to the OOD reconstruction loss penalizes the model for learning OOD reconstructions. An anomaly score is computed by weighting the reconstruction and discriminator loss. On internal RSNA mammogram held-out test and external Mayo clinic hand-curated dataset, the proposed HAND model outperformed encoder-based and GAN-based baselines, and interestingly, it also outperformed the hybrid CNN+transformer baselines. Therefore, the proposed HAND pipeline offers an automated efficient computational solution for domain-specific quality checks in external screening mammograms, yielding actionable insights without direct exposure to the private medical imaging data.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhemin Zhang et al.",
      "keywords": "Anomaly detection; Anomaly (physics); Computer science; Artificial intelligence; Pattern recognition (psychology); Machine learning; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.11534",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289761861",
      "doi": "10.48550/arxiv.1807.02908",
      "title": "Partial Policy-based Reinforcement Learning for Anatomical Landmark\\n Localization in 3D Medical Images",
      "abstract": "Deploying the idea of long-term cumulative return, reinforcement learning has\\nshown remarkable performance in various fields. We propose a formulation of the\\nlandmark localization in 3D medical images as a reinforcement learning problem.\\nWhereas value-based methods have been widely used to solve similar problems, we\\nadopt an actor-critic based direct policy search method framed in a temporal\\ndifference learning approach. Successful behavior learning is challenging in\\nlarge state and/or action spaces, requiring many trials. We introduce a partial\\npolicy-based reinforcement learning to enable solving the large problem of\\nlocalization by learning the optimal policy on smaller partial domains.\\nIndependent actors efficiently learn the corresponding partial policies, each\\nutilizing their own independent critic. The proposed policy reconstruction from\\nthe partial policies ensures a robust and efficient localization utilizing the\\nsub-agents solving simple binary decision problems in their corresponding\\npartial action spaces. The proposed reinforcement learning requires a small\\nnumber of trials to learn the optimal behavior compared with the original\\nbehavior learning scheme.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Walid Abdullah Al et al.",
      "keywords": "Reinforcement learning; Landmark; Computer science; Artificial intelligence; Bellman equation; Temporal difference learning; Action (physics); Machine learning; Term (time); Reinforcement; Mathematical optimization; Mathematics; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1807.02908",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388092192",
      "doi": "10.48550/arxiv.2310.17870",
      "title": "Ranking with Slot Constraints",
      "abstract": "We introduce the problem of ranking with slot constraints, which can be used to model a wide range of application problems -- from college admission with limited slots for different majors, to composing a stratified cohort of eligible participants in a medical trial. We show that the conventional Probability Ranking Principle (PRP) can be highly sub-optimal for slot-constrained ranking problems, and we devise a new ranking algorithm, called MatchRank. The goal of MatchRank is to produce rankings that maximize the number of filled slots if candidates are evaluated by a human decision maker in the order of the ranking. In this way, MatchRank generalizes the PRP, and it subsumes the PRP as a special case when there are no slot constraints. Our theoretical analysis shows that MatchRank has a strong approximation guarantee without any independence assumptions between slots or candidates. Furthermore, we show how MatchRank can be implemented efficiently. Beyond the theoretical guarantees, empirical evaluations show that MatchRank can provide substantial improvements over a range of synthetic and real-world tasks.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Wentao Guo et al.",
      "keywords": "Ranking (information retrieval); Independence (probability theory); Computer science; Range (aeronautics); Decision maker; Order (exchange); Mathematical optimization; Outcome (game theory); Machine learning; Operations research; Mathematics; Statistics; Mathematical economics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.17870",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4298035033",
      "doi": "10.48550/arxiv.2208.02912",
      "title": "Unsupervised Tissue Segmentation via Deep Constrained Gaussian Network",
      "abstract": "Tissue segmentation is the mainstay of pathological examination, whereas the manual delineation is unduly burdensome. To assist this time-consuming and subjective manual step, researchers have devised methods to automatically segment structures in pathological images. Recently, automated machine and deep learning based methods dominate tissue segmentation research studies. However, most machine and deep learning based approaches are supervised and developed using a large number of training samples, in which the pixelwise annotations are expensive and sometimes can be impossible to obtain. This paper introduces a novel unsupervised learning paradigm by integrating an end-to-end deep mixture model with a constrained indicator to acquire accurate semantic tissue segmentation. This constraint aims to centralise the components of deep mixture models during the calculation of the optimisation function. In so doing, the redundant or empty class issues, which are common in current unsupervised learning methods, can be greatly reduced. By validation on both public and in-house datasets, the proposed deep constrained Gaussian network achieves significantly (Wilcoxon signed-rank test) better performance (with the average Dice scores of 0.737 and 0.735, respectively) on tissue segmentation with improved stability and robustness, compared to other existing unsupervised segmentation approaches. Furthermore, the proposed method presents a similar performance (p-value &gt; 0.05) compared to the fully supervised U-Net.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Nan Yang et al.",
      "keywords": "Artificial intelligence; Segmentation; Computer science; Deep learning; Robustness (evolution); Pattern recognition (psychology); Dice; Machine learning; Unsupervised learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.02912",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417286980",
      "doi": "10.48550/arxiv.2505.13072",
      "title": "Orthogonal Survival Learners for Estimating Heterogeneous Treatment Effects from Time-to-Event Data",
      "abstract": "Estimating heterogeneous treatment effects (HTEs) is crucial for personalized decision-making. However, this task is challenging in survival analysis, which includes time-to-event data with censored outcomes (e.g., due to study dropout). In this paper, we propose a toolbox of novel orthogonal survival learners to estimate HTEs from time-to-event data under censoring. Our learners have three main advantages: (i) we show that learners from our toolbox are guaranteed to be orthogonal and thus come with favorable theoretical properties; (ii) our toolbox allows for incorporating a custom weighting function, which can lead to robustness against different types of low overlap, and (iii) our learners are model-agnostic (i.e., they can be combined with arbitrary machine learning models). We instantiate the learners from our toolbox using several weighting functions and, as a result, propose various neural orthogonal survival learners. Some of these coincide with existing survival learners (including survival versions of the DR- and R-learner), while others are novel and further robust w.r.t. low overlap regimes specific to the survival setting (i.e., survival overlap and censoring overlap). We then empirically verify the effectiveness of our learners for HTE estimation in different low-overlap regimes through numerical experiments. In sum, we provide practitioners with a large toolbox of learners that can be used for randomized and observational studies with censored time-to-event data.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Dennis Frauen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.13072",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4405253257",
      "doi": "10.48550/arxiv.2412.05520",
      "title": "More than Marketing? On the Information Value of AI Benchmarks for Practitioners",
      "abstract": "Public AI benchmark results are widely broadcast by model developers as indicators of model quality within a growing and competitive market. However, these advertised scores do not necessarily reflect the traits of interest to those who will ultimately apply AI models. In this paper, we seek to understand if and how AI benchmarks are used to inform decision-making. Based on the analyses of interviews with 19 individuals who have used, or decided against using, benchmarks in their day-to-day work, we find that across these settings, participants use benchmarks as a signal of relative performance difference between models. However, whether this signal was considered a definitive sign of model superiority, sufficient for downstream decisions, varied. In academia, public benchmarks were generally viewed as suitable measures for capturing research progress. By contrast, in both product and policy, benchmarks -- even those developed internally for specific tasks -- were often found to be inadequate for informing substantive decisions. Of the benchmarks deemed unsatisfactory, respondents reported that their goals were neither well-defined nor reflective of real-world use. Based on the study results, we conclude that effective benchmarks should provide meaningful, real-world evaluations, incorporate domain expertise, and maintain transparency in scope and goals. They must capture diverse, task-relevant capabilities, be challenging enough to avoid quick saturation, and account for trade-offs in model performance rather than relying on a single score. Additionally, proprietary data collection and contamination prevention are critical for producing reliable and actionable results. By adhering to these criteria, benchmarks can move beyond mere marketing tricks into robust evaluative frameworks.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Amelia Hardy et al.",
      "keywords": "Value (mathematics); Marketing; Business; Computer science; Knowledge management; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.05520",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396653609",
      "doi": "10.48550/arxiv.2405.00734",
      "title": "EEG-MACS: Manifold Attention and Confidence Stratification for EEG-based Cross-Center Brain Disease Diagnosis under Unreliable Annotations",
      "abstract": "Cross-center data heterogeneity and annotation unreliability significantly challenge the intelligent diagnosis of diseases using brain signals. A notable example is the EEG-based diagnosis of neurodegenerative diseases, which features subtler abnormal neural dynamics typically observed in small-group settings. To advance this area, in this work, we introduce a transferable framework employing Manifold Attention and Confidence Stratification (MACS) to diagnose neurodegenerative disorders based on EEG signals sourced from four centers with unreliable annotations. The MACS framework's effectiveness stems from these features: 1) The Augmentor generates various EEG-represented brain variants to enrich the data space; 2) The Switcher enhances the feature space for trusted samples and reduces overfitting on incorrectly labeled samples; 3) The Encoder uses the Riemannian manifold and Euclidean metrics to capture spatiotemporal variations and dynamic synchronization in EEG; 4) The Projector, equipped with dual heads, monitors consistency across multiple brain variants and ensures diagnostic accuracy; 5) The Stratifier adaptively stratifies learned samples by confidence levels throughout the training process; 6) Forward and backpropagation in MACS are constrained by confidence stratification to stabilize the learning system amid unreliable annotations. Our subject-independent experiments, conducted on both neurocognitive and movement disorders using cross-center corpora, have demonstrated superior performance compared to existing related algorithms. This work not only improves EEG-based diagnostics for cross-center and small-setting brain diseases but also offers insights into extending MACS techniques to other data analyses, tackling data heterogeneity and annotation unreliability in multimedia and multimodal content understanding.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhenxi Song et al.",
      "keywords": "Electroencephalography; Center (category theory); Stratification (seeds); Artificial intelligence; Psychology; Computer science; Neuroscience; Biology; Chemistry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.00734",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404389901",
      "doi": "10.48550/arxiv.2411.05663",
      "title": "Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation",
      "abstract": "Catastrophic forgetting is a significant challenge in online continual learning (OCL), especially for non-stationary data streams that do not have well-defined task boundaries. This challenge is exacerbated by the memory constraints and privacy concerns inherent in rehearsal buffers. To tackle catastrophic forgetting, in this paper, we introduce Online-LoRA, a novel framework for task-free OCL. Online-LoRA allows to finetune pre-trained Vision Transformer (ViT) models in real-time to address the limitations of rehearsal buffers and leverage pre-trained models' performance benefits. As the main contribution, our approach features a novel online weight regularization strategy to identify and consolidate important model parameters. Moreover, Online-LoRA leverages the training dynamics of loss values to enable the automatic recognition of the data distribution shifts. Extensive experiments across many task-free OCL scenarios and benchmark datasets (including CIFAR-100, ImageNet-R, ImageNet-S, CUB-200 and CORe50) demonstrate that Online-LoRA can be robustly adapted to various ViT architectures, while achieving better performance compared to SOTA methods. Our code will be publicly available at: https://github.com/Christina200/Online-LoRA-official.git.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiwen Wei et al.",
      "keywords": "Adaptation (eye); Task (project management); Computer science; Online learning; Rank (graph theory); Human\u2013computer interaction; Multimedia; Psychology; Engineering; Mathematics; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.05663",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226435540",
      "doi": "10.48550/arxiv.2112.04571",
      "title": "Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach",
      "abstract": "A main research goal in various studies is to use an observational data set and provide a new set of counterfactual guidelines that can yield causal improvements. Dynamic Treatment Regimes (DTRs) are widely studied to formalize this process. However, available methods in finding optimal DTRs often rely on assumptions that are violated in real-world applications (e.g., medical decision-making or public policy), especially when (a) the existence of unobserved confounders cannot be ignored, and (b) the unobserved confounders are time-varying (e.g., affected by previous actions). When such assumptions are violated, one often faces ambiguity regarding the underlying causal model. This ambiguity is inevitable, since the dynamics of unobserved confounders and their causal impact on the observed part of the data cannot be understood from the observed data. Motivated by a case study of finding superior treatment regimes for patients who underwent transplantation in our partner hospital and faced a medical condition known as New Onset Diabetes After Transplantation (NODAT), we extend DTRs to a new class termed Ambiguous Dynamic Treatment Regimes (ADTRs), in which the causal impact of treatment regimes is evaluated based on a \"cloud\" of causal models. We then connect ADTRs to Ambiguous Partially Observable Mark Decision Processes (APOMDPs) and develop Reinforcement Learning methods, which enable using the observed data to efficiently learn an optimal treatment regime. We establish theoretical results for these learning methods, including (weak) consistency and asymptotic normality. We further evaluate the performance of these learning methods both in our case study and in simulation experiments.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Soroush Saghafian",
      "keywords": "Counterfactual thinking; Ambiguity; Reinforcement learning; Confounding; Set (abstract data type); Econometrics; Computer science; Consistency (knowledge bases); Observational study; Causal inference; Machine learning; Artificial intelligence; Psychology; Economics; Mathematics; Statistics; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.04571",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297676259",
      "doi": "10.48550/arxiv.2209.02934",
      "title": "Boundary Guided Semantic Learning for Real-time COVID-19 Lung Infection Segmentation System",
      "abstract": "The coronavirus disease 2019 (COVID-19) continues to have a negative impact on healthcare systems around the world, though the vaccines have been developed and national vaccination coverage rate is steadily increasing. At the current stage, automatically segmenting the lung infection area from CT images is essential for the diagnosis and treatment of COVID-19. Thanks to the development of deep learning technology, some deep learning solutions for lung infection segmentation have been proposed. However, due to the scattered distribution, complex background interference and blurred boundaries, the accuracy and completeness of the existing models are still unsatisfactory. To this end, we propose a boundary guided semantic learning network (BSNet) in this paper. On the one hand, the dual-branch semantic enhancement module that combines the top-level semantic preservation and progressive semantic integration is designed to model the complementary relationship between different high-level features, thereby promoting the generation of more complete segmentation results. On the other hand, the mirror-symmetric boundary guidance module is proposed to accurately detect the boundaries of the lesion regions in a mirror-symmetric way. Experiments on the publicly available dataset demonstrate that our BSNet outperforms the existing state-of-the-art competitors and achieves a real-time inference speed of 44 FPS.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Runmin Cong et al.",
      "keywords": "Segmentation; Computer science; Deep learning; Artificial intelligence; Inference; Boundary (topology); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.02934",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393905751",
      "doi": "10.48550/arxiv.2404.00588",
      "title": "Memory-based Cross-modal Semantic Alignment Network for Radiology Report Generation",
      "abstract": "Generating radiology reports automatically reduces the workload of radiologists and helps the diagnoses of specific diseases. Many existing methods take this task as modality transfer process. However, since the key information related to disease accounts for a small proportion in both image and report, it is hard for the model to learn the latent relation between the radiology image and its report, thus failing to generate fluent and accurate radiology reports. To tackle this problem, we propose a memory-based cross-modal semantic alignment model (MCSAM) following an encoder-decoder paradigm. MCSAM includes a well initialized long-term clinical memory bank to learn disease-related representations as well as prior knowledge for different modalities to retrieve and use the retrieved memory to perform feature consolidation. To ensure the semantic consistency of the retrieved cross modal prior knowledge, a cross-modal semantic alignment module (SAM) is proposed. SAM is also able to generate semantic visual feature embeddings which can be added to the decoder and benefits report generation. More importantly, to memorize the state and additional information while generating reports with the decoder, we use learnable memory tokens which can be seen as prompts. Extensive experiments demonstrate the promising performance of our proposed method which generates state-of-the-art performance on the MIMIC-CXR dataset.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yitian Tao et al.",
      "keywords": "Modal; Computer science; Artificial intelligence; Natural language processing; Materials science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.00588",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286910589",
      "doi": "10.48550/arxiv.2110.01293",
      "title": "Light-weight Deformable Registration using Adversarial Learning with Distilling Knowledge",
      "abstract": "Deformable registration is a crucial step in many medical procedures such as image-guided surgery and radiation therapy. Most recent learning-based methods focus on improving the accuracy by optimizing the non-linear spatial correspondence between the input images. Therefore, these methods are computationally expensive and require modern graphic cards for real-time deployment. In this paper, we introduce a new Light-weight Deformable Registration network that significantly reduces the computational cost while achieving competitive accuracy. In particular, we propose a new adversarial learning with distilling knowledge algorithm that successfully leverages meaningful information from the effective but expensive teacher network to the student network. We design the student network such as it is light-weight and well suitable for deployment on a typical CPU. The extensively experimental results on different public datasets show that our proposed method achieves state-of-the-art accuracy while significantly faster than recent methods. We further show that the use of our adversarial learning algorithm is essential for a time-efficiency deformable registration method. Finally, our source code and trained models are available at: https://github.com/aioz-ai/LDR_ALDK.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Quang Tran Minh et al.",
      "keywords": "Computer science; Software deployment; Code (set theory); Focus (optics); Adversarial system; Deep learning; Artificial intelligence; Source code; Computer engineering; Image registration; Image (mathematics); Machine learning; Computer vision; Software engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.01293",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309872482",
      "doi": "10.48550/arxiv.2211.12118",
      "title": "HaRiM$^+$: Evaluating Summary Quality with Hallucination Risk",
      "abstract": "One of the challenges of developing a summarization model arises from the difficulty in measuring the factual inconsistency of the generated text. In this study, we reinterpret the decoder overconfidence-regularizing objective suggested in (Miao et al., 2021) as a hallucination risk measurement to better estimate the quality of generated summaries. We propose a reference-free metric, HaRiM+, which only requires an off-the-shelf summarization model to compute the hallucination risk based on token likelihoods. Deploying it requires no additional training of models or ad-hoc modules, which usually need alignment to human judgments. For summary-quality estimation, HaRiM+ records state-of-the-art correlation to human judgment on three summary-quality annotation sets: FRANK, QAGS, and SummEval. We hope that our work, which merits the use of summarization models, facilitates the progress of both automated evaluation and generation of summary.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Seonil Son et al.",
      "keywords": "Automatic summarization; Computer science; Metric (unit); Quality (philosophy); Annotation; Security token; Artificial intelligence; Natural language processing; Machine learning; Information retrieval",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2211.12118",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415160786",
      "doi": "10.48550/arxiv.2504.10405",
      "title": "Performance of Large Language Models in Supporting Medical Diagnosis and Treatment",
      "abstract": "The integration of Large Language Models (LLMs) into healthcare holds significant potential to enhance diagnostic accuracy and support medical treatment planning. These AI-driven systems can analyze vast datasets, assisting clinicians in identifying diseases, recommending treatments, and predicting patient outcomes. This study evaluates the performance of a range of contemporary LLMs, including both open-source and closed-source models, on the 2024 Portuguese National Exam for medical specialty access (PNA), a standardized medical knowledge assessment. Our results highlight considerable variation in accuracy and cost-effectiveness, with several models demonstrating performance exceeding human benchmarks for medical students on this specific task. We identify leading models based on a combined score of accuracy and cost, discuss the implications of reasoning methodologies like Chain-of-Thought, and underscore the potential for LLMs to function as valuable complementary tools aiding medical professionals in complex clinical decision-making.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Diogo de Sousa et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10405",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388067678",
      "doi": "10.48550/arxiv.2310.18087",
      "title": "A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation",
      "abstract": "Source-free domain adaptation (SFDA) aims to adapt models trained on a labeled source domain to an unlabeled target domain without the access to source data. In medical imaging scenarios, the practical significance of SFDA methods has been emphasized due to privacy concerns. Recent State-of-the-art SFDA methods primarily rely on self-training based on pseudo-labels (PLs). Unfortunately, PLs suffer from accuracy deterioration caused by domain shift, and thus limit the effectiveness of the adaptation process. To address this issue, we propose a Chebyshev confidence guided SFDA framework to accurately assess the reliability of PLs and generate self-improving PLs for self-training. The Chebyshev confidence is estimated by calculating probability lower bound of the PL confidence, given the prediction and the corresponding uncertainty. Leveraging the Chebyshev confidence, we introduce two confidence-guided denoising methods: direct denoising and prototypical denoising. Additionally, we propose a novel teacher-student joint training scheme (TJTS) that incorporates a confidence weighting module to improve PLs iteratively. The TJTS, in collaboration with the denoising methods, effectively prevents the propagation of noise and enhances the accuracy of PLs. Extensive experiments in diverse domain scenarios validate the effectiveness of our proposed framework and establish its superiority over state-of-the-art SFDA methods. Our paper contributes to the field of SFDA by providing a novel approach for precisely estimating the reliability of pseudo-labels and a framework for obtaining high-quality PLs, resulting in improved adaptation performance.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiesi Hu et al.",
      "keywords": "Reliability (semiconductor); Computer science; Noise (video); Weighting; Domain (mathematical analysis); Noise reduction; Adaptation (eye); Artificial intelligence; Machine learning; Image (mathematics); Mathematics; Psychology; Power (physics)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.18087",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386554881",
      "doi": "10.48550/arxiv.2309.03386",
      "title": "Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction",
      "abstract": "Positive-Unlabeled (PU) Learning is a challenge presented by binary classification problems where there is an abundance of unlabeled data along with a small number of positive data instances, which can be used to address chronic disease screening problem. State-of-the-art PU learning methods have resulted in the development of various risk estimators, yet they neglect the differences among distinct populations. To address this issue, we present a novel Positive-Unlabeled Learning Tree (PUtree) algorithm. PUtree is designed to take into account communities such as different age or income brackets, in tasks of chronic disease prediction. We propose a novel approach for binary decision-making, which hierarchically builds community-based PU models and then aggregates their deliverables. Our method can explicate each PU model on the tree for the optimized non-leaf PU node splitting. Furthermore, a mask-recovery data augmentation strategy enables sufficient training of the model in individual communities. Additionally, the proposed approach includes an adversarial PU risk estimator to capture hierarchical PU-relationships, and a model fusion network that integrates data from each tree path, resulting in robust binary classification results. We demonstrate the superior performance of PUtree as well as its variants on two benchmarks and a new diabetes-prediction dataset.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yang Wu et al.",
      "keywords": "Computer science; Artificial intelligence; Tree (set theory); Machine learning; Binary classification; Estimator; Path (computing); Binary number; Decision tree; Data mining; Mathematics; Statistics; Support vector machine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.03386",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4405627036",
      "doi": "10.48550/arxiv.2412.14193",
      "title": "Supplemental Material for Whom Do Explanations Serve? A Systematic Literature Survey of User Characteristics in Explainable Recommender Systems Evaluation",
      "abstract": "Adding explanations to recommender systems is said to have multiple benefits, such as increasing user trust or system transparency. Previous work from other application areas suggests that specific user characteristics impact the users' perception of the explanation. However, we rarely find this type of evaluation for recommender systems explanations. This paper addresses this gap by surveying 124 papers in which recommender systems explanations were evaluated in user studies. We analyzed their participant descriptions and study results where the impact of user characteristics on the explanation effects was measured. Our findings suggest that the results from the surveyed studies predominantly cover specific users who do not necessarily represent the users of recommender systems in the evaluation domain. This may seriously hamper the generalizability of any insights we may gain from current studies on explanations in recommender systems. We further find inconsistencies in the data reporting, which impacts the reproducibility of the reported results. Hence, we recommend actions to move toward a more inclusive and reproducible evaluation.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Kathrin Wardatzky et al.",
      "keywords": "Recommender system; Computer science; Systematic review; Information retrieval; Data science; MEDLINE; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.14193",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4282813377",
      "doi": "10.48550/arxiv.2206.05175",
      "title": "A Causal Research Pipeline and Tutorial for Psychologists and Social Scientists",
      "abstract": "Causality is a fundamental part of the scientific endeavour to understand the world. Unfortunately, causality is still taboo in much of psychology and social science. Motivated by a growing number of recommendations for the importance of adopting causal approaches to research, we reformulate the typical approach to research in psychology to harmonize inevitably causal theories with the rest of the research pipeline. We present a new process which begins with the incorporation of techniques from the confluence of causal discovery and machine learning for the development, validation, and transparent formal specification of theories. We then present methods for reducing the complexity of the fully specified theoretical model into the fundamental submodel relevant to a given target hypothesis. From here, we establish whether or not the quantity of interest is estimable from the data, and if so, propose the use of semi-parametric machine learning methods for the estimation of causal effects. The overall goal is the presentation of a new research pipeline which can (a) facilitate scientific inquiry compatible with the desire to test causal theories (b) encourage transparent representation of our theories as unambiguous mathematical objects, (c) to tie our statistical models to specific attributes of the theory, thus reducing under-specification problems frequently resulting from the theory-to-model gap, and (d) to yield results and estimates which are causally meaningful and reproducible. The process is demonstrated through didactic examples with real-world data, and we conclude with a summary and discussion of limitations.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Matthew J. Vowels",
      "keywords": "Causality (physics); Causal model; Process (computing); Computer science; Pipeline (software); Causal inference; Data science; Representation (politics); Presentation (obstetrics); Epistemology; Artificial intelligence; Management science; Econometrics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.05175",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392011899",
      "doi": "10.48550/arxiv.2402.11114",
      "title": "Whose Emotions and Moral Sentiments Do Language Models Reflect?",
      "abstract": "Language models (LMs) are known to represent the perspectives of some social groups better than others, which may impact their performance, especially on subjective tasks such as content moderation and hate speech detection. To explore how LMs represent different perspectives, existing research focused on positional alignment, i.e., how closely the models mimic the opinions and stances of different groups, e.g., liberals or conservatives. However, human communication also encompasses emotional and moral dimensions. We define the problem of affective alignment, which measures how LMs' emotional and moral tone represents those of different groups. By comparing the affect of responses generated by 36 LMs to the affect of Twitter messages, we observe significant misalignment of LMs with both ideological groups. This misalignment is larger than the partisan divide in the U.S. Even after steering the LMs towards specific ideological perspectives, the misalignment and liberal tendencies of the model persist, suggesting a systemic bias within LMs.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zihao He et al.",
      "keywords": "Psychology; Social psychology; Linguistics; Sociology; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.11114",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4402951419",
      "doi": "10.48550/arxiv.2408.17054",
      "title": "BTMuda: A Bi-level Multi-source unsupervised domain adaptation framework for breast cancer diagnosis",
      "abstract": "Deep learning has revolutionized the early detection of breast cancer, resulting in a significant decrease in mortality rates. However, difficulties in obtaining annotations and huge variations in distribution between training sets and real scenes have limited their clinical applications. To address these limitations, unsupervised domain adaptation (UDA) methods have been used to transfer knowledge from one labeled source domain to the unlabeled target domain, yet these approaches suffer from severe domain shift issues and often ignore the potential benefits of leveraging multiple relevant sources in practical applications. To address these limitations, in this work, we construct a Three-Branch Mixed extractor and propose a Bi-level Multi-source unsupervised domain adaptation method called BTMuda for breast cancer diagnosis. Our method addresses the problems of domain shift by dividing domain shift issues into two levels: intra-domain and inter-domain. To reduce the intra-domain shift, we jointly train a CNN and a Transformer as two paths of a domain mixed feature extractor to obtain robust representations rich in both low-level local and high-level global information. As for the inter-domain shift, we redesign the Transformer delicately to a three-branch architecture with cross-attention and distillation, which learns domain-invariant representations from multiple domains. Besides, we introduce two alignment modules - one for feature alignment and one for classifier alignment - to improve the alignment process. Extensive experiments conducted on three public mammographic datasets demonstrate that our BTMuda outperforms state-of-the-art methods.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuxiang Yang et al.",
      "keywords": "Adaptation (eye); Breast cancer; Computer science; Domain adaptation; Domain (mathematical analysis); Cancer; Artificial intelligence; Medicine; Psychology; Mathematics; Internal medicine; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.17054",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297648995",
      "doi": "10.48550/arxiv.2209.02625",
      "title": "Single-Stage Broad Multi-Instance Multi-Label Learning (BMIML) with Diverse Inter-Correlations and its application to medical image classification",
      "abstract": "described by multiple instances (e.g., image patches) and simultaneously associated with multiple labels. Existing MIML methods are useful in many applications but most of which suffer from relatively low accuracy and training efficiency due to several issues: i) the inter-label correlations(i.e., the probabilistic correlations between the multiple labels corresponding to an object) are neglected; ii) the inter-instance correlations (i.e., the probabilistic correlations of different instances in predicting the object label) cannot be learned directly (or jointly) with other types of correlations due to the missing instance labels; iii) diverse inter-correlations (e.g., inter-label correlations, inter-instance correlations) can only be learned in multiple stages. To resolve these issues, a new single-stage framework called broad multi-instance multi-label learning (BMIML) is proposed. In BMIML, there are three innovative modules: i) an auto-weighted label enhancement learning (AWLEL) based on broad learning system (BLS) is designed, which simultaneously and efficiently captures the inter-label correlations while traditional BLS cannot; ii) A specific MIML neural network called scalable multi-instance probabilistic regression (SMIPR) is constructed to effectively estimate the inter-instance correlations using the object label only, which can provide additional probabilistic information for learning; iii) Finally, an interactive decision optimization (IDO) is designed to combine and optimize the results from AWLEL and SMIPR and form a single-stage framework. Experiments show that BMIML is highly competitive to (or even better than) existing methods in accuracy and much faster than most MIML methods even for large medical image data sets (&gt; 90K images).",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Qi Lai et al.",
      "keywords": "Probabilistic logic; Computer science; Artificial intelligence; Scalability; Machine learning; Object (grammar); Pattern recognition (psychology); Image (mathematics); Correlation; Class (philosophy); Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.02625",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415160764",
      "doi": "10.48550/arxiv.2504.10343",
      "title": "Domain-Adversarial Neural Network and Explainable AI for Reducing Tissue-of-Origin Signal in Pan-cancer Mortality Classification",
      "abstract": "Tissue-of-origin signals dominate pan-cancer gene expression, often obscuring molecular features linked to patient survival. This hampers the discovery of generalizable biomarkers, as models tend to overfit tissue-specific patterns rather than capture survival-relevant signals. To address this, we propose a Domain-Adversarial Neural Network (DANN) trained on TCGA RNA-seq data to learn representations less biased by tissue and more focused on survival. Identifying tissue-independent genetic profiles is key to revealing core cancer programs. We assess the DANN using: (1) Standard SHAP, based on the original input space and DANN's mortality classifier; (2) A layer-aware strategy applied to hidden activations, including an unsupervised manifold from raw activations and a supervised manifold from mortality-specific SHAP values. Standard SHAP remains confounded by tissue signals due to biases inherent in its computation. The raw activation manifold was dominated by high-magnitude activations, which masked subtle tissue and mortality-related signals. In contrast, the layer-aware SHAP manifold offers improved low-dimensional representations of both tissue and mortality signals, independent of activation strength, enabling subpopulation stratification and pan-cancer identification of survival-associated genes.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Cristian Padr\u00f3n-Manrique et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10343",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415036953",
      "doi": "10.48550/arxiv.2505.21160",
      "title": "STEB: In Search of the Best Evaluation Approach for Synthetic Time Series",
      "abstract": "The growing need for synthetic time series, due to data augmentation or privacy regulations, has led to numerous generative models, frameworks, and evaluation measures alike. Objectively comparing these measures on a large scale remains an open challenge. We propose the Synthetic Time series Evaluation Benchmark (STEB) -- the first benchmark framework that enables comprehensive and interpretable automated comparisons of synthetic time series evaluation measures. Using 10 diverse datasets, randomness injection, and 13 configurable data transformations, STEB computes indicators for measure reliability and score consistency. It tracks running time, test errors, and features sequential and parallel modes of operation. In our experiments, we determine a ranking of 41 measures from literature and confirm that the choice of upstream time series embedding heavily impacts the final score.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Michael Stenger et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.21160",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3176015772",
      "doi": "10.48550/arxiv.2106.09929",
      "title": "Graph-based Joint Pandemic Concern and Relation Extraction on Twitter",
      "abstract": "Public concern detection provides potential guidance to the authorities for crisis management before or during a pandemic outbreak. Detecting people's concerns and attention from online social media platforms has been widely acknowledged as an effective approach to relieve public panic and prevent a social crisis. However, detecting concerns in time from massive information in social media turns out to be a big challenge, especially when sufficient manually labeled data is in the absence of public health emergencies, e.g., COVID-19. In this paper, we propose a novel end-to-end deep learning model to identify people's concerns and the corresponding relations based on Graph Convolutional Network and Bi-directional Long Short Term Memory integrated with Concern Graph. Except for the sequential features from BERT embeddings, the regional features of tweets can be extracted by the Concern Graph module, which not only benefits the concern detection but also enables our model to be high noise-tolerant. Thus, our model can address the issue of insufficient manually labeled data. We conduct extensive experiments to evaluate the proposed model by using both manually labeled tweets and automatically labeled tweets. The experimental results show that our model can outperform the state-of-art models on real-world datasets.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Jingli Shi et al.",
      "keywords": "Computer science; Social media; Graph; Data science; Pandemic; Social graph; Artificial intelligence; Data mining; Coronavirus disease 2019 (COVID-19); Machine learning; Computer security; World Wide Web; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.09929",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416888791",
      "doi": "10.48550/arxiv.2507.00889",
      "title": "Phase Transition in Nonparametric Minimax Rates for Covariate Shifts on Approximate Manifolds",
      "abstract": "We study nonparametric regression under covariate shift with structured data, where a small amount of labeled target data is supplemented by a large labeled source dataset. In many real-world settings, the covariates in the target domain lie near a low-dimensional manifold within the support of the source, e.g., personalized handwritten digits (target) within a large, high-dimensional image repository (source). Since density ratios may not exist in these settings, standard transfer learning techniques often fail to leverage such structure. This necessitates the development of methods that exploit both the size of the source dataset and the structured nature of the target. Motivated by this, we establish new minimax rates under covariate shift for estimating a regression function in a general H\u00f6lder class, assuming the target distribution lies near -- but not exactly on -- a smooth submanifold of the source. General smoothness helps reduce the curse of dimensionality when the target function is highly regular, while approximate manifolds capture realistic, noisy data. We identify a phase transition in the minimax rate of estimation governed by the distance to the manifold, source and target sample sizes, function smoothness, and intrinsic versus ambient dimensions. We propose a local polynomial regression estimator that achieves optimal rates on either side of the phase transition boundary. Additionally, we construct a fully adaptive procedure that adjusts to unknown smoothness and intrinsic dimension, and attains nearly optimal rates. Our results unify and extend key threads in covariate shift, manifold learning, and adaptive nonparametric inference.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuyao Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2507.00889",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3165053370",
      "doi": "10.48550/arxiv.2201.06074",
      "title": "Developing a data analysis pipeline for automated protein profiling in immunology",
      "abstract": "Accurate information about protein content in the organism is instrumental for a better understanding of human biology and disease mechanisms. While the presence of certain types of proteins can be life-threatening, the abundance of others is an essential condition for an individual's overall well-being. Protein microarray is a technology that enables the quantification of thousands of proteins in hundreds of human samples in a parallel manner. In a series of studies involving protein microarrays, we have explored and implemented various data science methods for all-around analysing of these data. This analysis has enabled the identification and characterisation of proteins targeted by the autoimmune reaction in patients with the APS1 condition. We have also assessed the utility of applying machine learning methods alongside statistical tests in a study based on protein expression data to evaluate potential biomarkers for endometriosis. The keystone of this work is a web-tool PAWER. PAWER implements relevant computational methods, and provides a semi-automatic way to run the analysis of protein microarray data online in a drag-and-drop and click-and-play style. The source code of the tool is publicly available. The work that laid the foundation of this thesis has been instrumental for a number of subsequent studies of human disease and also inspired a contribution to refining standards for validation of machine learning methods in biology.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Dmytro Fishman",
      "keywords": "Profiling (computer programming); Data science; Computational biology; Immunology; Medicine; Computer science; Biology",
      "mesh_terms": "",
      "pub_types": "dissertation",
      "url": "https://doi.org/10.48550/arxiv.2201.06074",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416047687",
      "doi": "10.48550/arxiv.2505.21958",
      "title": "Resolving Knowledge Conflicts in Domain-specific Data Selection: A Case Study on Medical Instruction-tuning",
      "abstract": "Domain-specific instruction-tuning has become the defacto standard for improving the performance of large language models (LLMs) in specialized applications, e.g., medical question answering. Since the instruction-tuning dataset might contain redundant or low-quality data, data selection (DS) is usually required to maximize the data efficiency. Despite the successes in the general domain, current DS methods often struggle to select the desired data for domain-specific instruction-tuning. One of the main reasons is that they neglect the impact of knowledge conflicts, i.e., the discrepancy between LLMs' pretrained knowledge and context knowledge of instruction data, which could damage LLMs' prior abilities and lead to hallucination. To this end, we propose a simple-yet-effective Knowledge-aware Data Selection (namely KDS) framework to select the domain-specific instruction-tuning data that meets LLMs' actual needs. The core of KDS is to leverage two knowledge-aware metrics for quantitatively measuring knowledge conflicts from two aspects: context-memory knowledge alignment and intra-memory knowledge consistency. By filtering the data with large knowledge conflicts and sampling the high-quality and diverse data, KDS can effectively stimulate the LLMs' abilities and achieve better domain-specific performance. Taking the medical domain as the testbed, we conduct extensive experiments and empirically prove that KDS surpasses the other baselines and brings significant and consistent performance gains among all LLMs. More encouragingly, KDS effectively improves the model generalization and alleviates the hallucination problem.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Qihuang Zhong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.21958",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415329119",
      "doi": "10.48550/arxiv.2505.15505",
      "title": "Deep Learning Enabled Segmentation, Classification and Risk Assessment of Cervical Cancer",
      "abstract": "Cervical cancer, the fourth leading cause of cancer in women globally, requires early detection through Pap smear tests to identify precancerous changes and prevent disease progression. In this study, we performed a focused analysis by segmenting the cellular boundaries and drawing bounding boxes to isolate the cancer cells. A novel Deep Learning (DL) architecture, the ``Multi-Resolution Fusion Deep Convolutional Network\", was proposed to effectively handle images with varying resolutions and aspect ratios, with its efficacy showcased using the SIPaKMeD dataset. The performance of this DL model was observed to be similar to the state-of-the-art models, with accuracy variations of a mere 2\\% to 3\\%, achieved using just 1.7 million learnable parameters, which is approximately 85 times less than the VGG-19 model. Furthermore, we introduced a multi-task learning technique that simultaneously performs segmentation and classification tasks and begets an Intersection over Union score of 0.83 and a classification accuracy of 90\\%. The final stage of the workflow employs a probabilistic approach for risk assessment, extracting feature vectors to predict the likelihood of normal cells progressing to malignant states, which can be utilized for the prognosis of cervical cancer.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Abdul Althaf Shaik et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.15505",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386081605",
      "doi": "10.48550/arxiv.2308.10631",
      "title": "PsyMo: A Dataset for Estimating Self-Reported Psychological Traits from Gait",
      "abstract": "Psychological trait estimation from external factors such as movement and appearance is a challenging and long-standing problem in psychology, and is principally based on the psychological theory of embodiment. To date, attempts to tackle this problem have utilized private small-scale datasets with intrusive body-attached sensors. Potential applications of an automated system for psychological trait estimation include estimation of occupational fatigue and psychology, and marketing and advertisement. In this work, we propose PsyMo (Psychological traits from Motion), a novel, multi-purpose and multi-modal dataset for exploring psychological cues manifested in walking patterns. We gathered walking sequences from 312 subjects in 7 different walking variations and 6 camera angles. In conjunction with walking sequences, participants filled in 6 psychological questionnaires, totalling 17 psychometric attributes related to personality, self-esteem, fatigue, aggressiveness and mental health. We propose two evaluation protocols for psychological trait estimation. Alongside the estimation of self-reported psychological traits from gait, the dataset can be used as a drop-in replacement to benchmark methods for gait recognition. We anonymize all cues related to the identity of the subjects and publicly release only silhouettes, 2D / 3D human skeletons and 3D SMPL human meshes.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Adrian Cosma et al.",
      "keywords": "Trait; Big Five personality traits; Psychology; Gait; Estimation; Personality; Applied psychology; Cognitive psychology; Computer science; Artificial intelligence; Social psychology; Physical medicine and rehabilitation; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.10631",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393212222",
      "doi": "10.48550/arxiv.2403.15482",
      "title": "Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors",
      "abstract": "Realistic practice and tailored feedback are key processes for training peer counselors with clinical skills. However, existing mechanisms of providing feedback largely rely on human supervision. Peer counselors often lack mechanisms to receive detailed feedback from experienced mentors, making it difficult for them to support the large number of people with mental health issues who use peer counseling. Our work aims to leverage large language models to provide contextualized and multi-level feedback to empower peer counselors, especially novices, at scale. To achieve this, we co-design with a group of senior psychotherapy supervisors to develop a multi-level feedback taxonomy, and then construct a publicly available dataset with comprehensive feedback annotations of 400 emotional support conversations. We further design a self-improvement method on top of large language models to enhance the automatic generation of feedback. Via qualitative and quantitative evaluation with domain experts, we demonstrate that our method minimizes the risk of potentially harmful and low-quality feedback generation which is desirable in such high-stakes scenarios.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Alicja Chaszczewicz et al.",
      "keywords": "Computer science; Peer feedback; Human\u2013computer interaction; Psychology; Multimedia; Mathematics education",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.15482",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404342391",
      "doi": "10.48550/arxiv.2410.22646",
      "title": "SleepNetZero: Zero-Burden Zero-Shot Reliable Sleep Staging With Neural Networks Based on Ballistocardiograms",
      "abstract": "Sleep monitoring plays a crucial role in maintaining good health, with sleep staging serving as an essential metric in the monitoring process. Traditional methods, utilizing medical sensors like EEG and ECG, can be effective but often present challenges such as unnatural user experience, complex deployment, and high costs. Ballistocardiography~(BCG), a type of piezoelectric sensor signal, offers a non-invasive, user-friendly, and easily deployable alternative for long-term home monitoring. However, reliable BCG-based sleep staging is challenging due to the limited sleep monitoring data available for BCG. A restricted training dataset prevents the model from generalization across populations. Additionally, transferring to BCG faces difficulty ensuring model robustness when migrating from other data sources. To address these issues, we introduce SleepNetZero, a zero-shot learning based approach for sleep staging. To tackle the generalization challenge, we propose a series of BCG feature extraction methods that align BCG components with corresponding respiratory, cardiac, and movement channels in PSG. This allows models to be trained on large-scale PSG datasets that are diverse in population. For the migration challenge, we employ data augmentation techniques, significantly enhancing generalizability. We conducted extensive training and testing on large datasets~(12393 records from 9637 different subjects), achieving an accuracy of 0.803 and a Cohen's Kappa of 0.718. ZeroSleepNet was also deployed in real prototype~(monitoring pads) and tested in actual hospital settings~(265 users), demonstrating an accuracy of 0.697 and a Cohen's Kappa of 0.589. To the best of our knowledge, this work represents the first known reliable BCG-based sleep staging effort and marks a significant step towards in-home health monitoring.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuzhen Li et al.",
      "keywords": "Zero (linguistics); Shot (pellet); Artificial neural network; Computer science; Medicine; Artificial intelligence; Philosophy; Chemistry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.22646",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387964463",
      "doi": "10.48550/arxiv.2310.15550",
      "title": "PET Synthesis via Self-supervised Adaptive Residual Estimation Generative Adversarial Network",
      "abstract": "Positron emission tomography (PET) is a widely used, highly sensitive molecular imaging in clinical diagnosis. There is interest in reducing the radiation exposure from PET but also maintaining adequate image quality. Recent methods using convolutional neural networks (CNNs) to generate synthesized high-quality PET images from low-dose counterparts have been reported to be state-of-the-art for low-to-high image recovery methods. However, these methods are prone to exhibiting discrepancies in texture and structure between synthesized and real images. Furthermore, the distribution shift between low-dose PET and standard PET has not been fully investigated. To address these issues, we developed a self-supervised adaptive residual estimation generative adversarial network (SS-AEGAN). We introduce (1) An adaptive residual estimation mapping mechanism, AE-Net, designed to dynamically rectify the preliminary synthesized PET images by taking the residual map between the low-dose PET and synthesized output as the input, and (2) A self-supervised pre-training strategy to enhance the feature representation of the coarse generator. Our experiments with a public benchmark dataset of total-body PET images show that SS-AEGAN consistently outperformed the state-of-the-art synthesis methods with various dose reduction factors.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuxin Xue et al.",
      "keywords": "Residual; Convolutional neural network; Computer science; Benchmark (surveying); Artificial intelligence; Feature (linguistics); Pattern recognition (psychology); Positron emission tomography; Reduction (mathematics); Generator (circuit theory); Pet imaging; Computer vision; Nuclear medicine; Mathematics; Algorithm",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.15550",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4310031850",
      "doi": "10.48550/arxiv.2105.05758",
      "title": "DEEMD: Drug Efficacy Estimation against SARS-CoV-2 based on cell Morphology with Deep multiple instance learning",
      "abstract": "Drug repurposing can accelerate the identification of effective compounds for clinical use against SARS-CoV-2, with the advantage of pre-existing clinical safety data and an established supply chain. RNA viruses such as SARS-CoV-2 manipulate cellular pathways and induce reorganization of subcellular structures to support their life cycle. These morphological changes can be quantified using bioimaging techniques. In this work, we developed DEEMD: a computational pipeline using deep neural network models within a multiple instance learning framework, to identify putative treatments effective against SARS-CoV-2 based on morphological analysis of the publicly available RxRx19a dataset. This dataset consists of fluorescence microscopy images of SARS-CoV-2 non-infected cells and infected cells, with and without drug treatment. DEEMD first extracts discriminative morphological features to generate cell morphological profiles from the non-infected and infected cells. These morphological profiles are then used in a statistical model to estimate the applied treatment efficacy on infected cells based on similarities to non-infected cells. DEEMD is capable of localizing infected cells via weak supervision without any expensive pixel-level annotations. DEEMD identifies known SARS-CoV-2 inhibitors, such as Remdesivir and Aloxistatin, supporting the validity of our approach. DEEMD can be explored for use on other emerging viruses and datasets to rapidly identify candidate antiviral treatments in the future}. Our implementation is available online at https://www.github.com/Sadegh-Saberian/DEEMD",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "M. Sadegh Saberian et al.",
      "keywords": "Drug repositioning; Discriminative model; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Deep learning; Repurposing; Pipeline (software); Computational biology; Coronavirus disease 2019 (COVID-19); Artificial intelligence; Computer science; Identification (biology); Drug discovery; Drug; Drug development; Biology; Bioinformatics; Medicine; Pathology; Pharmacology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2105.05758",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416608728",
      "doi": "10.48550/arxiv.2505.22981",
      "title": "Free Lunch for User Experience: Crowdsourcing Agents for Scalable User Studies",
      "abstract": "User studies are central to user experience research, yet recruiting participant is expensive, slow, and limited in diversity. Recent work has explored using Large Language Models as simulated users, but doubts about fidelity have hindered practical adoption. We deepen this line of research by asking whether scale itself can enable useful simulation, even if not perfectly accurate. We introduce Crowdsourcing Simulated User Agents, a method that recruits generative agents from billion-scale profile assets to act as study participants. Unlike handcrafted simulations, agents are treated as recruitable, screenable, and engageable across UX research stages. To ground this method, we demonstrate a game prototyping study with hundreds of simulated players, comparing their insights against a 10-participant local user study and a 20-participant crowdsourcing study with humans. We find a clear scaling effect: as the number of simulated user agents increases, coverage of human findings rises smoothly and plateaus around 90\\%. 12.8 simulated agents are as useful as one locally recruited human, and 3.2 agents are as useful as one crowdsourced human. Results show that while individual agents are imperfect, aggregated simulations produce representative and actionable insights comparable to real users. Professional designers further rated these insights as balancing fidelity, cost, time efficiency, and usefulness. Finally, we release an agent crowdsourcing toolkit with a modular open-source pipeline and a curated pool of profiles synced from ongoing simulation research, to lower the barrier for researchers to adopt simulated participants. Together, this work contributes a validated method and reusable toolkit that expand the options for conducting scalable and practical UX studies.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Siyang Liu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.22981",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4327989864",
      "doi": "10.48550/arxiv.2303.09638",
      "title": "Full-Body Cardiovascular Sensing with Remote Photoplethysmography",
      "abstract": "Remote photoplethysmography (rPPG) allows for noncontact monitoring of blood volume changes from a camera by detecting minor fluctuations in reflected light. Prior applications of rPPG focused on face videos. In this paper we explored the feasibility of rPPG from non-face body regions such as the arms, legs, and hands. We collected a new dataset titled Multi-Site Physiological Monitoring (MSPM), which will be released with this paper. The dataset consists of 90 frames per second video of exposed arms, legs, and face, along with 10 synchronized PPG recordings. We performed baseline heart rate estimation experiments from non-face regions with several state-of-the-art rPPG approaches, including chrominance-based (CHROM), plane-orthogonal-to-skin (POS) and RemotePulseNet (RPNet). To our knowledge, this is the first evaluation of the fidelity of rPPG signals simultaneously obtained from multiple regions of a human body. Our experiments showed that skin pixels from arms, legs, and hands are all potential sources of the blood volume pulse. The best-performing approach, POS, achieved a mean absolute error peaking at 7.11 beats per minute from non-facial body parts compared to 1.38 beats per minute from the face. Additionally, we performed experiments on pulse transit time (PTT) from both the contact PPG and rPPG signals. We found that remote PTT is possible with moderately high frame rate video when distal locations on the body are visible. These findings and the supporting dataset should facilitate new research on non-face rPPG and monitoring blood flow dynamics over the whole body with a camera.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Lu Niu et al.",
      "keywords": "Photoplethysmogram; Chrominance; Computer vision; Artificial intelligence; Computer science; Face masks; Face (sociological concept); Medicine; Luminance; Coronavirus disease 2019 (COVID-19); Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.09638",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4291335470",
      "doi": "10.48550/arxiv.1305.2401",
      "title": "Ethics of using language editing services in an era of digital\\n communication and heavily multiauthored papers",
      "abstract": "Scientists of many countries in which English is not the primary language\\nroutinely use a variety of manuscript preparation, correction or editing\\nservices, a practice that is openly endorsed by many journals and scientific\\ninstitutions. These services vary tremendously in their scope; at one end there\\nis simple proof-reading, and at the other extreme there is in-depth and\\nextensive peer-reviewing, proposal preparation, statistical analyses,\\nre-writing and co-writing. In this paper, the various types of service are\\nreviewed, along with authorship guidelines, and the question is raised of\\nwhether the high-end services surpass most guidelines' criteria for authorship.\\nThree other factors are considered. First, the ease of collaboration possible\\nin the internet era allows multiple iterations between authors and the editing\\nservice, so essentially, papers can be co-written. Second, 'editing services'\\noften offer subject-specific experts who comment not only on the language, but\\ninterpret and improve scientific content. Third, the trend towards heavily\\nmulti-authored papers implies that the threshold necessary to earn authorship\\nis declining. The inevitable conclusion is that at some point the contributions\\nby 'editing services' should be deemed sufficient to warrant authorship. Trying\\nto enforce any guidelines would likely be futile, but nevertheless, it might be\\ntime to revisit the ethics of using some of the high-end 'editing services'. In\\nan increasingly international job market, recognizing this problem might prove\\nprogressively more important in authorship disputes, the allocation of research\\ngrants, and hiring decisions\\n",
      "year": "2013",
      "journal": "arXiv (Cornell University)",
      "authors": "George A. Lozano",
      "keywords": "Scope (computer science); Warrant; Reading (process); Variety (cybernetics); Service (business); Computer science; Point (geometry); The Internet; Subject (documents); Public relations; World Wide Web; Political science; Business; Law; Marketing; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1305.2401",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4403884703",
      "doi": "10.48550/arxiv.2410.03594",
      "title": "Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments",
      "abstract": "Prior works formulate the extraction of event-specific arguments as a span extraction problem, where event arguments are explicit -- i.e. assumed to be contiguous spans of text in a document. In this study, we revisit this definition of Event Extraction (EE) by introducing two key argument types that cannot be modeled by existing EE frameworks. First, implicit arguments are event arguments which are not explicitly mentioned in the text, but can be inferred through context. Second, scattered arguments are event arguments that are composed of information scattered throughout the text. These two argument types are crucial to elicit the full breadth of information required for proper event modeling. To support the extraction of explicit, implicit, and scattered arguments, we develop a novel dataset, DiscourseEE, which includes 7,464 argument annotations from online health discourse. Notably, 51.2% of the arguments are implicit, and 17.4% are scattered, making DiscourseEE a unique corpus for complex event extraction. Additionally, we formulate argument extraction as a text generation problem to facilitate the extraction of complex argument types. We provide a comprehensive evaluation of state-of-the-art models and highlight critical open challenges in generative event extraction. Our data and codebase are available at https://omar-sharif03.github.io/DiscourseEE.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Omar Sharif et al.",
      "keywords": "Event (particle physics); Extraction (chemistry); Computer science; Physics; Chromatography; Chemistry; Astrophysics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.03594",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226471703",
      "doi": "10.48550/arxiv.2203.05880",
      "title": "Multi-modal Graph Learning for Disease Prediction",
      "abstract": "Benefiting from the powerful expressive capability of graphs, graph-based approaches have been popularly applied to handle multi-modal medical data and achieved impressive performance in various biomedical applications. For disease prediction tasks, most existing graph-based methods tend to define the graph manually based on specified modality (e.g., demographic information), and then integrated other modalities to obtain the patient representation by Graph Representation Learning (GRL). However, constructing an appropriate graph in advance is not a simple matter for these methods. Meanwhile, the complex correlation between modalities is ignored. These factors inevitably yield the inadequacy of providing sufficient information about the patient's condition for a reliable diagnosis. To this end, we propose an end-to-end Multi-modal Graph Learning framework (MMGL) for disease prediction with multi-modality. To effectively exploit the rich information across multi-modality associated with the disease, modality-aware representation learning is proposed to aggregate the features of each modality by leveraging the correlation and complementarity between the modalities. Furthermore, instead of defining the graph manually, the latent graph structure is captured through an effective way of adaptive graph learning. It could be jointly optimized with the prediction model, thus revealing the intrinsic connections among samples. Our model is also applicable to the scenario of inductive learning for those unseen data. An extensive group of experiments on two disease prediction tasks demonstrates that the proposed MMGL achieves more favorable performance. The code of MMGL is available at \\url{https://github.com/SsGood/MMGL}.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuai Zheng et al.",
      "keywords": "Computer science; Modalities; Feature learning; Graph; Modality (human\u2013computer interaction); Machine learning; Exploit; Artificial intelligence; Modal; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.05880",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414898957",
      "doi": "10.48550/arxiv.2506.01931",
      "title": "Red Teaming AI Policy: A Taxonomy of Avoision and the EU AI Act",
      "abstract": "The shape of AI regulation is beginning to emerge, most prominently through the EU AI Act (the \"AIA\"). By 2027, the AIA will be in full effect, and firms are starting to adjust their behavior in light of this new law. In this paper, we present a framework and taxonomy for reasoning about \"avoision\" -- conduct that walks the line between legal avoidance and evasion -- that firms might engage in so as to minimize the regulatory burden the AIA poses. We organize these avoision strategies around three \"tiers\" of increasing AIA exposure that regulated entities face depending on: whether their activities are (1) within scope of the AIA, (2) exempted from provisions of the AIA, or are (3) placed in a category with higher regulatory scrutiny. In each of these tiers and for each strategy, we specify the organizational and technological forms through which avoision may manifest. Our goal is to provide an adversarial framework for \"red teaming\" the AIA and AI regulation on the horizon.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Rui-Jie Yew et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01931",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4400667213",
      "doi": "10.48550/arxiv.2407.09019",
      "title": "Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media",
      "abstract": "Massive social media data can reflect people's authentic thoughts, emotions, communication, etc., and therefore can be analyzed for early detection of mental health problems such as depression. Existing works about early depression detection on social media lacked interpretability and neglected the heterogeneity of social media data. Furthermore, they overlooked the global interaction among users. To address these issues, we develop a novel method that leverages a Heterogeneous Subgraph Network with Prompt Learning(HSNPL) and contrastive learning mechanisms. Specifically, prompt learning is employed to map users' implicit psychological symbols with excellent interpretability while deep semantic and diverse behavioral features are incorporated by a heterogeneous information network. Then, the heterogeneous graph network with a dual attention mechanism is constructed to model the relationships among heterogeneous social information at the feature level. Furthermore, the heterogeneous subgraph network integrating subgraph attention and self-supervised contrastive learning is developed to explore complicated interactions among users and groups at the user level. Extensive experimental results demonstrate that our proposed method significantly outperforms state-of-the-art methods for depression detection on social media.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Chen Chen et al.",
      "keywords": "Depression (economics); Social media; Artificial intelligence; Psychology; Data science; Computer science; Machine learning; World Wide Web; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.09019",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390810350",
      "doi": "10.48550/arxiv.2401.04961",
      "title": "ECC-PolypDet: Enhanced CenterNet with Contrastive Learning for Automatic Polyp Detection",
      "abstract": "Accurate polyp detection is critical for early colorectal cancer diagnosis. Although remarkable progress has been achieved in recent years, the complex colon environment and concealed polyps with unclear boundaries still pose severe challenges in this area. Existing methods either involve computationally expensive context aggregation or lack prior modeling of polyps, resulting in poor performance in challenging cases. In this paper, we propose the Enhanced CenterNet with Contrastive Learning (ECC-PolypDet), a two-stage training \\&amp; end-to-end inference framework that leverages images and bounding box annotations to train a general model and fine-tune it based on the inference score to obtain a final robust model. Specifically, we conduct Box-assisted Contrastive Learning (BCL) during training to minimize the intra-class difference and maximize the inter-class difference between foreground polyps and backgrounds, enabling our model to capture concealed polyps. Moreover, to enhance the recognition of small polyps, we design the Semantic Flow-guided Feature Pyramid Network (SFFPN) to aggregate multi-scale features and the Heatmap Propagation (HP) module to boost the model's attention on polyp targets. In the fine-tuning stage, we introduce the IoU-guided Sample Re-weighting (ISR) mechanism to prioritize hard samples by adaptively adjusting the loss weight for each sample during fine-tuning. Extensive experiments on six large-scale colonoscopy datasets demonstrate the superiority of our model compared with previous state-of-the-art detectors.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuncheng Jiang et al.",
      "keywords": "Computer science; Inference; Artificial intelligence; Minimum bounding box; Weighting; Feature (linguistics); Class (philosophy); Pyramid (geometry); Bounding overwatch; Pattern recognition (psychology); Context (archaeology); Machine learning; Image (mathematics); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.04961",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289543057",
      "doi": "10.48550/arxiv.1809.06156",
      "title": "Convex Formulation for Regularized Estimation of Structural Equation\\n Models",
      "abstract": "Path analysis is a model class of structural equation modeling (SEM), which\\nit describes causal relations among measured variables in the form of a\\nmultiple linear regression. This paper presents two estimation formulations,\\none each for confirmatory and exploratory SEM, where a zero pattern of the\\nestimated path coefficient matrix can explain a causality structure of the\\nvariables. The original nonlinear equality constraints of the model parameters\\nwere relaxed to an inequality, allowing the transformation of the original\\nproblem into a convex framework. A regularized estimation formulation was then\\nproposed for exploratory SEM using an l1-type penalty of the path coefficient\\nmatrix. Under a condition on problem parameters, our optimal solution is low\\nrank and provides a useful solution to the original problem. Proximal\\nalgorithms were applied to solve our convex programs in a large-scale setting.\\nThe performance of this approach was demonstrated in both simulated and real\\ndata sets, and in comparison with an existing method. When applied to two real\\napplication results (learning causality among climate variables in Thailand and\\nexamining connectivity differences in autism patients using fMRI time series\\nfrom ABIDE data sets) the findings could explain known relationships among\\nenvironmental variables and discern known and new brain connectivity\\ndifferences, respectively.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Anupon Pruttiakaravanich et al.",
      "keywords": "Structural equation modeling; Mathematics; Causality (physics); Path coefficient; Mathematical optimization; Rank (graph theory); Matrix (chemical analysis); Path (computing); Applied mathematics; Regular polygon; Computer science; Regression analysis; Statistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1809.06156",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415037059",
      "doi": "10.48550/arxiv.2505.21242",
      "title": "Evaluation of LLMs in Medical Text Summarization: The Role of Vocabulary Adaptation in High OOV Settings",
      "abstract": "Large Language Models (LLMs) recently achieved great success in medical text summarization by simply using in-context learning. However, these recent efforts do not perform fine-grained evaluations under difficult settings where LLMs might fail. They typically report performance scores over the entire dataset. Through our benchmarking study, we show that LLMs show a significant performance drop for data points with high concentration of out-of-vocabulary (OOV) words or with high novelty. Vocabulary adaptation is an intuitive solution to this vocabulary mismatch issue where the LLM vocabulary gets updated with certain expert domain (here, medical) words or subwords. An interesting finding from our study is that Llama-3.1, even with a vocabulary size of around 128K tokens, still faces over-fragmentation issue with medical words. To that end, we show vocabulary adaptation helps improve the LLM summarization performance even in difficult settings. Through extensive experimentation of multiple vocabulary adaptation strategies, two continual pretraining strategies, and three benchmark medical summarization datasets, we gain valuable insights into the role of vocabulary adaptation strategies for customizing LLMs to the medical domain. We also performed a human evaluation study with medical experts where they found that vocabulary adaptation results in more relevant and faithful summaries. Our codebase is made publicly available at https://github.com/gb-kgp/LLM-MedicalSummarization-Benchmark.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Gunjan Balde et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.21242",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393213682",
      "doi": "10.48550/arxiv.2403.16852",
      "title": "Towards Explainability in Legal Outcome Prediction Models",
      "abstract": "Current legal outcome prediction models - a staple of legal NLP - do not explain their reasoning. However, to employ these models in the real world, human legal actors need to be able to understand the model's decisions. In the case of common law, legal practitioners reason towards the outcome of a case by referring to past case law, known as precedent. We contend that precedent is, therefore, a natural way of facilitating explainability for legal NLP models. In this paper, we contribute a novel method for identifying the precedent employed by legal outcome prediction models. Furthermore, by developing a taxonomy of legal precedent, we are able to compare human judges and neural models with respect to the different types of precedent they rely on. We find that while the models learn to predict outcomes reasonably well, their use of precedent is unlike that of human judges.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Josef Valvoda et al.",
      "keywords": "Outcome (game theory); Business; Psychology; Economics; Microeconomics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.16852",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415311653",
      "doi": "10.48550/arxiv.2506.14159",
      "title": "StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework",
      "abstract": "Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative, a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N=28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Shayan Talaei et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.14159",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287390871",
      "doi": "10.48550/arxiv.2101.04948",
      "title": "Deep State Inference: Toward Behavioral Model Inference of Black-box\\n Software Systems",
      "abstract": "Many software engineering tasks, such as testing, and anomaly detection can\\nbenefit from the ability to infer a behavioral model of the software.Most\\nexisting inference approaches assume access to code to collect execution\\nsequences. In this paper, we investigate a black-box scenario, where the system\\nunder analysis cannot be instrumented, in this granular fashion.This scenario\\nis particularly prevalent with control systems' log analysis in the form of\\ncontinuous signals. In this situation, an execution trace amounts to a\\nmultivariate time-series of input and output signals, where different states of\\nthe system correspond to different `phases` in the time-series. The main\\nchallenge is to detect when these phase changes take place. Unfortunately, most\\nexisting solutions are either univariate, make assumptions on the data\\ndistribution, or have limited learning power.Therefore, we propose a hybrid\\ndeep neural network that accepts as input a multivariate time series and\\napplies a set of convolutional and recurrent layers to learn the non-linear\\ncorrelations between signals and the patterns over time.We show how this\\napproach can be used to accurately detect state changes, and how the inferred\\nmodels can be successfully applied to transfer-learning scenarios, to\\naccurately process traces from different products with similar execution\\ncharacteristics. Our experimental results on two UAV autopilot case studies\\nindicate that our approach is highly accurate (over 90% F1 score for state\\nclassification) and significantly improves baselines (by up to 102% for change\\npoint detection).Using transfer learning we also show that up to 90% of the\\nmaximum achievable F1 scores in the open-source case study can be achieved by\\nreusing the trained models from the industrial case and only fine tuning them\\nusing as low as 5 labeled samples, which reduces the manual labeling effort by\\n98%.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Foozhan Ataiefard et al.",
      "keywords": "Computer science; Inference; Black box; TRACE (psycholinguistics); Process (computing); Set (abstract data type); Univariate; Anomaly detection; Artificial intelligence; Software; Deep learning; Multivariate statistics; Transfer of learning; Machine learning; Time series; Data mining; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2101.04948",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394973331",
      "doi": "10.48550/arxiv.2404.11767",
      "title": "Regret Analysis in Threshold Policy Design",
      "abstract": "Threshold policies are decision rules that assign treatments based on whether an observable characteristic exceeds a certain threshold. They are widespread across multiple domains, including welfare programs, taxation, and clinical medicine. This paper examines the problem of designing threshold policies using experimental data, when the goal is to maximize the population welfare. First, I characterize the regret - a measure of policy optimality - of the Empirical Welfare Maximizer (EWM) policy, popular in the literature. Next, I introduce the Smoothed Welfare Maximizer (SWM) policy, which improves the EWM's regret convergence rate under an additional smoothness condition. The two policies are compared by studying how differently their regrets depend on the population distribution, and investigating their finite sample performances through Monte Carlo simulations. In many contexts, the SWM policy guarantees larger welfare than the EWM. An empirical illustration demonstrates how the treatment recommendations of the two policies may differ in practice.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Federico Crippa",
      "keywords": "Regret; Computer science; Economics; Econometrics; Mathematics; Statistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.11767",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389260978",
      "doi": "10.48550/arxiv.2311.18339",
      "title": "Tight Bounds for The Price of Fairness",
      "abstract": "A central decision maker (CDM), who seeks an efficient allocation of scarce resources among a finite number of players, often has to incorporate fairness criteria to avoid unfair outcomes. Indeed, the Price of Fairness (POF), a term coined in the seminal work by Bertsimas et al. (2011), refers to the efficiency loss due to the incorporation of fairness criteria into the allocation method. Quantifying the POF would help the CDM strike an appropriate balance between efficiency and fairness. In this paper we improve upon existing results in the literature, by providing tight bounds for the POF for the proportional fairness criterion for any $n$, when the maximum achievable utilities of the players are equal or are not equal. Further, while Bertsimas et al. (2011) have already derived a tight bound for the max-min fairness criterion for the case that all players have equal maximum achievable utilities, we also provide a tight bound in scenarios where these utilities are not equal. For both criteria, we characterize the conditions where the POF reaches its peak and provide the supremum bounds of our bounds over all maximum achievable utility vectors, which are shown to be asymptotically strictly smaller than the supremum of the Bertsimas et al. (2011) bounds. Finally, we investigate the sensitivity of our bounds and the bounds in Bertsimas et al. (2011) for the POF to the variability of the maximum achievable utilities.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yifeng Cao et al.",
      "keywords": "Max-min fairness; Fairness measure; Mathematical optimization; Upper and lower bounds; Balance (ability); Sensitivity (control systems); Mathematical economics; Computer science; Term (time); Economics; Decision maker; Mathematics; Resource allocation; Operations research; Throughput; Telecommunications; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.18339",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392972157",
      "doi": "10.48550/arxiv.2403.11103",
      "title": "ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models",
      "abstract": "Although Large Language Models (LLMs) exhibit remarkable adaptability across domains, these models often fall short in structured knowledge extraction tasks such as named entity recognition (NER). This paper explores an innovative, cost-efficient strategy to harness LLMs with modest NER capabilities for producing superior NER datasets. Our approach diverges from the basic class-conditional prompts by instructing LLMs to self-reflect on the specific domain, thereby generating domain-relevant attributes (such as category and emotions for movie reviews), which are utilized for creating attribute-rich training data. Furthermore, we preemptively generate entity terms and then develop NER context data around these entities, effectively bypassing the LLMs' challenges with complex structures. Our experiments across both general and niche domains reveal significant performance enhancements over conventional data generation methods while being more cost-effective than existing alternatives.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuzhao Heng et al.",
      "keywords": "Computer science; Named-entity recognition; Natural language processing; Artificial intelligence; Entity linking; Reflexivity; Language model; Engineering; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.11103",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4403579651",
      "doi": "10.48550/arxiv.2410.13387",
      "title": "CLEAR: Towards Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation for Large Language Model Applications",
      "abstract": "The rise of end-user applications powered by large language models (LLMs), including both conversational interfaces and add-ons to existing graphical user interfaces (GUIs), introduces new privacy challenges. However, many users remain unaware of the risks. This paper explores methods to increase user awareness of privacy risks associated with LLMs in end-user applications. We conducted five co-design workshops to uncover user privacy concerns and their demand for contextual privacy information within LLMs. Based on these insights, we developed CLEAR (Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation), a just-in-time contextual assistant designed to help users identify sensitive information, summarize relevant privacy policies, and highlight potential risks when sharing information with LLMs. We evaluated the usability and usefulness of CLEAR across two example domains: ChatGPT and the Gemini plugin in Gmail. Our findings demonstrated that CLEAR is easy to use and improves users' understanding of data practices and privacy risks. We also discussed LLM's duality in posing and mitigating privacy risks, offering design and policy implications.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Chaoran Chen et al.",
      "keywords": "Privacy policy; Computer science; Language model; Internet privacy; Computer security; Risk analysis (engineering); Information privacy; Business; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.13387",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416174014",
      "doi": "10.48550/arxiv.2505.15274",
      "title": "Identification of Probabilities of Causation: from Recursive to Closed-Form Bounds",
      "abstract": "Probabilities of causation (PoCs) are fundamental quantities for counterfactual analysis and personalized decision making. However, existing analytical results are largely confined to binary settings. This paper extends PoCs to multi-valued treatments and outcomes by deriving closed form bounds for a representative family of discrete PoCs within Structural Causal Models, using standard experimental and observational distributions. We introduce the notion of equivalence classes of PoCs, which reduces arbitrary discrete PoCs to this family, and establish a replaceability principle that transfers bounds across value permutations. For the resulting bounds, we prove soundness in all dimensions and empirically verify tightness in low dimensional cases via Balke's linear programming method; we further conjecture that this tightness extends to all dimensions. Simulations indicate that our closed form bounds consistently tighten recent recursive bounds while remaining simpler to compute. Finally, we illustrate the practical relevance of our results through toy examples.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Xin Shu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.15274",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4288601341",
      "doi": "10.48550/arxiv.1902.01573",
      "title": "Classification of Breast Lesions Using Quantitative Ultrasound\\n Biomarkers",
      "abstract": "Quantitative ultrasound (QUS) based parameters like the effective scatterer\\ndiameter (ESD) and mean scatterer spacing (MSS) are gaining attention recently\\nas non-invasive biomarkers for soft tissue characterization. In this work, we\\npropose a multiple QUS parameter based technique that employs ESD and MSS, for\\nbinary classification of breast lesions. In order to produce improved ESD\\nestimates, we propose a modified frequency domain technique for ESD estimation\\nof breast tissues from the diffuse component of backscattered radio-frequency\\n(RF) data. Ensemble empirical mode decomposition (EEMD) is performed to\\nseparate the diffuse component from the coherent component by decomposing the\\nRF data into their intrinsic mode functions (IMFs). A non-parametric\\nKolmogorov-Smirnov (K-S) test is employed for automatic IMF selection along\\nwith a multi-step system effect minimization process. The ESD is estimated\\nusing a nearest neighborhood average regression line fitting algorithm.\\nFurthermore, we use an ameliorated EEMD domain autoregressive (AR) spectral\\nestimation technique for MSS estimation. On using the ESD for binary\\nclassification of 159 lesions, we obtain high sensitivity, specificity,\\naccuracy values of 91.07%, 96.12%, and 94.34%, respectively, with an area under\\nthe receiver operating characteristics (ROC) curve of 0.94. On combining ESD\\nwith MSS we obtain even more improved sensitivity, specificity, and accuracy\\nvalues of 96.43%, 95.15%, and 95.60%, respectively, with an area under the ROC\\nof 0.96. Such a high classification performance highlights the potential of\\nthese QUS parameters to be used as non-invasive biomarkers for breast cancer\\ndetection.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Navid Ibtehaj Nizam et al.",
      "keywords": "Receiver operating characteristic; Pattern recognition (psychology); Sensitivity (control systems); Autoregressive model; Parametric statistics; Hilbert\u2013Huang transform; Artificial intelligence; Computer science; Mathematics; Statistics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1902.01573",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386907485",
      "doi": "10.48550/arxiv.2309.10424",
      "title": "Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare",
      "abstract": "The Directorate General for Parliamentary Research Services of the European Parliament has prepared a report to the Members of the European Parliament where they enumerate seven main risks of Artificial Intelligence (AI) in medicine and healthcare: patient harm due to AI errors, misuse of medical AI tools, bias in AI and the perpetuation of existing inequities, lack of transparency, privacy and security issues, gaps in accountability, and obstacles in implementation. In this study, we propose fourteen functional requirements that AI systems may implement to reduce the risks associated with their medical purpose: AI passport, User management, Regulation check, Academic use only disclaimer, data quality assessment, Clinicians double check, Continuous performance evaluation, Audit trail, Continuous usability test, Review of retrospective/simulated cases, Bias check, eXplainable AI, Encryption and use of field-tested libraries, and Semantic interoperability. Our intention here is to provide specific high-level specifications of technical solutions to ensure continuous good performance and use of AI systems to benefit patients in compliance with the future EU regulatory framework.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Juan M. Garc\u00eda\u2010G\u00f3mez et al.",
      "keywords": "Usability; Parliament; Interoperability; Transparency (behavior); Audit; Harm; Health care; Accountability; Computer science; Computer security; Business; Accounting; Political science; Law; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.10424",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414888833",
      "doi": "10.48550/arxiv.2506.00233",
      "title": "Ethical AI: Towards Defining a Collective Evaluation Framework",
      "abstract": "Artificial Intelligence (AI) is transforming sectors such as healthcare, finance, and autonomous systems, offering powerful tools for innovation. Yet its rapid integration raises urgent ethical concerns related to data ownership, privacy, and systemic bias. Issues like opaque decision-making, misleading outputs, and unfair treatment in high-stakes domains underscore the need for transparent and accountable AI systems. This article addresses these challenges by proposing a modular ethical assessment framework built on ontological blocks of meaning-discrete, interpretable units that encode ethical principles such as fairness, accountability, and ownership. By integrating these blocks with FAIR (Findable, Accessible, Interoperable, Reusable) principles, the framework supports scalable, transparent, and legally aligned ethical evaluations, including compliance with the EU AI Act. Using a real-world use case in AI-powered investor profiling, the paper demonstrates how the framework enables dynamic, behavior-informed risk classification. The findings suggest that ontological blocks offer a promising path toward explainable and auditable AI ethics, though challenges remain in automation and probabilistic reasoning.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Aasish Kumar Sharma et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.00233",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4327993492",
      "doi": "10.48550/arxiv.2303.10158",
      "title": "Data-centric Artificial Intelligence: A Survey",
      "abstract": "Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Daochen Zha et al.",
      "keywords": "Computer science; Data science; Enabling; Data quality; Field (mathematics); GRASP; Quality (philosophy); Domain (mathematical analysis); Inference; Automation; Applications of artificial intelligence; Artificial intelligence; Software engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.10158",
      "cited_by_count": 97,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4283217613",
      "doi": "10.1145/3531146.3533118",
      "title": "Towards a multi-stakeholder value-based assessment framework for algorithmic systems",
      "abstract": "&lt;p&gt;In an effort to regulate Machine Learning-driven (ML) systems, current auditing processes mostly focus on detecting harmful algorithmic biases. While these strategies have proven to be impactful, some values outlined in documents dealing with ethics in ML-driven systems are still underrepresented in auditing processes. Such unaddressed values mainly deal with contextual factors that cannot be easily quantified. In this paper, we develop a value-based assessment framework that is not limited to bias auditing and that covers prominent ethical principles for algorithmic systems. Our framework presents a circular arrangement of values with two bipolar dimensions that make common motivations and potential tensions explicit. In order to operationalize these high-level principles, values are then broken down into specific criteria and their manifestations. However, some of these value-specific criteria are mutually exclusive and require negotiation. As opposed to some other auditing frameworks that merely rely on ML researchers' and practitioners' input, we argue that it is necessary to include stakeholders that present diverse standpoints to systematically negotiate and consolidate value and criteria tensions. To that end, we map stakeholders with different insight needs, and assign tailored means for communicating value manifestations to them. We, therefore, contribute to current ML auditing practices with an assessment framework that visualizes closeness and tensions between values and we give guidelines on how to operationalize them, while opening up the evaluation and deliberation process to a wide range of stakeholders.&lt;/p&gt;",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Mireia Yurrita et al.",
      "keywords": "Operationalization; Audit; Deliberation; Negotiation; Computer science; Stakeholder; Closeness; Value (mathematics); Process (computing); Knowledge management; Management science; Process management; Data science; Sociology; Epistemology; Accounting; Business; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3531146.3533118",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3154282744",
      "doi": "10.48550/arxiv.2104.04147",
      "title": "Artificial intelligence, human rights, democracy, and the rule of law: a primer",
      "abstract": "In September 2019, the Council of Europe's Committee of Ministers adopted the terms of reference for the Ad Hoc Committee on Artificial Intelligence (CAHAI). The CAHAI is charged with examining the feasibility and potential elements of a legal framework for the design, development, and deployment of AI systems that accord with Council of Europe standards across the interrelated areas of human rights, democracy, and the rule of law. As a first and necessary step in carrying out this responsibility, the CAHAI's Feasibility Study, adopted by its plenary in December 2020, has explored options for an international legal response that fills existing gaps in legislation and tailors the use of binding and non-binding legal instruments to the specific risks and opportunities presented by AI systems. The Study examines how the fundamental rights and freedoms that are already codified in international human rights law can be used as the basis for such a legal framework. The purpose of this primer is to introduce the main concepts and principles presented in the CAHAI's Feasibility Study for a general, non-technical audience. It also aims to provide some background information on the areas of AI innovation, human rights law, technology policy, and compliance mechanisms covered therein. In keeping with the Council of Europe's commitment to broad multi-stakeholder consultations, outreach, and engagement, this primer has been designed to help facilitate the meaningful and informed participation of an inclusive group of stakeholders as the CAHAI seeks feedback and guidance regarding the essential issues raised by the Feasibility Study.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "David Leslie et al.",
      "keywords": "Human rights; Outreach; Democracy; Political science; Rule of law; Legislation; Law; Stakeholder; Soft law; International human rights law; Fundamental rights; International law; Public administration; Public relations; Politics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2104.04147",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4405783454",
      "doi": "10.48550/arxiv.2412.17866",
      "title": "Artificial Intelligence, Scientific Discovery, and Product Innovation",
      "abstract": "This paper studies the impact of artificial intelligence on innovation, exploiting the randomized introduction of a new materials discovery technology to 1,018 scientists in the R&amp;D lab of a large U.S. firm. AI-assisted researchers discover 44% more materials, resulting in a 39% increase in patent filings and a 17% rise in downstream product innovation. These compounds possess more novel chemical structures and lead to more radical inventions. However, the technology has strikingly disparate effects across the productivity distribution: while the bottom third of scientists see little benefit, the output of top researchers nearly doubles. Investigating the mechanisms behind these results, I show that AI automates 57% of \"idea-generation\" tasks, reallocating researchers to the new task of evaluating model-produced candidate materials. Top scientists leverage their domain knowledge to prioritize promising AI suggestions, while others waste significant resources testing false positives. Together, these findings demonstrate the potential of AI-augmented research and highlight the complementarity between algorithms and expertise in the innovative process. Survey evidence reveals that these gains come at a cost, however, as 82% of scientists report reduced satisfaction with their work due to decreased creativity and skill underutilization.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Aidan Toner-Rodgers",
      "keywords": "Scientific discovery; Product innovation; Product (mathematics); Business; Data science; Computer science; Knowledge management; Cognitive science; Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.17866",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2884003968",
      "doi": "10.13016/m2pv6bb0c",
      "title": "An Intersectional Definition of Fairness",
      "abstract": "We propose definitions of fairness in machine learning and artificial intelligence systems that are informed by the framework of intersectionality, a critical lens arising from the Humanities literature which analyzes how interlocking systems of power and oppression affect individuals along overlapping dimensions including gender, race, sexual orientation, class, and disability. We show that our criteria behave sensibly for any subset of the set of protected attributes, and we prove economic, privacy, and generalization guarantees. We provide a learning algorithm which respects our intersectional fairness criteria. Case studies on census data and the COMPAS criminal recidivism dataset demonstrate the utility of our methods.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "James R. Foulds et al.",
      "keywords": "Oppression; Intersectionality; Recidivism; Generalization; Through-the-lens metering; Computer science; Privilege (computing); White privilege; Race (biology); Set (abstract data type); Class (philosophy); Sexual orientation; Sociology; Adversarial system; Artificial intelligence; Criminology; Computer security; Political science; Lens (geology); Law; Gender studies; Epistemology; Engineering; Politics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.13016/m2pv6bb0c",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3163095447",
      "doi": "10.48550/arxiv.2105.05460",
      "title": "A Systematic Literature Review on Blockchain Governance",
      "abstract": "Blockchain has been increasingly used as a software component to enable decentralisation in software architecture for a variety of applications. Blockchain governance has received considerable attention to ensure the safe and appropriate use and evolution of blockchain, especially after the Ethereum DAO attack in 2016. However, there are no systematic efforts to analyse existing governance solutions. To understand the state-of-the-art of blockchain governance, we conducted a systematic literature review with 37 primary studies. The extracted data from primary studies are synthesised to answer identified research questions. The study results reveal several major findings: 1) governance can improve the adaptability and upgradability of blockchain, whilst the current studies neglect broader ethical responsibilities as the objectives of blockchain governance; 2) governance is along with the development process of a blockchain platform, while ecosystem-level governance process is missing, and; 3) the responsibilities and capabilities of blockchain stakeholders are briefly discussed, whilst the decision rights, accountability, and incentives of blockchain stakeholders are still under studied. We provide actionable guidelines for academia and practitioners to use throughout the lifecycle of blockchain, and identify future trends to support researchers in this area.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Yue Liu et al.",
      "keywords": "Blockchain; Corporate governance; Accountability; Business; Process (computing); Decentralization; Incentive; Information governance; Systematic review; Variety (cybernetics); Process management; Knowledge management; Accounting; Political science; Computer science; Computer security; Economics; Finance; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2105.05460",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4200629364",
      "doi": "10.48550/arxiv.2112.05675",
      "title": "Assessing the Fairness of AI Systems: AI Practitioners' Processes, Challenges, and Needs for Support",
      "abstract": "Various tools and practices have been developed to support practitioners in identifying, assessing, and mitigating fairness-related harms caused by AI systems. However, prior research has highlighted gaps between the intended design of these tools and practices and their use within particular contexts, including gaps caused by the role that organizational factors play in shaping fairness work. In this paper, we investigate these gaps for one such practice: disaggregated evaluations of AI systems, intended to uncover performance disparities between demographic groups. By conducting semi-structured interviews and structured workshops with thirty-three AI practitioners from ten teams at three technology companies, we identify practitioners' processes, challenges, and needs for support when designing disaggregated evaluations. We find that practitioners face challenges when choosing performance metrics, identifying the most relevant direct stakeholders and demographic groups on which to focus, and collecting datasets with which to conduct disaggregated evaluations. More generally, we identify impacts on fairness work stemming from a lack of engagement with direct stakeholders or domain experts, business imperatives that prioritize customers over marginalized groups, and the drive to deploy AI systems at scale.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Michael Madaio et al.",
      "keywords": "Work (physics); Knowledge management; Scale (ratio); Face (sociological concept); Domain (mathematical analysis); Computer science; Process management; Business; Engineering; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.05675",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4383173593",
      "doi": "10.48550/arxiv.2307.00319",
      "title": "Explainable AI in 6G O-RAN: A Tutorial and Survey on Architecture, Use Cases, Challenges, and Future Research",
      "abstract": "The recent O-RAN specifications promote the evolution of RAN architecture by function disaggregation, adoption of open interfaces, and instantiation of a hierarchical closed-loop control architecture managed by RAN Intelligent Controllers (RICs) entities. This paves the road to novel data-driven network management approaches based on programmable logic. Aided by Artificial Intelligence (AI) and Machine Learning (ML), novel solutions targeting traditionally unsolved RAN management issues can be devised. Nevertheless, the adoption of such smart and autonomous systems is limited by the current inability of human operators to understand the decision process of such AI/ML solutions, affecting their trust in such novel tools. eXplainable AI (XAI) aims at solving this issue, enabling human users to better understand and effectively manage the emerging generation of artificially intelligent schemes, reducing the human-to-machine barrier. In this survey, we provide a summary of the XAI methods and metrics before studying their deployment over the O-RAN Alliance RAN architecture along with its main building blocks. We then present various use cases and discuss the automation of XAI pipelines for O-RAN as well as the underlying security aspects. We also review some projects/standards that tackle this area. Finally, we identify different challenges and research directions that may arise from the heavy adoption of AI/ML decision entities in this context, focusing on how XAI can help to interpret, understand, and improve trust in O-RAN operational networks.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Bouziane Brik et al.",
      "keywords": "Ran; Computer science; Architecture; Context (archaeology); Function (biology); Software deployment; Automation; Process (computing); Artificial intelligence; Data science; Software engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.00319",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391555523",
      "doi": "10.48550/arxiv.2402.00891",
      "title": "Large Language Models in Cybersecurity: State-of-the-Art",
      "abstract": "The rise of Large Language Models (LLMs) has revolutionized our comprehension of intelligence bringing us closer to Artificial Intelligence. Since their introduction, researchers have actively explored the applications of LLMs across diverse fields, significantly elevating capabilities. Cybersecurity, traditionally resistant to data-driven solutions and slow to embrace machine learning, stands out as a domain. This study examines the existing literature, providing a thorough characterization of both defensive and adversarial applications of LLMs within the realm of cybersecurity. Our review not only surveys and categorizes the current landscape but also identifies critical research gaps. By evaluating both offensive and defensive applications, we aim to provide a holistic understanding of the potential risks and opportunities associated with LLM-driven cybersecurity.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Farzad Nourmohammadzadeh Motlagh et al.",
      "keywords": "State (computer science); Computer security; Computer science; Natural language processing; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.00891",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4376311795",
      "doi": "10.48550/arxiv.2305.06360",
      "title": "Exploring the Landscape of Machine Unlearning: A Comprehensive Survey and Taxonomy",
      "abstract": "Machine unlearning (MU) is gaining increasing attention due to the need to remove or modify predictions made by machine learning (ML) models. While training models have become more efficient and accurate, the importance of unlearning previously learned information has become increasingly significant in fields such as privacy, security, and fairness. This paper presents a comprehensive survey of MU, covering current state-of-the-art techniques and approaches, including data deletion, perturbation, and model updates. In addition, commonly used metrics and datasets are also presented. The paper also highlights the challenges that need to be addressed, including attack sophistication, standardization, transferability, interpretability, training data, and resource constraints. The contributions of this paper include discussions about the potential benefits of MU and its future directions. Additionally, the paper emphasizes the need for researchers and practitioners to continue exploring and refining unlearning techniques to ensure that ML models can adapt to changing circumstances while maintaining user trust. The importance of unlearning is further highlighted in making Artificial Intelligence (AI) more trustworthy and transparent, especially with the increasing importance of AI in various domains that involve large amounts of personal user data.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Thanveer Shaik et al.",
      "keywords": "Computer science; Interpretability; Sophistication; Standardization; Transferability; Trustworthiness; Artificial intelligence; Taxonomy (biology); Data science; Knowledge management; Machine learning; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.06360",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W7114807892",
      "doi": "10.48550/arxiv.2512.08592",
      "title": "The SMART+ Framework for AI Systems",
      "abstract": "Artificial Intelligence (AI) systems are now an integral part of multiple industries. In clinical research, AI supports automated adverse event detection in clinical trials, patient eligibility screening for protocol enrollment, and data quality validation. Beyond healthcare, AI is transforming finance through real-time fraud detection, automated loan risk assessment, and algorithmic decision-making. Similarly, in manufacturing, AI enables predictive maintenance to reduce equipment downtime, enhances quality control through computer-vision inspection, and optimizes production workflows using real-time operational data. While these technologies enhance operational efficiency, they introduce new challenges regarding safety, accountability, and regulatory compliance. To address these concerns, we introduce the SMART+ Framework - a structured model built on the pillars of Safety, Monitoring, Accountability, Reliability, and Transparency, and further enhanced with Privacy &amp; Security, Data Governance, Fairness &amp; Bias, and Guardrails. SMART+ offers a practical, comprehensive approach to evaluating and governing AI systems across industries. This framework aligns with evolving mechanisms and regulatory guidance to integrate operational safeguards, oversight procedures, and strengthened privacy and governance controls. SMART+ demonstrates risk mitigation, trust-building, and compliance readiness. By enabling responsible AI adoption and ensuring auditability, SMART+ provides a robust foundation for effective AI governance in clinical research.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Kandikatla, Laxmiraju et al.",
      "keywords": "Workflow; Data governance; Quality (philosophy); Corporate governance; Event (particle physics); Control (management); Protocol (science)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2512.08592",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312108449",
      "doi": "10.48550/arxiv.2212.11136",
      "title": "It is not \"accuracy vs. explainability\" -- we need both for trustworthy AI systems",
      "abstract": "We are witnessing the emergence of an AI economy and society where AI technologies are increasingly impacting health care, business, transportation and many aspects of everyday life. Many successes have been reported where AI systems even surpassed the accuracy of human experts. However, AI systems may produce errors, can exhibit bias, may be sensitive to noise in the data, and often lack technical and judicial transparency resulting in reduction in trust and challenges in their adoption. These recent shortcomings and concerns have been documented in scientific but also in general press such as accidents with self driving cars, biases in healthcare, hiring and face recognition systems for people of color, seemingly correct medical decisions later found to be made due to wrong reasons etc. This resulted in emergence of many government and regulatory initiatives requiring trustworthy and ethical AI to provide accuracy and robustness, some form of explainability, human control and oversight, elimination of bias, judicial transparency and safety. The challenges in delivery of trustworthy AI systems motivated intense research on explainable AI systems (XAI). Aim of XAI is to provide human understandable information of how AI systems make their decisions. In this paper we first briefly summarize current XAI work and then challenge the recent arguments of accuracy vs. explainability for being mutually exclusive and being focused only on deep learning. We then present our recommendations for the use of XAI in full lifecycle of high stakes trustworthy AI systems delivery, e.g. development, validation and certification, and trustworthy production and maintenance.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "D. Petkovic",
      "keywords": "Transparency (behavior); Trustworthiness; Certification; Health care; Computer science; Risk analysis (engineering); Government (linguistics); Reputation; Business; Computer security; Political science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.11136",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416611563",
      "doi": "10.48550/arxiv.2505.23417",
      "title": "Toward Effective AI Governance: A Review of Principles",
      "abstract": "Artificial Intelligence (AI) governance is the practice of establishing frameworks, policies, and procedures to ensure the responsible, ethical, and safe development and deployment of AI systems. Although AI governance is a core pillar of Responsible AI, current literature still lacks synthesis across such governance frameworks and practices. Objective: To identify which frameworks, principles, mechanisms, and stakeholder roles are emphasized in secondary literature on AI governance. Method: We conducted a rapid tertiary review of nine peer-reviewed secondary studies from IEEE and ACM (20202024), using structured inclusion criteria and thematic semantic synthesis. Results: The most cited frameworks include the EU AI Act and NIST RMF; transparency and accountability are the most common principles. Few reviews detail actionable governance mechanisms or stakeholder strategies. Conclusion: The review consolidates key directions in AI governance and highlights gaps in empirical validation and inclusivity. Findings inform both academic inquiry and practical adoption in organizations.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Danilo Monteiro Ribeiro et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23417",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391376577",
      "doi": "10.48550/arxiv.2401.15897",
      "title": "Red-Teaming for Generative AI: Silver Bullet or Security Theater?",
      "abstract": "In response to rising concerns surrounding the safety, security, and trustworthiness of Generative AI (GenAI) models, practitioners and regulators alike have pointed to AI red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite AI red-teaming's central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the AI industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for AI red-teaming practices. Our analysis reveals that prior methods and practices of AI red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing GenAI harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard AI, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative AI, we synthesize our recommendations into a question bank meant to guide and scaffold future AI red-teaming practices.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Michael Feffer et al.",
      "keywords": "Silver bullet; Generative grammar; Computer science; Business; Artificial intelligence; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.15897",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320513979",
      "doi": "10.48550/arxiv.2301.01299",
      "title": "Recent Advances on Federated Learning: A Systematic Survey",
      "abstract": "Federated learning has emerged as an effective paradigm to achieve privacy-preserving collaborative learning among different parties. Compared to traditional centralized learning that requires collecting data from each party, in federated learning, only the locally trained models or computed gradients are exchanged, without exposing any data information. As a result, it is able to protect privacy to some extent. In recent years, federated learning has become more and more prevalent and there have been many surveys for summarizing related methods in this hot research topic. However, most of them focus on a specific perspective or lack the latest research progress. In this paper, we provide a systematic survey on federated learning, aiming to review the recent advanced federated methods and applications from different aspects. Specifically, this paper includes four major contributions. First, we present a new taxonomy of federated learning in terms of the pipeline and challenges in federated scenarios. Second, we summarize federated learning methods into several categories and briefly introduce the state-of-the-art methods under these categories. Third, we overview some prevalent federated learning frameworks and introduce their features. Finally, some potential deficiencies of current methods and several future directions are discussed.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Bingyan Liu et al.",
      "keywords": "Federated learning; Computer science; Data science; Taxonomy (biology); Perspective (graphical); Pipeline (software); Knowledge management; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2301.01299",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4220776026",
      "doi": "10.48550/arxiv.2202.02776",
      "title": "Human rights, democracy, and the rule of law assurance framework for AI systems: A proposal",
      "abstract": "Following on from the publication of its <em>Feasibility Study </em>in December 2020, the Council of Europe\u2019s Ad Hoc Committee on Artificial Intelligence (and its subgroups) initiated efforts to formulate and draft its <em>Possible elements of a legal framework on artificial intelligence, based on the Council of Europe\u2019s standards on human rights, democracy, and the rule of law</em>. This document was ultimately adopted by the CAHAI plenary in December 2021. To support this effort, The Alan Turing Institute undertook a programme of research that explored the governance processes and practical tools needed to operationalise the integration of human right due diligence with the assurance of trustworthy AI innovation practices. The resulting output, <em>Human Rights, Democracy, and the Rule of Law Assurance Framework for AI Systems: A proposal,</em> was completed and submitted to the Council of Europe in September 2021. It presents an end-to-end approach to the assurance of AI project lifecycles that integrates context-based risk analysis and appropriate stakeholder engagement with comprehensive impact assessment, and transparent risk management, impact mitigation, and innovation assurance practices. Taken together, these interlocking processes constitute a Human Rights, Democracy and the Rule of Law Assurance Framework (HUDERAF). The HUDERAF combines the procedural requirements for principles-based human rights due diligence with the governance mechanisms needed to set up technical and socio-technical guardrails for responsible and trustworthy AI innovation practices. Its purpose is to provide an accessible and user-friendly set of mechanisms for facilitating compliance with a binding legal framework on artificial intelligence, based on the Council of Europe\u2019s standards on human rights, democracy, and the rule of law, and to ensure that AI innovation projects are carried out with appropriate levels of public accountability, transparency, and democratic governance.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "David Leslie et al.",
      "keywords": "Human rights; Rule of law; Due diligence; Democracy; Political science; Corporate governance; Context (archaeology); Soft law; Law; Public relations; Public administration; International law; Management; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.02776",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3092485520",
      "doi": "10.48550/arxiv.2010.05774",
      "title": "Deep Learning for Information Systems Research",
      "abstract": "Artificial Intelligence (AI) has rapidly emerged as a key disruptive technology in the 21st century. At the heart of modern AI lies Deep Learning (DL), an emerging class of algorithms that has enabled today's platforms and organizations to operate at unprecedented efficiency, effectiveness, and scale. Despite significant interest, IS contributions in DL have been limited, which we argue is in part due to issues with defining, positioning, and conducting DL research. Recognizing the tremendous opportunity here for the IS community, this work clarifies, streamlines, and presents approaches for IS scholars to make timely and high-impact contributions. Related to this broader goal, this paper makes five timely contributions. First, we systematically summarize the major components of DL in a novel Deep Learning for Information Systems Research (DL-ISR) schematic that illustrates how technical DL processes are driven by key factors from an application environment. Second, we present a novel Knowledge Contribution Framework (KCF) to help IS scholars position their DL contributions for maximum impact. Third, we provide ten guidelines to help IS scholars generate rigorous and relevant DL-ISR in a systematic, high-quality fashion. Fourth, we present a review of prevailing journal and conference venues to examine how IS scholars have leveraged DL for various research inquiries. Finally, we provide a unique perspective on how IS scholars can formulate DL-ISR inquiries by carefully considering the interplay of business function(s), application areas(s), and the KCF. This perspective intentionally emphasizes inter-disciplinary, intra-disciplinary, and cross-IS tradition perspectives. Taken together, these contributions provide IS scholars a timely framework to advance the scale, scope, and impact of deep learning research.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Sagar Samtani et al.",
      "keywords": "Discipline; Computer science; Perspective (graphical); Artificial intelligence; Key (lock); Function (biology); Data science; Class (philosophy); Deep learning; Knowledge management; Sociology; Social science; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2010.05774",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395483228",
      "doi": "10.48550/arxiv.2404.15680",
      "title": "Legitimate Power, Illegitimate Automation: The problem of ignoring legitimacy in automated decision systems",
      "abstract": "Progress in machine learning and artificial intelligence has spurred the widespread adoption of automated decision systems (ADS). An extensive literature explores what conditions must be met for these systems' decisions to be fair. However, questions of legitimacy -- why those in control of ADS are entitled to make such decisions -- have received comparatively little attention. This paper shows that when such questions are raised theorists often incorrectly conflate legitimacy with either public acceptance or other substantive values such as fairness, accuracy, expertise or efficiency. In search of better theories, we conduct a critical analysis of the philosophical literature on the legitimacy of the state, focusing on consent, public reason, and democratic authorisation. This analysis reveals that the prevailing understanding of legitimacy in analytical political philosophy is also ill-suited to the task of establishing whether and when ADS are legitimate. The paper thus clarifies expectations for theories of ADS legitimacy and charts a path for a future research programme on the topic.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jake E. Stone et al.",
      "keywords": "Legitimacy; Automation; Power (physics); Law and economics; Political science; Computer science; Management science; Risk analysis (engineering); Computer security; Economics; Business; Engineering; Law; Politics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.15680",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312206453",
      "doi": "10.48550/arxiv.2212.12508",
      "title": "Ethical Design of Computers: From Semiconductors to IoT and Artificial Intelligence",
      "abstract": "Computing systems are tightly integrated today into our professional, social, and private lives. An important consequence of this growing ubiquity of computing is that it can have significant ethical implications of which computing professionals should take account. In most real-world scenarios, it is not immediately obvious how particular technical choices during the design and use of computing systems could be viewed from an ethical perspective. This article provides a perspective on the ethical challenges within semiconductor chip design, IoT applications, and the increasing use of artificial intelligence in the design processes, tools, and hardware-software stacks of these systems.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Sudeep Pasricha et al.",
      "keywords": "Perspective (graphical); Computer science; Internet of Things; Software; Ethical issues; Engineering ethics; Data science; Engineering management; Knowledge management; Management science; Artificial intelligence; Engineering; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.12508",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4229008394",
      "doi": "10.48550/arxiv.2205.01512",
      "title": "Fair Feature Subset Selection using Multiobjective Genetic Algorithm",
      "abstract": "The feature subset selection problem aims at selecting the relevant subset of features to improve the performance of a Machine Learning (ML) algorithm on training data. Some features in data can be inherently noisy, costly to compute, improperly scaled, or correlated to other features, and they can adversely affect the accuracy, cost, and complexity of the induced algorithm. The goal of traditional feature selection approaches has been to remove such irrelevant features. In recent years ML is making a noticeable impact on the decision-making processes of our everyday lives. We want to ensure that these decisions do not reflect biased behavior towards certain groups or individuals based on protected attributes such as age, sex, or race. In this paper, we present a feature subset selection approach that improves both fairness and accuracy objectives and computes Pareto-optimal solutions using the NSGA-II algorithm. We use statistical disparity as a fairness metric and F1-Score as a metric for model performance. Our experiments on the most commonly used fairness benchmark datasets with three different machine learning algorithms show that using the evolutionary algorithm we can effectively explore the trade-off between fairness and accuracy.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Ayaz Ur Rehman et al.",
      "keywords": "Benchmark (surveying); Metric (unit); Computer science; Feature selection; Feature (linguistics); Machine learning; Selection (genetic algorithm); Genetic algorithm; Artificial intelligence; Performance metric; Pareto principle; Evolutionary algorithm; Algorithm; Data mining; Mathematical optimization; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.01512",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320854675",
      "doi": "10.48550/arxiv.2302.06347",
      "title": "The Possibility of Fairness: Revisiting the Impossibility Theorem in Practice",
      "abstract": "The ``impossibility theorem'' -- which is considered foundational in algorithmic fairness literature -- asserts that there must be trade-offs between common notions of fairness and performance when fitting statistical models, except in two special cases: when the prevalence of the outcome being predicted is equal across groups, or when a perfectly accurate predictor is used. However, theory does not always translate to practice. In this work, we challenge the implications of the impossibility theorem in practical settings. First, we show analytically that, by slightly relaxing the impossibility theorem (to accommodate a \\textit{practitioner's} perspective of fairness), it becomes possible to identify a large set of models that satisfy seemingly incompatible fairness constraints. Second, we demonstrate the existence of these models through extensive experiments on five real-world datasets. We conclude by offering tools and guidance for practitioners to understand when -- and to what degree -- fairness along multiple criteria can be achieved. For example, if one allows only a small margin-of-error between metrics, there exists a large set of models simultaneously satisfying \\emph{False Negative Rate Parity}, \\emph{False Positive Rate Parity}, and \\emph{Positive Predictive Value Parity}, even when there is a moderate prevalence difference between groups. This work has an important implication for the community: achieving fairness along multiple metrics for multiple groups (and their intersections) is much more possible than was previously believed.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Andrew Bell et al.",
      "keywords": "Impossibility; Arrow's impossibility theorem; Mathematical economics; Outcome (game theory); Parity (physics); Set (abstract data type); Mathematics; Perspective (graphical); Margin (machine learning); Computer science; Discrete mathematics; Social choice theory; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.06347",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387074687",
      "doi": "10.48550/arxiv.2309.13057",
      "title": "The Return on Investment in AI Ethics: A Holistic Framework",
      "abstract": "We propose a Holistic Return on Ethics (HROE) framework for understanding the return on organizational investments in artificial intelligence (AI) ethics efforts. This framework is useful for organizations that wish to quantify the return for their investment decisions. The framework identifies the direct economic returns of such investments, the indirect paths to return through intangibles associated with organizational reputation, and real options associated with capabilities. The holistic framework ultimately provides organizations with the competency to employ and justify AI ethics investments.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Marialena Bevilacqua et al.",
      "keywords": "Return on investment; Reputation; Rate of return; Business; Investment (military); Business ethics; Knowledge management; Economics; Finance; Management; Sociology; Political science; Computer science; Microeconomics; Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.13057",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399425467",
      "doi": "10.48550/arxiv.2406.02630",
      "title": "AI Agents Under Threat: A Survey of Key Security Challenges and Future Pathways",
      "abstract": "An Artificial Intelligence (AI) agent is a software entity that autonomously performs tasks or makes decisions based on pre-defined objectives and data inputs. AI agents, capable of perceiving user inputs, reasoning and planning tasks, and executing actions, have seen remarkable advancements in algorithm development and task performance. However, the security challenges they pose remain under-explored and unresolved. This survey delves into the emerging security threats faced by AI agents, categorizing them into four critical knowledge gaps: unpredictability of multi-step user inputs, complexity in internal executions, variability of operational environments, and interactions with untrusted external entities. By systematically reviewing these threats, this paper highlights both the progress made and the existing limitations in safeguarding AI agents. The insights provided aim to inspire further research into addressing the security threats associated with AI agents, thereby fostering the development of more robust and secure AI agent applications.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zehang Deng et al.",
      "keywords": "Key (lock); Computer security; Computer science; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.02630",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390722865",
      "doi": "10.48550/arxiv.2401.03223",
      "title": "An intelligent sociotechnical systems (iSTS) framework: Enabling a hierarchical human-centered AI (hHCAI) approach",
      "abstract": "While artificial intelligence (AI) offers significant benefits, it also has negatively impacted humans and society. A human-centered AI (HCAI) approach has been proposed to address these issues. However, current HCAI practices have shown limited contributions due to a lack of sociotechnical thinking. To overcome these challenges, we conducted a literature review and comparative analysis of sociotechnical characteristics with respect to AI. Then, we propose updated sociotechnical systems (STS) design principles. Based on these findings, this paper introduces an intelligent sociotechnical systems (iSTS) framework to extend traditional STS theory and meet the demands with respect to AI. The iSTS framework emphasizes human-centered joint optimization across individual, organizational, ecosystem, and societal levels. The paper further integrates iSTS with current HCAI practices, proposing a hierarchical HCAI (hHCAI) approach. This hHCAI approach offers a structured approach to address challenges in HCAI practices from a broader sociotechnical perspective. Finally, we provide recommendations for future iSTS and hHCAI work.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Wei Xu et al.",
      "keywords": "Sociotechnical system; Computer science; Knowledge management; Engineering; Systems engineering; Management science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.03223",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4402853574",
      "doi": "10.48550/arxiv.2407.15685",
      "title": "The Atlas of AI Incidents in Mobile Computing: Visualizing the Risks and Benefits of AI Gone Mobile",
      "abstract": "Today's visualization tools for conveying the risks and benefits of AI technologies are largely tailored for those with technical expertise. To bridge this gap, we have developed a visualization that employs narrative patterns and interactive elements, enabling the broader public to gradually grasp the diverse risks and benefits associated with AI. Using a dataset of 54 real-world incidents involving AI in mobile computing, we examined design choices that enhance public understanding and provoke reflection on how certain AI applications - even those deemed low-risk by law - can still lead to significant incidents. Visualization: https://social-dynamics.net/mobile-ai-risks",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Edyta P. Bogucka et al.",
      "keywords": "Atlas (anatomy); Computer science; Data science; Computer security; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.15685",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416529460",
      "doi": "10.48550/arxiv.2504.05755",
      "title": "Unraveling Human-AI Teaming: A Review and Outlook",
      "abstract": "Artificial Intelligence (AI) is advancing at an unprecedented pace, with clear potential to enhance decision-making and productivity. Yet, the collaborative decision-making process between humans and AI remains underdeveloped, often falling short of its transformative possibilities. This paper explores the evolution of AI agents from passive tools to active collaborators in human-AI teams, emphasizing their ability to learn, adapt, and operate autonomously in complex environments. This paradigm shifts challenges traditional team dynamics, requiring new interaction protocols, delegation strategies, and responsibility distribution frameworks. Drawing on Team Situation Awareness (SA) theory, we identify two critical gaps in current human-AI teaming research: the difficulty of aligning AI agents with human values and objectives, and the underutilization of AI's capabilities as genuine team members. Addressing these gaps, we propose a structured research outlook centered on four key aspects of human-AI teaming: formulation, coordination, maintenance, and training. Our framework highlights the importance of shared mental models, trust-building, conflict resolution, and skill adaptation for effective teaming. Furthermore, we discuss the unique challenges posed by varying team compositions, goals, and complexities. This paper provides a foundational agenda for future research and practical design of sustainable, high-performing human-AI teams.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Bowen Lou et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.05755",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392616757",
      "doi": "10.48550/arxiv.2403.04226",
      "title": "Disciplining Deliberation: A Sociotechnical Perspective on Machine Learning Trade-offs",
      "abstract": "This paper examines two prominent formal trade-offs in artificial intelligence (AI) -- between predictive accuracy and fairness, and between predictive accuracy and interpretability. These trade-offs have become a central focus in normative and regulatory discussions as policymakers seek to understand the value tensions that can arise in the social adoption of AI tools. The prevailing interpretation views these formal trade-offs as directly corresponding to tensions between underlying social values, implying unavoidable conflicts between those social objectives. In this paper, I challenge that prevalent interpretation by introducing a sociotechnical approach to examining the value implications of trade-offs. Specifically, I identify three key considerations -- validity and instrumental relevance, compositionality, and dynamics -- for contextualizing and characterizing these implications. These considerations reveal that the relationship between model trade-offs and corresponding values depends on critical choices and assumptions. Crucially, judicious sacrifices in one model property for another can, in fact, promote both sets of corresponding values. The proposed sociotechnical perspective thus shows that we can and should aspire to higher epistemic and ethical possibilities than the prevalent interpretation suggests, while offering practical guidance for achieving those outcomes. Finally, I draw out the broader implications of this perspective for AI design and governance, highlighting the need to broaden normative engagement across the AI lifecycle, develop legal and auditing tools sensitive to sociotechnical considerations, and rethink the vital role and appropriate structure of interdisciplinary collaboration in fostering a responsible AI workforce.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Sina Fazelpour",
      "keywords": "Sociotechnical system; Deliberation; Perspective (graphical); Knowledge management; Sociology; Epistemology; Computer science; Political science; Economics; Management science; Artificial intelligence; Politics; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.04226",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399405797",
      "doi": "10.48550/arxiv.2406.01862",
      "title": "Charting the Landscape of Nefarious Uses of Generative Artificial Intelligence for Online Election Interference",
      "abstract": "Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) pose significant risks, particularly in the realm of online election interference. This paper explores the nefarious applications of GenAI, highlighting their potential to disrupt democratic processes through deepfakes, botnets, targeted misinformation campaigns, and synthetic identities. By examining recent case studies and public incidents, we illustrate how malicious actors exploit these technologies to try influencing voter behavior, spread disinformation, and undermine public trust in electoral systems. The paper also discusses the societal implications of these threats, emphasizing the urgent need for robust mitigation strategies and international cooperation to safeguard democratic integrity.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Emilio Ferrara",
      "keywords": "Generative grammar; Interference (communication); Artificial intelligence; Generative model; Computer science; Political science; Telecommunications",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.01862",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4397028052",
      "doi": "10.48550/arxiv.2405.09426",
      "title": "Global-Local Image Perceptual Score (GLIPS): Evaluating Photorealistic Quality of AI-Generated Images",
      "abstract": "This paper introduces the Global-Local Image Perceptual Score (GLIPS), an image metric designed to assess the photorealistic image quality of AI-generated images with a high degree of alignment to human visual perception. Traditional metrics such as FID and KID scores do not align closely with human evaluations. The proposed metric incorporates advanced transformer-based attention mechanisms to assess local similarity and Maximum Mean Discrepancy (MMD) to evaluate global distributional similarity. To evaluate the performance of GLIPS, we conducted a human study on photorealistic image quality. Comprehensive tests across various generative models demonstrate that GLIPS consistently outperforms existing metrics like FID, SSIM, and MS-SSIM in terms of correlation with human scores. Additionally, we introduce the Interpolative Binning Scale (IBS), a refined scaling method that enhances the interpretability of metric scores by aligning them more closely with human evaluative standards. The proposed metric and scaling approach not only provides more reliable assessments of AI-generated images but also suggest pathways for future enhancements in image generation technologies.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Memoona Aziz et al.",
      "keywords": "Artificial intelligence; Image (mathematics); Perception; Computer vision; Computer science; Image quality; Quality (philosophy); Psychology; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.09426",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4292954038",
      "doi": "10.48550/arxiv.2208.09967",
      "title": "Inferring Sensitive Attributes from Model Explanations",
      "abstract": "Model explanations provide transparency into a trained machine learning model's blackbox behavior to a model builder. They indicate the influence of different input attributes to its corresponding model prediction. The dependency of explanations on input raises privacy concerns for sensitive user data. However, current literature has limited discussion on privacy risks of model explanations. We focus on the specific privacy risk of attribute inference attack wherein an adversary infers sensitive attributes of an input (e.g., race and sex) given its model explanations. We design the first attribute inference attack against model explanations in two threat models where model builder either (a) includes the sensitive attributes in training data and input or (b) censors the sensitive attributes by not including them in the training data and input. We evaluate our proposed attack on four benchmark datasets and four state-of-the-art algorithms. We show that an adversary can successfully infer the value of sensitive attributes from explanations in both the threat models accurately. Moreover, the attack is successful even by exploiting only the explanations corresponding to sensitive attributes. These suggest that our attack is effective against explanations and poses a practical threat to data privacy. On combining the model predictions (an attack surface exploited by prior attacks) with explanations, we note that the attack success does not improve. Additionally, the attack success on exploiting model explanations is better compared to exploiting only model predictions. These suggest that model explanations are a strong attack surface to exploit for an adversary.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Vasisht Duddu et al.",
      "keywords": "Adversary; Computer science; Exploit; Attack model; Inference; Dependency (UML); Focus (optics); Benchmark (surveying); Transparency (behavior); Machine learning; Threat model; Artificial intelligence; Computer security; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.09967",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4300454822",
      "doi": "10.48550/arxiv.1610.01256",
      "title": "On the Safety of Machine Learning: Cyber-Physical Systems, Decision\\n Sciences, and Data Products",
      "abstract": "Machine learning algorithms increasingly influence our decisions and interact\\nwith us in all parts of our daily lives. Therefore, just as we consider the\\nsafety of power plants, highways, and a variety of other engineered\\nsocio-technical systems, we must also take into account the safety of systems\\ninvolving machine learning. Heretofore, the definition of safety has not been\\nformalized in a machine learning context. In this paper, we do so by defining\\nmachine learning safety in terms of risk, epistemic uncertainty, and the harm\\nincurred by unwanted outcomes. We then use this definition to examine safety in\\nall sorts of applications in cyber-physical systems, decision sciences, and\\ndata products. We find that the foundational principle of modern statistical\\nmachine learning, empirical risk minimization, is not always a sufficient\\nobjective. Finally, we discuss how four different categories of strategies for\\nachieving safety in engineering, including inherently safe design, safety\\nreserves, safe fail, and procedural safeguards can be mapped to a machine\\nlearning context. We then discuss example techniques that can be adopted in\\neach category, such as considering interpretability and causality of predictive\\nmodels, objective functions beyond expected prediction accuracy, human\\ninvolvement for labeling difficult or rare examples, and user experience design\\nof software and open data.\\n",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Kush R. Varshney et al.",
      "keywords": "Interpretability; Machine learning; Artificial intelligence; Computer science; Context (archaeology); Harm; Risk analysis (engineering); Variety (cybernetics); Data science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1610.01256",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387076081",
      "doi": "10.48550/arxiv.2309.13965",
      "title": "May I Ask a Follow-up Question? Understanding the Benefits of Conversations in Neural Network Explainability",
      "abstract": "Research in explainable AI (XAI) aims to provide insights into the decision-making process of opaque AI models. To date, most XAI methods offer one-off and static explanations, which cannot cater to the diverse backgrounds and understanding levels of users. With this paper, we investigate if free-form conversations can enhance users' comprehension of static explanations, improve acceptance and trust in the explanation methods, and facilitate human-AI collaboration. Participants are presented with static explanations, followed by a conversation with a human expert regarding the explanations. We measure the effect of the conversation on participants' ability to choose, from three machine learning models, the most accurate one based on explanations and their self-reported comprehension, acceptance, and trust. Empirical results show that conversations significantly improve comprehension, acceptance, trust, and collaboration. Our findings highlight the importance of customized model explanations in the format of free-form conversations and provide insights for the future design of conversational explanations.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Tong Zhang et al.",
      "keywords": "Conversation; Comprehension; Computer science; Ask price; Process (computing); Knowledge management; Psychology; Communication",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.13965",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4398192364",
      "doi": "10.48550/arxiv.2405.11825",
      "title": "Measuring Technical Debt in AI-Based Competition Platforms",
      "abstract": "Advances in AI have led to new types of technical debt in software engineering projects. AI-based competition platforms face challenges due to rapid prototyping and a lack of adherence to software engineering principles by participants, resulting in technical debt. Additionally, organizers often lack methods to evaluate platform quality, impacting sustainability and maintainability. In this research, we identify and categorize types of technical debt in AI systems through a scoping review. We develop a questionnaire for assessing technical debt in AI competition platforms, categorizing debt into various types, such as algorithm, architectural, code, configuration, data etc. We introduce Accessibility Debt, specific to AI competition platforms, highlighting challenges participants face due to inadequate platform usability. Our framework for managing technical debt aims to improve the sustainability and effectiveness of these platforms, providing tools for researchers, organizers, and participants.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Dionysios Sklavenitis et al.",
      "keywords": "Competition (biology); Debt; Economics; Business; Computer science; Industrial organization; Macroeconomics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.11825",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4306806875",
      "doi": "10.48550/arxiv.2210.09014",
      "title": "Addressing contingency in algorithmic (mis)information classification: Toward a responsible machine learning agenda",
      "abstract": "Machine learning (ML) enabled classification models are becoming increasingly popular for tackling the sheer volume and speed of online misinformation and other content that could be identified as harmful. In building these models, data scientists need to take a stance on the legitimacy, authoritativeness and objectivity of the sources of ``truth\" used for model training and testing. This has political, ethical and epistemic implications which are rarely addressed in technical papers. Despite (and due to) their reported high accuracy and performance, ML-driven moderation systems have the potential to shape online public debate and create downstream negative impacts such as undue censorship and the reinforcing of false beliefs. Using collaborative ethnography and theoretical insights from social studies of science and expertise, we offer a critical analysis of the process of building ML models for (mis)information classification: we identify a series of algorithmic contingencies--key moments during model development that could lead to different future outcomes, uncertainty and harmful effects as these tools are deployed by social media platforms. We conclude by offering a tentative path toward reflexive and responsible development of ML tools for moderating misinformation and other harmful content online.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Andr\u00e9s Dom\u00ednguez Hern\u00e1ndez et al.",
      "keywords": "Misinformation; Objectivity (philosophy); Social media; Computer science; Moderation; Contingency; Data science; Process (computing); Inference; Artificial intelligence; Epistemology; Machine learning; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.09014",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394708969",
      "doi": "10.48550/arxiv.2404.05990",
      "title": "Automatic Authorities: Power and AI",
      "abstract": "As rapid advances in Artificial Intelligence and the rise of some of history's most potent corporations meet the diminished neoliberal state, people are increasingly subject to power exercised by means of automated systems. Machine learning and related computational technologies now underpin vital government services. They connect consumers and producers in new algorithmic markets. They determine how we find out about everything from how to vote to where to get vaccinated, and whose speech is amplified, reduced, or restricted. And a new wave of products based on Large Language Models (LLMs) will further transform our economic and political lives. Automatic Authorities are automated computational systems used to exercise power over us by determining what we may know, what we may have, and what our options will be. In response to their rise, scholars working on the societal impacts of AI and related technologies have advocated shifting attention from how to make AI systems beneficial or fair towards a critical analysis of these new power relations. But power is everywhere, and is not necessarily bad. On what basis should we object to new or intensified power relations, and what can be done to justify them? This paper introduces the philosophical materials with which to formulate these questions, and offers preliminary answers. It starts by pinning down the concept of power, focusing on the ability that some agents have to shape others' lives. It then explores how AI enables and intensifies the exercise of power so understood, and sketches three problems with power and three ways to solve those problems. It emphasises, in particular, that justifying power requires more than satisfying substantive justificatory criteria; standards of proper authority and procedural legitimacy must also be met. We need to know not only what power may be used for, but how it may be used, and by whom.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Seth Lazar",
      "keywords": "Power (physics); Artificial intelligence; Computer science; Political science; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.05990",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226000146",
      "doi": "10.48550/arxiv.2204.03100",
      "title": "Data Justice Stories: A Repository of Case Studies",
      "abstract": "The idea of \u201cdata justice\u201d is of recent academic vintage. It has arisen over the past decade in Anglo-European research institutions as an attempt to bring together a critique of the power dynamics that underlie accelerating trends of datafication with a normative commitment to the principles of social justice\u2014a commitment to the achievement of a society that is equitable, fair, and capable of confronting the root causes of injustice.However, despite the seeming novelty of such a data justice pedigree, this joining up of the critique of the power imbalances that have shaped the digital and \u201cbig data\u201d revolutions with a commitment to social equity and constructive societal transformation has a deeper historical, and more geographically diverse, provenance. As the stories of the data justice initiatives, activism, and advocacy contained in this volume well evidence, practices of data justice across the globe have, in fact, largely preceded the elaboration and crystallisation of the idea of data justice in contemporary academic discourse. We have organised the stories contained in this repository into two groups. The first group, \u2018Challenges to Data Justice: Stories of Data Discrimination and Inequity\u201d, poses the question: What are the sorts of problems and challenges to which data justice practitioners are responding? This section is intended to orient the reader to the range of empirical problems faced by data justice researchers and practitioners the world over. We have provided examples of data practices that have been criticised as posing risks of moral injury and that have been identified as leading to inequitable or discriminatory outcomes. Case studies include a national ID card that serves as a government payment system in Venezuela, a courier service/digital technology company in Colombia, and a digital registry of \u2018rights, tenancy, and crops\u2019 in India. The second group, \u2018Transformational Stories of Data Justice: Initiatives, Activism, and Advocacy\u2019, poses the questions: What do responses to the range of challenges posed to data justice look like? What are the kinds of transformation that such responses are trying to bring about? The purpose of this section is to orient the reader to the \u2018moral grammar\u2019 intrinsic to boots-on-the-ground struggles for data justice. To be sure, the initiatives and instances of activism and advocacy that are covered are intended to provide insight into the sources of normativity and liberation that inhere <em>pre-reflectively</em> in the actual social and historical practices of resistance that organisations undertake. Case studies relating to these transformative data justice practices include a movement for Indigenous data sovereignty in Aotearoa, social mobilisation against violence done to trans people across Eastern Europe and Central Asia, and legal advocacy for public accountability in data use and algorithmic decision-making in the United Kingdom. Ultimately, by bringing the first and second sets of data justice stories into high relief, we hope to provide the reader with two interdependent tools of data justice thinking: First, we aim to provide the reader with the critical leverage needed to discern those distortions and malformations of data justice that manifest in subtle and explicit forms of power, domination, and coercion. Second, we aim to provide the reader with access to the historically effective forms of normativity and ethical insight that have been marshalled by data justice activists and advocates as tools of societal transformation\u2014so that these forms of normativity and insight can be drawn on, in turn, as constructive resources to spur future transformative data justice practices.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "David Leslie et al.",
      "keywords": "Economic Justice; Sociology; Power (physics); Political science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.03100",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388110011",
      "doi": "10.48550/arxiv.2310.19704",
      "title": "A Survey on Knowledge Editing of Neural Networks",
      "abstract": "Deep neural networks are becoming increasingly pervasive in academia and industry, matching and surpassing human performance on a wide variety of fields and related tasks. However, just as humans, even the largest artificial neural networks make mistakes, and once-correct predictions can become invalid as the world progresses in time. Augmenting datasets with samples that account for mistakes or up-to-date information has become a common workaround in practical applications. However, the well-known phenomenon of catastrophic forgetting poses a challenge in achieving precise changes in the implicitly memorized knowledge of neural network parameters, often requiring a full model re-training to achieve desired behaviors. That is expensive, unreliable, and incompatible with the current trend of large self-supervised pre-training, making it necessary to find more efficient and effective methods for adapting neural network models to changing data. To address this need, knowledge editing is emerging as a novel area of research that aims to enable reliable, data-efficient, and fast changes to a pre-trained target model, without affecting model behaviors on previously learned tasks. In this survey, we provide a brief review of this recent artificial intelligence field of research. We first introduce the problem of editing neural networks, formalize it in a common framework and differentiate it from more notorious branches of research such as continuous learning. Next, we provide a review of the most relevant knowledge editing approaches and datasets proposed so far, grouping works under four different families: regularization techniques, meta-learning, direct model editing, and architectural strategies. Finally, we outline some intersections with other fields of research and potential directions for future works.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Vittorio Mazzia et al.",
      "keywords": "Computer science; Workaround; Forgetting; Artificial intelligence; Artificial neural network; Field (mathematics); Variety (cybernetics); Machine learning; Deep learning; Data science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.19704",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3037624160",
      "doi": "10.48550/arxiv.2006.14662",
      "title": "The State of AI Ethics Report (June 2020)",
      "abstract": "These past few months have been especially challenging, and the deployment of technology in ways hitherto untested at an unrivalled pace has left the internet and technology watchers aghast. Artificial intelligence has become the byword for technological progress and is being used in everything from helping us combat the COVID-19 pandemic to nudging our attention in different directions as we all spend increasingly larger amounts of time online. It has never been more important that we keep a sharp eye out on the development of this field and how it is shaping our society and interactions with each other. With this inaugural edition of the State of AI Ethics we hope to bring forward the most important developments that caught our attention at the Montreal AI Ethics Institute this past quarter. Our goal is to help you navigate this ever-evolving field swiftly and allow you and your organization to make informed decisions. This pulse-check for the state of discourse, research, and development is geared towards researchers and practitioners alike who are making decisions on behalf of their organizations in considering the societal impacts of AI-enabled solutions. We cover a wide set of areas in this report spanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and Labor, the Future of AI Ethics, and more. Our staff has worked tirelessly over the past quarter surfacing signal from the noise so that you are equipped with the right tools and knowledge to confidently tread this complex yet consequential domain.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Abhishek Gupta et al.",
      "keywords": "Pace; Political science; Agency (philosophy); State (computer science); Software deployment; Public relations; Ethics of technology; Engineering ethics; Engineering; Sociology; Law; Information ethics; Computer science; Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2006.14662",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4407208977",
      "doi": "10.48550/arxiv.2502.02767",
      "title": "When Anti-Fraud Laws Become a Barrier to Computer Science Research",
      "abstract": "Computer science research sometimes brushes with the law, from red-team exercises that probe the boundaries of authentication mechanisms, to AI research processing copyrighted material, to platform research measuring the behavior of algorithms and users. U.S.-based computer security research is no stranger to the Computer Fraud and Abuse Act (CFAA) and the Digital Millennium Copyright Act (DMCA) in a relationship that is still evolving through case law, research practices, changing policies, and legislation. Amid the landscape computer scientists, lawyers, and policymakers have learned to navigate, anti-fraud laws are a surprisingly under-examined challenge for computer science research. Fraud brings separate issues that are not addressed by the methods for navigating CFAA, DMCA, and Terms of Service that are more familiar in the computer security literature. Although anti-fraud laws have been discussed to a limited extent in older research on phishing attacks, modern computer science researchers are left with little guidance when it comes to navigating issues of deception outside the context of pure laboratory research. In this paper, we analyze and taxonomize the anti-fraud and deception issues that arise in several areas of computer science research. We find that, despite the lack of attention to these issues in the legal and computer science literature, issues of misrepresented identity or false information that could implicate anti-fraud laws are actually relevant to many methodologies used in computer science research, including penetration testing, web scraping, user studies, sock puppets, social engineering, auditing AI or socio-technical systems, and attacks on artificial intelligence. We especially highlight the importance of anti-fraud laws in two research fields of great policy importance: attacking or auditing AI systems, and research involving legal identification.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiao Ma et al.",
      "keywords": "Political science; Law; Computer science; Engineering ethics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2502.02767",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4221163671",
      "doi": "10.48550/arxiv.2203.12212",
      "title": "Supporting Developers in Addressing Human-centric Issues in Mobile Apps",
      "abstract": "Failure to consider the characteristics, limitations, and abilities of diverse end-users during mobile apps development may lead to problems for end-users such as accessibility and usability issues. We refer to this class of problems as human-centric issues. Despite their importance, there is a limited understanding of the types of human-centric issues that are encountered by end-users and taken into account by the developers of mobile apps. In this paper, we examine what human-centric issues end-users report through Google App Store reviews, which human-centric issues are a topic of discussion for developers on GitHub, and whether end-users and developers discuss the same human-centric issues. We then investigate whether an automated tool might help detect such human-centric issues and whether developers would find such a tool useful. To do this, we conducted an empirical study by extracting and manually analysing a random sample of 1,200 app reviews and 1,200 issue comments from 12 diverse projects that exist on both Google App Store and GitHub. Our analysis led to a taxonomy of human-centric issues that categorises human-centric issues into three-high levels: App Usage, Inclusiveness, and User Reaction. We then developed machine learning and deep learning models that are promising in automatically identifying and classifying human-centric issues from app reviews and developer discussions. A survey of mobile app developers shows that the automated detection of human-centric issues has practical applications. Guided by our findings, we highlight some implications and possible future work to further understand and incorporate human-centric issues in mobile apps development.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Hourieh Khalajzadeh et al.",
      "keywords": "Usability; Computer science; Mobile apps; World Wide Web; End user; User-centered design; Data science; App store; Empirical research; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.12212",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388184314",
      "doi": "10.48550/arxiv.2310.19999",
      "title": "Systems Interoperability Types: A Tertiary Study",
      "abstract": "Interoperability has been a focus of attention over at least four decades, with the emergence of several interoperability types (or levels), diverse models, frameworks, and solutions, also as a result of a continuous effort from different domains. The current heterogeneity in technologies such as blockchain, IoT and new application domains such as Industry 4.0 brings not only new interaction possibilities but also challenges for interoperability. Moreover, confusion and ambiguity in the current understanding of interoperability types exist, hampering stakeholders' communication and decision making. This work presents an updated panorama of software-intensive systems interoperability with particular attention to its types. For this, we conducted a tertiary study that scrutinized 37 secondary studies published from 2012 to 2023, from which we found 36 interoperability types associated with 117 different definitions, besides 13 interoperability models and six frameworks in various domains. This panorama reveals that the concern with interoperability has migrated from technical to social-technical issues going beyond the software systems' boundary and still requiring solving many open issues. We also address the urgent actions and also potential research opportunities to leverage interoperability as a multidisciplinary research field to achieve low-coupled, cost-effective, and interoperable systems.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Paulo Maciel et al.",
      "keywords": "Interoperability; Semantic interoperability; Cross-domain interoperability; WS-I Basic Profile; Computer science; Leverage (statistics); Multidisciplinary approach; Knowledge management; Process management; Data science; World Wide Web; Engineering; Web service; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.19999",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4310633389",
      "doi": "10.48550/arxiv.2212.00740",
      "title": "Prioritizing Policies for Furthering Responsible Artificial Intelligence in the United States",
      "abstract": "Several policy options exist, or have been proposed, to further responsible artificial intelligence (AI) development and deployment. Institutions, including U.S. government agencies, states, professional societies, and private and public sector businesses, are well positioned to implement these policies. However, given limited resources, not all policies can or should be equally prioritized. We define and review nine suggested policies for furthering responsible AI, rank each policy on potential use and impact, and recommend prioritization relative to each institution type. We find that pre-deployment audits and assessments and post-deployment accountability are likely to have the highest impact but also the highest barriers to adoption. We recommend that U.S. government agencies and companies highly prioritize development of pre-deployment audits and assessments, while the U.S. national legislature should highly prioritize post-deployment accountability. We suggest that U.S. government agencies and professional societies should highly prioritize policies that support responsible AI research and that states should highly prioritize support of responsible AI education. We propose that companies can highly prioritize involving community stakeholders in development efforts and supporting diversity in AI development. We advise lower levels of prioritization across institutions for AI ethics statements and databases of AI technologies or incidents. We recognize that no one policy will lead to responsible AI and instead advocate for strategic policy implementation across institutions.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Emily Hadley",
      "keywords": "Software deployment; Accountability; Audit; Government (linguistics); Business; Prioritization; Legislature; Public policy; Public administration; Public relations; Political science; Accounting; Process management; Economics; Economic growth; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.00740",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404449902",
      "doi": "10.48550/arxiv.2411.09050",
      "title": "The Systems Engineering Approach in Times of Large Language Models",
      "abstract": "Using Large Language Models (LLMs) to address critical societal problems requires adopting this novel technology into socio-technical systems. However, the complexity of such systems and the nature of LLMs challenge such a vision. It is unlikely that the solution to such challenges will come from the Artificial Intelligence (AI) community itself. Instead, the Systems Engineering approach is better equipped to facilitate the adoption of LLMs by prioritising the problems and their context before any other aspects. This paper introduces the challenges LLMs generate and surveys systems research efforts for engineering AI-based systems. We reveal how the systems engineering principles have supported addressing similar issues to the ones LLMs pose and discuss our findings to provide future directions for adopting LLMs.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Christian Cabrera et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.09050",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415307578",
      "doi": "10.48550/arxiv.2504.17544",
      "title": "Auditing the Ethical Logic of Generative AI Models",
      "abstract": "As generative AI models become increasingly integrated into high-stakes domains, the need for robust methods to evaluate their ethical reasoning becomes increasingly important. This paper introduces a five-dimensional audit model -- assessing Analytic Quality, Breadth of Ethical Considerations, Depth of Explanation, Consistency, and Decisiveness -- to evaluate the ethical logic of leading large language models (LLMs). Drawing on traditions from applied ethics and higher-order thinking, we present a multi-battery prompt approach, including novel ethical dilemmas, to probe the models' reasoning across diverse contexts. We benchmark seven major LLMs finding that while models generally converge on ethical decisions, they vary in explanatory rigor and moral prioritization. Chain-of-Thought prompting and reasoning-optimized models significantly enhance performance on our audit metrics. This study introduces a scalable methodology for ethical benchmarking of AI systems and highlights the potential for AI to complement human moral reasoning in complex decision-making contexts.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "W. Russell Neuman et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.17544",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4407122907",
      "doi": "10.48550/arxiv.2502.00014",
      "title": "Algorithmic Bias and the New Chicago School",
      "abstract": "AI systems are increasingly deployed in both public and private sectors to independently make complicated decisions with far-reaching impact on individuals and the society. However, many AI algorithms are biased in the collection or processing of data, resulting in prejudiced decisions based on demographic features. Algorithmic biases occur because of the training data fed into the AI system or the design of algorithmic models. While most legal scholars propose a direct-regulation approach associated with the right of explanation or transparency obligation, this article provides a different picture regarding how indirect regulation can be used to regulate algorithmic bias based on the New Chicago School framework developed by Lawrence Lessig. This article concludes that an effective regulatory approach toward algorithmic bias will be the right mixture of direct and indirect regulations through architecture, norms, market, and the law.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "J. Hannah Lee",
      "keywords": "Computer science; Mathematics education; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2502.00014",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396914109",
      "doi": "10.48550/arxiv.2405.07893",
      "title": "Science based AI model certification for new operational environments with application in traffic state estimation",
      "abstract": "The expanding role of Artificial Intelligence (AI) in diverse engineering domains highlights the challenges associated with deploying AI models in new operational environments, involving substantial investments in data collection and model training. Rapid application of AI necessitates evaluating the feasibility of utilizing pre-trained models in unobserved operational settings with minimal or no additional data. However, interpreting the opaque nature of AI's black-box models remains a persistent challenge. Addressing this issue, this paper proposes a science-based certification methodology to assess the viability of employing pre-trained data-driven models in new operational environments. The methodology advocates a profound integration of domain knowledge, leveraging theoretical and analytical models from physics and related disciplines, with data-driven AI models. This novel approach introduces tools to facilitate the development of secure engineering systems, providing decision-makers with confidence in the trustworthiness and safety of AI-based models across diverse environments characterized by limited training data and dynamic, uncertain conditions. The paper demonstrates the efficacy of this methodology in real-world safety-critical scenarios, particularly in the context of traffic state estimation. Through simulation results, the study illustrates how the proposed methodology efficiently quantifies physical inconsistencies exhibited by pre-trained AI models. By utilizing analytical models, the methodology offers a means to gauge the applicability of pre-trained AI models in new operational environments. This research contributes to advancing the understanding and deployment of AI models, offering a robust certification framework that enhances confidence in their reliability and safety across a spectrum of operational conditions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Daryl Mupupuni et al.",
      "keywords": "State (computer science); Certification; Estimation; Computer science; Operations research; Data science; Industrial engineering; Systems engineering; Engineering; Political science; Algorithm",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.07893",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416118118",
      "doi": "10.48550/arxiv.2504.05007",
      "title": "Measuring the right thing: justifying metrics in AI impact assessments",
      "abstract": "AI Impact Assessments are only as good as the measures used to assess the impact of these systems. It is therefore paramount that we can justify our choice of metrics in these assessments, especially for difficult to quantify ethical and social values. We present a two-step approach to ensure metrics are properly motivated. First, a conception needs to be spelled out (e.g. Rawlsian fairness or fairness as solidarity) and then a metric can be fitted to that conception. Both steps require separate justifications, as conceptions can be judged on how well they fit with the function of, for example, fairness. We argue that conceptual engineering offers helpful tools for this step. Second, metrics need to be fitted to a conception. We illustrate this process through an examination of competing fairness metrics to illustrate that here the additional content that a conception offers helps us justify the choice for a specific metric. We thus advocate that impact assessments are not only clear on their metrics, but also on the conceptions that motivate those metrics.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Stefan Buijsman et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.05007",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4404305064",
      "doi": "10.48550/arxiv.2410.17492",
      "title": "BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers",
      "abstract": "Attacking fairness is crucial because compromised models can introduce biased outcomes, undermining trust and amplifying inequalities in sensitive applications like hiring, healthcare, and law enforcement. This highlights the urgent need to understand how fairness mechanisms can be exploited and to develop defenses that ensure both fairness and robustness. We introduce BadFair, a novel backdoored fairness attack methodology. BadFair stealthily crafts a model that operates with accuracy and fairness under regular conditions but, when activated by certain triggers, discriminates and produces incorrect results for specific groups. This type of attack is particularly stealthy and dangerous, as it circumvents existing fairness detection methods, maintaining an appearance of fairness in normal use. Our findings reveal that BadFair achieves a more than 85% attack success rate in attacks aimed at target groups on average while only incurring a minimal accuracy loss. Moreover, it consistently exhibits a significant discrimination score, distinguishing between pre-defined target and non-target attacked groups across various datasets and models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiaqi Xue et al.",
      "keywords": "Group (periodic table); Psychology; Computer security; Business; Computer science; Social psychology; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.17492",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417525072",
      "doi": "10.48550/arxiv.2504.21634",
      "title": "Quantitative Auditing of AI Fairness with Differentially Private Synthetic Data",
      "abstract": "Fairness auditing of AI systems can identify and quantify biases. However, traditional auditing using real-world data raises security and privacy concerns. It exposes auditors to security risks as they become custodians of sensitive information and targets for cyberattacks. Privacy risks arise even without direct breaches, as data analyses can inadvertently expose confidential information. To address these, we propose a framework that leverages differentially private synthetic data to audit the fairness of AI systems. By applying privacy-preserving mechanisms, it generates synthetic data that mirrors the statistical properties of the original dataset while ensuring privacy. This method balances the goal of rigorous fairness auditing and the need for strong privacy protections. Through experiments on real datasets like Adult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real data. By analyzing the alignment and discrepancies between these metrics, we assess the capacity of synthetic data to preserve the fairness properties of real data. Our results demonstrate the framework's ability to enable meaningful fairness evaluations while safeguarding sensitive information, proving its applicability across critical and sensitive domains.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Chih-Cheng Rex Yuan et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.21634",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416073762",
      "doi": "10.48550/arxiv.2506.03801",
      "title": "From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation",
      "abstract": "Traditional Business Process Management (BPM) struggles with rigidity, opacity, and scalability in dynamic environments while emerging Large Language Models (LLMs) present transformative opportunities alongside risks. This paper explores four real-world use cases that demonstrate how LLMs, augmented with trustworthy process intelligence, redefine process modeling, prediction, and automation. Grounded in early-stage research projects with industrial partners, the work spans manufacturing, modeling, life-science, and design processes, addressing domain-specific challenges through human-AI collaboration. In manufacturing, an LLM-driven framework integrates uncertainty-aware explainable Machine Learning (ML) with interactive dialogues, transforming opaque predictions into auditable workflows. For process modeling, conversational interfaces democratize BPMN design. Pharmacovigilance agents automate drug safety monitoring via knowledge-graph-augmented LLMs. Finally, sustainable textile design employs multi-agent systems to navigate regulatory and environmental trade-offs. We intend to examine tensions between transparency and efficiency, generalization and specialization, and human agency versus automation. By mapping these trade-offs, we advocate for context-sensitive integration prioritizing domain needs, stakeholder values, and iterative human-in-the-loop workflows over universal solutions. This work provides actionable insights for researchers and practitioners aiming to operationalize LLMs in critical BPM environments.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "P\u00e9ter Pfeiffer et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.03801",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415199950",
      "doi": "10.48550/arxiv.2505.10300",
      "title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages",
      "abstract": "Responsible AI (RAI) efforts increasingly emphasize the importance of addressing potential harms early in the AI development lifecycle through social-technical lenses. However, in cross-functional industry teams, this work is often stalled by a persistent knowledge handoff challenge: the difficulty of transferring high-level, early-stage technical design rationales from technical experts to non-technical or user-facing roles for ethical evaluation and harm identification. Through literature review and a co-design study with 8 practitioners, we unpack how this challenge manifests -- technical design choices are rarely handed off in ways that support meaningful engagement by non-technical roles; collaborative workflows lack shared, visual structures to support mutual understanding; and non-technical practitioners are left without scaffolds for systematic harm evaluation. Existing tools like JIRA or Google Docs, while useful for product tracking, are ill-suited for supporting joint harm identification across roles, often requiring significant extra effort to align understanding. To address this, we developed AI LEGO, a web-based prototype that supports cross-functional AI practitioners in effectively facilitating knowledge handoff and identifying harmful design choices in the early design stages. Technical roles use interactive blocks to draft development plans, while non-technical roles engage with those blocks through stage-specific checklists and LLM-driven persona simulations to surface potential harms. In a study with 18 cross-functional practitioners, AI LEGO increased the volume and likelihood of harms identified compared to baseline worksheets. Participants found that its modular structure and persona prompts made harm identification more accessible, fostering clearer and more collaborative RAI practices in early design.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mengyao Wu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.10300",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416928738",
      "doi": "10.48550/arxiv.2504.19956",
      "title": "Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents",
      "abstract": "As generative AI (GenAI) agents become more common in enterprise settings, they introduce security challenges that differ significantly from those posed by traditional systems. These agents are not just LLMs; they reason, remember, and act, often with minimal human oversight. This paper introduces a comprehensive threat model tailored specifically for GenAI agents, focusing on how their autonomy, persistent memory access, complex reasoning, and tool integration create novel risks. This research work identifies 9 primary threats and organizes them across five key domains: cognitive architecture vulnerabilities, temporal persistence threats, operational execution vulnerabilities, trust boundary violations, and governance circumvention. These threats are not just theoretical they bring practical challenges such as delayed exploitability, cross-system propagation, cross system lateral movement, and subtle goal misalignments that are hard to detect with existing frameworks and standard approaches. To help address this, the research work present two complementary frameworks: ATFAA - Advanced Threat Framework for Autonomous AI Agents, which organizes agent-specific risks, and SHIELD, a framework proposing practical mitigation strategies designed to reduce enterprise exposure. While this work builds on existing work in LLM and AI security, the focus is squarely on what makes agents different and why those differences matter. Ultimately, this research argues that GenAI agents require a new lens for security. If we fail to adapt our threat models and defenses to account for their unique architecture and behavior, we risk turning a powerful new tool into a serious enterprise liability.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Vineeth Sai Narajala et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.19956",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393023634",
      "doi": "10.48550/arxiv.2403.11046",
      "title": "Regulating Chatbot Output via Inter-Informational Competition",
      "abstract": "The advent of ChatGPT has sparked over a year of regulatory frenzy. However, few existing studies have rigorously questioned the assumption that, if left unregulated, AI chatbot's output would inflict tangible, severe real harm on human affairs. Most researchers have overlooked the critical possibility that the information market itself can effectively mitigate these risks and, as a result, they tend to use regulatory tools to address the issue directly. This Article develops a yardstick for reevaluating both AI-related content risks and corresponding regulatory proposals by focusing on inter-informational competition among various outlets. The decades-long history of regulating information and communications technologies indicates that regulators tend to err too much on the side of caution and to put forward excessive regulatory measures when encountering the uncertainties brought about by new technologies. In fact, a trove of empirical evidence has demonstrated that market competition among information outlets can effectively mitigate most risks and that overreliance on regulation is not only unnecessary but detrimental, as well. This Article argues that sufficient competition among chatbots and other information outlets in the information marketplace can sufficiently mitigate and even resolve most content risks posed by generative AI technologies. This renders certain loudly advocated regulatory strategies, like mandatory prohibitions, licensure, curation of datasets, and notice-and-response regimes, truly unnecessary and even toxic to desirable competition and innovation throughout the AI industry. Ultimately, the ideas that I advance in this Article should pour some much-needed cold water on the regulatory frenzy over generative AI and steer the issue back to a rational track.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiawei Zhang",
      "keywords": "Chatbot; Competition (biology); Business; Computer science; Industrial organization; World Wide Web; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.11046",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4403763021",
      "doi": "10.48550/arxiv.2409.13524",
      "title": "Contextualized AI for Cyber Defense: An Automated Survey using LLMs",
      "abstract": "This paper surveys the potential of contextualized AI in enhancing cyber defense capabilities, revealing significant research growth from 2015 to 2024. We identify a focus on robustness, reliability, and integration methods, while noting gaps in organizational trust and governance frameworks. Our study employs two LLM-assisted literature survey methodologies: (A) ChatGPT 4 for exploration, and (B) Gemma 2:9b for filtering with Claude 3.5 Sonnet for full-text analysis. We discuss the effectiveness and challenges of using LLMs in academic research, providing insights for future researchers.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Christoforus Yoga Haryanto et al.",
      "keywords": "Computer security; Psychology; Computer science; Political science; Data science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.13524",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4400668378",
      "doi": "10.48550/arxiv.2407.09322",
      "title": "Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of AI in Mobile and Wearable Uses",
      "abstract": "Integrating Artificial Intelligence (AI) into mobile and wearables offers numerous benefits at individual, societal, and environmental levels. Yet, it also spotlights concerns over emerging risks. Traditional assessments of risks and benefits have been sporadic, and often require costly expert analysis. We developed a semi-automatic method that leverages Large Language Models (LLMs) to identify AI uses in mobile and wearables, classify their risks based on the EU AI Act, and determine their benefits that align with globally recognized long-term sustainable development goals; a manual validation of our method by two experts in mobile and wearable technologies, a legal and compliance expert, and a cohort of nine individuals with legal backgrounds who were recruited from Prolific, confirmed its accuracy to be over 85\\%. We uncovered that specific applications of mobile computing hold significant potential in improving well-being, safety, and social equality. However, these promising uses are linked to risks involving sensitive data, vulnerable groups, and automated decision-making. To avoid rejecting these risky yet impactful mobile and wearable uses, we propose a risk assessment checklist for the Mobile HCI community.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Marios Constantinides et al.",
      "keywords": "Wearable computer; Wearable technology; Internet privacy; Business; Computer science; Risk analysis (engineering); Computer security; Advertising; Embedded system",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.09322",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414588097",
      "doi": "10.48550/arxiv.2505.20136",
      "title": "Engineering Trustworthy Machine-Learning Operations with Zero-Knowledge Proofs",
      "abstract": "As Artificial Intelligence (AI) systems, particularly those based on machine learning (ML), become integral to high-stakes applications, their probabilistic and opaque nature poses significant challenges to traditional verification and validation methods. These challenges are exacerbated in regulated sectors requiring tamper-proof, auditable evidence, as highlighted by apposite legal frameworks, e.g., the EU AI Act. Conversely, Zero-Knowledge Proofs (ZKPs) offer a cryptographic solution that enables provers to demonstrate, through verified computations, adherence to set requirements without revealing sensitive model details or data. Through a systematic survey of ZKP protocols, we identify five key properties (non-interactivity, transparent setup, standard representations, succinctness, and post-quantum security) critical for their application in AI validation and verification pipelines. Subsequently, we perform a follow-up systematic survey analyzing ZKP-enhanced ML applications across an adaptation of the Team Data Science Process (TDSP) model (Data &amp; Preprocessing, Training &amp; Offline Metrics, Inference, and Online Metrics), detailing verification objectives, ML models, and adopted protocols. Our findings indicate that current research on ZKP-Enhanced ML primarily focuses on inference verification, while the data preprocessing and training stages remain underexplored. Most notably, our analysis identifies a significant convergence within the research domain toward the development of a unified Zero-Knowledge Machine Learning Operations (ZKMLOps) framework. This emerging framework leverages ZKPs to provide robust cryptographic guarantees of correctness, integrity, and privacy, thereby promoting enhanced accountability, transparency, and compliance with Trustworthy AI principles.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Filippo Scaramuzza et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.20136",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288049930",
      "doi": "10.48550/arxiv.2202.01327",
      "title": "Adaptive Sampling Strategies to Construct Equitable Training Datasets",
      "abstract": "In domains ranging from computer vision to natural language processing, machine learning models have been shown to exhibit stark disparities, often performing worse for members of traditionally underserved groups. One factor contributing to these performance gaps is a lack of representation in the data the models are trained on. It is often unclear, however, how to operationalize representativeness in specific applications. Here we formalize the problem of creating equitable training datasets, and propose a statistical framework for addressing this problem. We consider a setting where a model builder must decide how to allocate a fixed data collection budget to gather training data from different subgroups. We then frame dataset creation as a constrained optimization problem, in which one maximizes a function of group-specific performance metrics based on (estimated) group-specific learning rates and costs per sample. This flexible approach incorporates preferences of model-builders and other stakeholders, as well as the statistical properties of the learning task. When data collection decisions are made sequentially, we show that under certain conditions this optimization problem can be efficiently solved even without prior knowledge of the learning rates. To illustrate our approach, we conduct a simulation study of polygenic risk scores on synthetic genomic data -- an application domain that often suffers from non-representative data collection. We find that our adaptive sampling strategy outperforms several common data collection heuristics, including equal and proportional sampling, demonstrating the value of strategic dataset design for building equitable models.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "William Cai et al.",
      "keywords": "Computer science; Heuristics; Machine learning; Representativeness heuristic; Data collection; Operationalization; Artificial intelligence; Sample (material); Adaptive sampling; Sampling (signal processing); Sample size determination; Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.01327",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4379958414",
      "doi": "10.48550/arxiv.2306.04489",
      "title": "Fair Column Subset Selection",
      "abstract": "The problem of column subset selection asks for a subset of columns from an input matrix such that the matrix can be reconstructed as accurately as possible within the span of the selected columns. A natural extension is to consider a setting where the matrix rows are partitioned into two groups, and the goal is to choose a subset of columns that minimizes the maximum reconstruction error of both groups, relative to their respective best rank-k approximation. Extending the known results of column subset selection to this fair setting is not straightforward: in certain scenarios it is unavoidable to choose columns separately for each group, resulting in double the expected column count. We propose a deterministic leverage-score sampling strategy for the fair setting and show that sampling a column subset of minimum size becomes NP-hard in the presence of two groups. Despite these negative results, we give an approximation algorithm that guarantees a solution within 1.5 times the optimal solution size. We also present practical heuristic algorithms based on rank-revealing QR factorization. Finally, we validate our methods through an extensive set of experiments using real-world data.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Antonis Matakos et al.",
      "keywords": "Leverage (statistics); Column (typography); Selection (genetic algorithm); Sampling (signal processing); Set (abstract data type); Mathematics; Computer science; Rank (graph theory); Algorithm; Combinatorics; Statistics; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.04489",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399795091",
      "doi": "10.48550/arxiv.2406.11391",
      "title": "P-TA: Using Proximal Policy Optimization to Enhance Tabular Data Augmentation via Large Language Models",
      "abstract": "A multitude of industries depend on accurate and reasonable tabular data augmentation for their business processes. Contemporary methodologies in generating tabular data revolve around utilizing Generative Adversarial Networks (GAN) or fine-tuning Large Language Models (LLM). However, GAN-based approaches are documented to produce samples with common-sense errors attributed to the absence of external knowledge. On the other hand, LLM-based methods exhibit a limited capacity to capture the disparities between synthesized and actual data distribution due to the absence of feedback from a discriminator during training. Furthermore, the decoding of LLM-based generation introduces gradient breakpoints, impeding the backpropagation of loss from a discriminator, thereby complicating the integration of these two approaches. To solve this challenge, we propose using proximal policy optimization (PPO) to apply GANs, guiding LLMs to enhance the probability distribution of tabular features. This approach enables the utilization of LLMs as generators for GANs in synthesizing tabular data. Our experiments demonstrate that PPO leads to an approximately 4\\% improvement in the accuracy of models trained on synthetically generated data over state-of-the-art across three real-world datasets.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuo Yang et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.11391",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4403624801",
      "doi": "10.48550/arxiv.2409.06708",
      "title": "Ensuring Fairness with Transparent Auditing of Quantitative Bias in AI Systems",
      "abstract": "With the rapid advancement of AI, there is a growing trend to integrate AI into decision-making processes. However, AI systems may exhibit biases that lead decision-makers to draw unfair conclusions. Notably, the COMPAS system used in the American justice system to evaluate recidivism was found to favor racial majority groups; specifically, it violates a fairness standard called equalized odds. Various measures have been proposed to assess AI fairness. We present a framework for auditing AI fairness, involving third-party auditors and AI system providers, and we have created a tool to facilitate systematic examination of AI systems. The tool is open-sourced and publicly available. Unlike traditional AI systems, we advocate a transparent white-box and statistics-based approach. It can be utilized by third-party auditors, AI developers, or the general public for reference when judging the fairness criterion of AI systems.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Chih-Cheng Rex Yuan et al.",
      "keywords": "Audit; Business; Computer science; Accounting",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.06708",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415312607",
      "doi": "10.48550/arxiv.2506.14680",
      "title": "Which Humans? Inclusivity and Representation in Human-Centered AI",
      "abstract": "As AI systems continue to spread and become integrated into many aspects of society, the concept of \"human-centered AI\" has gained increasing prominence, raising the critical question of which humans are the AI systems to be centered around.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Rada Mihalcea et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.14680",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4294529975",
      "doi": "10.48550/arxiv.2209.00366",
      "title": "How to Evaluate Explainability? -- A Case for Three Criteria",
      "abstract": "The increasing complexity of software systems and the influence of software-supported decisions in our society have sparked the need for software that is safe, reliable, and fair. Explainability has been identified as a means to achieve these qualities. It is recognized as an emerging non-functional requirement (NFR) that has a significant impact on system quality. However, in order to develop explainable systems, we need to understand when a system satisfies this NFR. To this end, appropriate evaluation methods are required. However, the field is crowded with evaluation methods, and there is no consensus on which are the \"right\" ones. Much less, there is not even agreement on which criteria should be evaluated. In this vision paper, we will provide a multidisciplinary motivation for three such quality criteria concerning the information that systems should provide: comprehensibility, fidelity, and assessability. Our aim is to to fuel the discussion regarding these criteria, such that adequate evaluation methods for them will be conceived.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Timo Speith",
      "keywords": "Fidelity; Computer science; Multidisciplinary approach; Quality (philosophy); Field (mathematics); Risk analysis (engineering); Software; Software quality; Order (exchange); Management science; Software development; Engineering; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.00366",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4404648159",
      "doi": "10.48550/arxiv.2411.12759",
      "title": "A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery",
      "abstract": "The increasing use of large language models (LLMs) in causal discovery as a substitute for human domain experts highlights the need for optimal model selection. This paper presents the first hallucination survey of popular LLMs for causal discovery. We show that hallucinations exist when using LLMs in causal discovery so the choice of LLM is important. We propose using Retrieval Augmented Generation (RAG) to reduce hallucinations when quality data is available. Additionally, we introduce a novel method employing multiple LLMs with an arbiter in a debate to audit edges in causal graphs, achieving a comparable reduction in hallucinations to RAG.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Grace Sng et al.",
      "keywords": "Language model; Computer science; Psychology; Cognitive science; Cognitive psychology; Natural language processing; Data science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.12759",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414940253",
      "doi": "10.48550/arxiv.2505.09595",
      "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models",
      "abstract": "Large Language Models (LLMs) are predominantly trained and aligned in ways that reinforce Western-centric epistemologies and socio-cultural norms, leading to cultural homogenization and limiting their ability to reflect global civilizational plurality. Existing benchmarking frameworks fail to adequately capture this bias, as they rely on rigid, closed-form assessments that overlook the complexity of cultural inclusivity. To address this, we introduce WorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity (GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our approach is grounded in the Multiplex Worldview proposed by Senturk et al., which distinguishes between Uniplex models, reinforcing cultural homogenization, and Multiplex models, which integrate diverse perspectives. WorldView-Bench measures Cultural Polarization, the exclusion of alternative perspectives, through free-form generative evaluation rather than conventional categorical benchmarks. We implement applied multiplexity through two intervention strategies: (1) Contextually-Implemented Multiplex LLMs, where system prompts embed multiplexity principles, and (2) Multi-Agent System (MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing distinct cultural perspectives collaboratively generate responses. Our results demonstrate a significant increase in Perspectives Distribution Score (PDS) entropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs, alongside a shift toward positive sentiment (67.7%) and enhanced cultural balance. These findings highlight the potential of multiplex-aware AI evaluation in mitigating cultural bias in LLMs, paving the way for more inclusive and ethically aligned AI systems.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "A. Mushtaq et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.09595",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392736656",
      "doi": "10.48550/arxiv.2403.05668",
      "title": "CFaiRLLM: Consumer Fairness Evaluation in Large-Language Model Recommender System",
      "abstract": "This work takes a critical stance on previous studies concerning fairness evaluation in Large Language Model (LLM)-based recommender systems, which have primarily assessed consumer fairness by comparing recommendation lists generated with and without sensitive user attributes. Such approaches implicitly treat discrepancies in recommended items as biases, overlooking whether these changes might stem from genuine personalization aligned with the true preferences of users. Moreover, these earlier studies typically address single sensitive attributes in isolation, neglecting the complex interplay of intersectional identities. In response to these shortcomings, we introduce CFaiRLLM, an enhanced evaluation framework that not only incorporates true preference alignment but also rigorously examines intersectional fairness by considering overlapping sensitive attributes. Additionally, CFaiRLLM introduces diverse user profile sampling strategies-random, top-rated, and recency-focused-to better understand the impact of profile generation fed to LLMs in light of inherent token limitations in these systems. Given that fairness depends on accurately understanding users' tastes and preferences, these strategies provide a more realistic assessment of fairness within RecLLMs. To validate the efficacy of CFaiRLLM, we conducted extensive experiments using MovieLens and LastFM datasets, applying various sampling strategies and sensitive attribute configurations. The evaluation metrics include both item similarity measures and true preference alignment considering both hit and ranking (Jaccard Similarity and PRAG), thereby conducting a multifaceted analysis of recommendation fairness.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yashar Deldjoo et al.",
      "keywords": "Recommender system; Computer science; Information retrieval",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.05668",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416611636",
      "doi": "10.48550/arxiv.2505.23397",
      "title": "A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy",
      "abstract": "This article presents a structured framework for Human-AI collaboration in Security Operations Centers (SOCs), integrating AI autonomy, trust calibration, and Human-in-the-loop decision making. Existing frameworks in SOCs often focus narrowly on automation, lacking systematic structures to manage human oversight, trust calibration, and scalable autonomy with AI. Many assume static or binary autonomy settings, failing to account for the varied complexity, criticality, and risk across SOC tasks considering Humans and AI collaboration. To address these limitations, we propose a novel autonomy tiered framework grounded in five levels of AI autonomy from manual to fully autonomous, mapped to Human-in-the-Loop (HITL) roles and task-specific trust thresholds. This enables adaptive and explainable AI integration across core SOC functions, including monitoring, protection, threat detection, alert triage, and incident response. The proposed framework differentiates itself from previous research by creating formal connections between autonomy, trust, and HITL across various SOC levels, which allows for adaptive task distribution according to operational complexity and associated risks. The framework is exemplified through a simulated cyber range that features the cybersecurity AI-Avatar, a fine-tuned LLM-based SOC assistant. The AI-Avatar case study illustrates human-AI collaboration for SOC tasks, reducing alert fatigue, enhancing response coordination, and strategically calibrating trust. This research systematically presents both the theoretical and practical aspects and feasibility of designing next-generation cognitive SOCs that leverage AI not to replace but to enhance human decision-making.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Ahmad Mohsin et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23397",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416013185",
      "doi": "10.48550/arxiv.2505.04313",
      "title": "KERAIA: An Adaptive and Explainable Framework for Dynamic Knowledge Representation and Reasoning",
      "abstract": "In this paper, we introduce KERAIA, a novel framework and software platform for symbolic knowledge engineering designed to address the persistent challenges of representing, reasoning with, and executing knowledge in dynamic, complex, and context-sensitive environments. The central research question that motivates this work is: How can unstructured, often tacit, human expertise be effectively transformed into computationally tractable algorithms that AI systems can efficiently utilise? KERAIA seeks to bridge this gap by building on foundational concepts such as Minsky's frame-based reasoning and K-lines, while introducing significant innovations. These include Clouds of Knowledge for dynamic aggregation, Dynamic Relations (DRels) for context-sensitive inheritance, explicit Lines of Thought (LoTs) for traceable reasoning, and Cloud Elaboration for adaptive knowledge transformation. This approach moves beyond the limitations of traditional, often static, knowledge representation paradigms. KERAIA is designed with Explainable AI (XAI) as a core principle, ensuring transparency and interpretability, particularly through the use of LoTs. The paper details the framework's architecture, the KSYNTH representation language, and the General Purpose Paradigm Builder (GPPB) to integrate diverse inference methods within a unified structure. We validate KERAIA's versatility, expressiveness, and practical applicability through detailed analysis of multiple case studies spanning naval warfare simulation, industrial diagnostics in water treatment plants, and strategic decision-making in the game of RISK. Furthermore, we provide a comparative analysis against established knowledge representation paradigms (including ontologies, rule-based systems, and knowledge graphs) and discuss the implementation aspects and computational considerations of the KERAIA platform.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Stephen Richard Varey et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04313",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4406093143",
      "doi": "10.48550/arxiv.2501.01793",
      "title": "Creating Artificial Students that Never Existed: Leveraging Large Language Models and CTGANs for Synthetic Data Generation",
      "abstract": "In this study, we explore the growing potential of AI and deep learning technologies, particularly Generative Adversarial Networks (GANs) and Large Language Models (LLMs), for generating synthetic tabular data. Access to quality students data is critical for advancing learning analytics, but privacy concerns and stricter data protection regulations worldwide limit their availability and usage. Synthetic data offers a promising alternative. We investigate whether synthetic data can be leveraged to create artificial students for serving learning analytics models. Using the popular GAN model CTGAN and three LLMs- GPT2, DistilGPT2, and DialoGPT, we generate synthetic tabular student data. Our results demonstrate the strong potential of these methods to produce high-quality synthetic datasets that resemble real students data. To validate our findings, we apply a comprehensive set of utility evaluation metrics to assess the statistical and predictive performance of the synthetic data and compare the different generator models used, specially the performance of LLMs. Our study aims to provide the learning analytics community with valuable insights into the use of synthetic data, laying the groundwork for expanding the field methodological toolbox with new innovative approaches for learning analytics data generation.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mohammad Khalil et al.",
      "keywords": "Computer science; Artificial intelligence; Data science; Mathematics education; Natural language processing; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2501.01793",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404088116",
      "doi": "10.48550/arxiv.2410.14825",
      "title": "Redesigning Service Level Agreements: Equity and Efficiency in City Government Operations",
      "abstract": "We consider government service allocation -- how the government allocates resources (e.g., maintenance of public infrastructure) over time. It is important to make these decisions efficiently and equitably -- though these desiderata may conflict. In particular, we consider the design of Service Level Agreements (SLA) in city government operations: promises that incidents such as potholes and fallen trees will be responded to within a certain time. We model the problem of designing a set of SLAs as an optimization problem with equity and efficiency objectives under a queuing network framework; the city has two decision levers: how to allocate response budgets to different neighborhoods, and how to schedule responses to individual incidents. We: (1) Theoretically analyze a stylized model and find that the \"price of equity\" is small in realistic settings; (2) Develop a simulation-optimization framework to optimize policies in practice; (3) Apply our framework empirically using data from NYC, finding that: (a) status quo inspections are highly inefficient and inequitable compared to optimal ones, and (b) in practice, the equity-efficiency trade-off is not substantial: generally, inefficient policies are inequitable, and vice versa.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhi Liu et al.",
      "keywords": "Equity (law); Business; Government (linguistics); Finance; Service (business); Service level; Marketing; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.14825",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387031661",
      "doi": "10.48550/arxiv.2309.12941",
      "title": "Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models",
      "abstract": "Assurance cases can be used to argue for the safety of products in safety engineering. In safety-critical areas, the construction of assurance cases is indispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance cases by incorporating formal methods, rendering it possible for automatic reasoning about assurance cases. We present Trustworthiness Derivation Tree Analyzer (Trusta), a desktop application designed to automatically construct and verify TDTs. The tool has a built-in Prolog interpreter in its backend, and is supported by the constraint solvers Z3 and MONA. Therefore, it can solve constraints about logical formulas involving arithmetic, sets, Horn clauses etc. Trusta also utilizes large language models to make the creation and evaluation of assurance cases more convenient. It allows for interactive human examination and modification. We evaluated top language models like ChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our tests showed a 50%-80% similarity between machine-generated and human-created cases. In addition, Trusta can extract formal constraints from text in natural languages, facilitating an easier interpretation and validation process. This extraction is subject to human review and correction, blending the best of automated efficiency with human insight. To our knowledge, this marks the first integration of large language models in automatic creating and reasoning about assurance cases, bringing a novel approach to a traditional challenge. Through several industrial case studies, Trusta has proven to quickly find some subtle issues that are typically missed in manual inspection, demonstrating its practical value in enhancing the assurance case development process.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Zezhong Chen et al.",
      "keywords": "Computer science; Prolog; Interpreter; Process (computing); Rendering (computer graphics); Artificial intelligence; Software engineering; Quality assurance; Formal methods; Construct (python library); Programming language; Natural language processing; Service (business)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.12941",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287375093",
      "doi": "10.48550/arxiv.2101.07361",
      "title": "Through the Data Management Lens: Experimental Analysis and Evaluation of Fair Classification",
      "abstract": "Classification, a heavily-studied data-driven machine learning task, drives an increasing number of prediction systems involving critical human decisions such as loan approval and criminal risk assessment. However, classifiers often demonstrate discriminatory behavior, especially when presented with biased data. Consequently, fairness in classification has emerged as a high-priority research area. Data management research is showing an increasing presence and interest in topics related to data and algorithmic fairness, including the topic of fair classification. The interdisciplinary efforts in fair classification, with machine learning research having the largest presence, have resulted in a large number of fairness notions and a wide range of approaches that have not been systematically evaluated and compared. In this paper, we contribute a broad analysis of 13 fair classification approaches and additional variants, over their correctness, fairness, efficiency, scalability, robustness to data errors, sensitivity to underlying ML model, data efficiency, and stability using a variety of metrics and real-world datasets. Our analysis highlights novel insights on the impact of different metrics and high-level approach characteristics on different aspects of performance. We also discuss general principles for choosing approaches suitable for different practical settings, and identify areas where data-management-centric solutions are likely to have the most impact.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Maliha Tashfia Islam et al.",
      "keywords": "Computer science; Correctness; Robustness (evolution); Machine learning; Scalability; Variety (cybernetics); Data science; Data mining; Artificial intelligence; Database",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2101.07361",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396813448",
      "doi": "10.48550/arxiv.2405.03710",
      "title": "Automating the Enterprise with Foundation Models",
      "abstract": "Automating enterprise workflows could unlock $4 trillion/year in productivity gains. Despite being of interest to the data management community for decades, the ultimate vision of end-to-end workflow automation has remained elusive. Current solutions rely on process mining and robotic process automation (RPA), in which a bot is hard-coded to follow a set of predefined rules for completing a workflow. Through case studies of a hospital and large B2B enterprise, we find that the adoption of RPA has been inhibited by high set-up costs (12-18 months), unreliable execution (60% initial accuracy), and burdensome maintenance (requiring multiple FTEs). Multimodal foundation models (FMs) such as GPT-4 offer a promising new approach for end-to-end workflow automation given their generalized reasoning and planning abilities. To study these capabilities we propose ECLAIR, a system to automate enterprise workflows with minimal human supervision. We conduct initial experiments showing that multimodal FMs can address the limitations of traditional RPA with (1) near-human-level understanding of workflows (93% accuracy on a workflow understanding task) and (2) instant set-up with minimal technical barrier (based solely on a natural language description of a workflow, ECLAIR achieves end-to-end completion rates of 40%). We identify human-AI collaboration, validation, and self-improvement as open challenges, and suggest ways they can be solved with data management techniques. Code is available at: https://github.com/HazyResearch/eclair-agents",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Michael Wornow et al.",
      "keywords": "Foundation (evidence); Computer science; Business; Geography; Archaeology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.03710",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415066433",
      "doi": "10.48550/arxiv.2504.16622",
      "title": "Cognitive Silicon: An Architectural Blueprint for Post-Industrial Computing Systems",
      "abstract": "Autonomous AI systems reveal foundational limitations in deterministic, human-authored computing architectures. This paper presents Cognitive Silicon: a hypothetical full-stack architectural framework projected toward 2035, exploring a possible trajectory for cognitive computing system design. The proposed architecture would integrate symbolic scaffolding, governed memory, runtime moral coherence, and alignment-aware execution across silicon-to-semantics layers. Our design grammar has emerged from dialectical co-design with LLMs under asymmetric epistemic conditions--creating structured friction to expose blind spots and trade-offs. The envisioned framework would establish mortality as a natural consequence of physical constraints, non-copyable tacit knowledge, and non-cloneable identity keys as cognitive-embodiment primitives. Core tensions (trust/agency, scaffolding/emergence, execution/governance) would function as central architectural pressures rather than edge cases. The architecture theoretically converges with the Free Energy Principle, potentially offering a formal account of how cognitive systems could maintain identity through prediction error minimization across physical and computational boundaries. The resulting framework aims to deliver a morally tractable cognitive infrastructure that could maintain human-alignment through irreversible hardware constraints and identity-bound epistemic mechanisms resistant to replication or subversion.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Christoforus Yoga Haryanto et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.16622",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400024619",
      "doi": "10.48550/arxiv.2406.16696",
      "title": "Public Constitutional AI",
      "abstract": "We are increasingly subjected to the power of AI authorities. As AI decisions become inescapable, entering domains such as healthcare, education, and law, we must confront a vital question: how can we ensure AI systems have the legitimacy necessary for effective governance? This essay argues that to secure AI legitimacy, we need methods that engage the public in designing and constraining AI systems, ensuring these technologies reflect the community's shared values. Constitutional AI, proposed by Anthropic, represents a step towards this goal, offering a model for democratic control of AI. However, while Constitutional AI's commitment to hardcoding explicit principles into AI models enhances transparency and accountability, it falls short in two crucial aspects: addressing the opacity of individual AI decisions and fostering genuine democratic legitimacy. To overcome these limitations, this essay proposes \"Public Constitutional AI.\" This approach envisions a participatory process where diverse stakeholders, including ordinary citizens, deliberate on the principles guiding AI development. The resulting \"AI Constitution\" would carry the legitimacy of popular authorship, grounding AI governance in the public will. Furthermore, the essay proposes \"AI Courts\" to develop \"AI case law,\" providing concrete examples for operationalizing constitutional principles in AI training. This evolving combination of constitutional principles and case law aims to make AI governance more responsive to public values. By grounding AI governance in deliberative democratic processes, Public Constitutional AI offers a path to imbue automated authorities with genuine democratic legitimacy, addressing the unique challenges posed by increasingly powerful AI systems while ensuring their alignment with the public interest.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Gilad Abiri",
      "keywords": "Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.16696",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415032555",
      "doi": "10.48550/arxiv.2505.02828",
      "title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review",
      "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a pillar of Trustworthy AI and aims to bring transparency in complex models that are opaque by nature. Despite the benefits of incorporating explanations in models, an urgent need is found in addressing the privacy concerns of providing this additional information to end users. In this article, we conduct a scoping review of existing literature to elicit details on the conflict between privacy and explainability. Using the standard methodology for scoping review, we extracted 57 articles from 1,943 studies published from January 2019 to December 2024. The review addresses 3 research questions to present readers with more understanding of the topic: (1) what are the privacy risks of releasing explanations in AI systems? (2) what current methods have researchers employed to achieve privacy preservation in XAI systems? (3) what constitutes a privacy preserving explanation? Based on the knowledge synthesized from the selected studies, we categorize the privacy risks and preservation methods in XAI and propose the characteristics of privacy preserving explanations to aid researchers and practitioners in understanding the requirements of XAI that is privacy compliant. Lastly, we identify the challenges in balancing privacy with other system desiderata and provide recommendations for achieving privacy preserving XAI. We expect that this review will shed light on the complex relationship of privacy and explainability, both being the fundamental principles of Trustworthy AI.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Sonal Allana et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.02828",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415036852",
      "doi": "10.48550/arxiv.2505.21112",
      "title": "Simulating Ethics: Using LLM Debate Panels to Model Deliberation on Medical Dilemmas",
      "abstract": "This paper introduces ADEPT, a system using Large Language Model (LLM) personas to simulate multi-perspective ethical debates. ADEPT assembles panels of 'AI personas', each embodying a distinct ethical framework or stakeholder perspective (like a deontologist, consequentialist, or disability rights advocate), to deliberate on complex moral issues. Its application is demonstrated through a scenario about prioritizing patients for a limited number of ventilators inspired by real-world challenges in allocating scarce medical resources. Two debates, each with six LLM personas, were conducted; they only differed in the moral viewpoints represented: one included a Catholic bioethicist and a care theorist, the other substituted a rule-based Kantian philosopher and a legal adviser. Both panels ultimately favoured the same policy -- a lottery system weighted for clinical need and fairness, crucially avoiding the withdrawal of ventilators for reallocation. However, each panel reached that conclusion through different lines of argument, and their voting coalitions shifted once duty- and rights-based voices were present. Examination of the debate transcripts shows that the altered membership redirected attention toward moral injury, legal risk and public trust, which in turn changed four continuing personas' final positions. The work offers three contributions: (i) a transparent, replicable workflow for running and analysing multi-agent AI debates in bioethics; (ii) evidence that the moral perspectives included in such panels can materially change the outcome even when the factual inputs remain constant; and (iii) an analysis of the implications and future directions for such AI-mediated approaches to ethical deliberation and policy.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Hazem Zohny",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.21112",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403995976",
      "doi": "10.48550/arxiv.2410.14501",
      "title": "Using sensitive data to de-bias AI systems: Article 10(5) of the EU AI Act",
      "abstract": "In June 2024, the EU AI Act came into force. The AI Act includes obligations for the provider of an AI system. Article 10 of the AI Act includes a new obligation for providers to evaluate whether their training, validation and testing datasets meet certain quality criteria, including an appropriate examination of biases in the datasets and correction measures. With the obligation comes a new provision in Article 10(5) AI Act, allowing providers to collect sensitive data to fulfil the obligation. The exception aims to prevent discrimination. In this paper, I research the scope and implications of Article 10(5) AI Act. The paper primarily concerns European Union law, but may be relevant in other parts of the world, as policymakers aim to regulate biases in AI systems.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Marvin van Bekkum",
      "keywords": "Law and economics; Computer science; Political science; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.14501",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390529347",
      "doi": "10.48550/arxiv.2401.00763",
      "title": "New Job, New Gender? Measuring the Social Bias in Image Generation Models",
      "abstract": "Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel evaluation framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race, and age-neutral queries. These queries span 62 professions, 39 activities, 57 types of objects, and 70 personality traits. The framework then compares the edited images to the original seed images, focusing on the significant changes related to gender, race, and age. BiasPainter adopts a key insight that these characteristics should not be modified when subjected to neutral prompts. Built upon this design, BiasPainter can trigger the social bias and evaluate the fairness of image generation models. We use BiasPainter to evaluate six widely-used image generation models, such as stable diffusion and Midjourney. Experimental results show that BiasPainter can successfully trigger social bias in image generation models. According to our human evaluation, BiasPainter can achieve 90.8% accuracy on automatic bias detection, which is significantly higher than the results reported in previous work.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Wenxuan Wang et al.",
      "keywords": "Computer science; Oracle; Image (mathematics); Software; Artificial intelligence; The Internet; Toolbox; Machine learning; Data science; World Wide Web; Software engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.00763",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417170935",
      "doi": "10.48550/arxiv.2504.20676",
      "title": "The Limits of AI Explainability: An Algorithmic Information Theory Approach",
      "abstract": "This paper establishes a theoretical foundation for understanding the fundamental limits of AI explainability through algorithmic information theory. We formalize explainability as the approximation of complex models by simpler ones, quantifying both approximation error and explanation complexity using Kolmogorov complexity. Our key theoretical contributions include: (1) a complexity gap theorem proving that any explanation significantly simpler than the original model must differ from it on some inputs; (2) precise bounds showing that explanation complexity grows exponentially with input dimension but polynomially with error tolerance for Lipschitz functions; and (3) a characterization of the gap between local and global explainability, demonstrating that local explanations can be significantly simpler while maintaining accuracy in relevant regions. We further establish a regulatory impossibility theorem proving that no governance framework can simultaneously pursue unrestricted AI capabilities, human-interpretable explanations, and negligible error. These results highlight considerations likely to be relevant to the design, evaluation, and oversight of explainable AI systems.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Shrisha Rao",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.20676",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4403666374",
      "doi": "10.48550/arxiv.2409.09041",
      "title": "Acceptable Use Policies for Foundation Models",
      "abstract": "As foundation models have accumulated hundreds of millions of users, developers have begun to take steps to prevent harmful types of uses. One salient intervention that foundation model developers adopt is acceptable use policies: legally binding policies that prohibit users from using a model for specific purposes. This paper identifies acceptable use policies from 30 foundation model developers, analyzes the use restrictions they contain, and argues that acceptable use policies are an important lens for understanding the regulation of foundation models. Taken together, developers' acceptable use policies include 127 distinct use restrictions; the wide variety in the number and type of use restrictions may create fragmentation across the AI supply chain. Developers also employ acceptable use policies to prevent competitors or specific industries from making use of their models. Developers alone decide what constitutes acceptable use, and rarely provide transparency about how they enforce their policies. In practice, acceptable use policies are difficult to enforce, and scrupulous enforcement can act as a barrier to researcher access and limit beneficial uses of foundation models. Nevertheless, acceptable use policies for foundation models are an early example of self-regulation that have a significant impact on the market for foundation models and the overall AI ecosystem.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Kevin Klyman",
      "keywords": "Foundation (evidence); Computer science; Political science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.09041",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400479916",
      "doi": "10.48550/arxiv.2407.04961",
      "title": "A PRISMA-Driven Bibliometric Analysis of the Scientific Literature on Assurance Case Patterns",
      "abstract": "Justifying the correct implementation of the non-functional requirements (e.g., safety, security) of mission-critical systems is crucial to prevent system failure. The later could have severe consequences such as the death of people and financial losses. Assurance cases can be used to prevent system failure, They are structured arguments that allow arguing and relaying various safety-critical systems' requirements extensively as well as checking the compliance of such systems with industrial standards to support their certification. Still, the creation of assurance cases is usually manual, error-prone, and time-consuming. Besides, it may involve numerous alterations as the system evolves. To overcome the bottlenecks in creating assurance cases, existing approaches usually promote the reuse of common structured evidence-based arguments (i.e. patterns) to aid the creation of assurance cases. To gain insights into the advancements of the research on assurance case patterns, we relied on SEGRESS to conduct a bibliometric analysis of 92 primary studies published within the past two decades. This allows capturing the evolutionary trends and patterns characterizing the research in that field. Our findings notably indicate the emergence of new assurance case patterns to support the assurance of ML-enabled systems that are characterized by their evolving requirements (e.g., cybersecurity and ethics).",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Oluwafemi Odu et al.",
      "keywords": "Bibliometrics; Management science; Computer science; Data science; Engineering; Library science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.04961",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4414631996",
      "doi": "10.48550/arxiv.2504.15622",
      "title": "Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey",
      "abstract": "With the rapid development of technology and the acceleration of digitalisation, the frequency and complexity of cyber security threats are increasing. Traditional cybersecurity approaches, often based on static rules and predefined scenarios, are struggling to adapt to the rapidly evolving nature of modern cyberattacks. There is an urgent need for more adaptive and intelligent defence strategies. The emergence of Large Language Model (LLM) provides an innovative solution to cope with the increasingly severe cyber threats, and its potential in analysing complex attack patterns, predicting threats and assisting real-time response has attracted a lot of attention in the field of cybersecurity, and exploring how to effectively use LLM to defend against cyberattacks has become a hot topic in the current research field. This survey examines the applications of LLM from the perspective of the cyber attack lifecycle, focusing on the three phases of defense reconnaissance, foothold establishment, and lateral movement, and it analyzes the potential of LLMs in Cyber Threat Intelligence (CTI) tasks. Meanwhile, we investigate how LLM-based security solutions are deployed and applied in different network scenarios. It also summarizes the internal and external risk issues faced by LLM during its application. Finally, this survey also points out the facing risk issues and possible future research directions in this domain.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuang Tian et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.15622",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416013665",
      "doi": "10.48550/arxiv.2505.04403",
      "title": "Blockchain Data Analytics: A Scoping Literature Review and Directions for Future Research",
      "abstract": "Blockchain technology has rapidly expanded beyond its original use in cryptocurrencies to a broad range of applications, creating vast amounts of immutable, decentralized data. As blockchain adoption grows, so does the need for advanced data analytics techniques to extract insights for business intelligence, fraud detection, financial analysis and many more. While previous research has examined specific aspects of blockchain data analytics, such as transaction patterns, illegal activity detection, and data management, there remains a lack of comprehensive reviews that explore the full scope of blockchain data analytics. This study addresses this gap through a scoping literature review, systematically mapping the existing research landscape, identifying key topics, and highlighting emerging trends. Using established methodologies for literature reviews, we analyze 466 publications, clustering them into six major research themes: illegal activity detection, data management, financial analysis, user analysis, community detection, and mining analysis. Our findings reveal a strong focus on detecting illicit activities and financial applications, while holistic business intelligence use cases remain underexplored. This review provides a structured overview of blockchain data analytics, identifying research gaps and proposing future directions to enhance the fields impact.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Marcel B\u00fchlmann et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04403",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388327715",
      "doi": "10.48550/arxiv.2311.00270",
      "title": "Survey on Quality Assurance of Smart Contracts",
      "abstract": "With the increasing adoption of smart contracts, ensuring their security has become a critical concern. Numerous vulnerabilities and attacks have been identified and exploited, resulting in significant financial losses. In response, researchers have developed various tools and techniques to identify and prevent vulnerabilities in smart contracts. In this survey, we present a systematic overview of the quality assurance of smart contracts, covering vulnerabilities, attacks, defenses, and tool support. By classifying vulnerabilities based on known attacks, we can identify patterns and common weaknesses that need to be addressed. Moreover, in order to effectively protect smart contracts, we have created a labeled dataset to evaluate various vulnerability detection tools and compare their effectiveness.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhiyuan Wei et al.",
      "keywords": "Vulnerability (computing); Computer security; Order (exchange); Risk analysis (engineering); Computer science; Quality assurance; Quality (philosophy); Vulnerability assessment; Business; Finance; Marketing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.00270",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4398156915",
      "doi": "10.48550/arxiv.2405.10467",
      "title": "Agent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model based Agents",
      "abstract": "Foundation model-enabled generative artificial intelligence facilitates the development and implementation of agents, which can leverage distinguished reasoning and language processing capabilities to takes a proactive, autonomous role to pursue users' goals. Nevertheless, there is a lack of systematic knowledge to guide practitioners in designing the agents considering challenges of goal-seeking (including generating instrumental goals and plans), such as hallucinations inherent in foundation models, explainability of reasoning process, complex accountability, etc. To address this issue, we have performed a systematic literature review to understand the state-of-the-art foundation model-based agents and the broader ecosystem. In this paper, we present a pattern catalogue consisting of 18 architectural patterns with analyses of the context, forces, and trade-offs as the outcomes from the previous literature review. We propose a decision model for selecting the patterns. The proposed catalogue can provide holistic guidance for the effective use of patterns, and support the architecture design of foundation model-based agents by facilitating goal-seeking and plan generation.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yue Liu et al.",
      "keywords": "Foundation (evidence); Computer science; Architectural pattern; Engineering; Geography; Archaeology; Programming language; Software; Software design",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.10467",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4406073462",
      "doi": "10.48550/arxiv.2407.15909",
      "title": "A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting",
      "abstract": "Artificial Intelligence (AI) models have reached a very significant level of accuracy. While their superior performance offers considerable benefits, their inherent complexity often decreases human trust, which slows their application in high-risk decision-making domains, such as finance. The field of eXplainable AI (XAI) seeks to bridge this gap, aiming to make AI models more understandable. This survey, focusing on published work from the past five years, categorizes XAI approaches that predict financial time series. In this paper, explainability and interpretability are distinguished, emphasizing the need to treat these concepts separately as they are not applied the same way in practice. Through clear definitions, a rigorous taxonomy of XAI approaches, a complementary characterization, and examples of XAI's application in the finance industry, this paper provides a comprehensive view of XAI's current role in finance. It can also serve as a guide for selecting the most appropriate XAI approach for future applications.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Pierre-Daniel Arsenault et al.",
      "keywords": "Series (stratigraphy); Artificial intelligence; Computer science; Geology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.15909",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415334253",
      "doi": "10.48550/arxiv.2506.15568",
      "title": "Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models",
      "abstract": "We present a comprehensive evaluation of gender fairness in large language models (LLMs), focusing on their ability to handle both binary and non-binary genders. While previous studies primarily focus on binary gender distinctions, we introduce the Gender Inclusivity Fairness Index (GIFI), a novel and comprehensive metric that quantifies the diverse gender inclusivity of LLMs. GIFI consists of a wide range of evaluations at different levels, from simply probing the model with respect to provided gender pronouns to testing various aspects of model generation and cognitive behaviors under different gender assumptions, revealing biases associated with varying gender identifiers. We conduct extensive evaluations with GIFI on 22 prominent open-source and proprietary LLMs of varying sizes and capabilities, discovering significant variations in LLMs' gender inclusivity. Our study highlights the importance of improving LLMs' inclusivity, providing a critical benchmark for future advancements in gender fairness in generative models.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhihong Shan et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.15568",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414897500",
      "doi": "10.48550/arxiv.2506.01609",
      "title": "Network Digital Twin for 6G and Beyond: An End-to-End View Across Multi-Domain Network Ecosystems",
      "abstract": "With the rapid development of technology, the number of smart mobile users is increasing, accompanied by growing demands from applications such as virtual/augmented reality (VR/XR), remote surgery, autonomous vehicles, and real-time holographic communications, all of which require high transmission rates and ultra-low latency in 6G and beyond networks (6G+). This poses enormous challenges in efficiently deploying large-scale networks, including network design, planning, troubleshooting, optimization, and maintenance, without affecting the user experience. Network Digital Twin (NDT) has emerged as a potential solution, enabling the creation of a virtual model that reflects the actual network, supporting the simulation of various network designs, applying diverse operating policies, and reproducing complex fault scenarios under real-world conditions. This motivate us for this study, where we provide a comprehensive survey of NDT in the context of 6G+, covering areas such as radio access networks (RAN), transport networks, 5G core networks and beyond (5GCORE+), cloud/edge computing, applications (blockchain, health system, manufacturing, security, and vehicular networks), non-terrestrial networks (NTNs), and quantum networks, from both academic and industrial perspectives. In particular, we are the first to provide an in-depth guide and usage of RAN and 5GCORE+ for NDT. Then, we provide an extensive review of foundation technologies such as transport networks, cloud/edge computing, applications, NTNs, and quantum networks in NDT. Finally, we discuss the key challenges, open issues, and future research directions for NDT in the context of 6G+.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Dinh-Hieu Tran et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01609",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390306367",
      "doi": "10.48550/arxiv.2312.15383",
      "title": "SoK: Technical Implementation and Human Impact of Internet Privacy Regulations",
      "abstract": "Growing recognition of the potential for exploitation of personal data and of the shortcomings of prior privacy regimes has led to the passage of a multitude of new online privacy regulations. Some of these laws -- notably the European Union's General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) -- have been the focus of large bodies of research by the computer science community, while others have received less attention. In this work, we analyze a set of Internet privacy and data protection regulations drawn from around the world -- both those that have frequently been studied by computer scientists and those that have not -- and develop a taxonomy of rights granted and obligations imposed by these laws. We then leverage this taxonomy to systematize 270 technical research papers published in computer science venues that investigate the impact of these laws and explore how technical solutions can complement legal protections. Finally, we analyze the results in this space through an interdisciplinary lens and make recommendations for future work at the intersection of computer science and legal privacy.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Eleanor Birrell et al.",
      "keywords": "Information privacy; Data Protection Act 1998; Internet privacy; The Internet; Leverage (statistics); Privacy by Design; European union; Work (physics); Privacy policy; Computer science; Business; Computer security; Engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2312.15383",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415132923",
      "doi": "10.48550/arxiv.2506.02443",
      "title": "Breaking the Barriers of Text-Hungry and Audio-Deficient AI",
      "abstract": "While global linguistic diversity spans more than 7164 recognized languages, the current dominant architecture of machine intelligence remains fundamentally biased toward written text. This bias excludes over 700 million people particularly in rural and remote regions who are audio-literate. In this work, we introduce a fully textless, audio-to-audio machine intelligence framework designed to serve this underserved population, and all the people who prefer audio-efficiency. Our contributions include novel Audio-to-Audio translation architectures that bypass text entirely, including spectrogram-, scalogram-, wavelet-, and unit-based models. Central to our approach is the Multiscale Audio-Semantic Transform (MAST), a representation that encodes tonal, prosodic, speaker, and expressive features. We further integrate MAST into a fractional diffusion of mean-field-type framework powered by fractional Brownian motion. It enables the generation of high-fidelity, semantically consistent speech without reliance on textual supervision. The result is a robust and scalable system capable of learning directly from raw audio, even in languages that are unwritten or rarely digitized. This work represents a fundamental shift toward audio-native machine intelligence systems, expanding access to language technologies for communities historically left out of the current machine intelligence ecosystem.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Hamidou Tembin\u00e9 et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.02443",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417346923",
      "doi": "10.48550/arxiv.2505.02686",
      "title": "Sailing by the Stars: A Survey on Reward Models and Learning Strategies for Learning from Rewards",
      "abstract": "Recent developments in Large Language Models (LLMs) have shifted from pre-training scaling to post-training and test-time scaling. Across these developments, a key unified paradigm has arisen: Learning from Rewards, where reward signals act as the guiding stars to steer LLM behavior. It has underpinned a wide range of prevalent techniques, such as reinforcement learning (RLHF, RLAIF, DPO, and GRPO), reward-guided decoding, and post-hoc correction. Crucially, this paradigm enables the transition from passive learning from static data to active learning from dynamic feedback. This endows LLMs with aligned preferences and deep reasoning capabilities for diverse tasks. In this survey, we present a comprehensive overview of learning from rewards, from the perspective of reward models and learning strategies across training, inference, and post-inference stages. We further discuss the benchmarks for reward models and the primary applications. Finally we highlight the challenges and future directions. We maintain a paper collection at https://github.com/bobxwu/learning-from-rewards-llm-papers.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiaobao Wu",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.02686",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4315706861",
      "doi": "10.48550/arxiv.2301.04016",
      "title": "Causal Inference for Recommendation: Foundations, Methods and Applications",
      "abstract": "Recommender systems are important and powerful tools for various personalized services. Traditionally, these systems use data mining and machine learning techniques to make recommendations based on correlations found in the data. However, relying solely on correlation without considering the underlying causal mechanism may lead to various practical issues such as fairness, explainability, robustness, bias, echo chamber and controllability problems. Therefore, researchers in related area have begun incorporating causality into recommendation systems to address these issues. In this survey, we review the existing literature on causal inference in recommender systems. We discuss the fundamental concepts of both recommender systems and causal inference as well as their relationship, and review the existing work on causal methods for different problems in recommender systems. Finally, we discuss open problems and future directions in the field of causal inference for recommendations.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuyuan Xu et al.",
      "keywords": "Recommender system; Causal inference; Computer science; Inference; Robustness (evolution); Collaborative filtering; Causality (physics); Field (mathematics); Artificial intelligence; Data science; Machine learning; Econometrics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2301.04016",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2949866548",
      "doi": "10.48550/arxiv.1702.03222",
      "title": "Mining Electronic Health Records: A Survey",
      "abstract": "The continuously increasing cost of the US healthcare system has received significant attention. Central to the ideas aimed at curbing this trend is the use of technology, in the form of the mandate to implement electronic health records (EHRs). EHRs consist of patient information such as demographics, medications, laboratory test results, diagnosis codes and procedures. Mining EHRs could lead to improvement in patient health management as EHRs contain detailed information related to disease prognosis for large patient populations. In this manuscript, we provide a structured and comprehensive overview of data mining techniques for modeling EHR data. We first provide a detailed understanding of the major application areas to which EHR mining has been applied and then discuss the nature of EHR data and its accompanying challenges. Next, we describe major approaches used for EHR mining, the metrics associated with EHRs, and the various study designs. With this foundation, we then provide a systematic and methodological organization of existing data mining techniques used to model EHRs and discuss ideas for future research. We conclude this survey with a comprehensive summary of clinical data mining applications of EHR data, as illustrated in the online supplement.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Pranjul Yadav et al.",
      "keywords": "Health records; Data science; Mandate; Health information technology; Electronic health record; Computer science; Data mining; Health care; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1702.03222",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2896923269",
      "doi": "10.48550/arxiv.1810.08255",
      "title": "Removing the influence of a group variable in high-dimensional predictive modelling",
      "abstract": "In many application areas, predictive models are used to support or make important decisions. There is increasing awareness that these models may contain spurious or otherwise undesirable correlations. Such correlations may arise from a variety of sources, including batch effects, systematic measurement errors, or sampling bias. Without explicit adjustment, machine learning algorithms trained using these data can produce poor out-of-sample predictions which propagate these undesirable correlations. We propose a method to pre-process the training data, producing an adjusted dataset that is statistically independent of the nuisance variables with minimum information loss. We develop a conceptually simple approach for creating an adjusted dataset in high-dimensional settings based on a constrained form of matrix decomposition. The resulting dataset can then be used in any predictive algorithm with the guarantee that predictions will be statistically independent of the group variable. We develop a scalable algorithm for implementing the method, along with theory support in the form of independence guarantees and optimality. The method is illustrated on some simulation examples and applied to two case studies: removing machine-specific correlations from brain scan data, and removing race and ethnicity information from a dataset used to predict recidivism. That the motivation for removing undesirable correlations is quite different in the two applications illustrates the broad applicability of our approach.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Emanuele Aliverti et al.",
      "keywords": "Spurious relationship; Computer science; Variable (mathematics); Independence (probability theory); Machine learning; Process (computing); Data mining; Scalability; Predictive analytics; Variety (cybernetics); Artificial intelligence; Sample (material); Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1810.08255",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386651296",
      "doi": "10.48550/arxiv.2309.05148",
      "title": "Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color",
      "abstract": "This paper strives to measure apparent skin color in computer vision, beyond a unidimensional scale on skin tone. In their seminal paper Gender Shades, Buolamwini and Gebru have shown how gender classification systems can be biased against women with darker skin tones. Subsequently, fairness researchers and practitioners have adopted the Fitzpatrick skin type classification as a common measure to assess skin color bias in computer vision systems. While effective, the Fitzpatrick scale only focuses on the skin tone ranging from light to dark. Towards a more comprehensive measure of skin color, we introduce the hue angle ranging from red to yellow. When applied to images, the hue dimension reveals additional biases related to skin color in both computer vision datasets and models. We then recommend multidimensional skin color scales, relying on both skin tone and hue, for fairness assessments.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "William Thong et al.",
      "keywords": "Hue; Tone (literature); Measure (data warehouse); Skin color; Artificial intelligence; Dark skin; Scale (ratio); Computer science; Dimension (graph theory); Computer vision; Skin colour; Mathematics; Dermatology; Geography; Medicine; Art; Cartography; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.05148",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396945374",
      "doi": "10.48550/arxiv.2405.08226",
      "title": "Self-Normalizing Foundation Model for Enhanced Multi-Omics Data Analysis in Oncology",
      "abstract": "Multi-omics research has enhanced our understanding of cancer heterogeneity and progression. Investigating molecular data through multi-omics approaches is crucial for unraveling the complex biological mechanisms underlying cancer, thereby enabling more effective diagnosis, treatment, and prevention strategies. However, predicting patient outcomes through the integration of all available multi-omics data is still an under-study research direction. Here, we present SeNMo, a foundation model that has been trained on multi-omics data across 33 cancer types. SeNMo is particularly efficient in handling multi-omics data characterized by high-width and low-length attributes. We trained SeNMo for the task of overall survival of patients using pan-cancer multi-omics data involving 33 cancer sites from the GDC. The training multi-omics data includes gene expression, DNA methylation, miRNA expression, DNA mutations, protein expression modalities, and clinical data. SeNMo was validated on two independent cohorts: Moffitt Cancer Center and CPTAC lung squamous cell carcinoma. We evaluated the model's performance in predicting patient's overall survival using the C-Index. SeNMo performed consistently well in the training regime, reflected by the validation C-Index of 0.76 on GDC's public data. In the testing regime, SeNMo performed with a C-Index of 0.758 on a held-out test set. The model showed an average accuracy of 99.8% on the task of classifying the primary cancer type on the pan-cancer test cohort. SeNMo demonstrated robust performance on the classification task of predicting the primary cancer type of patients. SeNMo further demonstrated significant performance in predicting tertiary lymph structures from multi-omics data, showing generalizability across cancer types, molecular data types, and clinical endpoints.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Asim Waqas et al.",
      "keywords": "Computer science; Deep learning; Omics; Computational biology; Artificial intelligence; Precision oncology; Data science; Oncology; Internal medicine; Medicine; Bioinformatics; Biology; Cancer",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.08226",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3130843348",
      "doi": "10.48550/arxiv.1912.08189",
      "title": "Learning from Discriminatory Training Data",
      "abstract": "Supervised learning systems are trained using historical data and, if the data was tainted by discrimination, they may unintentionally learn to discriminate against protected groups. We propose that fair learning methods, despite training on potentially discriminatory datasets, shall perform well on fair test datasets. Such dataset shifts crystallize application scenarios for specific fair learning methods. For instance, the removal of direct discrimination can be represented as a particular dataset shift problem. For this scenario, we propose a learning method that provably minimizes model error on fair datasets, while blindly training on datasets poisoned with direct additive discrimination. The method is compatible with existing legal systems and provides a solution to the widely discussed issue of protected groups' intersectionality by striking a balance between the protected groups. Technically, the method applies probabilistic interventions, has causal and counterfactual formulations, and is computationally lightweight - it can be used with any supervised learning model to prevent direct and indirect discrimination via proxies while maximizing model accuracy for business necessity.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Przemyslaw A. Grabowicz et al.",
      "keywords": "Computer science; Counterfactual thinking; Machine learning; Probabilistic logic; Artificial intelligence; Training set; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1912.08189",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319452071",
      "doi": "10.48550/arxiv.2302.02038",
      "title": "Rating Sentiment Analysis Systems for Bias through a Causal Lens",
      "abstract": "Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that, given a piece of text, assign one or more numbers conveying the polarity and emotional intensity expressed in the input. Like other automatic machine learning systems, they have also been known to exhibit model uncertainty where a (small) change in the input leads to drastic swings in the output. This can be especially problematic when inputs are related to protected features like gender or race since such behavior can be perceived as a lack of fairness, i.e., bias. We introduce a novel method to assess and rate SASs where inputs are perturbed in a controlled causal setting to test if the output sentiment is sensitive to protected variables even when other components of the textual input, e.g., chosen emotion words, are fixed. We then use the result to assign labels (ratings) at fine-grained and overall levels to convey the robustness of the SAS to input changes. The ratings serve as a principled basis to compare SASs and choose among them based on behavior. It benefits all users, especially developers who reuse off-the-shelf SASs to build larger AI systems but do not have access to their code or training data to compare.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Kausik Lakkaraju et al.",
      "keywords": "Sass; Sentiment analysis; Computer science; Robustness (evolution); Artificial intelligence; Reuse; Machine learning; Natural language processing; World Wide Web; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.02038",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387560593",
      "doi": "10.48550/arxiv.2310.05996",
      "title": "A novel Network Science Algorithm for Improving Triage of Patients",
      "abstract": "Patient triage plays a crucial role in healthcare, ensuring timely and appropriate care based on the urgency of patient conditions. Traditional triage methods heavily rely on human judgment, which can be subjective and prone to errors. Recently, a growing interest has been in leveraging artificial intelligence (AI) to develop algorithms for triaging patients. This paper presents the development of a novel algorithm for triaging patients. It is based on the analysis of patient data to produce decisions regarding their prioritization. The algorithm was trained on a comprehensive data set containing relevant patient information, such as vital signs, symptoms, and medical history. The algorithm was designed to accurately classify patients into triage categories through rigorous preprocessing and feature engineering. Experimental results demonstrate that our algorithm achieved high accuracy and performance, outperforming traditional triage methods. By incorporating computer science into the triage process, healthcare professionals can benefit from improved efficiency, accuracy, and consistency, prioritizing patients effectively and optimizing resource allocation. Although further research is needed to address challenges such as biases in training data and model interpretability, the development of AI-based algorithms for triaging patients shows great promise in enhancing healthcare delivery and patient outcomes.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Pietro Hiram Guzzi et al.",
      "keywords": "Triage; Computer science; Interpretability; Preprocessor; Health care; Artificial intelligence; Data pre-processing; Machine learning; Consistency (knowledge bases); Algorithm; Medical emergency; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.05996",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417516748",
      "doi": "10.48550/arxiv.2505.07339",
      "title": "Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory Decision-Making Algorithms",
      "abstract": "Affirmative algorithms have emerged as a potential answer to algorithmic discrimination, seeking to redress past harms and rectify the source of historical injustices. We present the results of two experiments ($N$$=$$1193$) capturing laypeople's perceptions of affirmative algorithms -- those which explicitly prioritize the historically marginalized -- in hiring and criminal justice. We contrast these opinions about affirmative algorithms with folk attitudes towards algorithms that prioritize the privileged (i.e., discriminatory) and systems that make decisions independently of demographic groups (i.e., fair). We find that people -- regardless of their political leaning and identity -- view fair algorithms favorably and denounce discriminatory systems. In contrast, we identify disagreements concerning affirmative algorithms: liberals and racial minorities rate affirmative systems as positively as their fair counterparts, whereas conservatives and those from the dominant racial group evaluate affirmative algorithms as negatively as discriminatory systems. We identify a source of these divisions: people have varying beliefs about who (if anyone) is marginalized, shaping their views of affirmative algorithms. We discuss the possibility of bridging these disagreements to bring people together towards affirmative algorithms.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Gabriel Lima et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07339",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4224330746",
      "doi": "10.48550/arxiv.2204.05899",
      "title": "VisCUIT: Visual Auditor for Bias in CNN Image Classifier",
      "abstract": "CNN image classifiers are widely used, thanks to their efficiency and accuracy. However, they can suffer from biases that impede their practical applications. Most existing bias investigation techniques are either inapplicable to general image classification tasks or require significant user efforts in perusing all data subgroups to manually specify which data attributes to inspect. We present VisCUIT, an interactive visualization system that reveals how and why a CNN classifier is biased. VisCUIT visually summarizes the subgroups on which the classifier underperforms and helps users discover and characterize the cause of the underperformances by revealing image concepts responsible for activating neurons that contribute to misclassifications. VisCUIT runs in modern browsers and is open-source, allowing people to easily access and extend the tool to other model architectures and datasets. VisCUIT is available at the following public demo link: https://poloclub.github.io/VisCUIT. A video demo is available at https://youtu.be/eNDbSyM4R_4.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Seongmin Lee et al.",
      "keywords": "Computer science; Classifier (UML); Visualization; Audit; Artificial intelligence; Open source; Machine learning; Software; Operating system; Accounting",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.05899",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3168121243",
      "doi": "10.48550/arxiv.2106.05127",
      "title": "Deep Clustering based Fair Outlier Detection",
      "abstract": "In this paper, we focus on the fairness issues regarding unsupervised outlier detection. Traditional algorithms, without a specific design for algorithmic fairness, could implicitly encode and propagate statistical bias in data and raise societal concerns. To correct such unfairness and deliver a fair set of potential outlier candidates, we propose Deep Clustering based Fair Outlier Detection (DCFOD) that learns a good representation for utility maximization while enforcing the learnable representation to be subgroup-invariant on the sensitive attribute. Considering the coupled and reciprocal nature between clustering and outlier detection, we leverage deep clustering to discover the intrinsic cluster structure and out-of-structure instances. Meanwhile, an adversarial training erases the sensitive pattern for instances for fairness adaptation. Technically, we propose an instance-level weighted representation learning strategy to enhance the joint deep clustering and outlier detection, where the dynamic weight module re-emphasizes contributions of likely-inliers while mitigating the negative impact from outliers. Demonstrated by experiments on eight datasets comparing to 17 outlier detection algorithms, our DCFOD method consistently achieves superior performance on both the outlier detection validity and two types of fairness notions in outlier detection.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Hanyu Song et al.",
      "keywords": "Anomaly detection; Outlier; Computer science; Cluster analysis; Artificial intelligence; Leverage (statistics); Pattern recognition (psychology); Data mining; Robustness (evolution); Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.05127",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4382322330",
      "doi": "10.48550/arxiv.2306.14123",
      "title": "Privacy and Fairness in Federated Learning: on the Perspective of Trade-off",
      "abstract": "Federated learning (FL) has been a hot topic in recent years. Ever since it was introduced, researchers have endeavored to devise FL systems that protect privacy or ensure fair results, with most research focusing on one or the other. As two crucial ethical notions, the interactions between privacy and fairness are comparatively less studied. However, since privacy and fairness compete, considering each in isolation will inevitably come at the cost of the other. To provide a broad view of these two critical topics, we presented a detailed literature review of privacy and fairness issues, highlighting unique challenges posed by FL and solutions in federated settings. We further systematically surveyed different interactions between privacy and fairness, trying to reveal how privacy and fairness could affect each other and point out new research directions in fair and private FL.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Huiqiang Chen et al.",
      "keywords": "Perspective (graphical); Internet privacy; Computer science; Information privacy; Point (geometry); Privacy policy; Affect (linguistics); Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.14123",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4289694618",
      "doi": "10.48550/arxiv.1808.04880",
      "title": "A Precision Environment-Wide Association Study of Hypertension via\\n Supervised Cadre Models",
      "abstract": "We consider the problem in precision health of grouping people into\\nsubpopulations based on their degree of vulnerability to a risk factor. These\\nsubpopulations cannot be discovered with traditional clustering techniques\\nbecause their quality is evaluated with a supervised metric: the ease of\\nmodeling a response variable over observations within them. Instead, we apply\\nthe supervised cadre model (SCM), which does use this metric. We extend the SCM\\nformalism so that it may be applied to multivariate regression and binary\\nclassification problems. We also develop a way to use conditional entropy to\\nassess the confidence in the process by which a subject is assigned their\\ncadre. Using the SCM, we generalize the environment-wide association study\\n(EWAS) workflow to be able to model heterogeneity in population risk. In our\\nEWAS, we consider more than two hundred environmental exposure factors and find\\ntheir association with diastolic blood pressure, systolic blood pressure, and\\nhypertension. This requires adapting the SCM to be applicable to data generated\\nby a complex survey design. After correcting for false positives, we found 25\\nexposure variables that had a significant association with at least one of our\\nresponse variables. Eight of these were significant for a discovered\\nsubpopulation but not for the overall population. Some of these associations\\nhave been identified by previous researchers, while others appear to be novel.\\nWe examine several discovered subpopulations in detail, and we find that they\\nare interpretable and that they suggest further research questions.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Alexander New et al.",
      "keywords": "False positive paradox; Multivariate statistics; Metric (unit); Population; Computer science; Logistic regression; Data mining; Machine learning; Statistics; Medicine; Mathematics; Environmental health; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1808.04880",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221165731",
      "doi": "10.48550/arxiv.2201.07677",
      "title": "Tiny, always-on and fragile: Bias propagation through design choices in on-device machine learning workflows",
      "abstract": "Billions of distributed, heterogeneous and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast and offline inference on personal data. On-device ML is highly context dependent, and sensitive to user, usage, hardware and environment attributes. This sensitivity and the propensity towards bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain, and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias. Our results validate that design choices made during model training, like the sample rate and input feature type, and choices made to optimize models, like light-weight architectures, the pruning learning rate and pruning sparsity, can result in disparate predictive performance across male and female groups. Based on our findings we suggest low effort strategies for engineers to mitigate bias in on-device ML.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Wiebke Toussaint et al.",
      "keywords": "Computer science; Workflow; Context (archaeology); Machine learning; Inference; Artificial intelligence; Pruning; Reliability (semiconductor); Task (project management); Domain (mathematical analysis); Feature (linguistics); Software",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2201.07677",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388747772",
      "doi": "10.48550/arxiv.2311.08472",
      "title": "Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models",
      "abstract": "Recently, work in NLP has shifted to few-shot (in-context) learning, with large language models (LLMs) performing well across a range of tasks. However, while fairness evaluations have become a standard for supervised methods, little is known about the fairness of LLMs as prediction systems. Further, common standard methods for fairness involve access to models weights or are applied during finetuning, which are not applicable in few-shot learning. Do LLMs exhibit prediction biases when used for standard NLP tasks? In this work, we explore the effect of shots, which directly affect the performance of models, on the fairness of LLMs as NLP classification systems. We consider how different shot selection strategies, both existing and new demographically sensitive methods, affect model fairness across three standard fairness datasets. We discuss how future work can include LLM fairness evaluations.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Carlos Aguirre et al.",
      "keywords": "Computer science; Affect (linguistics); Context (archaeology); Artificial intelligence; Selection (genetic algorithm); Machine learning; Shot (pellet); Work (physics); Range (aeronautics); Natural language processing; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.08472",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4402699316",
      "doi": "10.48550/arxiv.2408.12990",
      "title": "A Survey on Drowsiness Detection -- Modern Applications and Methods",
      "abstract": "Drowsiness detection holds paramount importance in ensuring safety in workplaces or behind the wheel, enhancing productivity, and healthcare across diverse domains. Therefore accurate and real-time drowsiness detection plays a critical role in preventing accidents, enhancing safety, and ultimately saving lives across various sectors and scenarios. This comprehensive review explores the significance of drowsiness detection in various areas of application, transcending the conventional focus solely on driver drowsiness detection. We delve into the current methodologies, challenges, and technological advancements in drowsiness detection schemes, considering diverse contexts such as public transportation, healthcare, workplace safety, and beyond. By examining the multifaceted implications of drowsiness, this work contributes to a holistic understanding of its impact and the crucial role of accurate and real-time detection techniques in enhancing safety and performance. We identified weaknesses in current algorithms and limitations in existing research such as accurate and real-time detection, stable data transmission, and building bias-free systems. Our survey frames existing works and leads to practical recommendations like mitigating the bias issue by using synthetic data, overcoming the hardware limitations with model compression, and leveraging fusion to boost model performance. This is a pioneering work to survey the topic of drowsiness detection in such an entirely and not only focusing on one single aspect. We consider the topic of drowsiness detection as a dynamic and evolving field, presenting numerous opportunities for further exploration.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Biying Fu et al.",
      "keywords": "Survey methodology; Computer science; Remote sensing; Environmental science; Geography; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.12990",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402427825",
      "doi": "10.48550/arxiv.2408.05328",
      "title": "From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management",
      "abstract": "This study explores the potential of Large Language Models (LLMs), specifically GPT-4, to enhance objectivity in organizational task performance evaluations. Through comparative analyses across two studies, including various task performance outputs, we demonstrate that LLMs can serve as a reliable and even superior alternative to human raters in evaluating knowledge-based performance outputs, which are a key contribution of knowledge workers. Our results suggest that GPT ratings are comparable to human ratings but exhibit higher consistency and reliability. Additionally, combined multiple GPT ratings on the same performance output show strong correlations with aggregated human performance ratings, akin to the consensus principle observed in performance evaluation literature. However, we also find that LLMs are prone to contextual biases, such as the halo effect, mirroring human evaluative biases. Our research suggests that while LLMs are capable of extracting meaningful constructs from text-based data, their scope is currently limited to specific forms of performance evaluation. By highlighting both the potential and limitations of LLMs, our study contributes to the discourse on AI role in management studies and sets a foundation for future research to refine AI theoretical and practical applications in management.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ning Li et al.",
      "keywords": "Computer science; Natural language processing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.05328",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417298439",
      "doi": "10.48550/arxiv.2505.13418",
      "title": "Dementia Through Different Eyes: Explainable Modeling of Human and LLM Perceptions for Early Awareness",
      "abstract": "Cognitive decline often surfaces in language years before diagnosis. It is frequently non-experts, such as those closest to the patient, who first sense a change and raise concern. As LLMs become integrated into daily communication and used over prolonged periods, it may even be an LLM that notices something is off. But what exactly do they notice--and should be noticing--when making that judgment? This paper investigates how dementia is perceived through language by non-experts. We presented transcribed picture descriptions to non-expert humans and LLMs, asking them to intuitively judge whether each text was produced by someone healthy or with dementia. We introduce an explainable method that uses LLMs to extract high-level, expert-guided features representing these picture descriptions, and use logistic regression to model human and LLM perceptions and compare with clinical diagnoses. Our analysis reveals that human perception of dementia is inconsistent and relies on a narrow, and sometimes misleading, set of cues. LLMs, by contrast, draw on a richer, more nuanced feature set that aligns more closely with clinical patterns. Still, both groups show a tendency toward false negatives, frequently overlooking dementia cases. Through our interpretable framework and the insights it provides, we hope to help non-experts better recognize the linguistic signs that matter.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Lotem Peled-Cohen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.13418",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417084250",
      "doi": "10.48550/arxiv.2505.05283",
      "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for Code Large Language Models and Agents",
      "abstract": "Code large language models (CodeLLMs) and agents have shown great promise in tackling complex software engineering tasks.Compared to traditional software engineering methods, CodeLLMs and agents offer stronger abilities, and can flexibly process inputs and outputs in both natural and code. Benchmarking plays a crucial role in evaluating the capabilities of CodeLLMs and agents, guiding their development and deployment. However, despite their growing significance, there remains a lack of comprehensive reviews of benchmarks for CodeLLMs and agents. To bridge this gap, this paper provides a comprehensive review of existing benchmarks for CodeLLMs and agents, studying and analyzing 181 benchmarks from 461 relevant papers, covering the different phases of the software development life cycle (SDLC). Our findings reveal a notable imbalance in the coverage of current benchmarks, with approximately 60% focused on the software development phase in SDLC, while requirements engineering and software design phases receive minimal attention at only 5% and 3%, respectively. Additionally, Python emerges as the dominant programming language across the reviewed benchmarks. Finally, this paper highlights the challenges of current research and proposes future directions, aiming to narrow the gap between the theoretical capabilities of CodeLLMs and agents and their application in real-world scenarios.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Kaixin Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.05283",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414898027",
      "doi": "10.48550/arxiv.2506.01732",
      "title": "Common Corpus: The Largest Collection of Ethical Data for LLM Pre-Training",
      "abstract": "Large Language Models (LLMs) are pre-trained on large amounts of data from different sources and domains. These data most often contain trillions of tokens with large portions of copyrighted or proprietary content, which hinders the usage of such models under AI legislation. This raises the need for truly open pre-training data that is compliant with the data security regulations. In this paper, we introduce Common Corpus, the largest open dataset for language model pre-training. The data assembled in Common Corpus are either uncopyrighted or under permissible licenses and amount to about two trillion tokens. The dataset contains a wide variety of languages, ranging from the main European languages to low-resource ones rarely present in pre-training datasets; in addition, it includes a large portion of code data. The diversity of data sources in terms of covered domains and time periods opens up the paths for both research and entrepreneurial needs in diverse areas of knowledge. In this technical report, we present the detailed provenance of data assembling and the details of dataset filtering and curation. Being already used by such industry leaders as Anthropic and multiple LLM training projects, we believe that Common Corpus will become a critical infrastructure for open science research in LLMs.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Pierre-Carl Langlais et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01732",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415160156",
      "doi": "10.48550/arxiv.2504.10179",
      "title": "The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance",
      "abstract": "Multimodal Large Language Models (MLLMs) are set to transform how machines process and generate human-like responses by integrating diverse modalities such as text, images, and code. Yet, effectively harnessing their capabilities hinges on optimal prompt engineering. We present a comprehensive experimental evaluation of seven prompt engineering methods applied to 13 open-source MLLMs over 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding and Alignment, Complex Code Generation and Execution, and Knowledge Retrieval and Integration. Our approach stratifies models by parameter count into Small (&lt;4B), Medium (4B-10B), and Large (&gt;10B) categories and compares prompting techniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought, Analogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel in structured tasks such as code generation, achieving accuracies up to 96.88% under Few-Shot prompting, all models struggle with complex reasoning and abstract understanding, often yielding accuracies below 60% and high hallucination rates. Structured reasoning prompts frequently increased hallucination up to 75% in small models and led to longer response times (over 20 seconds in Large MLLMs), while simpler prompting methods provided more concise and efficient outputs. No single prompting method uniformly optimises all task types. Instead, adaptive strategies combining example-based guidance with selective structured reasoning are essential to enhance robustness, efficiency, and factual accuracy. Our findings offer practical recommendations for prompt engineering and support more reliable deployment of MLLMs across applications including AI-assisted coding, knowledge retrieval, and multimodal content understanding.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Anwesha Mohanty et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10179",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320003957",
      "doi": "10.48550/arxiv.2211.09110",
      "title": "Holistic Evaluation of Language Models",
      "abstract": "Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what's missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios when possible (87.5% of the time). This ensures metrics beyond accuracy don't fall to the wayside, and that trade-offs are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to analyze specific aspects (e.g. reasoning, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, 21 of which were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: now all 30 models have been densely benchmarked on the same core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Percy Liang et al.",
      "keywords": "Computer science; Transparency (behavior); Language model; Robustness (evolution); Mainstream; Metric (unit); Data science; Machine learning; Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2211.09110",
      "cited_by_count": 113,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2946942188",
      "doi": "10.48550/arxiv.1905.13545",
      "title": "High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks",
      "abstract": "We investigate the relationship between the frequency spectrum of image data and the generalization behavior of convolutional neural networks (CNN). We first notice CNN's ability in capturing the high-frequency components of images. These high-frequency components are almost imperceptible to a human. Thus the observation leads to multiple hypotheses that are related to the generalization behaviors of CNN, including a potential explanation for adversarial examples, a discussion of CNN's trade-off between robustness and accuracy, and some evidence in understanding training heuristics.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Haohan Wang et al.",
      "keywords": "Convolutional neural network; Computer science; Generalization; Robustness (evolution); Artificial intelligence; Heuristics; Notice; Component (thermodynamics); Machine learning; Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1905.13545",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3082269314",
      "doi": "10.48550/arxiv.2009.00236",
      "title": "A Survey of Deep Active Learning",
      "abstract": "Active learning (AL) attempts to maximize the performance gain of the model by marking the fewest samples. Deep learning (DL) is greedy for data and requires a large amount of data supply to optimize massive parameters, so that the model learns how to extract high-quality features. In recent years, due to the rapid development of internet technology, we are in an era of information torrents and we have massive amounts of data. In this way, DL has aroused strong interest of researchers and has been rapidly developed. Compared with DL, researchers have relatively low interest in AL. This is mainly because before the rise of DL, traditional machine learning requires relatively few labeled samples. Therefore, early AL is difficult to reflect the value it deserves. Although DL has made breakthroughs in various fields, most of this success is due to the publicity of the large number of existing annotation datasets. However, the acquisition of a large number of high-quality annotated datasets consumes a lot of manpower, which is not allowed in some fields that require high expertise, especially in the fields of speech recognition, information extraction, medical images, etc. Therefore, AL has gradually received due attention. A natural idea is whether AL can be used to reduce the cost of sample annotations, while retaining the powerful learning capabilities of DL. Therefore, deep active learning (DAL) has emerged. Although the related research has been quite abundant, it lacks a comprehensive survey of DAL. This article is to fill this gap, we provide a formal classification method for the existing work, and a comprehensive and systematic overview. In addition, we also analyzed and summarized the development of DAL from the perspective of application. Finally, we discussed the confusion and problems in DAL, and gave some possible development directions for DAL.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Pengzhen Ren et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Publicity; Annotation; Machine learning; Quality (philosophy); The Internet; Active learning (machine learning); Big data; Data science; Data mining; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2009.00236",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4299608875",
      "doi": "10.48550/arxiv.1801.04016",
      "title": "Theoretical Impediments to Machine Learning With Seven Sparks from the\\n Causal Revolution",
      "abstract": "Current machine learning systems operate, almost exclusively, in a\\nstatistical, or model-free mode, which entails severe theoretical limits on\\ntheir power and performance. Such systems cannot reason about interventions and\\nretrospection and, therefore, cannot serve as the basis for strong AI. To\\nachieve human level intelligence, learning machines need the guidance of a\\nmodel of reality, similar to the ones used in causal inference tasks. To\\ndemonstrate the essential role of such models, I will present a summary of\\nseven tasks which are beyond reach of current machine learning systems and\\nwhich have been accomplished using the tools of causal modeling.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Judea Pearl",
      "keywords": "Causal inference; Computer science; Artificial intelligence; Machine learning; Causal model; Inference; Cognitive science; Psychology; Econometrics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1801.04016",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3118110910",
      "doi": "10.48550/arxiv.2012.11066",
      "title": "Fairness, Welfare, and Equity in Personalized Pricing",
      "abstract": "We study the interplay of fairness, welfare, and equity considerations in personalized pricing based on customer features. Sellers are increasingly able to conduct price personalization based on predictive modeling of demand conditional on covariates: setting customized interest rates, targeted discounts of consumer goods, and personalized subsidies of scarce resources with positive externalities like vaccines and bed nets. These different application areas may lead to different concerns around fairness, welfare, and equity on different objectives: price burdens on consumers, price envy, firm revenue, access to a good, equal access, and distributional consequences when the good in question further impacts downstream outcomes of interest. We conduct a comprehensive literature review in order to disentangle these different normative considerations and propose a taxonomy of different objectives with mathematical definitions. We focus on observational metrics that do not assume access to an underlying valuation distribution which is either unobserved due to binary feedback or ill-defined due to overriding behavioral concerns regarding interpreting revealed preferences. In the setting of personalized pricing for the provision of goods with positive benefits, we discuss how price optimization may provide unambiguous benefit by achieving a \"triple bottom line\": personalized pricing enables expanding access, which in turn may lead to gains in welfare due to heterogeneous utility, and improve revenue or budget utilization. We empirically demonstrate the potential benefits of personalized pricing in two settings: pricing subsidies for an elective vaccine, and the effects of personalized interest rates on downstream outcomes in microcredit.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Nathan Kallus et al.",
      "keywords": "Equity (law); Economics; Revenue; Microeconomics; Business; Welfare; Subsidy; Price discrimination; Public economics; Finance",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2012.11066",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4366999479",
      "doi": "10.48550/arxiv.2304.11431",
      "title": "A Review of Deep Learning for Video Captioning",
      "abstract": "Video captioning (VC) is a fast-moving, cross-disciplinary area of research that bridges work in the fields of computer vision, natural language processing (NLP), linguistics, and human-computer interaction. In essence, VC involves understanding a video and describing it with language. Captioning is used in a host of applications from creating more accessible interfaces (e.g., low-vision navigation) to video question answering (V-QA), video retrieval and content generation. This survey covers deep learning-based VC, including but, not limited to, attention-based architectures, graph networks, reinforcement learning, adversarial networks, dense video captioning (DVC), and more. We discuss the datasets and evaluation metrics used in the field, and limitations, applications, challenges, and future directions for VC.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Moloud Abdar et al.",
      "keywords": "Closed captioning; Computer science; Field (mathematics); Artificial intelligence; Multimedia; Adversarial system; Natural language processing; Human\u2013computer interaction; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2304.11431",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2891106796",
      "doi": "10.1145/3274342",
      "title": "Debiasing Desire: Addressing Bias & Discrimination on Intimate Platforms",
      "abstract": "Designing technical systems to be resistant to bias and discrimination represents vital new terrain for researchers, policymakers, and the anti-discrimination project more broadly. We consider bias and discrimination in the context of popular online dating and hookup platforms in the United States, which we call intimate platforms. Drawing on work in social-justice-oriented and Queer HCI, we review design features of popular intimate platforms and their potential role in exacerbating or mitigating interpersonal bias. We argue that focusing on platform design can reveal opportunities to reshape troubling patterns of intimate contact without overriding users' decisional autonomy. We identify and address the difficult ethical questions that nevertheless come along with such intervention, while urging the social computing community to engage more deeply with issues of bias, discrimination, and exclusion in the study and design of intimate platforms.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Jevan Hutson et al.",
      "keywords": "Debiasing; Autonomy; Context (archaeology); Queer; Internet privacy; Gender bias; Intervention (counseling); Prejudice (legal term); Social psychology; Psychology; Political science; Computer science; Sociology; Law; Gender studies",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3274342",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226252268",
      "doi": "10.48550/arxiv.2112.06033",
      "title": "Spatial Graph Convolutional Neural Network via Structured Subdomain Adaptation and Domain Adversarial Learning for Bearing Fault Diagnosis",
      "abstract": "Unsupervised domain adaptation (UDA) has shown remarkable results in bearing fault diagnosis under changing working conditions in recent years. However, most UDA methods do not consider the geometric structure of the data. Furthermore, the global domain adaptation technique is commonly applied, which ignores the relation between subdomains. This paper addresses mentioned challenges by presenting the novel deep subdomain adaptation graph convolution neural network (DSAGCN), which has two key characteristics: First, graph convolution neural network (GCNN) is employed to model the structure of data. Second, adversarial domain adaptation and local maximum mean discrepancy (LMMD) methods are applied concurrently to align the subdomain's distribution and reduce structure discrepancy between relevant subdomains and global domains. CWRU and Paderborn bearing datasets are used to validate the DSAGCN method's efficiency and superiority between comparison models. The experimental results demonstrate the significance of aligning structured subdomains along with domain adaptation methods to obtain an accurate data-driven model in unsupervised fault diagnosis.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Mohammadreza Ghorvei et al.",
      "keywords": "Computer science; Convolutional neural network; Domain adaptation; Graph; Convolution (computer science); Adaptation (eye); Artificial intelligence; Artificial neural network; Pattern recognition (psychology); Domain (mathematical analysis); Deep learning; Data mining; Fault (geology); Theoretical computer science; Machine learning; Algorithm; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.06033",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4307612903",
      "doi": "10.48550/arxiv.1512.07876",
      "title": "An unsupervised spatiotemporal graphical modeling approach to anomaly detection in distributed CPS",
      "abstract": "Modern distributed cyber-physical systems (CPSs) encounter a large variety of physical faults and cyber anomalies and in many cases, they are vulnerable to catastrophic fault propagation scenarios due to strong connectivity among the sub-systems. This paper presents a new data-driven framework for system-wide anomaly detection for addressing such issues. The framework is based on a spatiotemporal feature extraction scheme built on the concept of symbolic dynamics for discovering and representing causal interactions among the subsystems of a CPS. The extracted spatiotemporal features are then used to learn system-wide patterns via a Restricted Boltzmann Machine (RBM). The results show that: (1) the RBM free energy in the off-nominal conditions is different from that in the nominal conditions and can be used for anomaly detection; (2) the framework can capture multiple nominal modes with one graphical model; (3) the case studies with simulated data and an integrated building system validate the proposed approach.",
      "year": "2015",
      "journal": "arXiv (Cornell University)",
      "authors": "Chao Liu et al.",
      "keywords": "Anomaly detection; Computer science; Data mining; Variety (cybernetics); Boltzmann machine; Feature (linguistics); Graphical model; Cyber-physical system; Anomaly (physics); Feature extraction; Complex system; Distributed computing; Artificial intelligence; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1512.07876",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4365460621",
      "doi": "10.48550/arxiv.2304.05560",
      "title": "CoAIcoder: Examining the Effectiveness of AI-assisted Human-to-Human Collaboration in Qualitative Analysis",
      "abstract": "While AI-assisted individual qualitative analysis has been substantially studied, AI-assisted collaborative qualitative analysis (CQA)-a process that involves multiple researchers working together to interpret data-remains relatively unexplored. After identifying CQA practices and design opportunities through formative interviews, we designed and implemented CoAIcoder, a tool leveraging AI to enhance human-to-human collaboration within CQA through four distinct collaboration methods. With a between-subject design, we evaluated CoAIcoder with 32 pairs of CQA-trained participants across common CQA phases under each collaboration method. Our findings suggest that while using a shared AI model as a mediator among coders could improve CQA efficiency and foster agreement more quickly in the early coding stage, it might affect the final code diversity. We also emphasize the need to consider the independence level when using AI to assist human-to-human collaboration in various CQA scenarios. Lastly, we suggest design implications for future AI-assisted CQA systems.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie Gao et al.",
      "keywords": "Formative assessment; Computer science; Qualitative analysis; Coding (social sciences); Qualitative research; Process (computing); Psychology; Data science; Knowledge management; Sociology; Mathematics education",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.05560",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388184808",
      "doi": "10.48550/arxiv.2310.20448",
      "title": "A Survey on Federated Unlearning: Challenges, Methods, and Future Directions",
      "abstract": "In recent years, the notion of ``the right to be forgotten\" (RTBF) has become a crucial aspect of data privacy for digital trust and AI safety, requiring the provision of mechanisms that support the removal of personal data of individuals upon their requests. Consequently, machine unlearning (MU) has gained considerable attention which allows an ML model to selectively eliminate identifiable information. Evolving from MU, federated unlearning (FU) has emerged to confront the challenge of data erasure within federated learning (FL) settings, which empowers the FL model to unlearn an FL client or identifiable information pertaining to the client. Nevertheless, the distinctive attributes of federated learning introduce specific challenges for FU techniques. These challenges necessitate a tailored design when developing FU algorithms. While various concepts and numerous federated unlearning schemes exist in this field, the unified workflow and tailored design of FU are not yet well understood. Therefore, this comprehensive survey delves into the techniques and methodologies in FU providing an overview of fundamental concepts and principles, evaluating existing federated unlearning algorithms, and reviewing optimizations tailored to federated learning. Additionally, it discusses practical applications and assesses their limitations. Finally, it outlines promising directions for future research.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ziyao Liu et al.",
      "keywords": "Computer science; Process (computing); Domain (mathematical analysis); Federated learning; Data science; Information privacy; Knowledge management; Artificial intelligence; Internet privacy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.20448",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391047173",
      "doi": "10.48550/arxiv.2401.10016",
      "title": "Gender Bias in Machine Translation and The Era of Large Language Models",
      "abstract": "This chapter examines the role of Machine Translation in perpetuating gender bias, highlighting the challenges posed by cross-linguistic settings and statistical dependencies. A comprehensive overview of relevant existing work related to gender bias in both conventional Neural Machine Translation approaches and Generative Pretrained Transformer models employed as Machine Translation systems is provided. Through an experiment using ChatGPT (based on GPT-3.5) in an English-Italian translation context, we further assess ChatGPT's current capacity to address gender bias. The findings emphasize the ongoing need for advancements in mitigating bias in Machine Translation systems and underscore the importance of fostering fairness and inclusivity in language technologies.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Eva Vanmassenhove",
      "keywords": "Machine translation; Generative grammar; Computer science; Gender bias; Natural language processing; Artificial intelligence; Transformer; Machine learning; Psychology; Engineering; Social psychology; Voltage",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.10016",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4286894633",
      "doi": "10.48550/arxiv.2110.13029",
      "title": "Fair Enough: Searching for Sufficient Measures of Fairness",
      "abstract": "Testing machine learning software for ethical bias has become a pressing current concern. In response, recent research has proposed a plethora of new fairness metrics, for example, the dozens of fairness metrics in the IBM AIF360 toolkit. This raises the question: How can any fairness tool satisfy such a diverse range of goals? While we cannot completely simplify the task of fairness testing, we can certainly reduce the problem. This paper shows that many of those fairness metrics effectively measure the same thing. Based on experiments using seven real-world datasets, we find that (a) 26 classification metrics can be clustered into seven groups, and (b) four dataset metrics can be clustered into three groups. Further, each reduced set may actually predict different things. Hence, it is no longer necessary (or even possible) to satisfy all fairness metrics. In summary, to simplify the fairness testing problem, we recommend the following steps: (1)~determine what type of fairness is desirable (and we offer a handful of such types); then (2) lookup those types in our clusters; then (3) just test for one item per cluster.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Suvodeep Majumder et al.",
      "keywords": "Computer science; Fairness measure; Set (abstract data type); Task (project management); IBM; Range (aeronautics); Measure (data warehouse); Machine learning; Data mining; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.13029",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4224279722",
      "doi": "10.48550/arxiv.2204.09888",
      "title": "Fairness in Graph Mining: A Survey",
      "abstract": "Graph mining algorithms have been playing a significant role in myriad fields over the years. However, despite their promising performance on various graph analytical tasks, most of these algorithms lack fairness considerations. As a consequence, they could lead to discrimination towards certain populations when exploited in human-centered applications. Recently, algorithmic fairness has been extensively studied in graph-based applications. In contrast to algorithmic fairness on independent and identically distributed (i.i.d.) data, fairness in graph mining has exclusive backgrounds, taxonomies, and fulfilling techniques. In this survey, we provide a comprehensive and up-to-date introduction of existing literature under the context of fair graph mining. Specifically, we propose a novel taxonomy of fairness notions on graphs, which sheds light on their connections and differences. We further present an organized summary of existing techniques that promote fairness in graph mining. Finally, we summarize the widely used datasets in this emerging research field and provide insights on current research challenges and open questions, aiming at encouraging cross-breeding ideas and further advances.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yushun Dong et al.",
      "keywords": "Computer science; Graph; Data science; Theoretical computer science; Power graph analysis; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.09888",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4221159059",
      "doi": "10.48550/arxiv.2201.08006",
      "title": "Predictive modeling of movements of refugees and internally displaced people: Towards a computational framework",
      "abstract": "Predicting forced displacement is an important undertaking of many humanitarian aid agencies, which must anticipate flows in advance in order to provide vulnerable refugees and Internally Displaced Persons (IDPs) with shelter, food, and medical care. While there is a growing interest in using machine learning to better anticipate future arrivals, there is little standardized knowledge on how to predict refugee and IDP flows in practice. Researchers and humanitarian officers are confronted with the need to make decisions about how to structure their datasets and how to fit their problem to predictive analytics approaches, and they must choose from a variety of modeling options. Most of the time, these decisions are made without an understanding of the full range of options that could be considered, and using methodologies that have primarily been applied in different contexts - and with different goals - as opportunistic references. In this work, we attempt to facilitate a more comprehensive understanding of this emerging field of research by providing a systematic model-agnostic framework, adapted to the use of big data sources, for structuring the prediction problem. As we do so, we highlight existing work on predicting refugee and IDP flows. We also draw on our own experience building models to predict forced displacement in Somalia, in order to illustrate the choices facing modelers and point to open research questions that may be used to guide future work.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Katherine Hoffmann Pham et al.",
      "keywords": "Refugee; Variety (cybernetics); Forced migration; Field (mathematics); Work (physics); Data science; Computer science; Internally displaced person; Order (exchange); Displaced person; Structuring; Displacement (psychology); Analytics; Management science; Predictive analytics; Humanitarian aid; Political science; Operations research; Engineering; Artificial intelligence; Psychology; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2201.08006",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391046687",
      "doi": "10.48550/arxiv.2401.09512",
      "title": "MLAAD: The Multi-Language Audio Anti-Spoofing Dataset",
      "abstract": "Text-to-Speech (TTS) technology offers notable benefits, such as providing a voice for individuals with speech impairments, but it also facilitates the creation of audio deepfakes and spoofing attacks. AI-based detection methods can help mitigate these risks; however, the performance of such models is inherently dependent on the quality and diversity of their training data. Presently, the available datasets are heavily skewed towards English and Chinese audio, which limits the global applicability of these anti-spoofing systems. To address this limitation, this paper presents the Multi-Language Audio Anti-Spoofing Dataset (MLAAD), version 9, created using 140 TTS models, comprising 78 different architectures, to generate 678,3 hours of synthetic voice in 51 different languages. We train and evaluate three state-of-the-art deepfake detection models with MLAAD and observe that it demonstrates superior performance over comparable datasets like InTheWild and Fake-Or-Real when used as a training resource. Moreover, compared to the renowned ASVspoof 2019 dataset, MLAAD proves to be a complementary resource. In tests across eight datasets, MLAAD and ASVspoof 2019 alternately outperformed each other, each excelling on four datasets. By publishing MLAAD and making a trained model accessible via an interactive webserver, we aim to democratize anti-spoofing technology, making it accessible beyond the realm of specialists, and contributing to global efforts against audio spoofing and deepfakes.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Nicolas M. M\u00fcller et al.",
      "keywords": "Computer science; Spoofing attack; Speech recognition; Realm; Resource (disambiguation); Artificial intelligence; Natural language processing; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.09512",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4310884660",
      "doi": "10.48550/arxiv.2212.02985",
      "title": "Multi-Layer Personalized Federated Learning for Mitigating Biases in Student Predictive Analytics",
      "abstract": "Conventional methods for student modeling, which involve predicting grades based on measured activities, struggle to provide accurate results for minority/underrepresented student groups due to data availability biases. In this paper, we propose a Multi-Layer Personalized Federated Learning (MLPFL) methodology that optimizes inference accuracy over different layers of student grouping criteria, such as by course and by demographic subgroups within each course. In our approach, personalized models for individual student subgroups are derived from a global model, which is trained in a distributed fashion via meta-gradient updates that account for subgroup heterogeneity while preserving modeling commonalities that exist across the full dataset. The evaluation of the proposed methodology considers case studies of two popular downstream student modeling tasks, knowledge tracing and outcome prediction, which leverage multiple modalities of student behavior (e.g., visits to lecture videos and participation on forums) in model training. Experiments on three real-world online course datasets show significant improvements achieved by our approach over existing student modeling benchmarks, as evidenced by an increased average prediction quality and decreased variance across different student subgroups. Visual analysis of the resulting students' knowledge state embeddings confirm that our personalization methodology extracts activity patterns clustered into different student subgroups, consistent with the performance enhancements we obtain over the baselines.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yun-Wei Chu et al.",
      "keywords": "Personalization; Computer science; Leverage (statistics); Inference; Learning analytics; Machine learning; Modalities; Analytics; Artificial intelligence; Causal inference; Data science; World Wide Web; Statistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.02985",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386555702",
      "doi": "10.48550/arxiv.2309.02473",
      "title": "A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges",
      "abstract": "In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations. This paper aims to provide an introduction to IL and an overview of its underlying assumptions and approaches. It also offers a detailed description of recent advances and emerging areas of research in the field. Additionally, the paper discusses how researchers have addressed common challenges associated with IL and provides potential directions for future research. Overall, the goal of the paper is to provide a comprehensive guide to the growing field of IL in robotics and AI.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Maryam Zare et al.",
      "keywords": "Artificial intelligence; Computer science; Flexibility (engineering); Field (mathematics); Adaptability; Process (computing); Imitation; Robotics; Reinforcement learning; Set (abstract data type); Machine learning; Human\u2013computer interaction; Robot; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.02473",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400433803",
      "doi": "10.48550/arxiv.2407.03568",
      "title": "When LLM Meets Hypergraph: A Sociological Analysis on Personality via Online Social Networks",
      "abstract": "Individual personalities significantly influence our perceptions, decisions, and social interactions, which is particularly crucial for gaining insights into human behavior patterns in online social network analysis. Many psychological studies have observed that personalities are strongly reflected in their social behaviors and social environments. In light of these problems, this paper proposes a sociological analysis framework for one's personality in an environment-based view instead of individual-level data mining. Specifically, to comprehensively understand an individual's behavior from low-quality records, we leverage the powerful associative ability of LLMs by designing an effective prompt. In this way, LLMs can integrate various scattered information with their external knowledge to generate higher-quality profiles, which can significantly improve the personality analysis performance. To explore the interactive mechanism behind the users and their online environments, we design an effective hypergraph neural network where the hypergraph nodes are users and the hyperedges in the hypergraph are social environments. We offer a useful dataset with user profile data, personality traits, and several detected environments from the real-world social platform. To the best of our knowledge, this is the first network-based dataset containing both hypergraph structure and social information, which could push forward future research in this area further. By employing the framework on this dataset, we can effectively capture the nuances of individual personalities and their online behaviors, leading to a deeper understanding of human interactions in the digital world.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhiyao Shu et al.",
      "keywords": "Hypergraph; Sociology; Personality; Sociological research; Sociological theory; Social network analysis; Social psychology; Data science; Computer science; Social science; Psychology; Social capital; Mathematics; Discrete mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.03568",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4302605846",
      "doi": "10.48550/arxiv.1712.07924",
      "title": "Matching Code and Law: Achieving Algorithmic Fairness with Optimal\\n Transport",
      "abstract": "Increasingly, discrimination by algorithms is perceived as a societal and\\nlegal problem. As a response, a number of criteria for implementing algorithmic\\nfairness in machine learning have been developed in the literature. This paper\\nproposes the Continuous Fairness Algorithm (CFA$\\\\theta$) which enables a\\ncontinuous interpolation between different fairness definitions. More\\nspecifically, we make three main contributions to the existing literature.\\nFirst, our approach allows the decision maker to continuously vary between\\nspecific concepts of individual and group fairness. As a consequence, the\\nalgorithm enables the decision maker to adopt intermediate ``worldviews'' on\\nthe degree of discrimination encoded in algorithmic processes, adding nuance to\\nthe extreme cases of ``we're all equal'' (WAE) and ``what you see is what you\\nget'' (WYSIWYG) proposed so far in the literature. Second, we use optimal\\ntransport theory, and specifically the concept of the barycenter, to maximize\\ndecision maker utility under the chosen fairness constraints. Third, the\\nalgorithm is able to handle cases of intersectionality, i.e., of\\nmulti-dimensional discrimination of certain groups on grounds of several\\ncriteria. We discuss three main examples (credit applications; college\\nadmissions; insurance contracts) and map out the legal and policy implications\\nof our approach. The explicit formalization of the trade-off between individual\\nand group fairness allows this post-processing approach to be tailored to\\ndifferent situational contexts in which one or the other fairness criterion may\\ntake precedence. Finally, we evaluate our model experimentally.\\n",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Meike Zehlike et al.",
      "keywords": "Computer science; Situational ethics; Fairness measure; Matching (statistics); Decision maker; Theoretical computer science; Operations research; Psychology; Mathematics; Social psychology; Throughput",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1712.07924",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4398156974",
      "doi": "10.48550/arxiv.2405.10523",
      "title": "Adaptable and Reliable Text Classification using Large Language Models",
      "abstract": "Text classification is fundamental in Natural Language Processing (NLP), and the advent of Large Language Models (LLMs) has revolutionized the field. This paper introduces an adaptable and reliable text classification paradigm, which leverages LLMs as the core component to address text classification tasks. Our system simplifies the traditional text classification workflows, reducing the need for extensive preprocessing and domain-specific expertise to deliver adaptable and reliable text classification results. We evaluated the performance of several LLMs, machine learning algorithms, and neural network-based architectures on four diverse datasets. Results demonstrate that certain LLMs surpass traditional methods in sentiment analysis, spam SMS detection, and multi-label classification. Furthermore, it is shown that the system's performance can be further enhanced through few-shot or fine-tuning strategies, making the fine-tuned model the top performer across all datasets. Source code and datasets are available in this GitHub repository: https://github.com/yeyimilk/llm-zero-shot-classifiers.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhiqiang Wang et al.",
      "keywords": "Computer science; Natural language processing; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.10523",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3194435708",
      "doi": "10.48550/arxiv.2108.11884",
      "title": "Enabling SQL-based Training Data Debugging for Federated Learning",
      "abstract": "How can we debug a logistical regression model in a federated learning setting when seeing the model behave unexpectedly (e.g., the model rejects all high-income customers' loan applications)? The SQL-based training data debugging framework has proved effective to fix this kind of issue in a non-federated learning setting. Given an unexpected query result over model predictions, this framework automatically removes the label errors from training data such that the unexpected behavior disappears in the retrained model. In this paper, we enable this powerful framework for federated learning. The key challenge is how to develop a security protocol for federated debugging which is proved to be secure, efficient, and accurate. Achieving this goal requires us to investigate how to seamlessly integrate the techniques from multiple fields (Databases, Machine Learning, and Cybersecurity). We first propose FedRain, which extends Rain, the state-of-the-art SQL-based training data debugging framework, to our federated learning setting. We address several technical challenges to make FedRain work and analyze its security guarantee and time complexity. The analysis results show that FedRain falls short in terms of both efficiency and security. To overcome these limitations, we redesign our security protocol and propose Frog, a novel SQL-based training data debugging framework tailored for federated learning. Our theoretical analysis shows that Frog is more secure, more accurate, and more efficient than FedRain. We conduct extensive experiments using several real-world datasets and a case study. The experimental results are consistent with our theoretical analysis and validate the effectiveness of Frog in practice.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Yejia Liu et al.",
      "keywords": "Debugging; Computer science; SQL; SQL injection; Protocol (science); Federated learning; Machine learning; Software engineering; Database; Artificial intelligence; Query by Example; Programming language; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2108.11884",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4323923020",
      "doi": "10.48550/arxiv.2303.05091",
      "title": "Designing Automated Vehicle and Traffic Systems towards Meaningful Human Control",
      "abstract": "Ensuring operational control over automated vehicles is not trivial and failing to do so severely endangers the lives of road users. An integrated approach is necessary to ensure that all agents play their part including drivers, occupants, vehicle designers and governments. While progress is being made, a comprehensive approach to the problem is being ignored, which can be solved in the main through considering Meaningful Human Control (MHC). In this research, an Integrated System Proximity framework and Operational Process Design approach to assist the development of Connected Automated Vehicles (CAV) under the consideration of MHC are introduced. These offer a greater understanding and basis for vehicle and traffic system design by vehicle designers and governments as two important influencing stakeholders. The framework includes an extension to a system approach, which also considers ways that MHC can be improved through updating: either implicit proximal updating or explicit distal updating. The process and importance are demonstrated in three recent cases from practice. Finally, a call for action is made to government and regulatory authorities, as well as the automotive industry, to ensure that MHC processes are explicitly included in policy, regulations, and design processes to ensure future ad-vancement of CAVs in a responsible, safe and humanly agreeable fashion.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Simeon C. Calvert et al.",
      "keywords": "Automotive industry; Process (computing); Action (physics); Control (management); Computer science; Government (linguistics); Risk analysis (engineering); Process management; Class (philosophy); Computer security; Systems engineering; Engineering; Business; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.05091",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392222428",
      "doi": "10.48550/arxiv.2402.16347",
      "title": "CodeS: Towards Building Open-source Language Models for Text-to-SQL",
      "abstract": "Language models have shown promising performance on the task of translating natural language questions into SQL queries (Text-to-SQL). However, most of the state-of-the-art (SOTA) approaches rely on powerful yet closed-source large language models (LLMs), such as ChatGPT and GPT-4, which may have the limitations of unclear model architectures, data privacy risks, and expensive inference overheads. To address the limitations, we introduce CodeS, a series of pre-trained language models with parameters ranging from 1B to 15B, specifically designed for the text-to-SQL task. CodeS is a fully open-source language model, which achieves superior accuracy with much smaller parameter sizes. This paper studies the research challenges in building CodeS. To enhance the SQL generation abilities of CodeS, we adopt an incremental pre-training approach using a specifically curated SQL-centric corpus. Based on this, we address the challenges of schema linking and rapid domain adaptation through strategic prompt construction and a bi-directional data augmentation technique. We conduct comprehensive evaluations on multiple datasets, including the widely used Spider benchmark, the newly released BIRD benchmark, robustness-diagnostic benchmarks such as Spider-DK, Spider-Syn, Spider-Realistic, and Dr.Spider, as well as two real-world datasets created for financial and academic applications. The experimental results show that our CodeS achieves new SOTA accuracy and robustness on nearly all challenging text-to-SQL benchmarks.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Haoyang Li et al.",
      "keywords": "Computer science; Programming language; Open source; SQL; SQL/PSM; Data definition language; Natural language processing; World Wide Web; Query by Example; Software",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.16347",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390833205",
      "doi": "10.48550/arxiv.2401.05632",
      "title": "Natural Language Processing for Dialects of a Language: A Survey",
      "abstract": "State-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report a superlative performance on evaluation datasets. This survey delves into an important attribute of these datasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectal datasets and its implications for the equity of language technologies, we survey past research in NLP for dialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories: natural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing, and NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation, and dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic, German, among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect classification, and extends to several NLU and NLG tasks. For these tasks, we describe classical machine learning using statistical models, along with the recent deep learning-based approaches based on pre-trained language models. We expect that this survey will be useful to NLP researchers interested in building equitable language technologies by rethinking LLM benchmarks and model architectures.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Aditya Joshi et al.",
      "keywords": "Computer science; Natural language processing; Artificial intelligence; Machine translation; Parsing; Sentence; Natural language understanding; German; Natural language; Linguistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.05632",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285428817",
      "doi": "10.48550/arxiv.2207.05377",
      "title": "On the Generalization for Transfer Learning: An Information-Theoretic Analysis",
      "abstract": "Transfer learning, or domain adaptation, is concerned with machine learning problems in which training and testing data come from possibly different probability distributions. In this work, we give an information-theoretic analysis of the generalization error and excess risk of transfer learning algorithms. Our results suggest, perhaps as expected, that the Kullback-Leibler (KL) divergence $D(\u03bc\\|\u03bc')$ plays an important role in the characterizations where $\u03bc$ and $\u03bc'$ denote the distribution of the training data and the testing data, respectively. Specifically, we provide generalization error and excess risk upper bounds for learning algorithms where data from both distributions are available in the training phase. Recognizing that the bounds could be sub-optimal in general, we provide improved excess risk upper bounds for a certain class of algorithms, including the empirical risk minimization (ERM) algorithm, by making stronger assumptions through the \\textit{central condition}. To demonstrate the usefulness of the bounds, we further extend the analysis to the Gibbs algorithm and the noisy stochastic gradient descent method. We then generalize the mutual information bound with other divergences such as $\u03d5$-divergence and Wasserstein distance, which may lead to tighter bounds and can handle the case when $\u03bc$ is not absolutely continuous with respect to $\u03bc'$. Several numerical results are provided to demonstrate our theoretical findings. Lastly, to address the problem that the bounds are often not directly applicable in practice due to the absence of the distributional knowledge of the data, we develop an algorithm (called InfoBoost) that dynamically adjusts the importance weights for both source and target data based on certain information measures. The empirical results show the effectiveness of the proposed algorithm.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Xuetong Wu et al.",
      "keywords": "Divergence (linguistics); Generalization; Empirical risk minimization; Computer science; Transfer of learning; Algorithm; Upper and lower bounds; Mutual information; Mathematics; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2207.05377",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320854034",
      "doi": "10.48550/arxiv.2302.06037",
      "title": "Generalizable End-to-End Deep Learning Frameworks for Real-Time Attitude Estimation Using 6DoF Inertial Measurement Units",
      "abstract": "This paper presents a novel end-to-end deep learning framework for real-time inertial attitude estimation using 6DoF IMU measurements. Inertial Measurement Units are widely used in various applications, including engineering and medical sciences. However, traditional filters used for attitude estimation suffer from poor generalization over different motion patterns and environmental disturbances. To address this problem, we propose two deep learning models that incorporate accelerometer and gyroscope readings as inputs. These models are designed to be generalized to different motion patterns, sampling rates, and environmental disturbances. Our models consist of convolutional neural network layers combined with Bi-Directional Long-Short Term Memory followed by a Fully Forward Neural Network to estimate the quaternion. We evaluate the proposed method on seven publicly available datasets, totaling more than 120 hours and 200 kilometers of IMU measurements. Our results show that the proposed method outperforms state-of-the-art methods in terms of accuracy and robustness. Additionally, our framework demonstrates superior generalization over various motion characteristics and sensor sampling rates. Overall, this paper provides a comprehensive and reliable solution for real-time inertial attitude estimation using 6DoF IMUs, which has significant implications for a wide range of applications.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Arman Asgharpoor Golroudbari et al.",
      "keywords": "Inertial measurement unit; Computer science; Robustness (evolution); Artificial intelligence; Gyroscope; Units of measurement; Deep learning; Accelerometer; Inertial frame of reference; Quaternion; Convolutional neural network; Generalization; Computer vision; Real-time computing; Engineering; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.06037",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3203922469",
      "doi": "10.48550/arxiv.2106.08503",
      "title": "Understanding and Evaluating Racial Biases in Image Captioning",
      "abstract": "Image captioning is an important task for benchmarking visual reasoning and for enabling accessibility for people with vision impairments. However, as in many machine learning settings, social biases can influence image captioning in undesirable ways. In this work, we study bias propagation pathways within image captioning, focusing specifically on the COCO dataset. Prior work has analyzed gender bias in captions using automatically-derived gender labels; here we examine racial and intersectional biases using manual annotations. Our first contribution is in annotating the perceived gender and skin color of 28,315 of the depicted people after obtaining IRB approval. Using these annotations, we compare racial biases present in both manual and automatically-generated image captions. We demonstrate differences in caption performance, sentiment, and word choice between images of lighter versus darker-skinned people. Further, we find the magnitude of these differences to be greater in modern captioning systems compared to older ones, thus leading to concerns that without proper consideration and mitigation these differences will only become increasingly prevalent. Code and data is available at https://princetonvisualai.github.io/imagecaptioning-bias .",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Dora Zhao et al.",
      "keywords": "Closed captioning; Computer science; Benchmarking; Word (group theory); Natural language processing; Task (project management); Artificial intelligence; Image (mathematics); Code (set theory); Gender bias; Linguistics; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.08503",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4288611205",
      "doi": "10.48550/arxiv.1902.00334",
      "title": "SensitiveNets: Learning Agnostic Representations with Application to\\n Face Images",
      "abstract": "This work proposes a novel privacy-preserving neural network feature\\nrepresentation to suppress the sensitive information of a learned space while\\nmaintaining the utility of the data. The new international regulation for\\npersonal data protection forces data controllers to guarantee privacy and avoid\\ndiscriminative hazards while managing sensitive data of users. In our approach,\\nprivacy and discrimination are related to each other. Instead of existing\\napproaches aimed directly at fairness improvement, the proposed feature\\nrepresentation enforces the privacy of selected attributes. This way fairness\\nis not the objective, but the result of a privacy-preserving learning method.\\nThis approach guarantees that sensitive information cannot be exploited by any\\nagent who process the output of the model, ensuring both privacy and equality\\nof opportunity. Our method is based on an adversarial regularizer that\\nintroduces a sensitive information removal function in the learning objective.\\nThe method is evaluated on three different primary tasks (identity,\\nattractiveness, and smiling) and three publicly available benchmarks. In\\naddition, we present a new face annotation dataset with balanced distribution\\nbetween genders and ethnic origins. The experiments demonstrate that it is\\npossible to improve the privacy and equality of opportunity while retaining\\ncompetitive performance independently of the task.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Aythami Morales et al.",
      "keywords": "Computer science; Discriminative model; Feature learning; Representation (politics); Feature (linguistics); Machine learning; Artificial intelligence; Identity (music); Feature vector; Process (computing); Adversary; Information sensitivity; Data mining; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1902.00334",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394867571",
      "doi": "10.48550/arxiv.2404.08973",
      "title": "PraFFL: A Preference-Aware Scheme in Fair Federated Learning",
      "abstract": "Fairness in federated learning has emerged as a critical concern, aiming to develop an unbiased model among groups (e.g., male or female) of diverse sensitive features. However, there is a trade-off between model performance and fairness, i.e., improving model fairness will decrease model performance. Existing approaches have characterized such a trade-off by introducing hyperparameters to quantify client's preferences for model fairness and model performance. Nevertheless, these approaches are limited to scenarios where each client has only a single pre-defined preference, and fail to work in practical systems where each client generally has multiple preferences. To this end, we propose a Preference-aware scheme in Fair Federated Learning (called PraFFL) to generate preference-specific models in real time. PraFFL can adaptively adjust the model based on each client's preferences to meet their needs. We theoretically prove that PraFFL can offer the optimal model tailored to an arbitrary preference of each client, and show its linear convergence. Experimental results show that our proposed PraFFL outperforms six fair federated learning algorithms in terms of the model's capability of adapting to clients' different preferences. Our implementation is available at https://github.com/rG223/PraFFL.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Rongguang Ye et al.",
      "keywords": "Computer science; Preference; Scheme (mathematics); Hyperparameter; Federated learning; Key (lock); Preference learning; Artificial intelligence; Machine learning; Microeconomics; Computer security; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.08973",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4297798776",
      "doi": "10.48550/arxiv.2105.11160",
      "title": "Out-of-Distribution Detection in Dermatology using Input Perturbation and Subset Scanning",
      "abstract": "Recent advances in deep learning have led to breakthroughs in the development of automated skin disease classification. As we observe an increasing interest in these models in the dermatology space, it is crucial to address aspects such as the robustness towards input data distribution shifts. Current skin disease models could make incorrect inferences for test samples from different hardware devices and clinical settings or unknown disease samples, which are out-of-distribution (OOD) from the training samples. To this end, we propose a simple yet effective approach that detect these OOD samples prior to making any decision. The detection is performed via scanning in the latent space representation (e.g., activations of the inner layers of any pre-trained skin disease classifier). The input samples could also perturbed to maximise divergence of OOD samples. We validate our ODD detection approach in two use cases: 1) identify samples collected from different protocols, and 2) detect samples from unknown disease classes. Additionally, we evaluate the performance of the proposed approach and compare it with other state-of-the-art methods. Furthermore, data-driven dermatology applications may deepen the disparity in clinical care across racial and ethnic groups since most datasets are reported to suffer from bias in skin tone distribution. Therefore, we also evaluate the fairness of these OOD detection methods across different skin tones. Our experiments resulted in competitive performance across multiple datasets in detecting OOD samples, which could be used (in the future) to design more effective transfer learning techniques prior to inferring on these samples.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Hannah Kim et al.",
      "keywords": "Classifier (UML); Computer science; Robustness (evolution); Artificial intelligence; Pattern recognition (psychology); Machine learning; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2105.11160",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3099482545",
      "doi": "10.48550/arxiv.2011.06738",
      "title": "Metric-Free Individual Fairness with Cooperative Contextual Bandits",
      "abstract": "Data mining algorithms are increasingly used in automated decision making across all walks of daily life. Unfortunately, as reported in several studies these algorithms inject bias from data and environment leading to inequitable and unfair solutions. To mitigate bias in machine learning, different formalizations of fairness have been proposed that can be categorized into group fairness and individual fairness. Group fairness requires that different groups should be treated similarly which might be unfair to some individuals within a group. On the other hand, individual fairness requires that similar individuals be treated similarly. However, individual fairness remains understudied due to its reliance on problem-specific similarity metrics. We propose a metric-free individual fairness and a cooperative contextual bandits (CCB) algorithm. The CCB algorithm utilizes fairness as a reward and attempts to maximize it. The advantage of treating fairness as a reward is that the fairness criterion does not need to be differentiable. The proposed algorithm is tested on multiple real-world benchmark datasets. The results show the effectiveness of the proposed algorithm at mitigating bias and at achieving both individual and group fairness.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Qian Hu et al.",
      "keywords": "Fairness measure; Metric (unit); Computer science; Benchmark (surveying); Differentiable function; Group (periodic table); Similarity (geometry); Artificial intelligence; Machine learning; Mathematics; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2011.06738",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4376312352",
      "doi": "10.48550/arxiv.2305.06773",
      "title": "Towards a Better Understanding of the Computer Vision Research Community in Africa",
      "abstract": "Computer vision is a broad field of study that encompasses different tasks (e.g., object detection). Although computer vision is relevant to the African communities in various applications, yet computer vision research is under-explored in the continent and constructs only 0.06% of top-tier publications in the last ten years. In this paper, our goal is to have a better understanding of the computer vision research conducted in Africa and provide pointers on whether there is equity in research or not. We do this through an empirical analysis of the African computer vision publications that are Scopus indexed, where we collect around 63,000 publications over the period 2012-2022. We first study the opportunities available for African institutions to publish in top-tier computer vision venues. We show that African publishing trends in top-tier venues over the years do not exhibit consistent growth, unlike other continents such as North America or Asia. Moreover, we study all computer vision publications beyond top-tier venues in different African regions to find that mainly Northern and Southern Africa are publishing in computer vision with 68.5% and 15.9% of publications, resp. Nonetheless, we highlight that both Eastern and Western Africa are exhibiting a promising increase with the last two years closing the gap with Southern Africa. Additionally, we study the collaboration patterns in these publications to find that most of these exhibit international collaborations rather than African ones. We also show that most of these publications include an African author that is a key contributor as the first or last author. Finally, we present the most recurring keywords in computer vision publications per African region.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Abdul-Hakeem Omotayo et al.",
      "keywords": "Publication; Publishing; Equity (law); Scopus; Computer science; Geography; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.06773",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386044515",
      "doi": "10.48550/arxiv.2308.08833",
      "title": "CMB: A Comprehensive Medical Benchmark in Chinese",
      "abstract": "Large Language Models (LLMs) provide a possibility to make a great breakthrough in medicine. The establishment of a standardized medical benchmark becomes a fundamental cornerstone to measure progression. However, medical environments in different regions have their local characteristics, e.g., the ubiquity and significance of traditional Chinese medicine within China. Therefore, merely translating English-based medical evaluation may result in \\textit{contextual incongruities} to a local region. To solve the issue, we propose a localized medical benchmark called CMB, a Comprehensive Medical Benchmark in Chinese, designed and rooted entirely within the native Chinese linguistic and cultural framework. While traditional Chinese medicine is integral to this evaluation, it does not constitute its entirety. Using this benchmark, we have evaluated several prominent large-scale LLMs, including ChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical domain. We hope this benchmark provide first-hand experience in existing LLMs for medicine and also facilitate the widespread adoption and enhancement of medical LLMs within China. Our data and code are publicly available at https://github.com/FreedomIntelligence/CMB.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xidong Wang et al.",
      "keywords": "Benchmark (surveying); China; Cornerstone; Personalized medicine; Medicine; Political science; Geography; Bioinformatics; Law; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.08833",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396821633",
      "doi": "10.48550/arxiv.2405.00712",
      "title": "SoK: Behind the Accuracy of Complex Human Activity Recognition Using Deep Learning",
      "abstract": "Human Activity Recognition (HAR) is a well-studied field with research dating back to the 1980s. Over time, HAR technologies have evolved significantly from manual feature extraction, rule-based algorithms, and simple machine learning models to powerful deep learning models, from one sensor type to a diverse array of sensing modalities. The scope has also expanded from recognising a limited set of activities to encompassing a larger variety of both simple and complex activities. However, there still exist many challenges that hinder advancement in complex activity recognition using modern deep learning methods. In this paper, we comprehensively systematise factors leading to inaccuracy in complex HAR, such as data variety and model capacity. Among many sensor types, we give more attention to wearable and camera due to their prevalence. Through this Systematisation of Knowledge (SoK) paper, readers can gain a solid understanding of the development history and existing challenges of HAR, different categorisations of activities, obstacles in deep learning-based complex HAR that impact accuracy, and potential research directions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Duc\u2013Anh Nguyen et al.",
      "keywords": "Deep learning; Artificial intelligence; Computer science; Activity recognition; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.00712",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393063602",
      "doi": "10.48550/arxiv.2403.13536",
      "title": "Conceptualizing predictive conceptual model for unemployment rates in the implementation of Industry 4.0: Exploring machine learning techniques",
      "abstract": "Although there are obstacles related to obtaining data, ensuring model precision, and upholding ethical standards, the advantages of utilizing machine learning to generate predictive models for unemployment rates in developing nations amid the implementation of Industry 4.0 (I4.0) are noteworthy. This research delves into the concept of utilizing machine learning techniques through a predictive conceptual model to understand and address factors that contribute to unemployment rates in developing nations during the implementation of I4.0. A thorough examination of the literature was carried out through a literature review to determine the economic and social factors that have an impact on the unemployment rates in developing nations. The examination of the literature uncovered that considerable influence on unemployment rates in developing nations is attributed to elements such as economic growth, inflation, population increase, education levels, and technological progress. A predictive conceptual model was developed that indicates factors that contribute to unemployment in developing nations can be addressed by using techniques of machine learning like regression analysis and neural networks when adopting I4.0. The study's findings demonstrated the effectiveness of the proposed predictive conceptual model in accurately understanding and addressing unemployment rate factors within developing nations when deploying I4.0. The model serves a dual purpose of predicting future unemployment rates and tracking the advancement of reducing unemployment rates in emerging economies. By persistently conducting research and improvements, decision-makers and enterprises can employ these patterns to arrive at more knowledgeable judgments that can advance the growth of the economy, generation of employment, and alleviation of poverty specifically in emerging nations.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Joshua Ebere Chukwuere",
      "keywords": "Unemployment; Conceptual model; Computer science; Artificial intelligence; Machine learning; Knowledge management; Economics; Macroeconomics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.13536",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385015661",
      "doi": "10.48550/arxiv.2307.10223",
      "title": "Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms",
      "abstract": "Bias evaluation benchmarks and dataset and model documentation have emerged as central processes for assessing the biases and harms of artificial intelligence (AI) systems. However, these auditing processes have been criticized for their failure to integrate the knowledge of marginalized communities and consider the power dynamics between auditors and the communities. Consequently, modes of bias evaluation have been proposed that engage impacted communities in identifying and assessing the harms of AI systems (e.g., bias bounties). Even so, asking what marginalized communities want from such auditing processes has been neglected. In this paper, we ask queer communities for their positions on, and desires from, auditing processes. To this end, we organized a participatory workshop to critique and redesign bias bounties from queer perspectives. We found that when given space, the scope of feedback from workshop participants goes far beyond what bias bounties afford, with participants questioning the ownership, incentives, and efficacy of bounties. We conclude by advocating for community ownership of bounties and complementing bounties with participatory processes (e.g., co-creation).",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Organizers of QueerInAI et al.",
      "keywords": "Queer; Audit; Citizen journalism; Incentive; Documentation; Scope (computer science); Public relations; Space (punctuation); Political science; Sociology; Business; Computer science; Economics; Law; Accounting; Gender studies",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.10223",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226331163",
      "doi": "10.48550/arxiv.2201.07794",
      "title": "A Non-Expert's Introduction to Data Ethics for Mathematicians",
      "abstract": "I give a short introduction to data ethics. I begin with some background information and societal context for data ethics. I then discuss data ethics in mathematical-science education and indicate some available course material. I briefly highlight a few efforts -- at my home institution and elsewhere -- on data ethics, society, and social good. I then discuss open data in research, research replicability and some other ethical issues in research, and the tension between privacy and open data and code, and a few controversial studies and reactions to studies. I then discuss ethical principles, institutional review boards, and a few other considerations in the scientific use of human data. I then briefly survey a variety of research and lay articles that are relevant to data ethics and data privacy. I conclude with a brief summary and some closing remarks. My focal audience is mathematicians, but I hope that this chapter will also be useful to others. I am not an expert about data ethics, and this chapter provides only a starting point on this wide-ranging topic. I encourage you to examine the resources that I discuss and to reflect carefully on data ethics, its role in mathematics education, and the societal implications of data and data analysis. As data and technology continue to evolve, I hope that such careful reflection will continue throughout your life.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Mason A. Porter",
      "keywords": "Information ethics; Variety (cybernetics); Engineering ethics; Context (archaeology); Research ethics; Applied ethics; Ethics of technology; Meta-ethics; Data science; Computer science; Sociology; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2201.07794",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386080828",
      "doi": "10.48550/arxiv.2308.09857",
      "title": "DiffCharge: Generating EV Charging Scenarios via a Denoising Diffusion Model",
      "abstract": "Recent proliferation of electric vehicle (EV) charging events has brought prominent stress over power grid operation. Due to the stochastic and volatile EV charging behaviors, the induced charging loads are extremely uncertain, posing modeling and control challenges for grid operators and charging management. Generating EV charging scenarios would aid via synthesizing a myriad of realistic charging scenarios. To this end, we propose a novel denoising Diffusion-based Charging scenario generation model DiffCharge, which is capable of generating a broad variety of realistic EV charging profiles with distinctive temporal properties. It is able to progressively convert the simply known Gaussian noise to genuine charging time-series data, by learning a parameterized reversal of a forward diffusion process. Besides, we leverage the multi-head self-attention and prior conditions to capture the temporal correlations and unique information associated with EV or charging station types in real charging profiles. Moreover, We demonstrate the superiority of DiffCharge on extensive real-world charging datasets, as well as the efficacy on EV integration in power distribution grids.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Siyang Li et al.",
      "keywords": "Leverage (statistics); Computer science; Parameterized complexity; Grid; Electric vehicle; Noise (video); Power (physics); Noise reduction; Algorithm; Artificial intelligence; Physics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.09857",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415022901",
      "doi": "10.48550/arxiv.2505.14217",
      "title": "Federated learning in low-resource settings: A chest imaging study in Africa -- Challenges and lessons learned",
      "abstract": "This study explores the use of Federated Learning (FL) for tuberculosis (TB) diagnosis using chest X-rays in low-resource settings across Africa. FL allows hospitals to collaboratively train AI models without sharing raw patient data, addressing privacy concerns and data scarcity that hinder traditional centralized models. The research involved hospitals and research centers in eight African countries. Most sites used local datasets, while Ghana and The Gambia used public ones. The study compared locally trained models with a federated model built across all institutions to evaluate FL's real-world feasibility. Despite its promise, implementing FL in sub-Saharan Africa faces challenges such as poor infrastructure, unreliable internet, limited digital literacy, and weak AI regulations. Some institutions were also reluctant to share model updates due to data control concerns. In conclusion, FL shows strong potential for enabling AI-driven healthcare in underserved regions, but broader adoption will require improvements in infrastructure, education, and regulatory support.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Jorge Fabila et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.14217",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3133749823",
      "doi": "10.48550/arxiv.2103.04544",
      "title": "Exploring a Makeup Support System for Transgender Passing based on Automatic Gender Recognition",
      "abstract": "How to handle gender with machine learning is a controversial topic. A growing critical body of research brought attention to the numerous issues transgender communities face with the adoption of current automatic gender recognition (AGR) systems. In contrast, we explore how such technologies could potentially be appropriated to support transgender practices and needs, especially in non-Western contexts like Japan. We designed a virtual makeup probe to assist transgender individuals with passing, that is to be perceived as the gender they identify as. To understand how such an application might support expressing transgender individuals gender identity or not, we interviewed 15 individuals in Tokyo and found that in the right context and under strict conditions, AGR based systems could assist transgender passing.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Toby Chong et al.",
      "keywords": "Transgender; Context (archaeology); Gender identity; Face (sociological concept); Transgender women; Identity (music); Psychology; Gender studies; Sociology; Social psychology; Medicine; Human immunodeficiency virus (HIV); Geography; Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2103.04544",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404307878",
      "doi": "10.48550/arxiv.2410.17792",
      "title": "Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection",
      "abstract": "Federated Learning (FL) is a decentralized approach for collaborative model training on edge devices. This distributed method of model training offers advantages in privacy, security, regulatory compliance, and cost-efficiency. Our emphasis in this research lies in addressing statistical complexity in FL, especially when the data stored locally across devices is not identically and independently distributed (non-IID). We have observed an accuracy reduction of up to approximately 10\\% to 30\\%, particularly in skewed scenarios where each edge device trains with only 1 class of data. This reduction is attributed to weight divergence, quantified using the Euclidean distance between device-level class distributions and the population distribution, resulting in a bias term (\\(\u03b4_k\\)). As a solution, we present a method to improve convergence in FL by creating a global subset of data on the server and dynamically distributing it across devices using a Dynamic Data queue-driven Federated Learning (DDFL). Next, we leverage Data Entropy metrics to observe the process during each training round and enable reasonable device selection for aggregation. Furthermore, we provide a convergence analysis of our proposed DDFL to justify their viability in practical FL scenarios, aiming for better device selection, a non-sub-optimal global model, and faster convergence. We observe that our approach results in a substantial accuracy boost of approximately 5\\% for the MNIST dataset, around 18\\% for CIFAR-10, and 20\\% for CIFAR-100 with a 10\\% global subset of data, outperforming the state-of-the-art (SOTA) aggregation algorithms.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Charuka Herath et al.",
      "keywords": "Queue; Computer science; Convergence (economics); Selection (genetic algorithm); Entropy (arrow of time); Dynamic data; Artificial intelligence; Economics; Database; Computer network; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.17792",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389708762",
      "doi": "10.48550/arxiv.2312.06074",
      "title": "A Vision for Operationalising Diversity and Inclusion in AI",
      "abstract": "The growing presence of Artificial Intelligence (AI) in various sectors necessitates systems that accurately reflect societal diversity. This study seeks to envision the operationalization of the ethical imperatives of diversity and inclusion (D&amp;I) within AI ecosystems, addressing the current disconnect between ethical guidelines and their practical implementation. A significant challenge in AI development is the effective operationalization of D&amp;I principles, which is critical to prevent the reinforcement of existing biases and ensure equity across AI applications. This paper proposes a vision of a framework for developing a tool utilizing persona-based simulation by Generative AI (GenAI). The approach aims to facilitate the representation of the needs of diverse users in the requirements analysis process for AI software. The proposed framework is expected to lead to a comprehensive persona repository with diverse attributes that inform the development process with detailed user narratives. This research contributes to the development of an inclusive AI paradigm that ensures future technological advances are designed with a commitment to the diverse fabric of humanity.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Muneera Bano et al.",
      "keywords": "Operationalization; Persona; Inclusion (mineral); Computer science; Toolbox; Process (computing); Diversity (politics); Knowledge management; Equity (law); Engineering ethics; Data science; Sociology; Human\u2013computer interaction; Engineering; Political science; Epistemology; Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2312.06074",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4378501082",
      "doi": "10.48550/arxiv.2305.15922",
      "title": "Towards a Capability Assessment Model for the Comprehension and Adoption of AI in Organisations",
      "abstract": "The comprehension and adoption of Artificial Intelligence (AI) are beset with practical and ethical problems. This article presents a 5-level AI Capability Assessment Model (AI-CAM) and a related AI Capabilities Matrix (AI-CM) to assist practitioners in AI comprehension and adoption. These practical tools were developed with business executives, technologists, and other organisational stakeholders in mind. They are founded on a comprehensive conception of AI compared to those in other AI adoption models and are also open-source artefacts. Thus, the AI-CAM and AI-CM present an accessible resource to help inform organisational decision-makers on the capability requirements for (1) AI-based data analytics use cases based on machine learning technologies; (2) Knowledge representation to engineer and represent data, information and knowledge using semantic technologies; and (3) AI-based solutions that seek to emulate human reasoning and decision-making. The AI-CAM covers the core capability dimensions (business, data, technology, organisation, AI skills, risks, and ethical considerations) required at the five capability maturity levels to achieve optimal use of AI in organisations.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Butler et al.",
      "keywords": "Knowledge management; Computer science; Comprehension; Capability Maturity Model; Artificial intelligence; Knowledge representation and reasoning; Analytics; Applications of artificial intelligence; Resource (disambiguation); Data science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.15922",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4300980580",
      "doi": "10.48550/arxiv.2209.15560",
      "title": "Designing and Training of Lightweight Neural Networks on Edge Devices using Early Halting in Knowledge Distillation",
      "abstract": "Automated feature extraction capability and significant performance of Deep Neural Networks (DNN) make them suitable for Internet of Things (IoT) applications. However, deploying DNN on edge devices becomes prohibitive due to the colossal computation, energy, and storage requirements. This paper presents a novel approach for designing and training lightweight DNN using large-size DNN. The approach considers the available storage, processing speed, and maximum allowable processing time to execute the task on edge devices. We present a knowledge distillation based training procedure to train the lightweight DNN to achieve adequate accuracy. During the training of lightweight DNN, we introduce a novel early halting technique, which preserves network resources; thus, speedups the training procedure. Finally, we present the empirically and real-world evaluations to verify the effectiveness of the proposed approach under different constraints using various edge devices.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Rahul Mishra et al.",
      "keywords": "Computer science; Enhanced Data Rates for GSM Evolution; Artificial neural network; Edge device; Computation; Artificial intelligence; Task (project management); Edge computing; Feature (linguistics); Machine learning; Distillation; Training (meteorology); Engineering; Operating system; Systems engineering; Cloud computing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.15560",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388650734",
      "doi": "10.48550/arxiv.2311.05792",
      "title": "Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education",
      "abstract": "Despite the promises of ML in education, its adoption in the classroom has surfaced numerous issues regarding fairness, accountability, and transparency, as well as concerns about data privacy and student consent. A root cause of these issues is the lack of understanding of the complex dynamics of education, including teacher-student interactions, collaborative learning, and classroom environment. To overcome these challenges and fully utilize the potential of ML in education, software practitioners need to work closely with educators and students to fully understand the context of the data (the backbone of ML applications) and collaboratively define the ML data specifications. To gain a deeper understanding of such a collaborative process, we conduct ten co-design sessions with ML software practitioners, educators, and students. In the sessions, teachers and students work with ML engineers, UX designers, and legal practitioners to define dataset characteristics for a given ML application. We find that stakeholders contextualize data based on their domain and procedural knowledge, proactively design data requirements to mitigate downstream harms and data reliability concerns, and exhibit role-based collaborative strategies and contribution patterns. Further, we find that beyond a seat at the table, meaningful stakeholder participation in ML requires structured supports: defined processes for continuous iteration and co-evaluation, shared contextual data quality standards, and information scaffolds for both technical and non-technical stakeholders to traverse expertise boundaries.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Mei Tan et al.",
      "keywords": "Stakeholder; Computer science; Context (archaeology); Transparency (behavior); Table (database); Process (computing); Knowledge management; Accountability; Work (physics); Engineering; Public relations; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.05792",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399251467",
      "doi": "10.48550/arxiv.2405.19347",
      "title": "Near-Field Spot Beamfocusing: A Correlation-Aware Transfer Learning Approach",
      "abstract": "Three-dimensional (3D) spot beamfocusing (SBF), in contrast to conventional angular-domain beamforming, concentrates radiating power within a very small volume in both radial and angular domains in the near-field zone. Recently the implementation of channel-state-information (CSI)-independent machine learning (ML)-based approaches have been developed for effective SBF using extremely large-scale programmable metasurface (ELPMs). These methods involve dividing the ELPMs into subarrays and independently training them with Deep Reinforcement Learning to jointly focus the beam at the desired focal point (DFP). This paper explores near-field SBF using ELPMs, addressing challenges associated with lengthy training times resulting from independent training of subarrays. To achieve a faster CSI-independent solution, inspired by the correlation between the beamfocusing matrices of the subarrays, we leverage transfer learning techniques. First, we introduce a novel similarity criterion based on the phase distribution image (PDI) of subarray apertures. Then we devise a subarray policy propagation scheme that transfers the knowledge from trained to untrained subarrays. We further enhance learning by introducing quasi-liquid layers as a revised version of the adaptive policy reuse technique. We show through simulations that the proposed scheme improves the training speed about 5 times. Furthermore, for dynamic DFP management, we devised a DFP policy blending process, which augments the convergence rate up to 8-fold.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Mohammad Amir Fallah et al.",
      "keywords": "Transfer of learning; Blind spot; Sweet spot; Computer science; Field (mathematics); Correlation; Artificial intelligence; Mathematics; Simulation; Geometry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.19347",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4381249565",
      "doi": "10.48550/arxiv.2306.09690",
      "title": "An Analysis of Physiological and Psychological Responses in Virtual Reality and Flat Screen Gaming",
      "abstract": "Recent research has focused on the effectiveness of Virtual Reality (VR) in games as a more immersive method of interaction. However, there is a lack of robust analysis of the physiological effects between VR and flatscreen (FS) gaming. This paper introduces the first systematic comparison and analysis of emotional and physiological responses to commercially available games in VR and FS environments. To elicit these responses, we first selected four games through a pilot study of 6 participants to cover all four quadrants of the valence-arousal space. Using these games, we recorded the physiological activity, including Blood Volume Pulse and Electrodermal Activity, and self-reported emotions of 33 participants in a user study. Our data analysis revealed that VR gaming elicited more pronounced emotions, higher arousal, increased cognitive load and stress, and lower dominance than FS gaming. The Virtual Reality and Flat Screen (VRFS) dataset, containing over 15 hours of multimodal data comparing FS and VR gaming across different games, is also made publicly available for research purposes. Our analysis provides valuable insights for further investigations into the physiological and emotional effects of VR and FS gaming.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ritik Vatsal et al.",
      "keywords": "Virtual reality; Arousal; Valence (chemistry); Human\u2013computer interaction; Psychology; Psychophysiology; Computer science; Cognitive psychology; Social psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.09690",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4290392497",
      "doi": "10.48550/arxiv.2106.08258",
      "title": "Identifying Roles, Requirements and Responsibilities in Trustworthy AI\\n Systems",
      "abstract": "Artificial Intelligence (AI) systems are being deployed around the globe in\\ncritical fields such as healthcare and education. In some cases, expert\\npractitioners in these domains are being tasked with introducing or using such\\nsystems, but have little or no insight into what data these complex systems are\\nbased on, or how they are put together. In this paper, we consider an AI system\\nfrom the domain practitioner's perspective and identify key roles that are\\ninvolved in system deployment. We consider the differing requirements and\\nresponsibilities of each role, and identify a tension between transparency and\\nprivacy that needs to be addressed so that domain practitioners are able to\\nintelligently assess whether a particular AI system is appropriate for use in\\ntheir domain.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "I. Barclay et al.",
      "keywords": "Transparency (behavior); Software deployment; Domain (mathematical analysis); Trustworthiness; Computer science; Globe; Key (lock); Knowledge management; Data science; Computer security; Software engineering; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.08258",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4376163575",
      "doi": "10.48550/arxiv.2305.05027",
      "title": "Web Content Filtering through knowledge distillation of Large Language Models",
      "abstract": "We introduce a state-of-the-art approach for URL categorization that leverages the power of Large Language Models (LLMs) to address the primary objectives of web content filtering: safeguarding organizations from legal and ethical risks, limiting access to high-risk or suspicious websites, and fostering a secure and professional work environment. Our method utilizes LLMs to generate accurate classifications and then employs established knowledge distillation techniques to create smaller, more specialized student models tailored for web content filtering. Distillation results in a student model with a 9% accuracy rate improvement in classifying websites, sourced from customer telemetry data collected by a large security vendor, into 30 distinct content categories based on their URLs, surpassing the current state-of-the-art approach. Our student model matches the performance of the teacher LLM with 175 times less parameters, allowing the model to be used for in-line scanning of large volumes of URLs, and requires 3 orders of magnitude less manually labeled training data than the current state-of-the-art approach. Depending on the specific use case, the output generated by our approach can either be directly returned or employed as a pre-filter for more resource-intensive operations involving website images or HTML.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Tam\u00e1s V\u00f6r\u00f6s et al.",
      "keywords": "Computer science; Vendor; Filter (signal processing); Categorization; World Wide Web; Database; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.05027",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404304613",
      "doi": "10.48550/arxiv.2410.17290",
      "title": "Disease Outbreak Detection and Forecasting: A Review of Methods and Data Sources",
      "abstract": "Infectious diseases occur when pathogens from other individuals or animals infect a person, resulting in harm to both individuals and society as a whole. The outbreak of such diseases can pose a significant threat to human health. However, early detection and tracking of these outbreaks have the potential to reduce the mortality impact. To address these threats, public health authorities have endeavored to establish comprehensive mechanisms for collecting disease data. Many countries have implemented infectious disease surveillance systems, with the detection of epidemics being a primary objective. The clinical healthcare system, local/state health agencies, federal agencies, academic/professional groups, and collaborating governmental entities all play pivotal roles within this system. Moreover, nowadays, search engines and social media platforms can serve as valuable tools for monitoring disease trends. The Internet and social media have become significant platforms where users share information about their preferences and relationships. This real-time information can be harnessed to gauge the influence of ideas and societal opinions, making it highly useful across various domains and research areas, such as marketing campaigns, financial predictions, and public health, among others. This article provides a review of the existing standard methods developed by researchers for detecting outbreaks using time series data. These methods leverage various data sources, including conventional data sources and social media data or Internet data sources. The review particularly concentrates on works published within the timeframe of 2015 to 2022.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ghazaleh Babanejaddehaki et al.",
      "keywords": "Outbreak; Disease; Computer science; Econometrics; Data mining; Data science; Virology; Medicine; Mathematics; Pathology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2410.17290",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386555104",
      "doi": "10.48550/arxiv.2309.03554",
      "title": "Software Testing of Generative AI Systems: Challenges and Opportunities",
      "abstract": "Software Testing is a well-established area in software engineering, encompassing various techniques and methodologies to ensure the quality and reliability of software systems. However, with the advent of generative artificial intelligence (GenAI) systems, new challenges arise in the testing domain. These systems, capable of generating novel and creative outputs, introduce unique complexities that require novel testing approaches. In this paper, I aim to explore the challenges posed by generative AI systems and discuss potential opportunities for future research in the field of testing. I will touch on the specific characteristics of GenAI systems that make traditional testing techniques inadequate or insufficient. By addressing these challenges and pursuing further research, we can enhance our understanding of how to safeguard GenAI and pave the way for improved quality assurance in this rapidly evolving domain.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Aldeida Aleti",
      "keywords": "Computer science; Domain (mathematical analysis); Generative grammar; Software engineering; Software testing; Field (mathematics); Software quality; Quality (philosophy); Software; Systems engineering; Data science; Software development; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.03554",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396882130",
      "doi": "10.48550/arxiv.2405.06258",
      "title": "Automatic Generation of Model and Data Cards: A Step Towards Responsible AI",
      "abstract": "In an era of model and data proliferation in machine learning/AI especially marked by the rapid advancement of open-sourced technologies, there arises a critical need for standardized consistent documentation. Our work addresses the information incompleteness in current human-generated model and data cards. We propose an automated generation approach using Large Language Models (LLMs). Our key contributions include the establishment of CardBench, a comprehensive dataset aggregated from over 4.8k model cards and 1.4k data cards, coupled with the development of the CardGen pipeline comprising a two-step retrieval process. Our approach exhibits enhanced completeness, objectivity, and faithfulness in generated model and data cards, a significant step in responsible AI documentation practices ensuring better accountability and traceability.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiarui Liu et al.",
      "keywords": "Computer science; Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.06258",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4380994336",
      "doi": "10.48550/arxiv.2306.09147",
      "title": "Probabilistic Learning of Multivariate Time Series with Temporal Irregularity",
      "abstract": "Probabilistic forecasting of multivariate time series is essential for various downstream tasks. Most existing approaches rely on the sequences being uniformly spaced and aligned across all variables. However, real-world multivariate time series often suffer from temporal irregularities, including nonuniform intervals and misaligned variables, which pose significant challenges for accurate forecasting. To address these challenges, we propose an end-to-end framework that models temporal irregularities while capturing the joint distribution of variables at arbitrary continuous-time points. Specifically, we introduce a dynamic conditional continuous normalizing flow to model data distributions in a non-parametric manner, accommodating the complex, non-Gaussian characteristics commonly found in real-world datasets. Then, by leveraging a carefully factorized log-likelihood objective, our approach captures both temporal and cross-sectional dependencies efficiently. Extensive experiments on a range of real-world datasets demonstrate the superiority and adaptability of our method compared to existing approaches.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yijun Li et al.",
      "keywords": "Computer science; Probabilistic logic; Multivariate statistics; Parametric statistics; Multivariate normal distribution; Data mining; Imputation (statistics); Representation (politics); Gaussian; Missing data; Conditional probability distribution; Dependency (UML); Asynchrony (computer programming); Artificial intelligence; Machine learning; Econometrics; Mathematics; Statistics; Asynchronous communication",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.09147",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3157204791",
      "doi": "10.48550/arxiv.2105.01764",
      "title": "Surveilling Surveillance: Estimating the Prevalence of Surveillance Cameras with Street View Data",
      "abstract": "The use of video surveillance in public spaces -- both by government agencies and by private citizens -- has attracted considerable attention in recent years, particularly in light of rapid advances in face-recognition technology. But it has been difficult to systematically measure the prevalence and placement of cameras, hampering efforts to assess the implications of surveillance on privacy and public safety. Here, we combine computer vision, human verification, and statistical analysis to estimate the spatial distribution of surveillance cameras. Specifically, we build a camera detection model and apply it to 1.6 million street view images sampled from 10 large U.S. cities and 6 other major cities around the world, with positive model detections verified by human experts. After adjusting for the estimated recall of our model, and accounting for the spatial coverage of our sampled images, we are able to estimate the density of surveillance cameras visible from the road. Across the 16 cities we consider, the estimated number of surveillance cameras per linear kilometer ranges from 0.2 (in Los Angeles) to 0.9 (in Seoul). In a detailed analysis of the 10 U.S. cities, we find that cameras are concentrated in commercial, industrial, and mixed zones, and in neighborhoods with higher shares of non-white residents -- a pattern that persists even after adjusting for land use. These results help inform ongoing discussions on the use of surveillance technology, including its potential disparate impacts on communities of color.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Hao Sheng et al.",
      "keywords": "Government (linguistics); Geography; Public use; Computer science; Cartography; Business; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2105.01764",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389421360",
      "doi": "10.48550/arxiv.2312.02481",
      "title": "Learning to Holistically Detect Bridges from Large-Size VHR Remote Sensing Imagery",
      "abstract": "Bridge detection in remote sensing images (RSIs) plays a crucial role in various applications, but it poses unique challenges compared to the detection of other objects. In RSIs, bridges exhibit considerable variations in terms of their spatial scales and aspect ratios. Therefore, to ensure the visibility and integrity of bridges, it is essential to perform holistic bridge detection in large-size very-high-resolution (VHR) RSIs. However, the lack of datasets with large-size VHR RSIs limits the deep learning algorithms' performance on bridge detection. Due to the limitation of GPU memory in tackling large-size images, deep learning-based object detection methods commonly adopt the cropping strategy, which inevitably results in label fragmentation and discontinuous prediction. To ameliorate the scarcity of datasets, this paper proposes a large-scale dataset named GLH-Bridge comprising 6,000 VHR RSIs sampled from diverse geographic locations across the globe. These images encompass a wide range of sizes, varying from 2,048*2,048 to 16,38*16,384 pixels, and collectively feature 59,737 bridges. Furthermore, we present an efficient network for holistic bridge detection (HBD-Net) in large-size RSIs. The HBD-Net presents a separate detector-based feature fusion (SDFF) architecture and is optimized via a shape-sensitive sample re-weighting (SSRW) strategy. Based on the proposed GLH-Bridge dataset, we establish a bridge detection benchmark including the OBB and HBB tasks, and validate the effectiveness of the proposed HBD-Net. Additionally, cross-dataset generalization experiments on two publicly available datasets illustrate the strong generalization capability of the GLH-Bridge dataset.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yansheng Li et al.",
      "keywords": "Computer science; Bridge (graph theory); Remote sensing; Scalability; Feature (linguistics); Benchmark (surveying); Object detection; Artificial intelligence; Pattern recognition (psychology); Geography; Database; Cartography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2312.02481",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4299839334",
      "doi": "10.48550/arxiv.1802.10363",
      "title": "General Video Game AI: a Multi-Track Framework for Evaluating Agents,\\n Games and Content Generation Algorithms",
      "abstract": "General Video Game Playing (GVGP) aims at designing an agent that is capable\\nof playing multiple video games with no human intervention. In 2014, The\\nGeneral Video Game AI (GVGAI) competition framework was created and released\\nwith the purpose of providing researchers a common open-source and easy to use\\nplatform for testing their AI methods with potentially infinity of games\\ncreated using Video Game Description Language (VGDL). The framework has been\\nexpanded into several tracks during the last few years to meet the demand of\\ndifferent research directions. The agents are required either to play multiple\\nunknown games with or without access to game simulations, or to design new game\\nlevels or rules. This survey paper presents the VGDL, the GVGAI framework,\\nexisting tracks, and reviews the wide use of GVGAI framework in research,\\neducation and competitions five years after its birth. A future plan of\\nframework improvements is also described.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Diego P\u00e9rez-Li\u00e9bana et al.",
      "keywords": "Computer science; Video game; Video game design; Plan (archaeology); Game design; Game mechanics; Multimedia; Track (disk drive); Turns, rounds and time-keeping systems in games; Game Developer; Competition (biology); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1802.10363",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416097686",
      "doi": "10.48550/arxiv.2505.04960",
      "title": "Learning Item Representations Directly from Multimodal Features for Effective Recommendation",
      "abstract": "Conventional multimodal recommender systems predominantly leverage Bayesian Personalized Ranking (BPR) optimization to learn item representations by amalgamating item identity (ID) embeddings with multimodal features. Nevertheless, our empirical and theoretical findings unequivocally demonstrate a pronounced optimization gradient bias in favor of acquiring representations from multimodal features over item ID embeddings. As a consequence, item ID embeddings frequently exhibit suboptimal characteristics despite the convergence of multimodal feature parameters. Given the rich informational content inherent in multimodal features, in this paper, we propose a novel model (i.e., LIRDRec) that learns item representations directly from these features to augment recommendation performance. Recognizing that features derived from each modality may capture disparate yet correlated aspects of items, we propose a multimodal transformation mechanism, integrated with modality-specific encoders, to effectively fuse features from all modalities. Moreover, to differentiate the influence of diverse modality types, we devise a progressive weight copying fusion module within LIRDRec. This module incrementally learns the weight assigned to each modality in synthesizing the final user or item representations. Finally, we utilize the powerful visual understanding of Multimodal Large Language Models (MLLMs) to convert the item images into texts and extract semantics embeddings upon the texts via LLMs. Empirical evaluations conducted on five real-world datasets validate the superiority of our approach relative to competing baselines. It is worth noting the proposed model, equipped with embeddings extracted from MLLMs and LLMs, can further improve the recommendation accuracy of NDCG@20 by an average of 4.21% compared to the original embeddings.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Xin Zhou et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04960",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4379255921",
      "doi": "10.48550/arxiv.2306.00292",
      "title": "Sustainable AI Regulation",
      "abstract": "Current proposals for AI regulation, in the EU and beyond, aim to spur AI that is trustworthy (e.g., AI Act) and accountable (e.g., AI Liability) What is missing, however, is a robust regulatory discourse and roadmap to make AI, and technology more broadly, environmentally sustainable. This paper aims to take first steps to fill this gap. The ICT sector contributes up to 3.9 percent of global greenhouse gas (GHG) emissions-more than global air travel at 2.5 percent. The carbon footprint and water consumption of AI, especially large-scale generative models like GPT-4, raise significant sustainability concerns. The paper is the first to assess how current and proposed technology regulations, including EU environmental law, the General Data Protection Regulation (GDPR), and the AI Act, could be adjusted to better account for environmental sustainability. The GDPR, for instance, could be interpreted to limit certain individual rights like the right to erasure if these rights significantly conflict with broader sustainability goals. In a second step, the paper suggests a multi-faceted approach to achieve sustainable AI regulation. It advocates for transparency mechanisms, such as disclosing the GHG footprint of AI systems, as laid out in the proposed EU AI Act. However, sustainable AI regulation must go beyond mere transparency. The paper proposes a regulatory toolkit comprising co-regulation, sustainability-by-design principles, restrictions on training data, and consumption caps, including integration into the EU Emissions Trading Scheme. Finally, the paper argues that this regulatory toolkit could serve as a blueprint for regulating other high-emission technologies and infrastructures like blockchain, Metaverse applications, and data centers. The framework aims to cohesively address the crucial dual challenges of our era: digital transformation and climate change mitigation.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Philipp Hacker",
      "keywords": "Transparency (behavior); Sustainability; General Data Protection Regulation; Carbon footprint; Blueprint; Greenhouse gas; Sustainable development; Sustainable consumption; Business; Environmental economics; Data Protection Act 1998; Economics; Computer science; Political science; Computer security; Law; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.00292",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392020057",
      "doi": "10.48550/arxiv.2402.12801",
      "title": "Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting",
      "abstract": "Large language models (LLMs) have become the preferred solution for many natural language processing tasks. In low-resource environments such as specialized domains, their few-shot capabilities are expected to deliver high performance. Named Entity Recognition (NER) is a critical task in information extraction that is not covered in recent LLM benchmarks. There is a need for better understanding the performance of LLMs for NER in a variety of settings including languages other than English. This study aims to evaluate generative LLMs, employed through prompt engineering, for few-shot clinical NER. %from the perspective of F1 performance and environmental impact. We compare 13 auto-regressive models using prompting and 16 masked models using fine-tuning on 14 NER datasets covering English, French and Spanish. While prompt-based auto-regressive models achieve competitive F1 for general NER, they are outperformed within the clinical domain by lighter biLSTM-CRF taggers based on masked models. Additionally, masked models exhibit lower environmental impact compared to auto-regressive models. Findings are consistent across the three languages studied, which suggests that LLM prompting is not yet suited for NER production in the clinical domain.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Marco Naguib et al.",
      "keywords": "Computer science; Natural language processing; Shot (pellet); Speech recognition; Linguistics; Artificial intelligence; Philosophy; Chemistry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.12801",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387427526",
      "doi": "10.48550/arxiv.2310.03118",
      "title": "Blind CT Image Quality Assessment Using DDPM-derived Content and Transformer-based Evaluator",
      "abstract": "Lowering radiation dose per view and utilizing sparse views per scan are two common CT scan modes, albeit often leading to distorted images characterized by noise and streak artifacts. Blind image quality assessment (BIQA) strives to evaluate perceptual quality in alignment with what radiologists perceive, which plays an important role in advancing low-dose CT reconstruction techniques. An intriguing direction involves developing BIQA methods that mimic the operational characteristic of the human visual system (HVS). The internal generative mechanism (IGM) theory reveals that the HVS actively deduces primary content to enhance comprehension. In this study, we introduce an innovative BIQA metric that emulates the active inference process of IGM. Initially, an active inference module, implemented as a denoising diffusion probabilistic model (DDPM), is constructed to anticipate the primary content. Then, the dissimilarity map is derived by assessing the interrelation between the distorted image and its primary content. Subsequently, the distorted image and dissimilarity map are combined into a multi-channel image, which is inputted into a transformer-based image quality evaluator. Remarkably, by exclusively utilizing this transformer-based quality evaluator, we won the second place in the MICCAI 2023 low-dose computed tomography perceptual image quality assessment grand challenge. Leveraging the DDPM-derived primary content, our approach further improves the performance on the challenge dataset.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yongyi Shi et al.",
      "keywords": "Image quality; Computer science; Artificial intelligence; Inference; Streak; Computer vision; Transformer; Pattern recognition (psychology); Image (mathematics); Physics; Optics; Voltage",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.03118",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226497520",
      "doi": "10.48550/arxiv.2201.05538",
      "title": "A Fine-Grained Analysis of Public Opinion toward Chinese Technology Companies on Reddit",
      "abstract": "In the face of the growing global influence and prevalence of Chinese technology companies, governments worldwide have expressed concern and mistrust toward these companies. There is a scarcity of research that specifically examines the widespread public response to this phenomenon on a large scale. This study aims to fill in the gap in understanding public opinion toward Chinese technology companies using Reddit data, a popular news-oriented social media platform. We employ the state-of-the-art transformer model to build a reliable sentiment classifier. We then use LDA to extract the topics associated with positive and negative comments. We also conduct content analysis by studying the changes in the semantic meaning of the companies' names over time. Our main findings include the following: 1) Notable difference exists in the proportions of positive comments (8.42%) and negative comments (14.12%); 2) Positive comments are mostly associated with the companies' consumer products, such as smartphones, laptops, and wearable electronics. Negative comments have a more diverse topic distribution (notable topics include criticism toward the platform, dissatisfaction with the companies' smartphone products, companies' ties to the Chinese government, data security concerns, 5G construction, and general political discussions); and 3) Characterization of each technology company is usually centered around a particular predominant theme related to the company, while real-world political events may trigger drastic changes in users' characterization.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Enting Zhou et al.",
      "keywords": "Politics; Public opinion; Social media; Public relations; Scarcity; Government (linguistics); Opinion leadership; Business; Marketing; Political science; Economics; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2201.05538",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225394106",
      "doi": "10.48550/arxiv.2205.00893",
      "title": "A Survey on Security Issues in Modern Implantable Devices: Solutions and Future Issues",
      "abstract": "Implantable Medical Devices (IMD) is a fast pace growing medical field and continues to grow in the foreseeable future. Advancement in science and technology has led to the IMD devices offering advanced medical treatments. Modern IMDs can automatically monitor and manage different patients' health conditions without any manual intervention from medical professionals. While IMDs are also becoming more connected to enhance the delivery of care remotely and provide the means for both patients and physicians to adjust therapy at the comfort of their homes, it also increases security related concerns. Adversaries could take advantage and exploit device vulnerabilities to manipulate device settings remotely from anywhere around the world. This manuscript reviews the current threats, security goals, and proposed solutions by comparing them with their strengths and limitations. We also highlight the emerging IMD technologies and innovative ideas for new designs and implementations to improve the security of IMDs. Finally, we conclude the article with future research directions toward securing IMD systems to light the way for researchers.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Emmanuel Kwarteng et al.",
      "keywords": "Pace; Exploit; Implementation; Computer science; Intervention (counseling); Risk analysis (engineering); Field (mathematics); Computer security; Health care; Business; Medicine; Software engineering; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.00893",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4394906287",
      "doi": "10.48550/arxiv.2404.10343",
      "title": "The Ninth NTIRE 2024 Efficient Super-Resolution Challenge Report",
      "abstract": "This paper provides a comprehensive review of the NTIRE 2024 challenge, focusing on efficient single-image super-resolution (ESR) solutions and their outcomes. The task of this challenge is to super-resolve an input image with a magnification factor of x4 based on pairs of low and corresponding high-resolution images. The primary objective is to develop networks that optimize various aspects such as runtime, parameters, and FLOPs, while still maintaining a peak signal-to-noise ratio (PSNR) of approximately 26.90 dB on the DIV2K_LSDIR_valid dataset and 26.99 dB on the DIV2K_LSDIR_test dataset. In addition, this challenge has 4 tracks including the main track (overall performance), sub-track 1 (runtime), sub-track 2 (FLOPs), and sub-track 3 (parameters). In the main track, all three metrics (ie runtime, FLOPs, and parameter count) were considered. The ranking of the main track is calculated based on a weighted sum-up of the scores of all other sub-tracks. In sub-track 1, the practical runtime performance of the submissions was evaluated, and the corresponding score was used to determine the ranking. In sub-track 2, the number of FLOPs was considered. The score calculated based on the corresponding FLOPs was used to determine the ranking. In sub-track 3, the number of parameters was considered. The score calculated based on the corresponding parameters was used to determine the ranking. RLFN is set as the baseline for efficiency measurement. The challenge had 262 registered participants, and 34 teams made valid submissions. They gauge the state-of-the-art in efficient single-image super-resolution. To facilitate the reproducibility of the challenge and enable other researchers to build upon these findings, the code and the pre-trained model of validated solutions are made publicly available at https://github.com/Amazingren/NTIRE2024_ESR/.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Bin Ren et al.",
      "keywords": "Ninth; Resolution (logic); Computer science; Artificial intelligence; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.10343",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393023471",
      "doi": "10.48550/arxiv.2403.10982",
      "title": "Financial Performance and Innovation: Evidence From USA, 1998-2023",
      "abstract": "This study explores the relationship between R&amp;D intensity, as a measure of innovation, and financial performance among S&amp;P 500 companies over 100 quarters from 1998 to 2023, including multiple crisis periods. It challenges the conventional wisdom that larger companies are more prone to innovate, using a comprehensive dataset across various industries. The analysis reveals diverse associations between innovation and key financial indicators such as firm size, assets, EBITDA, and tangibility. Our findings underscore the importance of innovation in enhancing firm competitiveness and market positioning, highlighting the effectiveness of countercyclical innovation policies. This research contributes to the debate on the role of R&amp;D investments in driving firm value, offering new insights for both academic and policy discussions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Panteleimon Kruglov et al.",
      "keywords": "Business; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.10982",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4406093381",
      "doi": "10.48550/arxiv.2501.01785",
      "title": "Can Synthetic Data be Fair and Private? A Comparative Study of Synthetic Data Generation and Fairness Algorithms",
      "abstract": "The increasing use of machine learning in learning analytics (LA) has raised significant concerns around algorithmic fairness and privacy. Synthetic data has emerged as a dual-purpose tool, enhancing privacy and improving fairness in LA models. However, prior research suggests an inverse relationship between fairness and privacy, making it challenging to optimize both. This study investigates which synthetic data generators can best balance privacy and fairness, and whether pre-processing fairness algorithms, typically applied to real datasets, are effective on synthetic data. Our results highlight that the DEbiasing CAusal Fairness (DECAF) algorithm achieves the best balance between privacy and fairness. However, DECAF suffers in utility, as reflected in its predictive accuracy. Notably, we found that applying pre-processing fairness algorithms to synthetic data improves fairness even more than when applied to real data. These findings suggest that combining synthetic data generation with fairness pre-processing offers a promising approach to creating fairer LA models.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Qinyi Liu et al.",
      "keywords": "Synthetic data; Computer science; Algorithm",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2501.01785",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4360601585",
      "doi": "10.48550/arxiv.2206.06960",
      "title": "ABCinML: Anticipatory Bias Correction in Machine Learning Applications",
      "abstract": "The idealization of a static machine-learned model, trained once and deployed forever, is not practical. As input distributions change over time, the model will not only lose accuracy, any constraints to reduce bias against a protected class may fail to work as intended. Thus, researchers have begun to explore ways to maintain algorithmic fairness over time. One line of work focuses on dynamic learning: retraining after each batch, and the other on robust learning which tries to make algorithms robust against all possible future changes. Dynamic learning seeks to reduce biases soon after they have occurred and robust learning often yields (overly) conservative models. We propose an anticipatory dynamic learning approach for correcting the algorithm to mitigate bias before it occurs. Specifically, we make use of anticipations regarding the relative distributions of population subgroups (e.g., relative ratios of male and female applicants) in the next cycle to identify the right parameters for an importance weighing fairness approach. Results from experiments over multiple real-world datasets suggest that this approach has promise for anticipatory bias correction.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Abdulaziz A. Almuzaini et al.",
      "keywords": "Computer science; Idealization; Machine learning; Retraining; Artificial intelligence; Class (philosophy); Work (physics); Population; Engineering; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.06960",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416132658",
      "doi": "10.48550/arxiv.2506.04652",
      "title": "EMO-Debias: Benchmarking Gender Debiasing Techniques in Multi-Label Speech Emotion Recognition",
      "abstract": "Speech emotion recognition (SER) systems often exhibit gender bias. However, the effectiveness and robustness of existing debiasing methods in such multi-label scenarios remain underexplored. To address this gap, we present EMO-Debias, a large-scale comparison of 13 debiasing methods applied to multi-label SER. Our study encompasses techniques from pre-processing, regularization, adversarial learning, biased learners, and distributionally robust optimization. Experiments conducted on acted and naturalistic emotion datasets, using WavLM and XLSR representations, evaluate each method under conditions of gender imbalance. Our analysis quantifies the trade-offs between fairness and accuracy, identifying which approaches consistently reduce gender performance gaps without compromising overall model performance. The findings provide actionable insights for selecting effective debiasing strategies and highlight the impact of dataset distributions.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yi\u2010Cheng Lin et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.04652",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287813842",
      "doi": "10.48550/arxiv.2004.08945",
      "title": "Exploring Racial Bias within Face Recognition via per-subject\\n Adversarially-Enabled Data Augmentation",
      "abstract": "Whilst face recognition applications are becoming increasingly prevalent\\nwithin our daily lives, leading approaches in the field still suffer from\\nperformance bias to the detriment of some racial profiles within society. In\\nthis study, we propose a novel adversarial derived data augmentation\\nmethodology that aims to enable dataset balance at a per-subject level via the\\nuse of image-to-image transformation for the transfer of sensitive racial\\ncharacteristic facial features. Our aim is to automatically construct a\\nsynthesised dataset by transforming facial images across varying racial\\ndomains, while still preserving identity-related features, such that racially\\ndependant features subsequently become irrelevant within the determination of\\nsubject identity. We construct our experiments on three significant face\\nrecognition variants: Softmax, CosFace and ArcFace loss over a common\\nconvolutional neural network backbone. In a side-by-side comparison, we show\\nthe positive impact our proposed technique can have on the recognition\\nperformance for (racial) minority groups within an originally imbalanced\\ntraining dataset by reducing the pre-race variance in performance.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "\u015eeyma Y\u00fccer et al.",
      "keywords": "Softmax function; Computer science; Facial recognition system; Construct (python library); Convolutional neural network; Artificial intelligence; Identity (music); Face (sociological concept); Variance (accounting); Pattern recognition (psychology); Subject (documents); Field (mathematics); Transformation (genetics); Race (biology); Machine learning; Mathematics; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2004.08945",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416050707",
      "doi": "10.48550/arxiv.2508.15193",
      "title": "Revisiting Pre-processing Group Fairness: A Modular Benchmarking Framework",
      "abstract": "As machine learning systems become increasingly integrated into high-stakes decision-making processes, ensuring fairness in algorithmic outcomes has become a critical concern. Methods to mitigate bias typically fall into three categories: pre-processing, in-processing, and post-processing. While significant attention has been devoted to the latter two, pre-processing methods, which operate at the data level and offer advantages such as model-agnosticism and improved privacy compliance, have received comparatively less focus and lack standardised evaluation tools. In this work, we introduce FairPrep, an extensible and modular benchmarking framework designed to evaluate fairness-aware pre-processing techniques on tabular datasets. Built on the AIF360 platform, FairPrep allows seamless integration of datasets, fairness interventions, and predictive models. It features a batch-processing interface that enables efficient experimentation and automatic reporting of fairness and utility metrics. By offering standardised pipelines and supporting reproducible evaluations, FairPrep fills a critical gap in the fairness benchmarking landscape and provides a practical foundation for advancing data-level fairness research.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Brodie Oldfield et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2508.15193",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391948027",
      "doi": "10.48550/arxiv.2402.10762",
      "title": "On Explaining Unfairness: An Overview",
      "abstract": "Algorithmic fairness and explainability are foundational elements for achieving responsible AI. In this paper, we focus on their interplay, a research area that is recently receiving increasing attention. To this end, we first present two comprehensive taxonomies, each representing one of the two complementary fields of study: fairness and explanations. Then, we categorize explanations for fairness into three types: (a) Explanations to enhance fairness metrics, (b) Explanations to help us understand the causes of (un)fairness, and (c) Explanations to assist us in designing methods for mitigating unfairness. Finally, based on our fairness and explanation taxonomies, we present undiscovered literature paths revealing gaps that can serve as valuable insights for future research.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Christos Fragkathoulas et al.",
      "keywords": "Business; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.10762",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287815073",
      "doi": "10.48550/arxiv.2004.06592",
      "title": "InsideBias: Measuring Bias in Deep Networks and Application to Face\\n Gender Biometrics",
      "abstract": "This work explores the biases in learning processes based on deep neural\\nnetwork architectures. We analyze how bias affects deep learning processes\\nthrough a toy example using the MNIST database and a case study in gender\\ndetection from face images. We employ two gender detection models based on\\npopular deep neural networks. We present a comprehensive analysis of bias\\neffects when using an unbalanced training dataset on the features learned by\\nthe models. We show how bias impacts in the activations of gender detection\\nmodels based on face images. We finally propose InsideBias, a novel method to\\ndetect biased models. InsideBias is based on how the models represent the\\ninformation instead of how they perform, which is the normal practice in other\\nexisting methods for bias detection. Our strategy with InsideBias allows to\\ndetect biased models with very few samples (only 15 images in our case study).\\nOur experiments include 72K face images from 24K identities and 3 ethnic\\ngroups.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Ignacio Serna et al.",
      "keywords": "MNIST database; Artificial intelligence; Computer science; Biometrics; Face (sociological concept); Deep learning; Gender bias; Deep neural networks; Machine learning; Artificial neural network; Pattern recognition (psychology); Psychology; Social psychology; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2004.06592",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417083728",
      "doi": "10.48550/arxiv.2504.12236",
      "title": "Towards Human-Centered Early Prediction Models for Academic Performance in Real-World Contexts",
      "abstract": "Supporting student success requires collaboration among multiple stakeholders. Researchers have explored machine learning models for academic performance prediction; yet key challenges remain in ensuring these models are interpretable, equitable, and actionable within real-world educational support systems. First, many models prioritize predictive accuracy but overlook human-centered machine learning principles, limiting trust among students and reducing their usefulness for educators and institutional decision-makers. Second, most models require at least a month of data before making reliable predictions, delaying opportunities for early intervention. Third, current models primarily rely on sporadically collected, classroom-derived data, missing broader behavioral patterns that could provide more continuous and actionable insights. To address these gaps, we present three modeling approaches-LR, 1D-CNN, and MTL-1D-CNN-to classify students as low or high academic performers. We evaluate them based on explainability, fairness, and generalizability to assess their alignment with key social values. Using behavioral and self-reported data collected within the first week of two Spring terms, we demonstrate that these models can identify at-risk students as early as week one. However, trade-offs across human-centered machine learning principles highlight the complexity of designing predictive models that effectively support multi-stakeholder decision-making and intervention strategies. We discuss these trade-offs and their implications for different stakeholders, outlining how predictive models can be integrated into student support systems. Finally, we examine broader socio-technical challenges in deploying these models and propose future directions for advancing human-centered, collaborative academic prediction systems.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Han Zhang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.12236",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4402427617",
      "doi": "10.48550/arxiv.2408.07225",
      "title": "Longitudinal Evaluation of Child Face Recognition and the Impact of Underlying Age",
      "abstract": "The need for reliable identification of children in various emerging applications has sparked interest in leveraging child face recognition technology. This study introduces a longitudinal approach to enrollment and verification accuracy for child face recognition, focusing on the YFA database collected by Clarkson University CITeR research group over an 8 year period, at 6 month intervals.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Surendra Singh et al.",
      "keywords": "Face (sociological concept); Facial recognition system; Psychology; Political science; Developmental psychology; Cognitive psychology; Sociology; Pattern recognition (psychology); Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.07225",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396600658",
      "doi": "10.48550/arxiv.2404.19371",
      "title": "Fairness in AI: challenges in bridging the gap between algorithms and law",
      "abstract": "In this paper we examine algorithmic fairness from the perspective of law aiming to identify best practices and strategies for the specification and adoption of fairness definitions and algorithms in real-world systems and use cases. We start by providing a brief introduction of current anti-discrimination law in the European Union and the United States and discussing the concepts of bias and fairness from an legal and ethical viewpoint. We then proceed by presenting a set of algorithmic fairness definitions by example, aiming to communicate their objectives to non-technical audiences. Then, we introduce a set of core criteria that need to be taken into account when selecting a specific fairness definition for real-world use case applications. Finally, we enumerate a set of key considerations and best practices for the design and employment of fairness methods on real-world AI applications",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Giorgos Giannopoulos et al.",
      "keywords": "Bridging (networking); Algorithm; Computer science; Political science; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.19371",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4321853537",
      "doi": "10.48550/arxiv.2302.11137",
      "title": "Fairguard: Harness Logic-based Fairness Rules in Smart Cities",
      "abstract": "Smart cities operate on computational predictive frameworks that collect, aggregate, and utilize data from large-scale sensor networks. However, these frameworks are prone to multiple sources of data and algorithmic bias, which often lead to unfair prediction results. In this work, we first demonstrate that bias persists at a micro-level both temporally and spatially by studying real city data from Chattanooga, TN. To alleviate the issue of such bias, we introduce Fairguard, a micro-level temporal logic-based approach for fair smart city policy adjustment and generation in complex temporal-spatial domains. The Fairguard framework consists of two phases: first, we develop a static generator that is able to reduce data bias based on temporal logic conditions by minimizing correlations between selected attributes. Then, to ensure fairness in predictive algorithms, we design a dynamic component to regulate prediction results and generate future fair predictions by harnessing logic rules. Evaluations show that logic-enabled static Fairguard can effectively reduce the biased correlations while dynamic Fairguard can guarantee fairness on protected groups at run-time with minimal impact on overall performance.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yiqi Zhao et al.",
      "keywords": "Computer science; Component (thermodynamics); Generator (circuit theory); Smart city; Aggregate (composite); Scale (ratio); Data mining; Computer security; Internet of Things; Power (physics)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.11137",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4290802993",
      "doi": "10.48550/arxiv.2208.04705",
      "title": "Classification of Stress via Ambulatory ECG and GSR Data",
      "abstract": "In healthcare, detecting stress and enabling individuals to monitor their mental health and wellbeing is challenging. Advancements in wearable technology now enable continuous physiological data collection. This data can provide insights into mental health and behavioural states through psychophysiological analysis. However, automated analysis is required to provide timely results due to the quantity of data collected. Machine learning has shown efficacy in providing an automated classification of physiological data for health applications in controlled laboratory environments. Ambulatory uncontrolled environments, however, provide additional challenges requiring further modelling to overcome. This work empirically assesses several approaches utilising machine learning classifiers to detect stress using physiological data recorded in an ambulatory setting with self-reported stress annotations. A subset of the training portion SMILE dataset enables the evaluation of approaches before submission. The optimal stress detection approach achieves 90.77% classification accuracy, 91.24 F1-Score, 90.42 Sensitivity and 91.08 Specificity, utilising an ExtraTrees classifier and feature imputation methods. Meanwhile, accuracy on the challenge data is much lower at 59.23% (submission #54 from BEaTS-MTU, username ZacDair). The cause of the performance disparity is explored in this work.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Zachary Dair et al.",
      "keywords": "Computer science; Wearable computer; Machine learning; Artificial intelligence; Wearable technology; Data collection; Classifier (UML); Data mining; Data science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.04705",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416531216",
      "doi": "10.48550/arxiv.2504.07031",
      "title": "Identifying Key Challenges of Hardness-Based Resampling",
      "abstract": "Performance gap across classes remains a persistent challenge in machine learning, often attributed to variations in class hardness. One way to quantify class hardness is through sample complexity - the minimum number of samples required to effectively learn a given class. Sample complexity theory suggests that class hardness is driven by differences in the amount of data required for generalization. That is, harder classes need substantially more samples to achieve generalization. Therefore, hardness-based resampling is a promising approach to mitigate these performance disparities. While resampling has been studied extensively in data-imbalanced settings, its impact on balanced datasets remains unexplored. This raises the fundamental question whether resampling is effective because it addresses data imbalance or hardness imbalance. We begin addressing this question by introducing class imbalance into balanced datasets and evaluate its effect on performance disparities. We oversample hard classes and undersample easy classes to bring hard classes closer to their sample complexity requirements while maintaining a constant dataset size for fairness. We estimate class-level hardness using the Area Under the Margin (AUM) hardness estimator and leverage it to compute resampling ratios. Using these ratios, we perform hardness-based resampling on the well-known CIFAR-10 and CIFAR-100 datasets. Contrary to theoretical expectations, our results show that hardness-based resampling does not meaningfully affect class-wise performance disparities. To explain this discrepancy, we conduct detailed analyses to identify key challenges unique to hardness-based imbalance, distinguishing it from traditional data-based imbalance. Our insights help explain why theoretical sample complexity expectations fail to translate into practical performance gains and we provide guidelines for future research.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Pawel Pukowski et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.07031",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416047813",
      "doi": "10.48550/arxiv.2505.22114",
      "title": "BiMi Sheets: Infosheets for bias mitigation methods",
      "abstract": "Over the past 15 years, hundreds of bias mitigation methods have been proposed in the pursuit of fairness in machine learning (ML). However, algorithmic biases are domain-, task-, and model-specific, leading to a `portability trap': bias mitigation solutions in one context may not be appropriate in another. Thus, a myriad of design choices have to be made when creating a bias mitigation method, such as the formalization of fairness it pursues, and where and how it intervenes in the ML pipeline. This creates challenges in benchmarking and comparing the relative merits of different bias mitigation methods, and limits their uptake by practitioners. We propose BiMi Sheets as a portable, uniform guide to document the design choices of any bias mitigation method. This enables researchers and practitioners to quickly learn its main characteristics and to compare with their desiderata. Furthermore, the sheets' structure allow for the creation of a structured database of bias mitigation methods. In order to foster the sheets' adoption, we provide a platform for finding and creating BiMi Sheets at bimisheet.com.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "MaryBeth Defrance et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.22114",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389116301",
      "doi": "10.48550/arxiv.2311.15728",
      "title": "Adinkra Symbol Recognition using Classical Machine Learning and Deep Learning",
      "abstract": "Artificial intelligence (AI) has emerged as a transformative influence, engendering paradigm shifts in global societies, spanning academia and industry. However, in light of these rapid advances, addressing the underrepresentation of black communities and African countries in AI is crucial. Boosting enthusiasm for AI can be effectively accomplished by showcasing straightforward applications around tasks like identifying and categorizing traditional symbols, such as Adinkra symbols, or familiar objects within the community. In this research endeavor, we dived into classical machine learning and harnessed the power of deep learning models to tackle the intricate task of classifying and recognizing Adinkra symbols. The idea led to a newly constructed ADINKRA dataset comprising 174,338 images meticulously organized into 62 distinct classes, each representing a singular and emblematic symbol. We constructed a CNN model for classification and recognition using six convolutional layers, three fully connected (FC) layers, and optional dropout regularization. The model is a simpler and smaller version of VGG, with fewer layers, smaller channel sizes, and a fixed kernel size. Additionally, we tap into the transfer learning capabilities provided by pre-trained models like VGG and ResNet. These models assist us in both classifying images and extracting features that can be used with classical machine learning models. We assess the model's performance by measuring its accuracy and convergence rate and visualizing the areas that significantly influence its predictions. These evaluations serve as a foundational benchmark for future assessments of the ADINKRA dataset. We hope this application exemplar inspires ideas on the various uses of AI in organizing our traditional and modern lives.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Michael Adjeisah et al.",
      "keywords": "Artificial intelligence; Computer science; Machine learning; Deep learning; Transfer of learning; Boosting (machine learning); Convolutional neural network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.15728",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400486683",
      "doi": "10.48550/arxiv.2407.06014",
      "title": "Evaluating Predictive Models in Cybersecurity: A Comparative Analysis of Machine and Deep Learning Techniques for Threat Detection",
      "abstract": "As these attacks become more and more difficult to see, the need for the great hi-tech models that detect them is undeniable. This paper examines and compares various machine learning as well as deep learning models to choose the most suitable ones for detecting and fighting against cybersecurity risks. The two datasets are used in the study to assess models like Naive Bayes, SVM, Random Forest, and deep learning architectures, i.e., VGG16, in the context of accuracy, precision, recall, and F1-score. Analysis shows that Random Forest and Extra Trees do better in terms of accuracy though in different aspects of the dataset characteristics and types of threat. This research not only emphasizes the strengths and weaknesses of each predictive model but also addresses the difficulties associated with deploying such technologies in the real-world environment, such as data dependency and computational demands. The research findings are targeted at cybersecurity professionals to help them select appropriate predictive models and configure them to strengthen the security measures against cyber threats completely.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Momen Hesham et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Deep learning; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.06014",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287201178",
      "doi": "10.48550/arxiv.2104.12037",
      "title": "Precarity: Modeling the Long Term Effects of Compounded Decisions on\\n Individual Instability",
      "abstract": "When it comes to studying the impacts of decision making, the research has\\nbeen largely focused on examining the fairness of the decisions, the long-term\\neffects of the decision pipelines, and utility-based perspectives considering\\nboth the decision-maker and the individuals. However, there has hardly been any\\nfocus on precarity which is the term that encapsulates the instability in\\npeople's lives. That is, a negative outcome can overspread to other decisions\\nand measures of well-being. Studying precarity necessitates a shift in focus -\\nfrom the point of view of the decision-maker to the perspective of the decision\\nsubject. This centering of the subject is an important direction that unlocks\\nthe importance of parting with aggregate measures to examine the long-term\\neffects of decision making. To address this issue, in this paper, we propose a\\nmodeling framework that simulates the effects of compounded decision-making on\\nprecarity over time. Through our simulations, we are able to show the\\nheterogeneity of precarity by the non-uniform ruinous aftereffects of negative\\ndecisions on different income classes of the underlying population and how\\npolicy interventions can help mitigate such effects.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Pegah Nokhiz et al.",
      "keywords": "Precarity; Perspective (graphical); Psychological intervention; Decision maker; Term (time); Focus (optics); Population; Economics; Public economics; Psychology; Computer science; Sociology; Management science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2104.12037",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4414587537",
      "doi": "10.48550/arxiv.2505.19920",
      "title": "A Responsible Face Recognition Approach for Small and Mid-Scale Systems Through Personalized Neural Networks",
      "abstract": "Traditional face recognition systems rely on extracting fixed face representations, known as templates, to store and verify identities. These representations are typically generated by neural networks that often lack explainability and raise concerns regarding fairness and privacy. In this work, we propose a novel model-template (MOTE) approach that replaces vector-based face templates with small personalized neural networks. This design enables more responsible face recognition for small and medium-scale systems. During enrollment, MOTE creates a dedicated binary classifier for each identity, trained to determine whether an input face matches the enrolled identity. Each classifier is trained using only a single reference sample, along with synthetically balanced samples to allow adjusting fairness at the level of a single individual during enrollment. Extensive experiments across multiple datasets and recognition systems demonstrate substantial improvements in fairness and particularly in privacy. Although the method increases inference time and storage requirements, it presents a strong solution for small- and mid-scale applications where fairness and privacy are critical.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Sebastian Gro\u00df et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.19920",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387838336",
      "doi": "10.48550/arxiv.2310.12350",
      "title": "Equipping Federated Graph Neural Networks with Structure-aware Group Fairness",
      "abstract": "Graph Neural Networks (GNNs) have been widely used for various types of graph data processing and analytical tasks in different domains. Training GNNs over centralized graph data can be infeasible due to privacy concerns and regulatory restrictions. Thus, federated learning (FL) becomes a trending solution to address this challenge in a distributed learning paradigm. However, as GNNs may inherit historical bias from training data and lead to discriminatory predictions, the bias of local models can be easily propagated to the global model in distributed settings. This poses a new challenge in mitigating bias in federated GNNs. To address this challenge, we propose $\\text{F}^2$GNN, a Fair Federated Graph Neural Network, that enhances group fairness of federated GNNs. As bias can be sourced from both data and learning algorithms, $\\text{F}^2$GNN aims to mitigate both types of bias under federated settings. First, we provide theoretical insights on the connection between data bias in a training graph and statistical fairness metrics of the trained GNN models. Based on the theoretical analysis, we design $\\text{F}^2$GNN which contains two key components: a fairness-aware local model update scheme that enhances group fairness of the local models on the client side, and a fairness-weighted global model update scheme that takes both data bias and fairness metrics of local models into consideration in the aggregation process. We evaluate $\\text{F}^2$GNN empirically versus a number of baseline methods, and demonstrate that $\\text{F}^2$GNN outperforms these baselines in terms of both fairness and model accuracy.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Nan Cui et al.",
      "keywords": "Computer science; Graph; Theoretical computer science; Artificial neural network; Scheme (mathematics); Artificial intelligence; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.12350",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399198095",
      "doi": "10.48550/arxiv.2405.18737",
      "title": "WLC-Net: a robust and fast deep-learning wood-leaf classification method",
      "abstract": "Wood-leaf classification is an essential and fundamental prerequisite in the analysis and estimation of forest attributes from terrestrial laser scanning (TLS) point clouds,including critical measurements such as diameter at breast height(DBH),above-ground biomass(AGB),wood volume.To address this,we introduce the Wood-Leaf Classification Network(WLC-Net),a deep learning model derived from PointNet++,designed to differentiate between wood and leaf points within tree point clouds.WLC-Net enhances classification accuracy,completeness,and speed by incorporating linearity as an inherent feature,refining the input-output framework,and optimizing the centroid sampling technique.WLC-Net was trained and assessed using three distinct tree species datasets,comprising a total of 102 individual tree point clouds:21 Chinese ash trees,21 willow trees,and 60 tropical trees.For comparative evaluation,five alternative methods,including PointNet++,DGCNN,Krishna Moorthy's method,LeWoS, and Sun's method,were also applied to these datasets.The classification accuracy of all six methods was quantified using three metrics:overall accuracy(OA),mean Intersection over Union(mIoU),and F1-score.Across all three datasets,WLC-Net demonstrated superior performance, achieving OA scores of 0.9778, 0.9712, and 0.9508;mIoU scores of 0.9761, 0.9693,and 0.9141;and F1-scores of 0.8628, 0.7938,and 0.9019,respectively.The time costs of WLC-Net were also recorded to evaluate the efficiency.The average processing time was 102.74s per million points for WLC-Net.In terms of visual inspect,accuracy evaluation and efficiency evaluation,the results suggest that WLC-Net presents a promising approach for wood-leaf classification,distinguished by its high accuracy. In addition,WLC-Net also exhibits strong applicability across various tree point clouds and holds promise for further optimization.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Hanlong Li et al.",
      "keywords": "Net (polyhedron); Artificial intelligence; Deep learning; Computer science; Pattern recognition (psychology); Mathematics; Geometry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.18737",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389217320",
      "doi": "10.48550/arxiv.2311.17259",
      "title": "SoUnD Framework: Analyzing (So)cial Representation in (Un)structured (D)ata",
      "abstract": "The unstructured nature of data used in foundation model development is a challenge to systematic analyses for making data use and documentation decisions. From a Responsible AI perspective, these decisions often rely upon understanding how people are represented in data. We propose a framework designed to guide analysis of human representation in unstructured data and identify downstream risks. We apply the framework in two toy examples using the Common Crawl web text corpus (C4) and LAION-400M. We also propose a set of hypothetical action steps in service of dataset use, development, and documentation.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Mark D\u00edaz et al.",
      "keywords": "Documentation; Computer science; Set (abstract data type); Representation (politics); Perspective (graphical); Unstructured data; Service (business); Data science; Artificial intelligence; Data mining; Big data; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.17259",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414633719",
      "doi": "10.48550/arxiv.2504.15743",
      "title": "iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment",
      "abstract": "Respiratory auscultation is crucial for early detection of pediatric pneumonia, a condition that can quickly worsen without timely intervention. In areas with limited physician access, effective auscultation is challenging. We present a smartphone-based system that leverages built-in microphones and advanced deep learning algorithms to detect abnormal respiratory sounds indicative of pneumonia risk. Our end-to-end deep learning framework employs domain generalization to integrate a large electronic stethoscope dataset with a smaller smartphone-derived dataset, enabling robust feature learning for accurate respiratory assessments without expensive equipment. The accompanying mobile application guides caregivers in collecting high-quality lung sound samples and provides immediate feedback on potential pneumonia risks. User studies show strong classification performance and high acceptance, demonstrating the system's ability to facilitate proactive interventions and reduce preventable childhood pneumonia deaths. By seamlessly integrating into ubiquitous smartphones, this approach offers a promising avenue for more equitable and comprehensive remote pediatric care.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Seung Gyu Jeong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.15743",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4307537762",
      "doi": "10.48550/arxiv.2210.15614",
      "title": "Private and Reliable Neural Network Inference",
      "abstract": "Reliable neural networks (NNs) provide important inference-time reliability guarantees such as fairness and robustness. Complementarily, privacy-preserving NN inference protects the privacy of client data. So far these two emerging areas have been largely disconnected, yet their combination will be increasingly important. In this work, we present the first system which enables privacy-preserving inference on reliable NNs. Our key idea is to design efficient fully homomorphic encryption (FHE) counterparts for the core algorithmic building blocks of randomized smoothing, a state-of-the-art technique for obtaining reliable models. The lack of required control flow in FHE makes this a demanding task, as na\u00efve solutions lead to unacceptable runtime. We employ these building blocks to enable privacy-preserving NN inference with robustness and fairness guarantees in a system called Phoenix. Experimentally, we demonstrate that Phoenix achieves its goals without incurring prohibitive latencies. To our knowledge, this is the first work which bridges the areas of client data privacy and reliability guarantees for NNs.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Nikola Jovanovi\u0107 et al.",
      "keywords": "Computer science; Inference; Robustness (evolution); Homomorphic encryption; Artificial neural network; Correctness; Reliability (semiconductor); Machine learning; Artificial intelligence; Key (lock); Smoothing; Encryption; Data mining; Distributed computing; Theoretical computer science; Computer security; Algorithm",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.15614",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416048309",
      "doi": "10.48550/arxiv.2505.22401",
      "title": "Facial Age Estimation: A Research Roadmap for Technological and Legal Development and Deployment",
      "abstract": "Automated facial age assessment systems operate in either estimation mode - predicting age based on facial traits, or verification mode - confirming a claimed age. These systems support access control to age-restricted goods, services, and content, and can be used in areas like e-commerce, social media, forensics, and refugee support. They may also personalise services in healthcare, finance, and advertising. While improving technological accuracy is essential, deployment must consider legal, ethical, sociological, alongside technological factors. This white paper reviews the current challenges in deploying such systems, outlines the relevant legal and regulatory landscape, and explores future research for fair, robust, and ethical age estimation technologies.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Richard Guest et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.22401",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403884079",
      "doi": "10.48550/arxiv.2410.02584",
      "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions",
      "abstract": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations (&gt;= 50\\% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Angana Borah et al.",
      "keywords": "Implicit bias; Computer science; Artificial intelligence; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.02584",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416051380",
      "doi": "10.48550/arxiv.2508.15643",
      "title": "Reading Between the Lines: A Study of Thematic Bias in Book Recommender Systems",
      "abstract": "Recommender systems help users discover new content, but can also reinforce existing biases, leading to unfair exposure and reduced diversity. This paper introduces and investigates thematic bias in book recommendations, defined as a disproportionate favouring or neglect of certain book themes. We adopt a multi-stage bias evaluation framework using the Book-Crossing dataset to evaluate thematic bias in recommendations and its impact on different user groups. Our findings show that thematic bias originates from content imbalances and is amplified by user engagement patterns. By segmenting users based on their thematic preferences, we find that users with niche and long-tail interests receive less personalised recommendations, whereas users with diverse interests receive more consistent recommendations. These findings suggest that recommender systems should be carefully designed to accommodate a broader range of user interests. By contributing to the broader goal of responsible AI, this work also lays the groundwork for extending thematic bias analysis to other domains.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Nishita Kalra et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2508.15643",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4361193747",
      "doi": "10.48550/arxiv.2303.14966",
      "title": "Adaptive Federated Learning via New Entropy Approach",
      "abstract": "Federated Learning (FL) has emerged as a prominent distributed machine learning framework that enables geographically discrete clients to train a global model collaboratively while preserving their privacy-sensitive data. However, due to the non-independent-and-identically-distributed (Non-IID) data generated by heterogeneous clients, the performances of the conventional federated optimization schemes such as FedAvg and its variants deteriorate, requiring the design to adaptively adjust specific model parameters to alleviate the negative influence of heterogeneity. In this paper, by leveraging entropy as a new metric for assessing the degree of system disorder, we propose an adaptive FEDerated learning algorithm based on ENTropy theory (FedEnt) to alleviate the parameter deviation among heterogeneous clients and achieve fast convergence. Nevertheless, given the data disparity and parameter deviation of heterogeneous clients, determining the optimal dynamic learning rate for each client becomes a challenging task as there is no communication among participating clients during the local training epochs. To enable a decentralized learning rate for each participating client, we first introduce the mean-field terms to estimate the components associated with other clients' local parameters. Furthermore, we provide rigorous theoretical analysis on the existence and determination of the mean-field estimators. Based on the mean-field estimators, the closed-form adaptive learning rate for each client is derived by constructing the Hamilton equation. Moreover, the convergence rate of our proposed FedEnt is proved. The extensive experimental results on the real-world datasets (i.e., MNIST, EMNIST-L, CIFAR10, and CIFAR100) show that our FedEnt algorithm surpasses FedAvg and its variants (i.e., FedAdam, FedProx, and FedDyn) under Non-IID settings and achieves a faster convergence rate.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shensheng Zheng et al.",
      "keywords": "Computer science; Rate of convergence; Estimator; Principle of maximum entropy; Entropy (arrow of time); Convergence (economics); Artificial intelligence; Mathematical optimization; Machine learning; Key (lock); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.14966",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399026116",
      "doi": "10.48550/arxiv.2405.13903",
      "title": "ST-Gait++: Leveraging spatio-temporal convolutions for gait-based emotion recognition on videos",
      "abstract": "Emotion recognition is relevant for human behaviour understanding, where facial expression and speech recognition have been widely explored by the computer vision community. Literature in the field of behavioural psychology indicates that gait, described as the way a person walks, is an additional indicator of emotions. In this work, we propose a deep framework for emotion recognition through the analysis of gait. More specifically, our model is composed of a sequence of spatial-temporal Graph Convolutional Networks that produce a robust skeleton-based representation for the task of emotion classification. We evaluate our proposed framework on the E-Gait dataset, composed of a total of 2177 samples. The results obtained represent an improvement of approximately 5% in accuracy compared to the state of the art. In addition, during training we observed a faster convergence of our model compared to the state-of-the-art methodologies.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Maria Lu\u0131\u0301sa Lima et al.",
      "keywords": "Gait; Computer science; Physical medicine and rehabilitation; Artificial intelligence; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.13903",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396765645",
      "doi": "10.48550/arxiv.2405.01614",
      "title": "RULSurv: A probabilistic survival-based method for early censoring-aware prediction of remaining useful life in ball bearings",
      "abstract": "Predicting the remaining useful life (RUL) of ball bearings is an active area of research, where novel machine learning techniques are continuously being applied to predict degradation trends and anticipate failures before they occur. However, few studies have explicitly addressed the challenge of handling censored data, where information about a specific event (\\eg mechanical failure) is incomplete or only partially observed. To address this issue, we introduce a novel and flexible method for early fault detection using Kullback-Leibler (KL) divergence and RUL estimation using survival analysis that naturally supports censored data. We demonstrate our approach in the XJTU-SY dataset using a 5-fold cross-validation strategy across three different operating conditions. When predicting the time to failure for bearings under the highest load (C1, 12.0 kN and 2100 RPM) with 25% random censoring, our approach achieves a mean absolute error (MAE) of 14.7 minutes (95% CI = 13.6-15.8) using a linear CoxPH model, and an MAE of 12.6 minutes (95% CI = 11.8-13.4) using a nonlinear Random Survival Forests model, compared to an MAE of 18.5 minutes (95% CI = 17.4-19.6) using a linear LASSO model that does not support censoring. Moreover, our approach achieves a mean cumulative relative accuracy (CRA) of 0.7586 over 5 bearings under the highest load, which improves over several state-of-the-art baselines. Our work highlights the importance of considering censored data as part of the model design when building predictive models for early fault detection and RUL estimation.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Christian Marius Lillelund et al.",
      "keywords": "Estimation; Probabilistic logic; Event (particle physics); Statistics; Econometrics; Computer science; Event data; Data mining; Mathematics; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.01614",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392340234",
      "doi": "10.48550/arxiv.2402.18528",
      "title": "Gradient Reweighting: Towards Imbalanced Class-Incremental Learning",
      "abstract": "Class-Incremental Learning (CIL) trains a model to continually recognize new classes from non-stationary data while retaining learned knowledge. A major challenge of CIL arises when applying to real-world data characterized by non-uniform distribution, which introduces a dual imbalance problem involving (i) disparities between stored exemplars of old tasks and new class data (inter-phase imbalance), and (ii) severe class imbalances within each individual task (intra-phase imbalance). We show that this dual imbalance issue causes skewed gradient updates with biased weights in FC layers, thus inducing over/under-fitting and catastrophic forgetting in CIL. Our method addresses it by reweighting the gradients towards balanced optimization and unbiased classifier learning. Additionally, we observe imbalanced forgetting where paradoxically the instance-rich classes suffer higher performance degradation during CIL due to a larger amount of training data becoming unavailable in subsequent learning phases. To tackle this, we further introduce a distribution-aware knowledge distillation loss to mitigate forgetting by aligning output logits proportionally with the distribution of lost training data. We validate our method on CIFAR-100, ImageNetSubset, and Food101 across various evaluation protocols and demonstrate consistent improvements compared to existing works, showing great potential to apply CIL in real-world scenarios with enhanced robustness and effectiveness.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiangpeng He et al.",
      "keywords": "Class (philosophy); Computer science; Incremental learning; Artificial intelligence; Machine learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.18528",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404450391",
      "doi": "10.48550/arxiv.2411.09101",
      "title": "Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery",
      "abstract": "Vision Transformers (ViT) have recently brought a new wave of research in the field of computer vision. These models have performed particularly well in image classification and segmentation. Research on semantic and instance segmentation has accelerated with the introduction of the new architecture, with over 80% of the top 20 benchmarks for the iSAID dataset based on either the ViT architecture or the attention mechanism behind its success. This paper focuses on the heuristic comparison of three key factors of using (or not using) ViT for semantic segmentation of remote sensing aerial images on the iSAID dataset. The experimental results observed during this research were analyzed based on three objectives. First, we studied the use of a weighted fused loss function to maximize the mean Intersection over Union (mIoU) score and Dice score while minimizing entropy or class representation loss. Second, we compared transfer learning on Meta's MaskFormer, a ViT-based semantic segmentation model, against a generic UNet Convolutional Neural Network (CNN) based on mIoU, Dice scores, training efficiency, and inference time. Third, we examined the trade-offs between the two models in comparison to current state-of-the-art segmentation models. We show that the novel combined weighted loss function significantly boosts the CNN model's performance compared to transfer learning with ViT. The code for this implementation can be found at: https://github.com/ashimdahal/ViT-vs-CNN-Image-Segmentation.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ashim Dahal et al.",
      "keywords": "Convolutional neural network; Segmentation; Artificial intelligence; Transformer; Computer science; Computer vision; Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.09101",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387560822",
      "doi": "10.48550/arxiv.2310.06219",
      "title": "Runtime Monitoring of Human-centric Requirements in Machine Learning Components: A Model-driven Engineering Approach",
      "abstract": "As machine learning (ML) components become increasingly integrated into software systems, the emphasis on the ethical or responsible aspects of their use has grown significantly. This includes building ML-based systems that adhere to human-centric requirements, such as fairness, privacy, explainability, well-being, transparency and human values. Meeting these human-centric requirements is not only essential for maintaining public trust but also a key factor determining the success of ML-based systems. However, as these requirements are dynamic in nature and continually evolve, pre-deployment monitoring of these models often proves insufficient to establish and sustain trust in ML components. Runtime monitoring approaches for ML are potentially valuable solutions to this problem. Existing state-of-the-art techniques often fall short as they seldom consider more than one human-centric requirement, typically focusing on fairness, safety, and trust. The technical expertise and effort required to set up a monitoring system are also challenging. In my PhD research, I propose a novel approach for the runtime monitoring of multiple human-centric requirements. This approach leverages model-driven engineering to more comprehensively monitor ML components. This doctoral symposium paper outlines the motivation for my PhD work, a potential solution, progress so far and future plans.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Hira Naveed",
      "keywords": "Software deployment; Computer science; Transparency (behavior); Requirements engineering; Key (lock); Risk analysis (engineering); Systems engineering; System requirements; Set (abstract data type); Software engineering; Separation of concerns; Software; Computer security; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.06219",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415240914",
      "doi": "10.48550/arxiv.2508.14741",
      "title": "CaTE Data Curation for Trustworthy AI",
      "abstract": "This report provides practical guidance to teams designing or developing AI-enabled systems for how to promote trustworthiness during the data curation phase of development. In this report, the authors first define data, the data curation phase, and trustworthiness. We then describe a series of steps that the development team, especially data scientists, can take to build a trustworthy AI-enabled system. We enumerate the sequence of core steps and trace parallel paths where alternatives exist. The descriptions of these steps include strengths, weaknesses, preconditions, outcomes, and relevant open-source software tool implementations. In total, this report is a synthesis of data curation tools and approaches from relevant academic literature, and our goal is to equip readers with a diverse yet coherent set of practices for improving AI trustworthiness.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mary Versa Clemens-Sewall et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2508.14741",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4407759137",
      "doi": "10.48550/arxiv.2502.12176",
      "title": "Ten Challenging Problems in Federated Foundation Models",
      "abstract": "Federated Foundation Models (FedFMs) represent a distributed learning paradigm that fuses general competences of foundation models as well as privacy-preserving capabilities of federated learning. This combination allows the large foundation models and the small local domain models at the remote clients to learn from each other in a teacher-student learning setting. This paper provides a comprehensive summary of the ten challenging problems inherent in FedFMs, encompassing foundational theory, utilization of private data, continual learning, unlearning, Non-IID and graph data, bidirectional knowledge transfer, incentive mechanism design, game mechanism design, model watermarking, and efficiency. The ten challenging problems manifest in five pivotal aspects: ``Foundational Theory,\" which aims to establish a coherent and unifying theoretical framework for FedFMs. ``Data,\" addressing the difficulties in leveraging domain-specific knowledge from private data while maintaining privacy; ``Heterogeneity,\" examining variations in data, model, and computational resources across clients; ``Security and Privacy,\" focusing on defenses against malicious attacks and model theft; and ``Efficiency,\" highlighting the need for improvements in training, communication, and parameter efficiency. For each problem, we offer a clear mathematical definition on the objective function, analyze existing methods, and discuss the key challenges and potential solutions. This in-depth exploration aims to advance the theoretical foundations of FedFMs, guide practical implementations, and inspire future research to overcome these obstacles, thereby enabling the robust, efficient, and privacy-preserving FedFMs in various real-world applications.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Tao Fan et al.",
      "keywords": "Foundation (evidence); Computer science; Data science; Computer security; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2502.12176",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390214996",
      "doi": "10.48550/arxiv.2312.14626",
      "title": "DSAP: Analyzing Bias Through Demographic Comparison of Datasets",
      "abstract": "In the last few years, Artificial Intelligence systems have become increasingly widespread. Unfortunately, these systems can share many biases with human decision-making, including demographic biases. Often, these biases can be traced back to the data used for training, where large uncurated datasets have become the norm. Despite our knowledge of these biases, we still lack general tools to detect and quantify them, as well as to compare the biases in different datasets. Thus, in this work, we propose DSAP (Demographic Similarity from Auxiliary Profiles), a two-step methodology for comparing the demographic composition of two datasets. DSAP can be deployed in three key applications: to detect and characterize demographic blind spots and bias issues across datasets, to measure dataset demographic bias in single datasets, and to measure dataset demographic shift in deployment scenarios. An essential feature of DSAP is its ability to robustly analyze datasets without explicit demographic labels, offering simplicity and interpretability for a wide range of situations. To show the usefulness of the proposed methodology, we consider the Facial Expression Recognition task, where demographic bias has previously been found. The three applications are studied over a set of twenty datasets with varying properties. The code is available at https://github.com/irisdominguez/DSAP.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Iris Dominguez-Catena et al.",
      "keywords": "Interpretability; Computer science; Artificial intelligence; Data mining; Machine learning; Task (project management); Set (abstract data type); Feature (linguistics)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2312.14626",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4364383169",
      "doi": "10.48550/arxiv.2304.04222",
      "title": "CILIATE: Towards Fairer Class-based Incremental Learning by Dataset and Training Refinement",
      "abstract": "Due to the model aging problem, Deep Neural Networks (DNNs) need updates to adjust them to new data distributions. The common practice leverages incremental learning (IL), e.g., Class-based Incremental Learning (CIL) that updates output labels, to update the model with new data and a limited number of old data. This avoids heavyweight training (from scratch) using conventional methods and saves storage space by reducing the number of old data to store. But it also leads to poor performance in fairness. In this paper, we show that CIL suffers both dataset and algorithm bias problems, and existing solutions can only partially solve the problem. We propose a novel framework, CILIATE, that fixes both dataset and algorithm bias in CIL. It features a novel differential analysis guided dataset and training refinement process that identifies unique and important samples overlooked by existing CIL and enforces the model to learn from them. Through this process, CILIATE improves the fairness of CIL by 17.03%, 22.46%, and 31.79% compared to state-of-the-art methods, iCaRL, BiC, and WA, respectively, based on our evaluation on three popular datasets and widely used ResNet models.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xuanqi Gao et al.",
      "keywords": "Computer science; Class (philosophy); Process (computing); Artificial intelligence; Machine learning; Scratch; Artificial neural network; Training set; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.04222",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416098619",
      "doi": "10.48550/arxiv.2505.05211",
      "title": "Incentive-Aware Machine Learning; Robustness, Fairness, Improvement &amp; Causality",
      "abstract": "The article explores the emerging domain of incentive-aware machine learning (ML), which focuses on algorithmic decision-making in contexts where individuals can strategically modify their inputs to influence outcomes. It categorizes the research into three perspectives: robustness, aiming to design models resilient to \"gaming\"; fairness, analyzing the societal impacts of such systems; and improvement/causality, recognizing situations where strategic actions lead to genuine personal or societal improvement. The paper introduces a unified framework encapsulating models for these perspectives, including offline, online, and causal settings, and highlights key challenges such as differentiating between gaming and improvement and addressing heterogeneity among agents. By synthesizing findings from diverse works, we outline theoretical advancements and practical solutions for robust, fair, and causally-informed incentive-aware ML systems.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Chara Podimata",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.05211",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320342473",
      "doi": "10.48550/arxiv.2302.04453",
      "title": "Data Quality-aware Mixed-precision Quantization via Hybrid Reinforcement Learning",
      "abstract": "Mixed-precision quantization mostly predetermines the model bit-width settings before actual training due to the non-differential bit-width sampling process, obtaining sub-optimal performance. Worse still, the conventional static quality-consistent training setting, i.e., all data is assumed to be of the same quality across training and inference, overlooks data quality changes in real-world applications which may lead to poor robustness of the quantized models. In this paper, we propose a novel Data Quality-aware Mixed-precision Quantization framework, dubbed DQMQ, to dynamically adapt quantization bit-widths to different data qualities. The adaption is based on a bit-width decision policy that can be learned jointly with the quantization training. Concretely, DQMQ is modeled as a hybrid reinforcement learning (RL) task that combines model-based policy optimization with supervised quantization training. By relaxing the discrete bit-width sampling to a continuous probability distribution that is encoded with few learnable parameters, DQMQ is differentiable and can be directly optimized end-to-end with a hybrid optimization target considering both task performance and quantization benefits. Trained on mixed-quality image datasets, DQMQ can implicitly select the most proper bit-width for each layer when facing uneven input qualities. Extensive experiments on various benchmark datasets and networks demonstrate the superiority of DQMQ against existing fixed/mixed-precision quantization methods.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yingchun Wang et al.",
      "keywords": "Quantization (signal processing); Computer science; Reinforcement learning; Inference; Robustness (evolution); Benchmark (surveying); Algorithm; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.04453",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4283324439",
      "doi": "10.48550/arxiv.2206.10043",
      "title": "Classification Utility, Fairness, and Compactness via Tunable Information Bottleneck and R\u00e9nyi Measures",
      "abstract": "Designing machine learning algorithms that are accurate yet fair, not discriminating based on any sensitive attribute, is of paramount importance for society to accept AI for critical applications. In this article, we propose a novel fair representation learning method termed the R\u00e9nyi Fair Information Bottleneck Method (RFIB) which incorporates constraints for utility, fairness, and compactness (compression) of representation, and apply it to image and tabular data classification. A key attribute of our approach is that we consider - in contrast to most prior work - both demographic parity and equalized odds as fairness constraints, allowing for a more nuanced satisfaction of both criteria. Leveraging a variational approach, we show that our objectives yield a loss function involving classical Information Bottleneck (IB) measures and establish an upper bound in terms of two R\u00e9nyi measures of order $\u03b1$ on the mutual information IB term measuring compactness between the input and its encoded embedding. We study the influence of the $\u03b1$ parameter as well as two other tunable IB parameters on achieving utility/fairness trade-off goals, and show that the $\u03b1$ parameter gives an additional degree of freedom that can be used to control the compactness of the representation. Experimenting on three different image datasets (EyePACS, CelebA, and FairFace) and two tabular datasets (Adult and COMPAS), using both binary and categorical sensitive attributes, we show that on various utility, fairness, and compound utility/fairness metrics RFIB outperforms current state-of-the-art approaches.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Adam Gronowski et al.",
      "keywords": "Compact space; Information bottleneck method; Categorical variable; Bottleneck; Computer science; Representation (politics); Key (lock); Embedding; Binary number; Artificial intelligence; Machine learning; Mutual information; Mathematics; Data mining; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.10043",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399151207",
      "doi": "10.48550/arxiv.2405.17493",
      "title": "Overcoming Negative Transfer by Online Selection: Distant Domain Adaptation for Fault Diagnosis",
      "abstract": "Unsupervised domain adaptation (UDA) has achieved remarkable success in fault diagnosis, bringing significant benefits to diverse industrial applications. While most UDA methods focus on cross-working condition scenarios where the source and target domains are notably similar, real-world applications often grapple with severe domain shifts. We coin the term `distant domain adaptation problem' to describe the challenge of adapting from a labeled source domain to a significantly disparate unlabeled target domain. This problem exhibits the risk of negative transfer, where extraneous knowledge from the source domain adversely affects the target domain performance. Unfortunately, conventional UDA methods often falter in mitigating this negative transfer, leading to suboptimal performance. In response to this challenge, we propose a novel Online Selective Adversarial Alignment (OSAA) approach. Central to OSAA is its ability to dynamically identify and exclude distant source samples via an online gradient masking approach, focusing primarily on source samples that closely resemble the target samples. Furthermore, recognizing the inherent complexities in bridging the source and target domains, we construct an intermediate domain to act as a transitional domain and ease the adaptation process. Lastly, we develop a class-conditional adversarial adaptation to address the label distribution disparities while learning domain invariant representation to account for potential label distribution disparities between the domains. Through detailed experiments and ablation studies on two real-world datasets, we validate the superior performance of the OSAA method over state-of-the-art methods, underscoring its significant utility in practical scenarios with severe domain shifts.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ziyan Wang et al.",
      "keywords": "Adaptation (eye); Domain adaptation; Selection (genetic algorithm); Computer science; Domain (mathematical analysis); Fault (geology); Psychology; Artificial intelligence; Seismology; Neuroscience; Geology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.17493",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388926335",
      "doi": "10.48550/arxiv.2311.11882",
      "title": "Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection of Face Images for Various Classification Tasks",
      "abstract": "Human facial data offers valuable potential for tackling classification problems, including face recognition, age estimation, gender identification, emotion analysis, and race classification. However, recent privacy regulations, particularly the EU General Data Protection Regulation, have restricted the collection and usage of human images in research. As a result, several previously published face data sets have been removed from the internet due to inadequate data collection methods and privacy concerns. While synthetic data sets have been suggested as an alternative, they fall short of accurately representing the real data distribution. Additionally, most existing data sets are labeled for just a single task, which limits their versatility. To address these limitations, we introduce the Multi-Task Face (MTF) data set, designed for various tasks, including face recognition and classification by race, gender, and age, as well as for aiding in training generative networks. The MTF data set comes in two versions: a non-curated set containing 132,816 images of 640 individuals and a manually curated set with 5,246 images of 240 individuals, meticulously selected to maximize their classification quality. Both data sets were ethically sourced, using publicly available celebrity images in full compliance with copyright regulations. Along with providing detailed descriptions of data collection and processing, we evaluated the effectiveness of the MTF data set in training five deep learning models across the aforementioned classification tasks, achieving up to 98.88\\% accuracy for gender classification, 95.77\\% for race classification, 97.60\\% for age classification, and 79.87\\% for face recognition with the ConvNeXT model. Both MTF data sets can be accessed through the following link. https://github.com/RamiHaf/MTF_data_set",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Rami Haffar et al.",
      "keywords": "Computer science; Data set; Task (project management); Data collection; Set (abstract data type); Face (sociological concept); Facial recognition system; Raw data; The Internet; Artificial intelligence; Identification (biology); Data mining; Pattern recognition (psychology); World Wide Web; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.11882",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4307084247",
      "doi": "10.48550/arxiv.2111.08710",
      "title": "CNN Filter Learning from Drawn Markers for the Detection of Suggestive\\n Signs of COVID-19 in CT Images",
      "abstract": "Early detection of COVID-19 is vital to control its spread. Deep learning\\nmethods have been presented to detect suggestive signs of COVID-19 from chest\\nCT images. However, due to the novelty of the disease, annotated volumetric\\ndata are scarce. Here we propose a method that does not require either large\\nannotated datasets or backpropagation to estimate the filters of a\\nconvolutional neural network (CNN). For a few CT images, the user draws markers\\nat representative normal and abnormal regions. The method generates a feature\\nextractor composed of a sequence of convolutional layers, whose kernels are\\nspecialized in enhancing regions similar to the marked ones, and the decision\\nlayer of our CNN is a support vector machine. As we have no control over the CT\\nimage acquisition, we also propose an intensity standardization approach. Our\\nmethod can achieve mean accuracy and kappa values of $0.97$ and $0.93$,\\nrespectively, on a dataset with 117 CT images extracted from different sites,\\nsurpassing its counterpart in all scenarios.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Azael M. Sousa et al.",
      "keywords": "Convolutional neural network; Artificial intelligence; Computer science; Extractor; Pattern recognition (psychology); Backpropagation; Support vector machine; Feature (linguistics); Coronavirus disease 2019 (COVID-19); Filter (signal processing); Deep learning; Cohen's kappa; Novelty; Feature extraction; Artificial neural network; Computer vision; Machine learning; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2111.08710",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396778742",
      "doi": "10.48550/arxiv.2405.01790",
      "title": "Understanding Position Bias Effects on Fairness in Social Multi-Document Summarization",
      "abstract": "Text summarization models have typically focused on optimizing aspects of quality such as fluency, relevance, and coherence, particularly in the context of news articles. However, summarization models are increasingly being used to summarize diverse sources of text, such as social media data, that encompass a wide demographic user base. It is thus crucial to assess not only the quality of the generated summaries, but also the extent to which they can fairly represent the opinions of diverse social groups. Position bias, a long-known issue in news summarization, has received limited attention in the context of social multi-document summarization. We deeply investigate this phenomenon by analyzing the effect of group ordering in input documents when summarizing tweets from three distinct linguistic communities: African-American English, Hispanic-aligned Language, and White-aligned Language. Our empirical analysis shows that although the textual quality of the summaries remains consistent regardless of the input document order, in terms of fairness, the results vary significantly depending on how the dialect groups are presented in the input data. Our results suggest that position bias manifests differently in social multi-document summarization, severely impacting the fairness of summarization models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Olubusayo Olabisi et al.",
      "keywords": "Automatic summarization; Position (finance); Computer science; Position paper; Information retrieval; World Wide Web; Business; Finance",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.01790",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287684722",
      "doi": "10.48550/arxiv.2008.12138",
      "title": "How to \"Improve\" Prediction Using Behavior Modification",
      "abstract": "Many internet platforms that collect behavioral big data use it to predict user behavior for internal purposes and for their business customers (e.g., advertisers, insurers, security forces, governments, political consulting firms) who utilize the predictions for personalization, targeting, and other decision-making. Improving predictive accuracy is therefore extremely valuable. Data science researchers design algorithms, models, and approaches to improve prediction. Prediction is also improved with larger and richer data. Beyond improving algorithms and data, platforms can stealthily achieve better prediction accuracy by pushing users' behaviors towards their predicted values, using behavior modification techniques, thereby demonstrating more certain predictions. Such apparent \"improved\" prediction can result from employing reinforcement learning algorithms that combine prediction and behavior modification. This strategy is absent from the machine learning and statistics literature. Investigating its properties requires integrating causal with predictive notation. To this end, we incorporate Pearl's causal do(.) operator into the predictive vocabulary. We then decompose the expected prediction error given behavior modification, and identify the components impacting predictive power. Our derivation elucidates implications of such behavior modification to data scientists, platforms, their customers, and the humans whose behavior is manipulated. Behavior modification can make users' behavior more predictable and even more homogeneous; yet this apparent predictability might not generalize when business customers use predictions in practice. Outcomes pushed towards their predictions can be at odds with customers' intentions, and harmful to manipulated users.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Galit Shmueli et al.",
      "keywords": "Predictive power; Computer science; Predictability; Machine learning; Predictive modelling; Artificial intelligence; Personalization; Reinforcement learning; Predictive analytics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2008.12138",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417168976",
      "doi": "10.48550/arxiv.2504.20419",
      "title": "Plant Disease Detection through Multimodal Large Language Models and Convolutional Neural Networks",
      "abstract": "Automation in agriculture plays a vital role in addressing challenges related to crop monitoring and disease management, particularly through early detection systems. This study investigates the effectiveness of combining multimodal Large Language Models (LLMs), specifically GPT-4o, with Convolutional Neural Networks (CNNs) for automated plant disease classification using leaf imagery. Leveraging the PlantVillage dataset, we systematically evaluate model performance across zero-shot, few-shot, and progressive fine-tuning scenarios. A comparative analysis between GPT-4o and the widely used ResNet-50 model was conducted across three resolutions (100, 150, and 256 pixels) and two plant species (apple and corn). Results indicate that fine-tuned GPT-4o models achieved slightly better performance compared to the performance of ResNet-50, achieving up to 98.12% classification accuracy on apple leaf images, compared to 96.88% achieved by ResNet-50, with improved generalization and near-zero training loss. However, zero-shot performance of GPT-4o was significantly lower, underscoring the need for minimal training. Additional evaluations on cross-resolution and cross-plant generalization revealed the models' adaptability and limitations when applied to new domains. The findings highlight the promise of integrating multimodal LLMs into automated disease detection pipelines, enhancing the scalability and intelligence of precision agriculture systems while reducing the dependence on large, labeled datasets and high-resolution sensor infrastructure. Large Language Models, Vision Language Models, LLMs and CNNs, Disease Detection with Vision Language Models, VLMs",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Konstantinos I. Roumeliotis et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.20419",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402696782",
      "doi": "10.48550/arxiv.2408.07966",
      "title": "Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization",
      "abstract": "Federated learning is an efficient framework designed to facilitate collaborative model training across multiple distributed devices while preserving user data privacy. A significant challenge of federated learning is data-level heterogeneity, i.e., skewed or long-tailed distribution of private data. Although various methods have been proposed to address this challenge, most of them assume that the underlying global data is uniformly distributed across all clients. This paper investigates data-level heterogeneity federated learning with a brief review and redefines a more practical and challenging setting called Skewed Heterogeneous Federated Learning (SHFL). Accordingly, we propose a novel Federated Prototype Rectification with Personalization which consists of two parts: Federated Personalization and Federated Prototype Rectification. The former aims to construct balanced decision boundaries between dominant and minority classes based on private data, while the latter exploits both inter-class discrimination and intra-class consistency to rectify empirical prototypes. Experiments on three popular benchmarks show that the proposed approach outperforms current state-of-the-art methods and achieves balanced performance in both personalization and generalization.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Shunxin Guo et al.",
      "keywords": "Personalization; Rectification; Computer science; World Wide Web; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.07966",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386501206",
      "doi": "10.48550/arxiv.2309.01026",
      "title": "Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging",
      "abstract": "We present a method for zero-shot recommendation of multimodal non-stationary content that leverages recent advancements in the field of generative AI. We propose rendering inputs of different modalities as textual descriptions and to utilize pre-trained LLMs to obtain their numerical representations by computing semantic embeddings. Once unified representations of all content items are obtained, the recommendation can be performed by computing an appropriate similarity metric between them without any additional learning. We demonstrate our approach on a synthetic multimodal nudging environment, where the inputs consist of tabular, textual, and visual data.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Rachel Harrison et al.",
      "keywords": "Computer science; Generative grammar; Modalities; Rendering (computer graphics); Zero (linguistics); Metric (unit); Artificial intelligence; Generative model; Natural language processing; Similarity (geometry); Image (mathematics); Linguistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.01026",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4403808716",
      "doi": "10.48550/arxiv.2409.03741",
      "title": "Understanding Data Importance in Machine Learning Attacks: Does Valuable Data Pose Greater Harm?",
      "abstract": "Machine learning has revolutionized numerous domains, playing a crucial role in driving advancements and enabling data-centric processes. The significance of data in training models and shaping their performance cannot be overstated. Recent research has highlighted the heterogeneous impact of individual data samples, particularly the presence of valuable data that significantly contributes to the utility and effectiveness of machine learning models. However, a critical question remains unanswered: are these valuable data samples more vulnerable to machine learning attacks? In this work, we investigate the relationship between data importance and machine learning attacks by analyzing five distinct attack types. Our findings reveal notable insights. For example, we observe that high importance data samples exhibit increased vulnerability in certain attacks, such as membership inference and model stealing. By analyzing the linkage between membership inference vulnerability and data importance, we demonstrate that sample characteristics can be integrated into membership metrics by introducing sample-specific criteria, therefore enhancing the membership inference performance. These findings emphasize the urgent need for innovative defense mechanisms that strike a balance between maximizing utility and safeguarding valuable data against potential exploitation.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Rui Wen et al.",
      "keywords": "Harm; Computer science; Computer security; Data science; Artificial intelligence; Internet privacy; Machine learning; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.03741",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416014152",
      "doi": "10.48550/arxiv.2505.04531",
      "title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review",
      "abstract": "Generative language modelling has surged in popularity with the emergence of services such as ChatGPT and Google Gemini. While these models have demonstrated transformative potential in productivity and communication, they overwhelmingly cater to high-resource languages like English. This has amplified concerns over linguistic inequality in natural language processing (NLP). This paper presents the first systematic review focused specifically on strategies to address data scarcity in generative language modelling for low-resource languages (LRL). Drawing from 54 studies, we identify, categorise and evaluate technical approaches, including monolingual data augmentation, back-translation, multilingual training, and prompt engineering, across generative tasks. We also analyse trends in architecture choices, language family representation, and evaluation methods. Our findings highlight a strong reliance on transformer-based models, a concentration on a small subset of LRLs, and a lack of consistent evaluation across studies. We conclude with recommendations for extending these methods to a wider range of LRLs and outline open challenges in building equitable generative language systems. Ultimately, this review aims to support researchers and developers in building inclusive AI tools for underrepresented languages, a necessary step toward empowering LRL speakers and the preservation of linguistic diversity in a world increasingly shaped by large-scale language technologies.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "J C McGiff et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04531",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399794544",
      "doi": "10.48550/arxiv.2406.10773",
      "title": "Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles",
      "abstract": "Large language models (LLMs) are increasingly being utilised across a range of tasks and domains, with a burgeoning interest in their application within the field of journalism. This trend raises concerns due to our limited understanding of LLM behaviour in this domain, especially with respect to political bias. Existing studies predominantly focus on LLMs undertaking political questionnaires, which offers only limited insights into their biases and operational nuances. To address this gap, our study establishes a new curated dataset that contains 2,100 human-written articles and utilises their descriptions to generate 56,700 synthetic articles using nine LLMs. This enables us to analyse shifts in properties between human-authored and machine-generated articles, with this study focusing on political bias, detecting it using both supervised models and LLMs. Our findings reveal significant disparities between base and instruction-tuned LLMs, with instruction-tuned models exhibiting consistent political bias. Furthermore, we are able to study how LLMs behave as classifiers, observing their display of political bias even in this role. Overall, for the first time within the journalistic domain, this study outlines a framework and provides a structured dataset for quantifiable experiments, serving as a foundation for further research into LLM political bias and its implications.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Filip Trhl\u00edk et al.",
      "keywords": "Generative grammar; Computer science; Natural language processing; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.10773",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404570703",
      "doi": "10.48550/arxiv.2411.11249",
      "title": "EXCON: Extreme Instance-based Contrastive Representation Learning of Severely Imbalanced Multivariate Time Series for Solar Flare Prediction",
      "abstract": "In heliophysics research, predicting solar flares is crucial due to their potential to impact both space-based systems and Earth's infrastructure substantially. Magnetic field data from solar active regions, recorded by solar imaging observatories, are transformed into multivariate time series to enable solar flare prediction using temporal window-based analysis. In the realm of multivariate time series-driven solar flare prediction, addressing severe class imbalance with effective strategies for multivariate time series representation learning is key to developing robust predictive models. Traditional methods often struggle with overfitting to the majority class in prediction tasks where major solar flares are infrequent. This work presents EXCON, a contrastive representation learning framework designed to enhance classification performance amidst such imbalances. EXCON operates through four stages: obtaining core features from multivariate time series data; selecting distinctive contrastive representations for each class to maximize inter-class separation; training a temporal feature embedding module with a custom extreme reconstruction loss to minimize intra-class variation; and applying a classifier to the learned embeddings for robust classification. The proposed method leverages contrastive learning principles to map similar instances closer in the feature space while distancing dissimilar ones, a strategy not extensively explored in solar flare prediction tasks. This approach not only addresses class imbalance but also offers a versatile solution applicable to univariate and multivariate time series across binary and multiclass classification problems. Experimental results, including evaluations on the benchmark solar flare dataset and multiple time series archive datasets with binary and multiclass labels, demonstrate EXCON's efficacy in enhancing classification performance.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Onur Vural et al.",
      "keywords": "Series (stratigraphy); Solar flare; Multivariate statistics; Flare; Representation (politics); Extreme learning machine; Computer science; Artificial intelligence; Machine learning; Astrophysics; Geology; Physics; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.11249",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386148152",
      "doi": "10.48550/arxiv.2308.11841",
      "title": "A Survey for Federated Learning Evaluations: Goals and Measures",
      "abstract": "Evaluation is a systematic approach to assessing how well a system achieves its intended purpose. Federated learning (FL) is a novel paradigm for privacy-preserving machine learning that allows multiple parties to collaboratively train models without sharing sensitive data. However, evaluating FL is challenging due to its interdisciplinary nature and diverse goals, such as utility, efficiency, and security. In this survey, we first review the major evaluation goals adopted in the existing studies and then explore the evaluation metrics used for each goal. We also introduce FedEval, an open-source platform that provides a standardized and comprehensive evaluation framework for FL algorithms in terms of their utility, efficiency, and security. Finally, we discuss several challenges and future research directions for FL evaluation.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Di Chai et al.",
      "keywords": "Computer science; Federated learning; Data science; Open research; Knowledge management; Artificial intelligence; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.11841",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417262062",
      "doi": "10.48550/arxiv.2505.04963",
      "title": "ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis",
      "abstract": "Synthesizing medical images remains challenging due to limited annotated pathological data, modality domain gaps, and the complexity of representing diffuse pathologies such as liver cirrhosis. Existing methods often struggle to maintain anatomical fidelity while accurately modeling pathological features, frequently relying on priors derived from natural images or inefficient multi-step sampling. In this work, we introduce ViCTr (Vital Consistency Transfer), a novel two-stage framework that combines a rectified flow trajectory with a Tweedie-corrected diffusion process to achieve high-fidelity, pathology-aware image synthesis. First, we pretrain ViCTr on the ATLAS-8k dataset using Elastic Weight Consolidation (EWC) to preserve critical anatomical structures. We then fine-tune the model adversarially with Low-Rank Adaptation (LoRA) modules for precise control over pathology severity. By reformulating Tweedie's formula within a linear trajectory framework, ViCTr supports one-step sampling, reducing inference from 50 steps to just 4, without sacrificing anatomical realism. We evaluate ViCTr on BTCV (CT), AMOS (MRI), and CirrMRI600+ (cirrhosis) datasets. Results demonstrate state-of-the-art performance, achieving a Medical Frechet Inception Distance (MFID) of 17.01 for cirrhosis synthesis 28% lower than existing approaches and improving nnUNet segmentation by +3.8% mDSC when used for data augmentation. Radiologist reviews indicate that ViCTr-generated liver cirrhosis MRIs are clinically indistinguishable from real scans. To our knowledge, ViCTr is the first method to provide fine-grained, pathology-aware MRI synthesis with graded severity control, closing a critical gap in AI-driven medical imaging research.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Onkar Susladkar et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04963",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4382766191",
      "doi": "10.48550/arxiv.2306.16961",
      "title": "AI-Powered Interfaces for Extended Reality to support Remote Maintenance",
      "abstract": "High-end components that conduct complicated tasks automatically are a part of modern industrial systems. However, in order for these parts to function at the desired level, they need to be maintained by qualified experts. Solutions based on Augmented Reality (AR) have been established with the goal of raising production rates and quality while lowering maintenance costs. With the introduction of two unique interaction interfaces based on wearable targets and human face orientation, we are proposing hands-free advanced interactive solutions in this study with the goal of reducing the bias towards certain users. Using traditional devices in real time, a comparison investigation using alternative interaction interfaces is conducted. The suggested solutions are supported by various AI powered methods such as novel gravity-map based motion adjustment that is made possible by predictive deep models that reduce the bias of traditional hand- or finger-based interaction interfaces",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "\u00c1kos Nagy et al.",
      "keywords": "Computer science; Human\u2013computer interaction; Wearable computer; Augmented reality; Face (sociological concept); Orientation (vector space); Function (biology); Quality (philosophy); Wearable technology; Motion (physics); Raising (metalworking); Artificial intelligence; Embedded system; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.16961",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404650179",
      "doi": "10.48550/arxiv.2411.13797",
      "title": "Hugging Rain Man: A Novel Facial Action Units Dataset for Analyzing Atypical Facial Expressions in Children with Autism Spectrum Disorder",
      "abstract": "Children with Autism Spectrum Disorder (ASD) often exhibit atypical facial expressions. However, the specific objective facial features that underlie this subjective perception remain unclear. In this paper, we introduce a novel dataset, Hugging Rain Man (HRM), which includes facial action units (AUs) manually annotated by FACS experts for both children with ASD and typical development (TD). The dataset comprises a rich collection of posed and spontaneous facial expressions, totaling approximately 130,000 frames, along with 22 AUs, 10 Action Descriptors (ADs), and atypicality ratings. A statistical analysis of static images from the HRM reveals significant differences between the ASD and TD groups across multiple AUs and ADs when displaying the same emotional expressions, confirming that participants with ASD tend to demonstrate more irregular and diverse expression patterns. Subsequently, a temporal regression method was presented to analyze atypicality of dynamic sequences, thereby bridging the gap between subjective perception and objective facial characteristics. Furthermore, baseline results for AU detection are provided for future research reference. This work not only contributes to our understanding of the unique facial expression characteristics associated with ASD but also provides potential tools for ASD early screening. Portions of the dataset, features, and pretrained models are accessible at: \\url{https://github.com/Jonas-DL/Hugging-Rain-Man}.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Y. Y. Ji et al.",
      "keywords": "Autism spectrum disorder; Action (physics); Psychology; Facial expression; Autism; Spectrum (functional analysis); Cognitive psychology; Developmental psychology; Communication; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.13797",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4381253462",
      "doi": "10.48550/arxiv.2306.09871",
      "title": "Going public: the role of public participation approaches in commercial AI labs",
      "abstract": "In recent years, discussions of responsible AI practices have seen growing support for \"participatory AI\" approaches, intended to involve members of the public in the design and development of AI systems. Prior research has identified a lack of standardised methods or approaches for how to use participatory approaches in the AI development process. At present, there is a dearth of evidence on attitudes to and approaches for participation in the sites driving major AI developments: commercial AI labs. Through 12 semi-structured interviews with industry practitioners and subject-matter experts, this paper explores how commercial AI labs understand participatory AI approaches and the obstacles they have faced implementing these practices in the development of AI systems and research. We find that while interviewees view participation as a normative project that helps achieve \"societally beneficial\" AI systems, practitioners face numerous barriers to embedding participatory approaches in their companies: participation is expensive and resource intensive, it is \"atomised\" within companies, there is concern about exploitation, there is no incentive to be transparent about its adoption, and it is complicated by a lack of clear context. These barriers result in a piecemeal approach to participation that confers no decision-making power to participants and has little ongoing impact for AI labs. This papers contribution is to provide novel empirical research on the implementation of public participation in commercial AI labs, and shed light on the current challenges of using participatory approaches in this context.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Lara Groves et al.",
      "keywords": "Citizen journalism; Context (archaeology); Knowledge management; Process (computing); Public participation; Incentive; Public relations; Normative; Business; Sociology; Political science; Computer science; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.09871",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416014100",
      "doi": "10.48550/arxiv.2505.04600",
      "title": "Perpetuating Misogyny with Generative AI: How Model Personalization Normalizes Gendered Harm",
      "abstract": "Open-source text-to-image (TTI) pipelines have become dominant in the landscape of AI-generated visual content, driven by technological advances that enable users to personalize models through adapters tailored to specific tasks. While personalization methods such as LoRA offer unprecedented creative opportunities, they also facilitate harmful practices, including the generation of non-consensual deepfakes and the amplification of misogynistic or hypersexualized content. This study presents an exploratory sociotechnical analysis of CivitAI, the most active platform for sharing and developing open-source TTI models. Drawing on a dataset of more than 40 million user-generated images and over 230,000 models, we find a disproportionate rise in not-safe-for-work (NSFW) content and a significant number of models intended to mimic real individuals. We also observe a strong influence of internet subcultures on the tools and practices shaping model personalizations and resulting visual media. In response to these findings, we contextualize the emergence of exploitative visual media through feminist and constructivist perspectives on technology, emphasizing how design choices and community dynamics shape platform outcomes. Building on this analysis, we propose interventions aimed at mitigating downstream harm, including improved content moderation, rethinking tool design, and establishing clearer platform policies to promote accountability and consent.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Laura A. Wagner et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04600",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415329710",
      "doi": "10.48550/arxiv.2505.16946",
      "title": "NY Real Estate Racial Equity Analysis via Applied Machine Learning",
      "abstract": "This study analyzes tract-level real estate ownership patterns in New York State (NYS) and New York City (NYC) to uncover racial disparities. We use an advanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering, validated at 89.2% accuracy) to compare the predicted racial composition of property owners to the resident population from census data. We examine both a Full Model (statewide) and a Name-Only LSTM Model (NYC) to assess how incorporating geospatial context affects our predictions and disparity estimates. The results reveal significant inequities: White individuals hold a disproportionate share of properties and property value relative to their population, while Black, Hispanic, and Asian communities are underrepresented as property owners. These disparities are most pronounced in minority-majority neighborhoods, where ownership is predominantly White despite a predominantly non-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates these gaps by reducing owner-occupied opportunities in urban minority communities. We provide a breakdown of ownership vs. population by race for majority-White, -Black, -Hispanic, and -Asian tracts, identify those with extreme ownership disparities, and compare patterns in urban, suburban, and rural contexts. The findings underscore persistent racial inequity in property ownership, reflecting broader historical and socio-economic forces, and highlight the importance of data-driven approaches to address these issues.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Sanjana Chalavadi et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.16946",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415135018",
      "doi": "10.48550/arxiv.2506.02887",
      "title": "Overcoming Challenges of Partial Client Participation in Federated Learning : A Comprehensive Review",
      "abstract": "Federated Learning (FL) is a learning mechanism that falls under the distributed training umbrella, which collaboratively trains a shared global model without disclosing the raw data from different clients. This paper presents an extensive survey on the impact of partial client participation in federated learning. While much of the existing research focuses on addressing issues such as generalization, robustness, and fairness caused by data heterogeneity under the assumption of full client participation, limited attention has been given to the practical and theoretical challenges arising from partial client participation, which is common in real-world scenarios. This survey provides an in-depth review of existing FL methods designed to cope with partial client participation. We offer a comprehensive analysis supported by theoretical insights and empirical findings, along with a structured categorization of these methods, highlighting their respective advantages and disadvantages.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mrinmay Sen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.02887",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4297820980",
      "doi": "10.48550/arxiv.2209.05602",
      "title": "It's Not Fairness, and It's Not Fair: The Failure of Distributional Equality and the Promise of Relational Equality in Complete-Information Hiring Games",
      "abstract": "Existing efforts to formulate computational definitions of fairness have largely focused on distributional notions of equality, where equality is defined by the resources or decisions given to individuals in the system. Yet existing discrimination and injustice is often the result of unequal social relations, rather than an unequal distribution of resources. Here, we show how optimizing for existing computational and economic definitions of fairness and equality fail to prevent unequal social relations. To do this, we provide an example of a self-confirming equilibrium in a simple hiring market that is relationally unequal but satisfies existing distributional notions of fairness. In doing so, we introduce a notion of blatant relational unfairness for complete-information games, and discuss how this definition helps initiate a new approach to incorporating relational equality into computational systems.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Benjamin Fish et al.",
      "keywords": "Injustice; Fairness measure; Simple (philosophy); Distribution (mathematics); Computer science; Microeconomics; Inequality; Law and economics; Mathematical economics; Economics; Social psychology; Epistemology; Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.05602",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4400141422",
      "doi": "10.48550/arxiv.2406.18682",
      "title": "The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm",
      "abstract": "A key concern with the concept of \"alignment\" is the implicit question of \"alignment to what?\". AI systems are increasingly used across the world, yet safety alignment is often focused on homogeneous monolingual settings. Additionally, preference training and safety measures often overfit to harms common in Western-centric datasets. Here, we explore the viability of different alignment approaches when balancing dual objectives: addressing and optimizing for a non-homogeneous set of languages and cultural preferences while minimizing both global and local harms. We collect the first set of human annotated red-teaming prompts in different languages distinguishing between global and local harm, which serve as a laboratory for understanding the reliability of alignment techniques when faced with preference distributions that are non-stationary across geographies and languages. While this setting is seldom covered by the literature to date, which primarily centers on English harm mitigation, it captures real-world interactions with AI systems around the world. We establish a new precedent for state-of-the-art alignment techniques across 6 languages with minimal degradation in general performance. Our work provides important insights into cross-lingual transfer and novel optimization approaches to safeguard AI systems designed to serve global populations.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Aakanksha et al.",
      "keywords": "Harm; Prism; Business; Computer science; Psychology; Optics; Physics; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.18682",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4400104912",
      "doi": "10.48550/arxiv.2406.18422",
      "title": "Repeat and Concatenate: 2D to 3D Image Translation with 3D to 3D Generative Modeling",
      "abstract": "This paper investigates a 2D to 3D image translation method with a straightforward technique, enabling correlated 2D X-ray to 3D CT-like reconstruction. We observe that existing approaches, which integrate information across multiple 2D views in the latent space, lose valuable signal information during latent encoding. Instead, we simply repeat and concatenate the 2D views into higher-channel 3D volumes and approach the 3D reconstruction challenge as a straightforward 3D to 3D generative modeling problem, sidestepping several complex modeling issues. This method enables the reconstructed 3D volume to retain valuable information from the 2D inputs, which are passed between channel states in a Swin UNETR backbone. Our approach applies neural optimal transport, which is fast and stable to train, effectively integrating signal information across multiple views without the requirement for precise alignment; it produces non-collapsed reconstructions that are highly faithful to the 2D views, even after limited training. We demonstrate correlated results, both qualitatively and quantitatively, having trained our model on a single dataset and evaluated its generalization ability across six datasets, including out-of-distribution samples.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Abril Corona-Figueroa et al.",
      "keywords": "Translation (biology); Generative grammar; Image (mathematics); Computer science; Artificial intelligence; Computer vision; Image translation",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.18422",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417241830",
      "doi": "10.48550/arxiv.2504.06125",
      "title": "Robo-taxi Fleet Coordination at Scale via Reinforcement Learning",
      "abstract": "Fleets of robo-taxis offering on-demand transportation services, commonly known as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise for societal benefits, such as reducing pollution, energy consumption, and urban congestion. However, orchestrating these systems at scale remains a critical challenge, with existing coordination algorithms often failing to exploit the systems' full potential. This work introduces a novel decision-making framework that unites mathematical modeling with data-driven techniques. In particular, we present the AMoD coordination problem through the lens of reinforcement learning and propose a graph network-based framework that exploits the main strengths of graph representation learning, reinforcement learning, and classical operations research tools. Extensive evaluations across diverse simulation fidelities and scenarios demonstrate the flexibility of our approach, achieving superior system performance, computational efficiency, and generalizability compared to prior methods. Finally, motivated by the need to democratize research efforts in this area, we release publicly available benchmarks, datasets, and simulators for network-level coordination alongside an open-source codebase designed to provide accessible simulation platforms and establish a standardized validation process for comparing methodologies. Code available at: https://github.com/StanfordASL/RL4AMOD",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Luigi Tresca et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.06125",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415023957",
      "doi": "10.48550/arxiv.2505.14435",
      "title": "Choosing a Model, Shaping a Future: Comparing LLM Perspectives on Sustainability and its Relationship with AI",
      "abstract": "As organizations increasingly rely on AI systems for decision support in sustainability contexts, it becomes critical to understand the inherent biases and perspectives embedded in Large Language Models (LLMs). This study systematically investigates how five state-of-the-art LLMs -- Claude, DeepSeek, GPT, LLaMA, and Mistral - conceptualize sustainability and its relationship with AI. We administered validated, psychometric sustainability-related questionnaires - each 100 times per model -- to capture response patterns and variability. Our findings revealed significant inter-model differences: For example, GPT exhibited skepticism about the compatibility of AI and sustainability, whereas LLaMA demonstrated extreme techno-optimism with perfect scores for several Sustainable Development Goals (SDGs). Models also diverged in attributing institutional responsibility for AI and sustainability integration, a results that holds implications for technology governance approaches. Our results demonstrate that model selection could substantially influence organizational sustainability strategies, highlighting the need for awareness of model-specific biases when deploying LLMs for sustainability-related decision-making.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Ashley I. Bush et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.14435",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415064599",
      "doi": "10.48550/arxiv.2504.14985",
      "title": "aiXamine: Simplified LLM Safety and Security",
      "abstract": "Evaluating Large Language Models (LLMs) for safety and security remains a complex task, often requiring users to navigate a fragmented landscape of ad hoc benchmarks, datasets, metrics, and reporting formats. To address this challenge, we present aiXamine, a comprehensive black-box evaluation platform for LLM safety and security. aiXamine integrates over 40 tests (i.e., benchmarks) organized into eight key services targeting specific dimensions of safety and security: adversarial robustness, code security, fairness and bias, hallucination, model and data privacy, out-of-distribution (OOD) robustness, over-refusal, and safety alignment. The platform aggregates the evaluation results into a single detailed report per model, providing a detailed breakdown of model performance, test examples, and rich visualizations. We used aiXamine to assess over 50 publicly available and proprietary LLMs, conducting over 2K examinations. Our findings reveal notable vulnerabilities in leading models, including susceptibility to adversarial attacks in OpenAI's GPT-4o, biased outputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0. Additionally, we observe that open-source models can match or exceed proprietary models in specific services such as safety alignment, fairness and bias, and OOD robustness. Finally, we identify trade-offs between distillation strategies, model size, training methods, and architectural choices.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Fatih Deniz et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.14985",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396622218",
      "doi": "10.48550/arxiv.2405.00401",
      "title": "Optimized Drug Design using Multi-Objective Evolutionary Algorithms with SELFIES",
      "abstract": "Computer aided drug design is a promising approach to reduce the tremendous costs, i.e. time and resources, for developing new medicinal drugs. It finds application in aiding the traversal of the vast chemical space of potentially useful compounds. In this paper, we deploy multi-objective evolutionary algorithms, namely NSGA-II, NSGA-III, and MOEA/D, for this purpose. At the same time, we used the SELFIES string representation method. In addition to the QED and SA score, we optimize compounds using the GuacaMol benchmark multi-objective task sets. Our results indicate that all three algorithms show converging behavior and successfully optimize the defined criteria whilst differing mainly in the number of potential solutions found. We observe that novel and promising candidates for synthesis are discovered among obtained compounds in the Pareto-sets.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Tomoya H\u00f6mberg et al.",
      "keywords": "Computer science; Algorithm; Evolutionary algorithm; Drug; Mathematical optimization; Artificial intelligence; Mathematics; Medicine; Pharmacology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.00401",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404450808",
      "doi": "10.48550/arxiv.2411.09349",
      "title": "ParaLBench: A Large-Scale Benchmark for Computational Paralinguistics over Acoustic Foundation Models",
      "abstract": "Computational paralinguistics (ComParal) aims to develop algorithms and models to automatically detect, analyze, and interpret non-verbal information from speech communication, e. g., emotion, health state, age, and gender. Despite its rapid progress, it heavily depends on sophisticatedly designed models given specific paralinguistic tasks. Thus, the heterogeneity and diversity of ComParal models largely prevent the realistic implementation of ComParal models. Recently, with the advent of acoustic foundation models because of self-supervised learning, developing more generic models that can efficiently perceive a plethora of paralinguistic information has become an active topic in speech processing. However, it lacks a unified evaluation framework for a fair and consistent performance comparison. To bridge this gap, we conduct a large-scale benchmark, namely ParaLBench, which concentrates on standardizing the evaluation process of diverse paralinguistic tasks, including critical aspects of affective computing such as emotion recognition and emotion dimensions prediction, over different acoustic foundation models. This benchmark contains ten datasets with thirteen distinct paralinguistic tasks, covering short-, medium- and long-term characteristics. Each task is carried out on 14 acoustic foundation models under a unified evaluation framework, which allows for an unbiased methodological comparison and offers a grounded reference for the ComParal community. Based on the insights gained from ParaLBench, we also point out potential research directions, i.e., the cross-corpus generalizability, to propel ComParal research in the future. The code associated with this study will be available to foster the transparency and replicability of this work for succeeding researchers.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zixing Zhang et al.",
      "keywords": "Benchmark (surveying); Foundation (evidence); Scale (ratio); Computer science; Acoustics; History; Geography; Physics; Archaeology; Cartography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.09349",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416543814",
      "doi": "10.48550/arxiv.2504.12151",
      "title": "Towards Explainable Fusion and Balanced Learning in Multimodal Sentiment Analysis",
      "abstract": "Multimodal Sentiment Analysis (MSA) faces two critical challenges: the lack of interpretability in the decision logic of multimodal fusion and modality imbalance caused by disparities in inter-modal information density. To address these issues, we propose KAN-MCP, a novel framework that integrates the interpretability of Kolmogorov-Arnold Networks (KAN) with the robustness of the Multimodal Clean Pareto (MCPareto) framework. First, KAN leverages its univariate function decomposition to achieve transparent analysis of cross-modal interactions. This structural design allows direct inspection of feature transformations without relying on external interpretation tools, thereby ensuring both high expressiveness and interpretability. Second, the proposed MCPareto enhances robustness by addressing modality imbalance and noise interference. Specifically, we introduce the Dimensionality Reduction and Denoising Modal Information Bottleneck (DRD-MIB) method, which jointly denoises and reduces feature dimensionality. This approach provides KAN with discriminative low-dimensional inputs to reduce the modeling complexity of KAN while preserving critical sentiment-related information. Furthermore, MCPareto dynamically balances gradient contributions across modalities using the purified features output by DRD-MIB, ensuring lossless transmission of auxiliary signals and effectively alleviating modality imbalance. This synergy of interpretability and robustness not only achieves superior performance on benchmark datasets such as CMU-MOSI, CMU-MOSEI, and CH-SIMS v2 but also offers an intuitive visualization interface through KAN's interpretable architecture.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "M. X. Luo et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.12151",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4414588337",
      "doi": "10.48550/arxiv.2505.20227",
      "title": "Measure Domain's Gap: A Similar Domain Selection Principle for Multi-Domain Recommendation",
      "abstract": "Multi-Domain Recommendation (MDR) achieves the desirable recommendation performance by effectively utilizing the transfer information across different domains. Despite the great success, most existing MDR methods adopt a single structure to transfer complex domain-shared knowledge. However, the beneficial transferring information should vary across different domains. When there is knowledge conflict between domains or a domain is of poor quality, unselectively leveraging information from all domains will lead to a serious Negative Transfer Problem (NTP). Therefore, how to effectively model the complex transfer relationships between domains to avoid NTP is still a direction worth exploring. To address these issues, we propose a simple and dynamic Similar Domain Selection Principle (SDSP) for multi-domain recommendation in this paper. SDSP presents the initial exploration of selecting suitable domain knowledge for each domain to alleviate NTP. Specifically, we propose a novel prototype-based domain distance measure to effectively model the complexity relationship between domains. Thereafter, the proposed SDSP can dynamically find similar domains for each domain based on the supervised signals of the domain metrics and the unsupervised distance measure from the learned domain prototype. We emphasize that SDSP is a lightweight method that can be incorporated with existing MDR methods for better performance while not introducing excessive time overheads. To the best of our knowledge, it is the first solution that can explicitly measure domain-level gaps and dynamically select appropriate domains in the MDR field. Extensive experiments on three datasets demonstrate the effectiveness of our proposed method.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yi Wen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.20227",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403755030",
      "doi": "10.48550/arxiv.2409.13168",
      "title": "Economic Policy Challenges for the Age of AI",
      "abstract": "This paper examines the profound challenges that transformative advances in AI towards Artificial General Intelligence (AGI) will pose for economists and economic policymakers. I examine how the Age of AI will revolutionize the basic structure of our economies by diminishing the role of labor, leading to unprecedented productivity gains but raising concerns about job disruption, income distribution, and the value of education and human capital. I explore what roles may remain for labor post-AGI, and which production factors will grow in importance. The paper then identifies eight key challenges for economic policy in the Age of AI: (1) inequality and income distribution, (2) education and skill development, (3) social and political stability, (4) macroeconomic policy, (5) antitrust and market regulation, (6) intellectual property, (7) environmental implications, and (8) global AI governance. It concludes by emphasizing how economists can contribute to a better understanding of these challenges.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Anton Korinek",
      "keywords": "Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.13168",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399991039",
      "doi": "10.48550/arxiv.2406.15074",
      "title": "Balancing The Perception of Cheating Detection, Privacy and Fairness: A Mixed-Methods Study of Visual Data Obfuscation in Remote Proctoring",
      "abstract": "Remote proctoring technology, a cheating-preventive measure, often raises privacy and fairness concerns that may affect test-takers' experiences and the validity of test results. Our study explores how selectively obfuscating information in video recordings can protect test-takers' privacy while ensuring effective and fair cheating detection. Interviews with experts (N=9) identified four key video regions indicative of potential cheating behaviors: the test-taker's face, body, background and the presence of individuals in the background. Experts recommended specific obfuscation methods for each region based on privacy significance and cheating behavior frequency, ranging from conventional blurring to advanced methods like replacement with deepfake, 3D avatars and silhouetting. We then conducted a vignette experiment with potential test-takers (N=259, non-experts) to evaluate their perceptions of cheating detection, visual privacy and fairness, using descriptions and examples of still images for each expert-recommended combination of video regions and obfuscation methods. Our results indicate that the effectiveness of obfuscation methods varies by region. Tailoring remote proctoring with region-specific advanced obfuscation methods can improve the perceptions of privacy and fairness compared to the conventional methods, though it may decrease perceived information sufficiency for detecting cheating. However, non-experts preferred conventional blurring for videos they were more willing to share, highlighting a gap between the perceived effectiveness of the advanced obfuscation methods and their practical acceptance. This study contributes to the field of user-centered privacy by suggesting promising directions to address current remote proctoring challenges and guiding future research.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Suvadeep Mukherjee et al.",
      "keywords": "Cheating; Computer science; Internet privacy; Obfuscation; Perception; Computer security; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.15074",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4406072390",
      "doi": "10.48550/arxiv.2407.14850",
      "title": "A Tale of Single-channel Electroencephalogram: Devices, Datasets, Signal Processing, Applications, and Future Directions",
      "abstract": "Single-channel electroencephalogram (EEG) is a cost-effective, comfortable, and non-invasive method for monitoring brain activity, widely adopted by researchers, consumers, and clinicians. The increasing number and proportion of articles on single-channel EEG underscore its growing potential. This paper provides a comprehensive review of single-channel EEG, focusing on development trends, devices, datasets, signal processing methods, recent applications, and future directions. Definitions of bipolar and unipolar configurations in single-channel EEG are clarified to guide future advancements. Applications mainly span sleep staging, emotion recognition, educational research, and clinical diagnosis. Ongoing advancements of single-channel EEG in AI-based EEG generation techniques suggest potential parity or superiority over multichannel EEG performance.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yueyang Li et al.",
      "keywords": "Signal processing; Computer science; Channel (broadcasting); SIGNAL (programming language); Electroencephalography; Telecommunications; Psychology; Computer hardware; Digital signal processing; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.14850",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4394946949",
      "doi": "10.48550/arxiv.2404.10857",
      "title": "D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation",
      "abstract": "While human annotations play a crucial role in language technologies, annotator subjectivity has long been overlooked in data collection. Recent studies that have critically examined this issue are often situated in the Western context, and solely document differences across age, gender, or racial groups. As a result, NLP research on subjectivity have overlooked the fact that individuals within demographic groups may hold diverse values, which can influence their perceptions beyond their group norms. To effectively incorporate these considerations into NLP pipelines, we need datasets with extensive parallel annotations from various social and cultural groups. In this paper we introduce the \\dataset dataset: a large-scale cross-cultural dataset of parallel annotations for offensive language in over 4.5K sentences annotated by a pool of over 4k annotators, balanced across gender and age, from across 21 countries, representing eight geo-cultural regions. The dataset contains annotators' moral values captured along six moral foundations: care, equality, proportionality, authority, loyalty, and purity. Our analyses reveal substantial regional variations in annotators' perceptions that are shaped by individual moral values, offering crucial insights for building pluralistic, culturally sensitive NLP models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Aida Mostafazadeh Davani et al.",
      "keywords": "Psychology; Social psychology; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.10857",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4398796665",
      "doi": "10.48550/arxiv.2405.14211",
      "title": "ChronosLex: Time-aware Incremental Training for Temporal Generalization of Legal Classification Tasks",
      "abstract": "This study investigates the challenges posed by the dynamic nature of legal multi-label text classification tasks, where legal concepts evolve over time. Existing models often overlook the temporal dimension in their training process, leading to suboptimal performance of those models over time, as they treat training data as a single homogeneous block. To address this, we introduce ChronosLex, an incremental training paradigm that trains models on chronological splits, preserving the temporal order of the data. However, this incremental approach raises concerns about overfitting to recent data, prompting an assessment of mitigation strategies using continual learning and temporal invariant methods. Our experimental results over six legal multi-label text classification datasets reveal that continual learning methods prove effective in preventing overfitting thereby enhancing temporal generalizability, while temporal invariant methods struggle to capture these dynamics of temporal shifts.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "T. Y. S. S Santosh et al.",
      "keywords": "Generalization; Computer science; Training (meteorology); Artificial intelligence; Machine learning; Mathematics; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.14211",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415307359",
      "doi": "10.48550/arxiv.2504.17419",
      "title": "How Do Communities of ML-Enabled Systems Smell? A Cross-Sectional Study on the Prevalence of Community Smells",
      "abstract": "Effective software development relies on managing both collaboration and technology, but sociotechnical challenges can harm team dynamics and increase technical debt. Although teams working on ML enabled systems are interdisciplinary, research has largely focused on technical issues, leaving their socio-technical dynamics underexplored. This study aims to address this gap by examining the prevalence, evolution, and interrelations of community smells, in open-source ML projects. We conducted an empirical study on 188 repositories from the NICHE dataset using the CADOCS tool to identify and analyze community smells. Our analysis focused on their prevalence, interrelations, and temporal variations. We found that certain smells, such as Prima Donna Effects and Sharing Villainy, are more prevalent and fluctuate over time compared to others like Radio Silence or Organizational Skirmish. These insights might provide valuable support for ML project managers in addressing socio-technical issues and improving team coordination.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Giusy Annunziata et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.17419",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393809163",
      "doi": "10.48550/arxiv.2402.17916",
      "title": "Adversarial Math Word Problem Generation",
      "abstract": "Large language models (LLMs) have significantly transformed the educational landscape. As current plagiarism detection tools struggle to keep pace with LLMs' rapid advancements, the educational community faces the challenge of assessing students' true problem-solving abilities in the presence of LLMs. In this work, we explore a new paradigm for ensuring fair evaluation -- generating adversarial examples which preserve the structure and difficulty of the original questions aimed for assessment, but are unsolvable by LLMs. Focusing on the domain of math word problems, we leverage abstract syntax trees to structurally generate adversarial examples that cause LLMs to produce incorrect answers by simply editing the numeric values in the problems. We conduct experiments on various open- and closed-source LLMs, quantitatively and qualitatively demonstrating that our method significantly degrades their math problem-solving ability. We identify shared vulnerabilities among LLMs and propose a cost-effective approach to attack high-cost models. Additionally, we conduct automatic analysis to investigate the cause of failure, providing further insights into the limitations of LLMs.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Roy Xie et al.",
      "keywords": "Adversarial system; Word (group theory); Computer science; Arithmetic; Mathematics education; Mathematics; Linguistics; Artificial intelligence; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.17916",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385895048",
      "doi": "10.48550/arxiv.2308.01453",
      "title": "The Shapes of the Fourth Estate During the Pandemic: Profiling COVID-19 News Consumption in Eight Countries",
      "abstract": "News media is often referred to as the Fourth Estate, a recognition of its political power. New understandings of how media shape political beliefs and influence collective behaviors are urgently needed in an era when public opinion polls do not necessarily reflect election results and users influence each other in real-time under algorithm-mediated content personalization. In this work, we measure not only the average but also the distribution of audience political leanings for different media across different countries. The methodological components of these new measures include a high-fidelity COVID-19 tweet dataset; high-precision user geolocation extraction; and user political leaning estimated from the within-country retweet networks involving local politicians. We focus on geolocated users from eight countries, profile user leaning distribution for each country, and analyze bridging users who have interactions across multiple countries. Except for France and Turkey, we observe consistent bi-modal user leaning distributions in the other six countries, and find that cross-country retweeting behaviors do not oscillate across the partisan divide. More importantly, this study contributes a new set of media bias estimates by averaging the leaning scores of users who share the URLs from media domains. Through two validations, we find that the new average audience leaning scores strongly correlate with existing media bias scores. Lastly, we profile the COVID-19 news consumption by examining the audience leaning distribution for top media in each country, and for selected media across all countries. Those analyses help answer questions such as: Does center media Reuters have a more balanced audience base than partisan media CNN in the US? Does far-right media Breitbart attract any left-leaning readers in any countries? Does CNN reach a more balanced audience base in the US than in the UK?",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yang Cai et al.",
      "keywords": "Media bias; Politics; Profiling (computer programming); News media; Newspaper; Media consumption; Consumption (sociology); Advertising; Political science; Fourth Estate; Geolocation; Sociology; Business; Computer science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.01453",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387929166",
      "doi": "10.48550/arxiv.2310.14434",
      "title": "Enhancing Accuracy-Privacy Trade-off in Differentially Private Split Learning",
      "abstract": "Split learning (SL) aims to protect user data privacy by distributing deep models between client-server and keeping private data locally. Only processed or `smashed' data can be transmitted from the clients to the server during the SL process. However, recently proposed model inversion attacks can recover the original data from the smashed data. In order to enhance privacy protection against such attacks, a strategy is to adopt differential privacy (DP), which involves safeguarding the smashed data at the expense of some accuracy loss. This paper presents the first investigation into the impact on accuracy when training multiple clients in SL with various privacy requirements. Subsequently, we propose an approach that reviews the DP noise distributions of other clients during client training to address the identified accuracy degradation. We also examine the application of DP to the local model of SL to gain insights into the trade-off between accuracy and privacy. Specifically, findings reveal that introducing noise in the later local layers offers the most favorable balance between accuracy and privacy. Drawing from our insights in the shallower layers, we propose an approach to reduce the size of smashed data to minimize data leakage while maintaining higher accuracy, optimizing the accuracy-privacy trade-off. Additionally, a smaller size of smashed data reduces communication overhead on the client side, mitigating one of the notable drawbacks of SL. Experiments with popular datasets demonstrate that our proposed approaches provide an optimal trade-off for incorporating DP into SL, ultimately enhancing training accuracy for multi-client SL with varying privacy requirements.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ngoc Duy Pham et al.",
      "keywords": "Differential privacy; Computer science; Safeguarding; Federated learning; Overhead (engineering); Information privacy; Noise (video); Data mining; Computer security; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.14434",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415160039",
      "doi": "10.48550/arxiv.2504.10139",
      "title": "Conditional Distribution Compression via the Kernel Conditional Mean Embedding",
      "abstract": "Existing distribution compression methods, like Kernel Herding (KH), were originally developed for unlabelled data. However, no existing approach directly compresses the conditional distribution of \\textit{labelled} data. To address this gap, we first introduce the Average Maximum Conditional Mean Discrepancy (AMCMD), a metric for comparing conditional distributions, and derive a closed form estimator. Next, we make a key observation: in the context of distribution compression, the cost of constructing a compressed set targeting the AMCMD can be reduced from cubic to linear. Leveraging this, we extend KH to propose Average Conditional Kernel Herding (ACKH), a linear-time greedy algorithm for constructing compressed sets that target the AMCMD. To better understand the advantages of directly compressing the conditional distribution rather than doing so via the joint distribution, we introduce Joint Kernel Herding (JKH), an adaptation of KH designed to compress the joint distribution of labelled data. While herding methods provide a simple and interpretable selection process, they rely on a greedy heuristic. To explore alternative optimisation strategies, we also propose Joint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing Points (ACKIP), which jointly optimise the compressed set while maintaining linear complexity. Experiments show that directly preserving conditional distributions with ACKIP outperforms both joint distribution compression and the greedy selection used in ACKH. Moreover, we see that JKIP consistently outperforms JKH.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "D. \u0395. Broadbent et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10139",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4310646394",
      "doi": "10.48550/arxiv.2206.09978",
      "title": "German AI Start-Ups and AI Ethics: Using A Social Practice Lens for Assessing and Implementing Socio-Technical Innovation",
      "abstract": "Within the current AI ethics discourse, there is a gap in empirical research on understanding how AI practitioners understand ethics and socially organize to operationalize ethical concerns, particularly in the context of AI start-ups. This gap intensifies the risk of a disconnect between scholarly research, innovation, and application. This risk materializes acutely as mounting pressures to identify and mitigate the potential harms of AI systems have created an urgent need to assess and implement socio-technical innovation for fairness, accountability, and transparency. Building on social practice theory, we address this need via a framework that allows AI researchers, practitioners, and regulators to systematically analyze existing cultural understandings, histories, and social practices of ethical AI to define appropriate strategies for effectively implementing socio-technical innovations. Our contributions are threefold: 1) we introduce a practice-based approach for understanding ethical AI; 2) we present empirical findings from our study on the operationalization of ethics in German AI start-ups to underline that AI ethics and social practices must be understood in their specific cultural and historical contexts; and 3) based on our empirical findings, we suggest that ethical AI practices can be broken down into principles, needs, narratives, materializations, and cultural genealogies to form a useful backdrop for considering socio-technical innovations.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Mona Sloane et al.",
      "keywords": "Operationalization; Transparency (behavior); German; Accountability; Engineering ethics; Empirical research; Context (archaeology); Sociology; Knowledge management; Political science; Epistemology; Computer science; Engineering; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.09978",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415333638",
      "doi": "10.48550/arxiv.2506.15278",
      "title": "Not Even Nice Work If You Can Get It; A Longitudinal Study of Uber's Algorithmic Pay and Pricing",
      "abstract": "Ride-sharing platforms like Uber market themselves as enabling `flexibility' for their workforce, meaning that drivers are expected to anticipate when and where the algorithm will allocate them jobs, and how well remunerated those jobs will be. In this work we describe our process of participatory action research with drivers and trade union organisers, culminating in a participatory audit of Uber's algorithmic pay and work allocation, before and after the introduction of dynamic pricing. Through longitudinal analysis of 1.5 million trips from 258 drivers in the UK, we find that after dynamic pricing, pay has decreased, Uber's cut has increased, job allocation and pay is less predictable, inequality between drivers is increased, and drivers spend more time waiting for jobs. In addition to these findings, we provide methodological and theoretical contributions to algorithm auditing, gig work, and the emerging practice of worker data science.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Reuben Binns et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.15278",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4405626868",
      "doi": "10.48550/arxiv.2412.13943",
      "title": "On Explaining Knowledge Distillation: Measuring and Visualising the Knowledge Transfer Process",
      "abstract": "Knowledge distillation (KD) remains challenging due to the opaque nature of the knowledge transfer process from a Teacher to a Student, making it difficult to address certain issues related to KD. To address this, we proposed UniCAM, a novel gradient-based visual explanation method, which effectively interprets the knowledge learned during KD. Our experimental results demonstrate that with the guidance of the Teacher's knowledge, the Student model becomes more efficient, learning more relevant features while discarding those that are not relevant. We refer to the features learned with the Teacher's guidance as distilled features and the features irrelevant to the task and ignored by the Student as residual features. Distilled features focus on key aspects of the input, such as textures and parts of objects. In contrast, residual features demonstrate more diffused attention, often targeting irrelevant areas, including the backgrounds of the target objects. In addition, we proposed two novel metrics: the feature similarity score (FSS) and the relevance score (RS), which quantify the relevance of the distilled knowledge. Experiments on the CIFAR10, ASIRRA, and Plant Disease datasets demonstrate that UniCAM and the two metrics offer valuable insights to explain the KD process.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Gereziher Adhane et al.",
      "keywords": "Process (computing); Knowledge transfer; Distillation; Computer science; Knowledge management; Process management; Process engineering; Business; Engineering; Chemistry; Chromatography; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.13943",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403799686",
      "doi": "10.48550/arxiv.2409.18931",
      "title": "Social Media Bot Policies: Evaluating Passive and Active Enforcement",
      "abstract": "The emergence of Multimodal Foundation Models (MFMs) holds significant promise for transforming social media platforms. However, this advancement also introduces substantial security and ethical concerns, as it may facilitate malicious actors in the exploitation of online users. We aim to evaluate the strength of security protocols on prominent social media platforms in mitigating the deployment of MFM bots. We examined the bot and content policies of eight popular social media platforms: X (formerly Twitter), Instagram, Facebook, Threads, TikTok, Mastodon, Reddit, and LinkedIn. Using Selenium, we developed a web bot to test bot deployment and AI-generated content policies and their enforcement mechanisms. Our findings indicate significant vulnerabilities within the current enforcement mechanisms of these platforms. Despite having explicit policies against bot activity, all platforms failed to detect and prevent the operation of our MFM bots. This finding reveals a critical gap in the security measures employed by these social media platforms, underscoring the potential for malicious actors to exploit these weaknesses to disseminate misinformation, commit fraud, or manipulate users.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Kristina Radivojevic et al.",
      "keywords": "Enforcement; Social media; Business; Public relations; Internet privacy; Advertising; Political science; Computer science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.18931",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3144815567",
      "doi": "10.13140/rg.2.2.31659.16168",
      "title": "Not Cheating on the Turing Test: Towards Grounded Language Learning in Artificial Intelligence",
      "abstract": "Recent hype surrounding the increasing sophistication of language processing models has renewed optimism regarding machines achieving a human-like command of natural language. Research in the area of natural language understanding (NLU) in artificial intelligence claims to have been making great strides in this area, however, the lack of conceptual clarity/consistency in how 'understanding' is used in this and other disciplines makes it difficult to discern how close we actually are. In this interdisciplinary research thesis, I integrate insights from cognitive science/psychology, philosophy of mind, and cognitive linguistics, and evaluate it against a critical review of current approaches in NLU to explore the basic requirements--and remaining challenges--for developing artificially intelligent systems with human-like capacities for language use and comprehension.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Lize Alberts",
      "keywords": "Cheating; Turing test; Test (biology); Artificial intelligence; Computer science; Cognitive science; Natural language processing; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "dissertation",
      "url": "https://doi.org/10.13140/rg.2.2.31659.16168",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383860193",
      "doi": "10.48550/arxiv.2307.03241",
      "title": "The Mathematics of Mathematics: Using Mathematics and Data Science to Analyze the Mathematical Sciences Community and Enhance Social Justice",
      "abstract": "We present and discuss a curated selection of recent literature related to the application of quantitative techniques, tools, and topics from mathematics and data science that have been used to analyze the mathematical sciences community. We engage in this project with a focus on including research that highlights, documents, or quantifies (in)equities that exist in the mathematical sciences, specifically, and STEM (science, technology, engineering, and mathematics) more broadly. We seek to enhance social justice in the mathematics and data science communities by providing numerous examples of the ways in which the mathematical sciences fails to meet standards of equity, equal opportunity and inclusion. We introduce the term ``mathematics of Mathematics\" for this project, explicitly building upon the growing, interdisciplinary field known as ``Science of Science\" to interrogate, investigate, and identify the nature of the mathematical sciences itself. We aim to promote, provide, and posit sources of productive collaborations and we invite interested researchers to contribute to this developing body of work.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ron Buckmire et al.",
      "keywords": "Mathematical sciences; Field (mathematics); Computer science; Mathematics; Mathematics education; Engineering ethics; Engineering; Pure mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.03241",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4385750226",
      "doi": "10.48550/arxiv.2308.04887",
      "title": "Targeted and Troublesome: Tracking and Advertising on Children's Websites",
      "abstract": "On the modern web, trackers and advertisers frequently construct and monetize users' detailed behavioral profiles without consent. Despite various studies on web tracking mechanisms and advertisements, there has been no rigorous study focusing on websites targeted at children. To address this gap, we present a measurement of tracking and (targeted) advertising on websites directed at children. Motivated by lacking a comprehensive list of child-directed (i.e., targeted at children) websites, we first build a multilingual classifier based on web page titles and descriptions. Applying this classifier to over two million pages, we compile a list of two thousand child-directed websites. Crawling these sites from five vantage points, we measure the prevalence of trackers, fingerprinting scripts, and advertisements. Our crawler detects ads displayed on child-directed websites and determines if ad targeting is enabled by scraping ad disclosure pages whenever available. Our results show that around 90% of child-directed websites embed one or more trackers, and about 27% contain targeted advertisements--a practice that should require verifiable parental consent. Next, we identify improper ads on child-directed websites by developing an ML pipeline that processes both images and text extracted from ads. The pipeline allows us to run semantic similarity queries for arbitrary search terms, revealing ads that promote services related to dating, weight loss, and mental health; as well as ads for sex toys and flirting chat services. Some of these ads feature repulsive and sexually explicit imagery. In summary, our findings indicate a trend of non-compliance with privacy regulations and troubling ad safety practices among many advertisers and child-directed websites. To protect children and create a safer online environment, regulators and stakeholders must adopt and enforce more stringent measures.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Zahra Moti et al.",
      "keywords": "Computer science; BitTorrent tracker; Crawling; World Wide Web; Web page; Targeted advertising; Internet privacy; Information retrieval; Advertising; Artificial intelligence; Eye tracking; Medicine; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.04887",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403566307",
      "doi": "10.48550/arxiv.2410.09527",
      "title": "LexSumm and LexT5: Benchmarking and Modeling Legal Summarization Tasks in English",
      "abstract": "In the evolving NLP landscape, benchmarks serve as yardsticks for gauging progress. However, existing Legal NLP benchmarks only focus on predictive tasks, overlooking generative tasks. This work curates LexSumm, a benchmark designed for evaluating legal summarization tasks in English. It comprises eight English legal summarization datasets, from diverse jurisdictions, such as the US, UK, EU and India. Additionally, we release LexT5, legal oriented sequence-to-sequence model, addressing the limitation of the existing BERT-style encoder-only models in the legal domain. We assess its capabilities through zero-shot probing on LegalLAMA and fine-tuning on LexSumm. Our analysis reveals abstraction and faithfulness errors even in summaries generated by zero-shot LLMs, indicating opportunities for further improvements. LexSumm benchmark and LexT5 model are available at https://github.com/TUMLegalTech/LexSumm-LexT5.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "T. Y. S. S Santosh et al.",
      "keywords": "Automatic summarization; Benchmarking; Computer science; Natural language processing; Information retrieval; Business; Marketing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.09527",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391590660",
      "doi": "10.48550/arxiv.2402.02063",
      "title": "Improving the Learning of Code Review Successive Tasks with Cross-Task Knowledge Distillation",
      "abstract": "Code review is a fundamental process in software development that plays a pivotal role in ensuring code quality and reducing the likelihood of errors and bugs. However, code review can be complex, subjective, and time-consuming. Quality estimation, comment generation, and code refinement constitute the three key tasks of this process, and their automation has traditionally been addressed separately in the literature using different approaches. In particular, recent efforts have focused on fine-tuning pre-trained language models to aid in code review tasks, with each task being considered in isolation. We believe that these tasks are interconnected, and their fine-tuning should consider this interconnection. In this paper, we introduce a novel deep-learning architecture, named DISCOREV, which employs cross-task knowledge distillation to address these tasks simultaneously. In our approach, we utilize a cascade of models to enhance both comment generation and code refinement models. The fine-tuning of the comment generation model is guided by the code refinement model, while the fine-tuning of the code refinement model is guided by the quality estimation model. We implement this guidance using two strategies: a feedback-based learning objective and an embedding alignment objective. We evaluate DISCOREV by comparing it to state-of-the-art methods based on independent training and fine-tuning. Our results show that our approach generates better review comments, as measured by the BLEU score, as well as more accurate code refinement according to the CodeBLEU score",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Oussama Ben Sghaier et al.",
      "keywords": "Task (project management); Computer science; Code (set theory); Distillation; Artificial intelligence; Machine learning; Programming language; Chromatography; Management; Chemistry; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.02063",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4311413815",
      "doi": "10.48550/arxiv.2212.05565",
      "title": "Robust Estimation and Inference for Expected Shortfall Regression with Many Regressors",
      "abstract": "Expected Shortfall (ES), also known as superquantile or Conditional Value-at-Risk, has been recognized as an important measure in risk analysis and stochastic optimization, and is also finding applications beyond these areas. In finance, it refers to the conditional expected return of an asset given that the return is below some quantile of its distribution. In this paper, we consider a recently proposed joint regression framework that simultaneously models the quantile and the ES of a response variable given a set of covariates, for which the state-of-the-art approach is based on minimizing a joint loss function that is non-differentiable and non-convex. This inevitably raises numerical challenges and limits its applicability for analyzing large-scale data. Motivated by the idea of using Neyman-orthogonal scores to reduce sensitivity with respect to nuisance parameters, we propose a statistically robust (to highly skewed and heavy-tailed data) and computationally efficient two-step procedure for fitting joint quantile and ES regression models. With increasing covariate dimensions, we establish explicit non-asymptotic bounds on estimation and Gaussian approximation errors, which lay the foundation for statistical inference. Finally, we demonstrate through numerical experiments and two data applications that our approach well balances robustness, statistical, and numerical efficiencies for expected shortfall regression.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Xuming He et al.",
      "keywords": "Quantile; Expected shortfall; Quantile regression; Econometrics; Covariate; Conditional probability distribution; Inference; Mathematics; Statistical inference; Robustness (evolution); Risk measure; Computer science; Mathematical optimization; Statistics; Finance; Risk management",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2212.05565",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417071444",
      "doi": "10.48550/arxiv.2509.09076",
      "title": "Content Moderation Futures",
      "abstract": "This study examines the failures and possibilities of contemporary social media governance through the lived experiences of various content moderation professionals. Drawing on participatory design workshops with 33 practitioners in both the technology industry and broader civil society, this research identifies significant structural misalignments between corporate incentives and public interests. While experts agree that successful content moderation is principled, consistent, contextual, proactive, transparent, and accountable, current technology companies fail to achieve these goals, due in part to exploitative labor practices, chronic underinvestment in user safety, and pressures of global scale. I argue that successful governance is undermined by the pursuit of technological novelty and rapid growth, resulting in platforms that necessarily prioritize innovation and expansion over public trust and safety. To counter this dynamic, I revisit the computational history of care work, to motivate present-day solidarity amongst platform governance workers and inspire systemic change.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Lindsay Blackwell",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2509.09076",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393212037",
      "doi": "10.5281/zenodo.10680345",
      "title": "AI Sustainability in Practice Part Two: Sustainability Throughout the AI Workflow",
      "abstract": "The sustainability of AI systems depends on the capacity of project teams to proceed with a continuous sensitivity to their potential real-world impacts and transformative effects. Stakeholder Impact Assessments (SIAs) are governance mechanisms that enable this kind of responsiveness. They are tools that create a procedure for, and a means of documenting, the collaborative evaluation and reflective anticipation of the possible harms and benefits of AI innovation projects. SIAs are not one-off governance actions. They require project teams to pay continuous attention to the dynamic and changing character of AI production and use and to the shifting conditions of the real-world environments in which AI technologies are embedded. This workbook is part two of two workbooks on AI Sustainability. It provides a template of the SIA and activities that allow a deeper dive into crucial parts of it. It discusses methods for weighing values and considering trade-offs during the SIA. And, it highlights the need to treat the SIA as an end-to-end process of responsive evaluation and re-assessment.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "David Leslie et al.",
      "keywords": "Sustainability; Workflow; Business; Process management; Knowledge management; Environmental economics; Computer science; Environmental resource management; Economics; Management; Ecology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.5281/zenodo.10680345",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4286977983",
      "doi": "10.48550/arxiv.2109.06287",
      "title": "Project 412Connect: Bridging Students and Communities",
      "abstract": "In this work, we describe some of the challenges Black-owned businesses face in the United States, and specifically in the city of Pittsburgh. Taking into account local dynamics and the communicated desires of Black-owned businesses in the Pittsburgh region, we determine that university students represent an under-utilized market for these businesses. We investigate the root causes for this inefficiency and design and implement a platform, 412Connect (https://www.412connect.org/), to increase online support for Pittsburgh Black-owned businesses from students in the Pittsburgh university community. The site operates by coordinating interactions between student users and participating businesses via targeted recommendations. For platform designers, we describe the project from its conception, paying special attention to our motivation and design choices. Our design choices are aided by two simple, novel models for badge design and recommendation systems that may be of theoretical interest. Along the way we highlight challenges and lessons from coordinating a grassroots volunteer project working in conjunction with community partners, and the opportunities and pitfalls of engaged scholarship.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Alex DiChristofano et al.",
      "keywords": "Grassroots; Inefficiency; Bridging (networking); Public relations; Scholarship; Work (physics); Online community; Marketing; Sociology; Business; Political science; Computer science; Engineering; World Wide Web; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2109.06287",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417516959",
      "doi": "10.48550/arxiv.2505.07528",
      "title": "SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion",
      "abstract": "Retrieval-Augmented Generation (RAG) models frequently encounter hallucination phenomena when integrating external information with internal parametric knowledge. Empirical studies demonstrate that the disequilibrium between external contextual information and internal parametric knowledge constitutes a primary factor in hallucination generation. Existing hallucination detection methodologies predominantly emphasize either the external or internal mechanism in isolation, thereby overlooking their synergistic effects. The recently proposed ReDeEP framework decouples these dual mechanisms, identifying two critical contributors to hallucinations: excessive reliance on parametric knowledge encoded in feed-forward networks (FFN) and insufficient utilization of external information by attention mechanisms (particularly copy heads). ReDeEP quantitatively assesses these factors to detect hallucinations and dynamically modulates the contributions of FFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and numerous other hallucination detection approaches have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, inadequately address the semantic dimensions of model responses, resulting in inconsistent hallucination assessments in RAG implementations. Building upon ReDeEP's foundation, this paper introduces SEReDeEP, which enhances computational processes through semantic entropy captured via trained linear probes, thereby achieving hallucination assessments that more accurately reflect ground truth evaluations.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Lei Wang",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07528",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415248513",
      "doi": "10.48550/arxiv.2505.03601",
      "title": "Doing Audits Right? The Role of Sampling and Legal Content Analysis in Systemic Risk Assessments and Independent Audits in the Digital Services Act",
      "abstract": "A central requirement of the European Union's Digital Services Act (DSA) is that online platforms undergo internal and external audits. A key component of these audits is the assessment of systemic risks, including the dissemination of illegal content, threats to fundamental rights, impacts on democratic processes, and gender-based violence. The DSA Delegated Regulation outlines how such audits should be conducted, setting expectations for both platforms and auditors. This article evaluates the strengths and limitations of different qualitative and quantitative methods for auditing these systemic risks and proposes a mixed-method approach for DSA compliance. We argue that content sampling, combined with legal and empirical analysis, offers a viable method for risk-specific audits. First, we examine relevant legal provisions on sample selection for audit purposes. We then assess sampling techniques and methods suitable for detecting systemic risks, focusing on how representativeness can be understood across disciplines. Finally, we review initial systemic risk assessment reports submitted by platforms, analyzing their testing and sampling methodologies. By proposing a structured, mixed-method approach tailored to specific risk categories and platform characteristics, this article addresses the challenge of evidence-based audits under the DSA. Our contribution emphasizes the need for adaptable, context-sensitive auditing strategies and adds to the emerging field of DSA compliance research.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Marie-Therese Sekwenz et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.03601",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4404314385",
      "doi": "10.48550/arxiv.2410.20740",
      "title": "A Comprehensive Study on Static Application Security Testing (SAST) Tools for Android",
      "abstract": "To identify security vulnerabilities in Android applications, numerous static application security testing (SAST) tools have been proposed. However, it poses significant challenges to assess their overall performance on diverse vulnerability types. The task is non-trivial and poses considerable challenges. {Firstly, the absence of a unified evaluation platform for defining and describing tools' supported vulnerability types, coupled with the lack of normalization for the intricate and varied reports generated by different tools, significantly adds to the complexity.} Secondly, there is a scarcity of adequate benchmarks, particularly those derived from real-world scenarios. To address these problems, we are the first to propose a unified platform named VulsTotal, supporting various vulnerability types, enabling comprehensive and versatile analysis across diverse SAST tools. Specifically, we begin by meticulously selecting 11 free and open-sourced SAST tools from a pool of 97 existing options, adhering to clearly defined criteria. After that, we invest significant efforts in comprehending the detection rules of each tool, subsequently unifying 67 general/common vulnerability types for {Android} SAST tools. We also redefine and implement a standardized reporting format, ensuring uniformity in presenting results across all tools. Additionally, to mitigate the problem of benchmarks, we conducted a manual analysis of huge amounts of CVEs to construct a new CVE-based benchmark based on our comprehension of Android app vulnerabilities. Leveraging the evaluation platform, which integrates both existing synthetic benchmarks and newly constructed CVE-based benchmarks from this study, we conducted a comprehensive analysis to evaluate and compare these selected tools from various perspectives, such as general vulnerability type coverage, type consistency, tool effectiveness, and time performance.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jingyun Zhu et al.",
      "keywords": "Android (operating system); Computer science; Android application; Security testing; Computer security; Application security; Information security; Software security assurance; Operating system; Cloud computing; Cloud computing security; Security service; Security information and event management",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.20740",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287702824",
      "doi": "10.48550/arxiv.2007.16172",
      "title": "Patterns of Patient and Caregiver Mutual Support Connections in an\\n Online Health Community",
      "abstract": "Online health communities offer the promise of support benefits to users, in\\nparticular because these communities enable users to find peers with similar\\nexperiences. Building mutually supportive connections between peers is a key\\nmotivation for using online health communities. However, a user's role in a\\ncommunity may influence the formation of peer connections. In this work, we\\nstudy patterns of peer connections between two structural health roles: patient\\nand non-professional caregiver. We examine user behavior in an online health\\ncommunity where finding peers is not explicitly supported. This context lets us\\nuse social network analysis methods to explore the growth of such connections\\nin the wild and identify users' peer communication preferences. We investigated\\nhow connections between peers were initiated, finding that initiations are more\\nlikely between two authors who have the same role and who are close within the\\nbroader communication network. Relationships are also more likely to form and\\nbe more interactive when authors have the same role. Our results have\\nimplications for the design of systems supporting peer communication, e.g.\\npeer-to-peer recommendation systems.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Zachary Levonian et al.",
      "keywords": "Online community; Context (archaeology); Peer-to-peer; Peer support; Psychology; Social network (sociolinguistics); Online participation; Internet privacy; Computer science; World Wide Web; Social media; The Internet; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2007.16172",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403965318",
      "doi": "10.48550/arxiv.2408.03579",
      "title": "\"The Strength of Weak Ties\" Varies Across Viral Channels",
      "abstract": "The diffusion of novel information through social networks is essential for dismantling echo chambers and promoting innovation. Our study examines how two major types of viral channels, specifically Direct Messaging (DM) and Broadcasting (BC), impact the well-known \"strength of weak ties\" in disseminating novel information across social networks. We conducted a large-scale empirical analysis, examining the sharing behavior of 500,000 users over a two-month period on a major social media platform. Our results suggest a greater capacity for DM to transmit novel information compared to BC, although DM typically involves stronger ties. Furthermore, the \"strength of weak ties\" is only evident in BC, not in DM where weaker ties do not transmit significantly more novel information. Our mechanism analysis indicates that the content selection by both senders and recipients, contingent on tie strength, contributes to the observed differences between these two channels. These findings expand both our understanding of contemporary weak tie theory and our knowledge of how to disseminate novel information in social networks.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Shan Huang et al.",
      "keywords": "Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.03579",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399837731",
      "doi": "10.48550/arxiv.2406.12680",
      "title": "Measuring Psychological Depth in Language Models",
      "abstract": "Evaluations of creative stories generated by large language models (LLMs) often focus on objective properties of the text, such as its style, coherence, and diversity. While these metrics are indispensable, they do not speak to a story's subjective, psychological impact from a reader's perspective. We introduce the Psychological Depth Scale (PDS), a novel framework rooted in literary theory that measures an LLM's ability to produce authentic and narratively complex stories that provoke emotion, empathy, and engagement. We empirically validate our framework by showing that humans can consistently evaluate stories based on PDS (0.72 Krippendorff's alpha). We also explore techniques for automating the PDS to easily scale future analyses. GPT-4o, combined with a novel Mixture-of-Personas (MoP) prompting strategy, achieves an average Spearman correlation of 0.51 with human judgment while Llama-3-70B with constrained decoding scores as high as 0.68 for empathy. Finally, we compared the depth of stories authored by both humans and LLMs. Surprisingly, GPT-4 stories either surpassed or were statistically indistinguishable from highly-rated human-written stories sourced from Reddit. By shifting the focus from text to reader, the Psychological Depth Scale is a validated, automated, and systematic means of measuring the capacity of LLMs to connect with humans through the stories they tell.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Fabrice Harel-Canada et al.",
      "keywords": "Psychology; Linguistics; Computer science; Cognitive psychology; Natural language processing; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.12680",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417524030",
      "doi": "10.48550/arxiv.2504.21663",
      "title": "Reducing Weighted Ensemble Variance With Optimal Trajectory Management",
      "abstract": "Weighted ensemble (WE) is an enhanced path-sampling method that is conceptually simple, widely applicable, and statistically exact. In a WE simulation, an ensemble of trajectories is periodically pruned or replicated to enhance sampling of rare transitions and improve estimation of mean first passage times (MFPTs). However, poor choices of the parameters governing pruning and replication can lead to high-variance MFPT estimates. Our previous work [J. Chem. Phys. 158, 014108 (2023)] presented an optimal WE parameterization strategy and applied it in low-dimensional example systems. The strategy harnesses estimated local MFPTs from different initial configurations to a single target state. In the present work, we apply the optimal parameterization strategy to more challenging, high-dimensional molecular models, namely, synthetic molecular dynamics (MD) models of Trp-cage folding and unfolding, as well as atomistic MD models of NTL9 folding in high-friction and low-friction continuum solvents. In each system we use WE to estimate the MFPT for folding or unfolding events. We show that the optimal parameterization reduces the variance of MFPT estimates in three of four systems, with dramatic improvement in the most challenging atomistic system. Overall, the parameterization strategy improves the accuracy and reliability of WE estimates for the kinetics of biophysical processes.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Won Hee Ryu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.21663",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388787832",
      "doi": "10.48550/arxiv.2311.09694",
      "title": "Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness",
      "abstract": "Do larger and more performant models resolve NLP's longstanding robustness issues? We investigate this question using over 20 models of different sizes spanning different architectural choices and pretraining objectives. We conduct evaluations using (a) out-of-domain and challenge test sets, (b) behavioral testing with CheckLists, (c) contrast sets, and (d) adversarial inputs. Our analysis reveals that not all out-of-domain tests provide insight into robustness. Evaluating with CheckLists and contrast sets shows significant gaps in model performance; merely scaling models does not make them adequately robust. Finally, we point out that current approaches for adversarial evaluations of models are themselves problematic: they can be easily thwarted, and in their current forms, do not represent a sufficiently deep probe of model robustness. We conclude that not only is the question of robustness in NLP as yet unresolved, but even some of the approaches to measure robustness need to be reassessed.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ashim Gupta et al.",
      "keywords": "Robustness (evolution); Artificial intelligence; Computer science; Natural language processing; History; Chemistry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.09694",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391244970",
      "doi": "10.48550/arxiv.2401.13656",
      "title": "Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity",
      "abstract": "The prevalent perspective in quantitative research on opinion dynamics flattens the landscape of the online political discourse into a traditional left--right dichotomy. While this approach helps simplify the analysis and modeling effort, it also neglects the intrinsic multidimensional richness of ideologies. In this study, we analyze social interactions on Reddit, under the lens of a multi-dimensional ideological framework: the political compass. We examine over 8 million comments posted on the subreddits /r/PoliticalCompass and /r/PoliticalCompassMemes during 2020--2022. By leveraging their self-declarations, we disentangle the ideological dimensions of users into economic (left--right) and social (libertarian--authoritarian) axes. In addition, we characterize users by their demographic attributes (age, gender, and affluence). We find significant homophily for interactions along the social axis of the political compass and demographic attributes. Compared to a null model, interactions among individuals of similar ideology surpass expectations by 6%. In contrast, we uncover a significant heterophily along the economic axis: left/right interactions exceed expectations by 10%. Furthermore, heterophilic interactions are characterized by a higher language toxicity than homophilic interactions, which hints at a conflictual discourse between every opposite ideology. Our results help reconcile apparent contradictions in recent literature, which found a superposition of homophilic and heterophilic interactions in online political discussions. By disentangling such interactions into the economic and social axes we pave the way for a deeper understanding of opinion dynamics on social media.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ernesto Colacrai et al.",
      "keywords": "Ideology; Politics; Sociology; Authoritarianism; Social psychology; Positive economics; Compass; Political science; Democracy; Psychology; Geography; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.13656",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4290443069",
      "doi": "10.48550/arxiv.1707.02853",
      "title": "The Wealth of Nations: Complexity Science for an Interdisciplinary\\n Approach in Economics",
      "abstract": "Classic economic science is reaching the limits of its explanatory powers.\\nComplexity science uses an increasingly larger set of different methods to\\nanalyze physical, biological, cultural, social, and economic factors, providing\\na broader understanding of the socio-economic dynamics involved in the\\ndevelopment of nations worldwide. The use of tools developed in the natural\\nsciences, such as thermodynamics, evolutionary biology, and analysis of complex\\nsystems, help us to integrate aspects, formerly reserved to the social\\nsciences, with the natural sciences. This integration reveals details of the\\nsynergistic mechanisms that drive the evolution of societies. By doing so, we\\nincrease the available alternatives for economic analysis and provide ways to\\nincrease the efficiency of decision-making mechanisms in complex social\\ncontexts. This interdisciplinary analysis seeks to deepen our understanding of\\nwhy chronic poverty is still common, and how the emergence of prosperous\\ntechnological societies can be made possible. This understanding should\\nincrease the chances of achieving a sustainable, harmonious and prosperous\\nfuture for humanity. The analysis evidences that complex fundamental economic\\nproblems require multidisciplinary approaches and rigorous application of the\\nscientific method if we want to advance significantly our understanding of\\nthem. The analysis reveals viable routes for the generation of wealth and the\\nreduction of poverty, but also reveals huge gaps in our knowledge about the\\ndynamics of our societies and about the means to guide social development\\ntowards a better future for all.\\n",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Klaus Jaff\u00e9",
      "keywords": "Multidisciplinary approach; Poverty; Management science; Set (abstract data type); Natural (archaeology); Sociology; Social science; Economics; Economic growth; Computer science; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1707.02853",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2963178340",
      "doi": "10.48550/arxiv.1709.02012",
      "title": "On Fairness and Calibration",
      "abstract": "The machine learning community has become increasingly concerned with the potential for bias and discrimination in predictive models. This has motivated a growing line of work on what it means for a classification procedure to be \"fair.\" In this paper, we investigate the tension between minimizing error disparity across different population groups while maintaining calibrated probability estimates. We show that calibration is compatible only with a single error constraint (i.e. equal false-negatives rates across groups), and show that any algorithm that satisfies this relaxation is no better than randomizing a percentage of predictions for an existing classifier. These unsettling findings, which extend and generalize existing results, are empirically confirmed on several datasets.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Geoff Pleiss et al.",
      "keywords": "Classifier (UML); Calibration; Computer science; Constraint (computer-aided design); Artificial intelligence; Population; Machine learning; Algorithm; Pattern recognition (psychology); Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.48550/arxiv.1709.02012",
      "cited_by_count": 287,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387192100",
      "doi": "10.48550/arxiv.2309.14345",
      "title": "Bias Testing and Mitigation in LLM-based Code Generation",
      "abstract": "As the adoption of LLMs becomes more widespread in software coding ecosystems, a pressing issue has emerged: does the generated code contain social bias and unfairness, such as those related to age, gender, and race? This issue concerns the integrity, fairness, and ethical foundation of software applications that depend on the code generated by these models but are underexplored in the literature. This paper presents a novel bias testing framework that is specifically designed for code generation tasks. Based on this framework, we conduct an extensive empirical study on the biases in code generated by five widely studied LLMs (i.e., PALM-2-CodeChat-bison, Claude-instant-1, GPT-3.5-turbo, GPT-4-turbo, and GPT-4). Our findings reveal that biases are prevalent. For example, 13.47% to 49.10% of the codes generated by these LLMs have biased behaviors towards gender. Moreover, we study five bias mitigation prompt strategies that are commonly used in current code generation scenarios, i.e., zero-shot, one-shot, few-shot, and two Chain-of-Thought (CoT) prompts, with and without provided feedback-driven refinement. Our evaluation results illustrate that using direct prompt engineering strategies has limited effectiveness in mitigating bias, but our test execution feedback can help to reduce the ratio of code biases to a large extent (e.g., from 59.88% to 4.79% for GPT-4).",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Dong Huang et al.",
      "keywords": "Computer science; Code (set theory); Coding (social sciences); Software; Unintended consequences; Computer security; Political science; Programming language; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.14345",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287759409",
      "doi": "10.48550/arxiv.2006.06053",
      "title": "Causal Feature Selection for Algorithmic Fairness",
      "abstract": "The use of machine learning (ML) in high-stakes societal decisions has encouraged the consideration of fairness throughout the ML lifecycle. Although data integration is one of the primary steps to generate high quality training data, most of the fairness literature ignores this stage. In this work, we consider fairness in the integration component of data management, aiming to identify features that improve prediction without adding any bias to the dataset. We work under the causal interventional fairness paradigm. Without requiring the underlying structural causal model a priori, we propose an approach to identify a sub-collection of features that ensure the fairness of the dataset by performing conditional independence tests between different subsets of features. We use group testing to improve the complexity of the approach. We theoretically prove the correctness of the proposed algorithm to identify features that ensure interventional fairness and show that sub-linear conditional independence tests are sufficient to identify these variables. A detailed empirical evaluation is performed on real-world datasets to demonstrate the efficacy and efficiency of our technique.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Sainyam Galhotra et al.",
      "keywords": "Computer science; Correctness; Conditional independence; A priori and a posteriori; Machine learning; Feature selection; Independence (probability theory); Quality (philosophy); Data mining; Fairness measure; Feature (linguistics); Selection (genetic algorithm); Artificial intelligence; Algorithm; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2006.06053",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4361866109",
      "doi": "10.48550/arxiv.2303.17566",
      "title": "Non-Invasive Fairness in Learning through the Lens of Data Drift",
      "abstract": "Machine Learning (ML) models are widely employed to drive many modern data systems. While they are undeniably powerful tools, ML models often demonstrate imbalanced performance and unfair behaviors. The root of this problem often lies in the fact that different subpopulations commonly display divergent trends: as a learning algorithm tries to identify trends in the data, it naturally favors the trends of the majority groups, leading to a model that performs poorly and unfairly for minority populations. Our goal is to improve the fairness and trustworthiness of ML models by applying only non-invasive interventions, i.e., without altering the data or the learning algorithm. We use a simple but key insight: the divergence of trends between different populations, and, consecutively, between a learned model and minority populations, is analogous to data drift, which indicates the poor conformance between parts of the data and the trained model. We explore two strategies (model-splitting and reweighing) to resolve this drift, aiming to improve the overall conformance of models to the underlying data. Both our methods introduce novel ways to employ the recently-proposed data profiling primitive of Conformance Constraints. Our experimental evaluation over 7 real-world datasets shows that both DifFair and ConFair improve the fairness of ML models. We demonstrate scenarios where DifFair has an edge, though ConFair has the greatest practical impact and outperforms other baselines. Moreover, as a model-agnostic technique, ConFair stays robust when used against different models than the ones on which the weights have been learned, which is not the case for other state of the art.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ke Yang et al.",
      "keywords": "Computer science; Machine learning; Trustworthiness; Artificial intelligence; Key (lock); Divergence (linguistics); Profiling (computer programming); Data mining; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.17566",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4310746865",
      "doi": "10.51628/001c.7125",
      "title": "Correlated Components Analysis - Extracting Reliable Dimensions in\\n Multivariate Data",
      "abstract": "How does one find dimensions in multivariate data that are reliably expressed\\nacross repetitions? For example, in a brain imaging study one may want to\\nidentify combinations of neural signals that are reliably expressed across\\nmultiple trials or subjects. For a behavioral assessment with multiple ratings,\\none may want to identify an aggregate score that is reliably reproduced across\\nraters. Correlated Components Analysis (CorrCA) addresses this problem by\\nidentifying components that are maximally correlated between repetitions (e.g.\\ntrials, subjects, raters). Here we formalize this as the maximization of the\\nratio of between-repetition to within-repetition covariance. We show that this\\ncriterion maximizes repeat-reliability, defined as mean over variance across\\nrepeats, and that it leads to CorrCA or to multi-set Canonical Correlation\\nAnalysis, depending on the constraints. Surprisingly, we also find that CorrCA\\nis equivalent to Linear Discriminant Analysis for zero-mean signals, which\\nprovides an unexpected link between classic concepts of multivariate analysis.\\nWe present an exact parametric test of statistical significance based on the\\nF-statistic for normally distributed independent samples, and present and\\nvalidate shuffle statistics for the case of dependent samples. Regularization\\nand extension to non-linear mappings using kernels are also presented. The\\nalgorithms are demonstrated on a series of data analysis applications, and we\\nprovide all code and data required to reproduce the results.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Lucas C. Parra et al.",
      "keywords": "Multivariate statistics; Canonical correlation; Covariance; Statistics; Linear discriminant analysis; Multivariate analysis; Pattern recognition (psychology); Computer science; Mathematics; Statistic; Data set; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.51628/001c.7125",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3012974261",
      "doi": "10.48550/arxiv.2003.11461",
      "title": "Emotion Recognition From Gait Analyses: Current Research and Future Directions",
      "abstract": "Human gait refers to a daily motion that represents not only mobility, but it can also be used to identify the walker by either human observers or computers. Recent studies reveal that gait even conveys information about the walker's emotion. Individuals in different emotion states may show different gait patterns. The mapping between various emotions and gait patterns provides a new source for automated emotion recognition. Compared to traditional emotion detection biometrics, such as facial expression, speech and physiological parameters, gait is remotely observable, more difficult to imitate, and requires less cooperation from the subject. These advantages make gait a promising source for emotion detection. This article reviews current research on gait-based emotion detection, particularly on how gait parameters can be affected by different emotion states and how the emotion states can be recognized through distinct gait patterns. We focus on the detailed methods and techniques applied in the whole process of emotion recognition: data collection, preprocessing, and classification. At last, we discuss possible future developments of efficient and effective gait-based emotion recognition using the state of the art techniques on intelligent computation and big data.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Shihao Xu et al.",
      "keywords": "Gait; Biometrics; Computer science; Preprocessor; Facial expression; Gait analysis; Focus (optics); Artificial intelligence; Physical medicine and rehabilitation",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2003.11461",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4290715206",
      "doi": "10.1109/access.2022.3197279",
      "title": "Unstructured Handwashing Recognition using Smartwatch to Reduce Contact\\n Transmission of Pathogens",
      "abstract": "Current guidelines from the World Health Organization indicate that the\\nSARS-CoV-2 coronavirus, which results in the novel coronavirus disease\\n(COVID-19), is transmitted through respiratory droplets or by contact. Contact\\ntransmission occurs when contaminated hands touch the mucous membrane of the\\nmouth, nose, or eyes so hands hygiene is extremely important to prevent the\\nspread of the SARSCoV-2 as well as of other pathogens. The vast proliferation\\nof wearable devices, such as smartwatches, containing acceleration, rotation,\\nmagnetic field sensors, etc., together with the modern technologies of\\nartificial intelligence, such as machine learning and more recently\\ndeep-learning, allow the development of accurate applications for recognition\\nand classification of human activities such as: walking, climbing stairs,\\nrunning, clapping, sitting, sleeping, etc. In this work, we evaluate the\\nfeasibility of a machine learning based system which, starting from inertial\\nsignals collected from wearable devices such as current smartwatches,\\nrecognizes when a subject is washing or rubbing its hands. Preliminary results,\\nobtained over two different datasets, show a classification accuracy of about\\n95% and of about 94% for respectively deep and standard learning techniques.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Emanuele Lattanzi et al.",
      "keywords": "Smartwatch; Computer science; Artificial intelligence; Wearable computer; Wearable technology; Transmission (telecommunications); Machine learning; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3197279",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3003941880",
      "doi": "10.48550/arxiv.1908.01839",
      "title": "Text-to-SQL Generation for Question Answering on Electronic Medical Records",
      "abstract": "Electronic medical records (EMR) contain comprehensive patient information and are typically stored in a relational database with multiple tables. Effective and efficient patient information retrieval from EMR data is a challenging task for medical experts. Question-to-SQL generation methods tackle this problem by first predicting the SQL query for a given question about a database, and then, executing the query on the database. However, most of the existing approaches have not been adapted to the healthcare domain due to a lack of healthcare Question-to-SQL dataset for learning models specific to this domain. In addition, wide use of the abbreviation of terminologies and possible typos in questions introduce additional challenges for accurately generating the corresponding SQL queries. In this paper, we tackle these challenges by developing a deep learning based TRanslate-Edit Model for Question-to-SQL (TREQS) generation, which adapts the widely used sequence-to-sequence model to directly generate the SQL query for a given question, and further performs the required edits using an attentive-copying mechanism and task-specific look-up tables. Based on the widely used publicly available electronic medical database, we create a new large-scale Question-SQL pair dataset, named MIMICSQL, in order to perform the Question-to-SQL generation task in healthcare domain. An extensive set of experiments are conducted to evaluate the performance of our proposed model on MIMICSQL. Both quantitative and qualitative experimental results indicate the flexibility and efficiency of our proposed method in predicting condition values and its robustness to random questions with abbreviations and typos.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Ping Wang et al.",
      "keywords": "Computer science; SQL; Information retrieval; Stored procedure; Task (project management); Database; Query by Example; Copying; Data mining; Web search query; Search engine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1908.01839",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289106643",
      "doi": "10.48550/arxiv.1812.07715",
      "title": "A Tour of Unsupervised Deep Learning for Medical Image Analysis",
      "abstract": "Interpretation of medical images for diagnosis and treatment of complex disease from high-dimensional and heterogeneous data remains a key challenge in transforming healthcare. In the last few years, both supervised and unsupervised deep learning achieved promising results in the area of medical imaging and image analysis. Unlike supervised learning which is biased towards how it is being supervised and manual efforts to create class label for the algorithm, unsupervised learning derive insights directly from the data itself, group the data and help to make data driven decisions without any external bias. This review systematically presents various unsupervised models applied to medical image analysis, including autoencoders and its several variants, Restricted Boltzmann machines, Deep belief networks, Deep Boltzmann machine and Generative adversarial network. Future research opportunities and challenges of unsupervised techniques for medical image analysis have also been discussed.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Khalid Raza et al.",
      "keywords": "Artificial intelligence; Unsupervised learning; Deep learning; Computer science; Boltzmann machine; Machine learning; Restricted Boltzmann machine; Deep belief network; Image (mathematics); Generative grammar; Key (lock); Supervised learning; Medical imaging; Pattern recognition (psychology); Artificial neural network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1812.07715",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2804985110",
      "doi": "10.48550/arxiv.1805.06826",
      "title": "The Blessings of Multiple Causes",
      "abstract": "Causal inference from observational data often assumes \"ignorability,\" that all confounders are observed. This assumption is standard yet untestable. However, many scientific studies involve multiple causes, different variables whose effects are simultaneously of interest. We propose the deconfounder, an algorithm that combines unsupervised machine learning and predictive model checking to perform causal inference in multiple-cause settings. The deconfounder infers a latent variable as a substitute for unobserved confounders and then uses that substitute to perform causal inference. We develop theory for the deconfounder, and show that it requires weaker assumptions than classical causal inference. We analyze its performance in three types of studies: semi-simulated data around smoking and lung cancer, semi-simulated data around genome-wide association studies, and a real dataset about actors and movie revenue. The deconfounder provides a checkable approach to estimating closer-to-truth causal effects.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhaoran Wang et al.",
      "keywords": "Causal inference; Inference; Confounding; Latent variable; Computer science; Observational study; Machine learning; Causal model; Causal structure; Artificial intelligence; Econometrics; Predictive inference; Statistics; Frequentist inference; Mathematics; Bayesian inference",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1805.06826",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400331951",
      "doi": "10.48550/arxiv.2407.00978",
      "title": "Hybrid RAG-empowered Multi-modal LLM for Secure Data Management in Internet of Medical Things: A Diffusion-based Contract Approach",
      "abstract": "Secure data management and effective data sharing have become paramount in the rapidly evolving healthcare landscape, especially with the growing integration of the Internet of Medical Things (IoMT). The rise of generative artificial intelligence has further elevated Multi-modal Large Language Models (MLLMs) as essential tools for managing and optimizing healthcare data in IoMT. MLLMs can support multi-modal inputs and generate diverse types of content by leveraging large-scale training on vast amounts of multi-modal data. However, critical challenges persist in developing medical MLLMs, including security and freshness issues of healthcare data, affecting the output quality of MLLMs. To this end, in this paper, we propose a hybrid Retrieval-Augmented Generation (RAG)-empowered medical MLLM framework for healthcare data management. This framework leverages a hierarchical cross-chain architecture to facilitate secure data training. Moreover, it enhances the output quality of MLLMs through hybrid RAG, which employs multi-modal metrics to filter various unimodal RAG results and incorporates these retrieval results as additional inputs to MLLMs. Additionally, we employ age of information to indirectly evaluate the data freshness impact of MLLMs and utilize contract theory to incentivize healthcare data holders to share their fresh data, mitigating information asymmetry during data sharing. Finally, we utilize a generative diffusion model-based deep reinforcement learning algorithm to identify the optimal contract for efficient data sharing. Numerical results demonstrate the effectiveness of the proposed schemes, which achieve secure and efficient healthcare data management.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Su Cheng et al.",
      "keywords": "Modal; Health care; Business; Contract theory; Diffusion; Computer science; Process management; Knowledge management; Economics; Microeconomics; Political science; Physics; Law; Materials science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.00978",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287645965",
      "doi": "10.48550/arxiv.2010.02803",
      "title": "A Transformer-based Framework for Multivariate Time Series\\n Representation Learning",
      "abstract": "In this work we propose for the first time a transformer-based framework for\\nunsupervised representation learning of multivariate time series. Pre-trained\\nmodels can be potentially used for downstream tasks such as regression and\\nclassification, forecasting and missing value imputation. By evaluating our\\nmodels on several benchmark datasets for multivariate time series regression\\nand classification, we show that not only does our modeling approach represent\\nthe most successful method employing unsupervised learning of multivariate time\\nseries presented to date, but also that it exceeds the current state-of-the-art\\nperformance of supervised methods; it does so even when the number of training\\nsamples is very limited, while offering computational efficiency. Finally, we\\ndemonstrate that unsupervised pre-training of our transformer models offers a\\nsubstantial performance benefit over fully supervised learning, even without\\nleveraging additional unlabeled data, i.e., by reusing the same data samples\\nthrough the unsupervised objective.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "George Zerveas et al.",
      "keywords": "Multivariate statistics; Computer science; Machine learning; Unsupervised learning; Artificial intelligence; Regression; Missing data; Transformer; Imputation (statistics); Feature learning; Data mining; Pattern recognition (psychology); Statistics; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2010.02803",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390961125",
      "doi": "10.48550/arxiv.2401.06796",
      "title": "AI Hallucinations: A Misnomer Worth Clarifying",
      "abstract": "As large language models continue to advance in Artificial Intelligence (AI), text generation systems have been shown to suffer from a problematic phenomenon termed often as \"hallucination.\" However, with AI's increasing presence across various domains including medicine, concerns have arisen regarding the use of the term itself. In this study, we conducted a systematic review to identify papers defining \"AI hallucination\" across fourteen databases. We present and analyze definitions obtained across all databases, categorize them based on their applications, and extract key points within each category. Our results highlight a lack of consistency in how the term is used, but also help identify several alternative terms in the literature. We discuss implications of these and call for a more unified effort to bring consistency to an important contemporary AI issue that can affect multiple domains significantly.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Negar Maleki et al.",
      "keywords": "Misnomer; Consistency (knowledge bases); Categorization; Term (time); Phenomenon; Key (lock); Affect (linguistics); Computer science; Psychology; Data science; Cognitive psychology; Artificial intelligence; Epistemology; Communication",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.06796",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403345294",
      "doi": "10.48550/arxiv.2410.06586",
      "title": "Use of Real-World Data and Real-World Evidence in Rare Disease Drug Development: A Statistical Perspective",
      "abstract": "Real-world data (RWD) and real-world evidence (RWE) have been increasingly used in medical product development and regulatory decision-making, especially for rare diseases. After outlining the challenges and possible strategies to address the challenges in rare disease drug development (see the accompanying paper), the Real-World Evidence (RWE) Scientific Working Group of the American Statistical Association Biopharmaceutical Section reviews the roles of RWD and RWE in clinical trials for drugs treating rare diseases. This paper summarizes relevant guidance documents and frameworks by selected regulatory agencies and the current practice on the use of RWD and RWE in natural history studies and the design, conduct, and analysis of rare disease clinical trials. A targeted learning roadmap for rare disease trials is described, followed by case studies on the use of RWD and RWE to support a natural history study and marketing applications in various settings.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie Chen et al.",
      "keywords": "Perspective (graphical); Real world data; Drug development; Disease; Real world evidence; Data science; Drug; Computer science; Medicine; Pharmacology; Internal medicine; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.06586",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391244310",
      "doi": "10.48550/arxiv.2401.12994",
      "title": "Automated Scoring of Clinical Patient Notes using Advanced NLP and Pseudo Labeling",
      "abstract": "Clinical patient notes are critical for documenting patient interactions, diagnoses, and treatment plans in medical practice. Ensuring accurate evaluation of these notes is essential for medical education and certification. However, manual evaluation is complex and time-consuming, often resulting in variability and resource-intensive assessments. To tackle these challenges, this research introduces an approach leveraging state-of-the-art Natural Language Processing (NLP) techniques, specifically Masked Language Modeling (MLM) pretraining, and pseudo labeling. Our methodology enhances efficiency and effectiveness, significantly reducing training time without compromising performance. Experimental results showcase improved model performance, indicating a potential transformation in clinical note assessment.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jingyu Xu et al.",
      "keywords": "Computer science; Certification; Natural language processing; Medical diagnosis; Artificial intelligence; Clinical Practice; Resource (disambiguation); Transformation (genetics); Machine learning; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.12994",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4302937696",
      "doi": "10.48550/arxiv.1707.03778",
      "title": "Catching Zika Fever: Application of Crowdsourcing and Machine Learning\\n for Tracking Health Misinformation on Twitter",
      "abstract": "In February 2016, World Health Organization declared the Zika outbreak a\\nPublic Health Emergency of International Concern. With developing evidence it\\ncan cause birth defects, and the Summer Olympics coming up in the worst\\naffected country, Brazil, the virus caught fire on social media. In this work,\\nuse Zika as a case study in building a tool for tracking the misinformation\\naround health concerns on Twitter. We collect more than 13 million tweets --\\nspanning the initial reports in February 2016 and the Summer Olympics --\\nregarding the Zika outbreak and track rumors outlined by the World Health\\nOrganization and Snopes fact checking website. The tool pipeline, which\\nincorporates health professionals, crowdsourcing, and machine learning, allows\\nus to capture health-related rumors around the world, as well as clarification\\ncampaigns by reputable health organizations. In the case of Zika, we discover\\nan extremely bursty behavior of rumor-related topics, and show that, once the\\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\\nusing automated techniques. Thus, we illustrate insights the proposed tools\\nprovide into potentially harmful information on social media, allowing public\\nhealth researchers and practitioners to respond with a targeted and timely\\naction.\\n",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Amira Ghenai et al.",
      "keywords": "Misinformation; Crowdsourcing; Rumor; Social media; Zika virus; Public health; Internet privacy; Citizen science; Public relations; Work (physics); Pandemic; Tracking (education); Data science; Political science; Business; Coronavirus disease 2019 (COVID-19); Computer science; Computer security; Medicine; Engineering; Psychology; World Wide Web; Virology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1707.03778",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2759311048",
      "doi": "10.48550/arxiv.1709.06908",
      "title": "EMR-based medical knowledge representation and inference via Markov random fields and distributed representation learning",
      "abstract": "Objective: Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support (CDS). Our objective is a general system that can extract and represent these knowledge contained in EMRs to support three CDS tasks: test recommendation, initial diagnosis, and treatment plan recommendation, with the given condition of one patient. Methods: We extracted four kinds of medical entities from records and constructed an EMR-based medical knowledge network (EMKN), in which nodes are entities and edges reflect their co-occurrence in a single record. Three bipartite subgraphs (bi-graphs) were extracted from the EMKN to support each task. One part of the bi-graph was the given condition (e.g., symptoms), and the other was the condition to be inferred (e.g., diseases). Each bi-graph was regarded as a Markov random field to support the inference. Three lazy energy functions and one parameter-based energy function were proposed, as well as two knowledge representation learning-based energy functions, which can provide a distributed representation of medical entities. Three measures were utilized for performance evaluation. Results: On the initial diagnosis task, 80.11% of the test records identified at least one correct disease from top 10 candidates. Test and treatment recommendation results were 87.88% and 92.55%, respectively. These results altogether indicate that the proposed system outperformed the baseline methods. The distributed representation of medical entities does reflect similarity relationships in regards to knowledge level. Conclusion: Combining EMKN and MRF is an effective approach for general medical knowledge representation and inference. Different tasks, however, require designing their energy functions individually.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Chao Zhao et al.",
      "keywords": "Inference; Computer science; Bipartite graph; Representation (politics); Similarity (geometry); Markov random field; Markov chain; Task (project management); Artificial intelligence; Machine learning; Graph; Knowledge representation and reasoning; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1709.06908",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283464782",
      "doi": "10.48550/arxiv.2206.11612",
      "title": "Constructing Cross-lingual Consumer Health Vocabulary with Word-Embedding from Comparable User Generated Content",
      "abstract": "The online health community (OHC) is the primary channel for laypeople to share health information. To analyze the health consumer-generated content (HCGC) from the OHCs, identifying the colloquial medical expressions used by laypeople is a critical challenge. The open-access and collaborative consumer health vocabulary (OAC CHV) is the controlled vocabulary for addressing such a challenge. Nevertheless, OAC CHV is only available in English, limiting its applicability to other languages. This research proposes a cross-lingual automatic term recognition framework for extending the English CHV into a cross-lingual one. Our framework requires an English HCGC corpus and a non-English (i.e., Chinese in this study) HCGC corpus as inputs. Two monolingual word vector spaces are determined using the skip-gram algorithm so that each space encodes common word associations from laypeople within a language. Based on the isometry assumption, the framework aligns two monolingual spaces into a bilingual word vector space, where we employ cosine similarity as a metric for identifying semantically similar words across languages. The experimental results demonstrate that our framework outperforms the other two large language models in identifying CHV across languages. Our framework only requires raw HCGC corpora and a limited size of medical translations, reducing human efforts in compiling cross-lingual CHV.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Chia\u2010Hsuan Chang et al.",
      "keywords": "Computer science; Vocabulary; Natural language processing; Similarity (geometry); Word (group theory); Artificial intelligence; Metric (unit); Word embedding; Space (punctuation); Variation (astronomy); Limiting; Embedding; Linguistics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.11612",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386754881",
      "doi": "10.48550/arxiv.2309.06055",
      "title": "Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review",
      "abstract": "Language Models (LMs) are becoming increasingly popular in real-world applications. Outsourcing model training and data hosting to third-party platforms has become a standard method for reducing costs. In such a situation, the attacker can manipulate the training process or data to inject a backdoor into models. Backdoor attacks are a serious threat where malicious behavior is activated when triggers are present, otherwise, the model operates normally. However, there is still no systematic and comprehensive review of LMs from the attacker's capabilities and purposes on different backdoor attack surfaces. Moreover, there is a shortage of analysis and comparison of the diverse emerging backdoor countermeasures. Therefore, this work aims to provide the NLP community with a timely review of backdoor attacks and countermeasures. According to the attackers' capability and affected stage of the LMs, the attack surfaces are formalized into four categorizations: attacking the pre-trained model with fine-tuning (APMF) or parameter-efficient fine-tuning (APMP), attacking the final model with training (AFMT), and attacking Large Language Models (ALLM). Thus, attacks under each categorization are combed. The countermeasures are categorized into two general classes: sample inspection and model inspection. Thus, we review countermeasures and analyze their advantages and disadvantages. Also, we summarize the benchmark datasets and provide comparable evaluations for representative attacks and defenses. Drawing the insights from the review, we point out the crucial areas for future research on the backdoor, especially soliciting more efficient and practical countermeasures.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Pengzhou Cheng et al.",
      "keywords": "Backdoor; Computer security; Computer science; Attack model; Context (archaeology); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.06055",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4221153552",
      "doi": "10.48550/arxiv.2203.05112",
      "title": "Librarian-in-the-Loop: A Natural Language Processing Paradigm for Detecting Informal Mentions of Research Data in Academic Literature",
      "abstract": "Data citations provide a foundation for studying research data impact. Collecting and managing data citations is a new frontier in archival science and scholarly communication. However, the discovery and curation of research data citations is labor intensive. Data citations that reference unique identifiers (i.e. DOIs) are readily findable; however, informal mentions made to research data are more challenging to infer. We propose a natural language processing (NLP) paradigm to support the human task of identifying informal mentions made to research datasets. The work of discovering informal data mentions is currently performed by librarians and their staff in the Inter-university Consortium for Political and Social Research (ICPSR), a large social science data archive that maintains a large bibliography of data-related literature. The NLP model is bootstrapped from data citations actively collected by librarians at ICPSR. The model combines pattern matching with multiple iterations of human annotations to learn additional rules for detecting informal data mentions. These examples are then used to train an NLP pipeline. The librarian-in-the-loop paradigm is centered in the data work performed by ICPSR librarians, supporting broader efforts to build a more comprehensive bibliography of data-related literature that reflects the scholarly communities of research data users.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Lizhou Fan et al.",
      "keywords": "Computer science; Identifier; Data science; Data curation; Pipeline (software); Task (project management); Information retrieval; Matching (statistics); World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.05112",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4221142950",
      "doi": "10.48550/arxiv.2202.03513",
      "title": "Causal survival analysis under competing risks using longitudinal modified treatment policies",
      "abstract": "Longitudinal modified treatment policies (LMTP) have been recently developed as a novel method to define and estimate causal parameters that depend on the natural value of treatment. LMTPs represent an important advancement in causal inference for longitudinal studies as they allow the non-parametric definition and estimation of the joint effect of multiple categorical, numerical, or continuous exposures measured at several time points. We extend the LMTP methodology to problems in which the outcome is a time-to-event variable subject to right-censoring and competing risks. We present identification results and non-parametric locally efficient estimators that use flexible data-adaptive regression techniques to alleviate model misspecification bias, while retaining important asymptotic properties such as $\\sqrt{n}$-consistency. We present an application to the estimation of the effect of the time-to-intubation on acute kidney injury amongst COVID-19 hospitalized patients, where death by other causes is taken to be the competing event.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Iv\u00e1n D\u00edaz et al.",
      "keywords": "Censoring (clinical trials); Causal inference; Econometrics; Estimator; Categorical variable; Nonparametric statistics; Consistency (knowledge bases); Regression; Parametric statistics; Event (particle physics); Statistics; Inference; Survival analysis; Computer science; Mathematics; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.03513",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4290926546",
      "doi": "10.13016/m2tqay-zzzz",
      "title": "Structural Causal Model with Expert Augmented Knowledge to Estimate the Effect of Oxygen Therapy on Mortality in the ICU",
      "abstract": "Recent advances in causal inference techniques, more specifically, in the theory of structural causal models, provide the framework for identification of causal effects from observational data in the cases where the causal graph is identifiable, i.e., the data generating mechanism can be recovered from the joint distribution. However, no such studies have been done to demonstrate this concept with a clinical example. We present a complete framework to estimate the causal effect from observational data by augmenting expert knowledge in the model development phase and with a practical clinical application. Our clinical application entails a timely and important research question, i.e., the effect of oxygen therapy intervention in the intensive care unit (ICU); the result of this project is useful in a variety of disease conditions, including severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) patients in the ICU. We used data from the MIMIC III database, a standard database in the machine learning community that contains 58,976 admissions from an ICU in Boston, MA, for estimating the oxygen therapy effect on morality. We also identified the covariate-specific effect to oxygen therapy from the model for more personalized intervention.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Md Osman Gani et al.",
      "keywords": "Causal inference; Observational study; Causal model; Intensive care unit; Identification (biology); Intensive care medicine; Machine learning; Computer science; Intervention (counseling); Medicine; Artificial intelligence; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.13016/m2tqay-zzzz",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3117191893",
      "doi": "10.48550/arxiv.2012.07450",
      "title": "FedHome: Cloud-Edge based Personalized Federated Learning for In-Home Health Monitoring",
      "abstract": "In-home health monitoring has attracted great attention for the ageing population worldwide. With the abundant user health data accessed by Internet of Things (IoT) devices and recent development in machine learning, smart healthcare has seen many successful stories. However, existing approaches for in-home health monitoring do not pay sufficient attention to user data privacy and thus are far from being ready for large-scale practical deployment. In this paper, we propose FedHome, a novel cloud-edge based federated learning framework for in-home health monitoring, which learns a shared global model in the cloud from multiple homes at the network edges and achieves data privacy protection by keeping user data locally. To cope with the imbalanced and non-IID distribution inherent in user's monitoring data, we design a generative convolutional autoencoder (GCAE), which aims to achieve accurate and personalized health monitoring by refining the model with a generated class-balanced dataset from user's personal data. Besides, GCAE is lightweight to transfer between the cloud and edges, which is useful to reduce the communication cost of federated learning in FedHome. Extensive experiments based on realistic human activity recognition data traces corroborate that FedHome significantly outperforms existing widely-adopted methods.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Qiong Wu et al.",
      "keywords": "Cloud computing; Computer science; Autoencoder; Software deployment; Enhanced Data Rates for GSM Evolution; Edge computing; Deep learning; Machine learning; Data science; Human\u2013computer interaction; Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2012.07450",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384112015",
      "doi": "10.48550/arxiv.2307.05050",
      "title": "Considerations for Master Protocols Using External Controls",
      "abstract": "There has been an increasing use of master protocols in oncology clinical trials because of its efficiency and flexibility to accelerate cancer drug development. Depending on the study objective and design, a master protocol trial can be a basket trial, an umbrella trial, a platform trial, or any other form of trials in which multiple investigational products and/or subpopulations are studied under a single protocol. Master protocols can use external data and evidence (e.g., external controls) for treatment effect estimation, which can further improve efficiency of master protocol trials. This paper provides an overview of different types of external controls and their unique features when used in master protocols. Some key considerations in master protocols with external controls are discussed including construction of estimands, assessment of fit-for-use real-world data, and considerations for different types of master protocols. Similarities and differences between regular randomized controlled trials and master protocols when using external controls are discussed. A targeted learning-based causal roadmap is presented which constitutes three key steps: (1) define a target statistical estimand that aligns with the causal estimand for the study objective, (2) use an efficient estimator to estimate the target statistical estimand and its uncertainty, and (3) evaluate the impact of causal assumptions on the study conclusion by performing sensitivity analyses. Two illustrative examples for master protocols using external controls are discussed for their merits and possible improvement in causal effect estimation.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie Chen et al.",
      "keywords": "Protocol (science); Flexibility (engineering); Estimator; Computer science; Clinical trial; Key (lock); Statistics; Medicine; Mathematics; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.05050",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287330378",
      "doi": "10.48550/arxiv.2102.04702",
      "title": "AttDMM: An Attentive Deep Markov Model for Risk Scoring in Intensive\\n Care Units",
      "abstract": "Clinical practice in intensive care units (ICUs) requires early warnings when\\na patient's condition is about to deteriorate so that preventive measures can\\nbe undertaken. To this end, prediction algorithms have been developed that\\nestimate the risk of mortality in ICUs. In this work, we propose a novel\\ngenerative deep probabilistic model for real-time risk scoring in ICUs.\\nSpecifically, we develop an attentive deep Markov model called AttDMM. To the\\nbest of our knowledge, AttDMM is the first ICU prediction model that jointly\\nlearns both long-term disease dynamics (via attention) and different disease\\nstates in health trajectory (via a latent variable model). Our evaluations were\\nbased on an established baseline dataset (MIMIC-III) with 53,423 ICU stays. The\\nresults confirm that compared to state-of-the-art baselines, our AttDMM was\\nsuperior: AttDMM achieved an area under the receiver operating characteristic\\ncurve (AUROC) of 0.876, which yielded an improvement over the state-of-the-art\\nmethod by 2.2%. In addition, the risk score from the AttDMM provided warnings\\nseveral hours earlier. Thereby, our model shows a path towards identifying\\npatients at risk so that health practitioners can intervene early and save\\npatient lives.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Y\u0131lmazcan \u00d6zyurt et al.",
      "keywords": "Intensive care; Receiver operating characteristic; Markov model; Baseline (sea); Computer science; Health care; Artificial intelligence; Path (computing); Probabilistic logic; Trajectory; Machine learning; Medicine; Markov chain; Medical emergency; Intensive care medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2102.04702",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225716263",
      "doi": "10.48550/arxiv.2203.04921",
      "title": "The Severity Prediction of The Binary And Multi-Class Cardiovascular Disease -- A Machine Learning-Based Fusion Approach",
      "abstract": "In today's world, a massive amount of data is available in almost every sector. This data has become an asset as we can use this enormous amount of data to find information. Mainly health care industry contains many data consisting of patient and disease-related information. By using the machine learning technique, we can look for hidden data patterns to predict various diseases. Recently CVDs, or cardiovascular disease, have become a leading cause of death around the world. The number of death due to CVDs is frightening. That is why many researchers are trying their best to design a predictive model that can save many lives using the data mining model. In this research, some fusion models have been constructed to diagnose CVDs along with its severity. Machine learning(ML) algorithms like artificial neural network, SVM, logistic regression, decision tree, random forest, and AdaBoost have been applied to the heart disease dataset to predict disease. Randomoversampler was implemented because of the class imbalance in multiclass classification. To improve the performance of classification, a weighted score fusion approach was taken. At first, the models were trained. After training, two algorithms' decision was combined using a weighted sum rule. A total of three fusion models have been developed from the six ML algorithms. The results were promising in the performance parameter. The proposed approach has been experimented with different test training ratios for binary and multiclass classification problems, and for both of them, the fusion models performed well. The highest accuracy for multiclass classification was found as 75%, and it was 95% for binary. The code can be found in : https://github.com/hafsa-kibria/Weighted_score_fusion_model_heart_disease_prediction",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Hafsa Binte Kibria et al.",
      "keywords": "Machine learning; Artificial intelligence; Decision tree; Support vector machine; Computer science; Multiclass classification; AdaBoost; Artificial neural network; Random forest; Logistic regression; Class (philosophy); Binary classification; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.04921",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287546289",
      "doi": "10.48550/arxiv.2101.00159",
      "title": "Fidel: Reconstructing Private Training Samples from Weight Updates in Federated Learning",
      "abstract": "With the increasing number of data collectors such as smartphones, immense amounts of data are available. Federated learning was developed to allow for distributed learning on a massive scale whilst still protecting each users' privacy. This privacy is claimed by the notion that the centralized server does not have any access to a client's data, solely the client's model update. In this paper, we evaluate a novel attack method within regular federated learning which we name the First Dense Layer Attack (Fidel). The methodology of using this attack is discussed, and as a proof of viability we show how this attack method can be used to great effect for densely connected networks and convolutional neural networks. We evaluate some key design decisions and show that the usage of ReLu and Dropout are detrimental to the privacy of a client's local dataset. We show how to recover on average twenty out of thirty private data samples from a client's model update employing a fully connected neural network with very little computational resources required. Similarly, we show that over thirteen out of twenty samples can be recovered from a convolutional neural network update. An open source implementation of this attack can be found here https://github.com/Davidenthoven/Fidel-Reconstruction-Demo",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "David Enthoven et al.",
      "keywords": "Computer science; Convolutional neural network; Federated learning; Dropout (neural networks); Key (lock); Artificial neural network; Training set; Deep learning; Artificial intelligence; Layer (electronics); Machine learning; Computer security; Computer network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2101.00159",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3126354667",
      "doi": "10.48550/arxiv.2102.01194",
      "title": "A Statistician Teaches Deep Learning",
      "abstract": "Deep learning (DL) has gained much attention and become increasingly popular in modern data science. Computer scientists led the way in developing deep learning techniques, so the ideas and perspectives can seem alien to statisticians. Nonetheless, it is important that statisticians become involved -- many of our students need this expertise for their careers. In this paper, developed as part of a program on DL held at the Statistical and Applied Mathematical Sciences Institute, we address this culture gap and provide tips on how to teach deep learning to statistics graduate students. After some background, we list ways in which DL and statistical perspectives differ, provide a recommended syllabus that evolved from teaching two iterations of a DL graduate course, offer examples of suggested homework assignments, give an annotated list of teaching resources, and discuss DL in the context of two research areas.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "G. Jogesh Babu et al.",
      "keywords": "Statistician; Syllabus; Context (archaeology); Computer science; Deep learning; Mathematics education; Graduate students; Artificial intelligence; Data science; Engineering ethics; Psychology; Mathematics; Pedagogy; Statistics; Engineering; History",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2102.01194",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4229027555",
      "doi": "10.48550/arxiv.2205.01851",
      "title": "Toward Data-Driven Digital Therapeutics Analytics: Literature Review and Research Directions",
      "abstract": "With the advent of Digital Therapeutics (DTx), the development of software as a medical device (SaMD) for mobile and wearable devices has gained significant attention in recent years. Existing DTx evaluations, such as randomized clinical trials, mostly focus on verifying the effectiveness of DTx products. To acquire a deeper understanding of DTx engagement and behavioral adherence, beyond efficacy, a large amount of contextual and interaction data from mobile and wearable devices during field deployment would be required for analysis. In this work, the overall flow of the data-driven DTx analytics is reviewed to help researchers and practitioners to explore DTx datasets, to investigate contextual patterns associated with DTx usage, and to establish the (causal) relationship of DTx engagement and behavioral adherence. This review of the key components of data-driven analytics provides novel research directions in the analysis of mobile sensor and interaction datasets, which helps to iteratively improve the receptivity of existing DTx.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Uichin Lee et al.",
      "keywords": "Analytics; Data science; Computer science; Wearable computer; Software deployment; Wearable technology; Human\u2013computer interaction; Field (mathematics); Mobile device; Citizen science; Digital health; Data analysis; World Wide Web; Data mining; Health care; Software engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.01851",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2949831464",
      "doi": "10.48550/arxiv.1807.09119",
      "title": "A Structured Learning Approach with Neural Conditional Random Fields for Sleep Staging",
      "abstract": "Sleep plays a vital role in human health, both mental and physical. Sleep disorders like sleep apnea are increasing in prevalence, with the rapid increase in factors like obesity. Sleep apnea is most commonly treated with Continuous Positive Air Pressure (CPAP) therapy. Presently, however, there is no mechanism to monitor a patient's progress with CPAP. Accurate detection of sleep stages from CPAP flow signal is crucial for such a mechanism. We propose, for the first time, an automated sleep staging model based only on the flow signal. Deep neural networks have recently shown high accuracy on sleep staging by eliminating handcrafted features. However, these methods focus exclusively on extracting informative features from the input signal, without paying much attention to the dynamics of sleep stages in the output sequence. We propose an end-to-end framework that uses a combination of deep convolution and recurrent neural networks to extract high-level features from raw flow signal with a structured output layer based on a conditional random field to model the temporal transition structure of the sleep stages. We improve upon the previous methods by 10% using our model, that can be augmented to the previous sleep staging deep learning methods. We also show that our method can be used to accurately track sleep metrics like sleep efficiency calculated from sleep stages that can be deployed for monitoring the response of CPAP therapy on sleep apnea patients. Apart from the technical contributions, we expect this study to motivate new research questions in sleep science.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Karan Aggarwal et al.",
      "keywords": "Sleep (system call); Conditional random field; Deep learning; Sleep apnea; Computer science; Artificial intelligence; Sleep Stages; Artificial neural network; Recurrent neural network; Apnea; Obstructive sleep apnea; SIGNAL (programming language); Machine learning; Polysomnography; Medicine; Anesthesia",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1807.09119",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3159558705",
      "doi": "10.48550/arxiv.2105.00568",
      "title": "InferNet for Delayed Reinforcement Tasks: Addressing the Temporal Credit Assignment Problem",
      "abstract": "The temporal Credit Assignment Problem (CAP) is a well-known and challenging task in AI. While Reinforcement Learning (RL), especially Deep RL, works well when immediate rewards are available, it can fail when only delayed rewards are available or when the reward function is noisy. In this work, we propose delegating the CAP to a Neural Network-based algorithm named InferNet that explicitly learns to infer the immediate rewards from the delayed rewards. The effectiveness of InferNet was evaluated on two online RL tasks: a simple GridWorld and 40 Atari games; and two offline RL tasks: GridWorld and a real-life Sepsis treatment task. For all tasks, the effectiveness of using the InferNet inferred rewards is compared against the immediate and the delayed rewards with two settings: with noisy rewards and without noise. Overall, our results show that the effectiveness of InferNet is robust against noisy reward functions and is an effective add-on mechanism for solving temporal CAP in a wide range of RL tasks, from classic RL simulation environments to a real-world RL problem and for both online and offline learning.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Markel Sanz Ausin et al.",
      "keywords": "Reinforcement learning; Computer science; Task (project management); Artificial intelligence; Function (biology); Noise (video); Range (aeronautics); Simple (philosophy); Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2105.00568",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395064848",
      "doi": "10.48550/arxiv.2404.13235",
      "title": "TrialDura: Hierarchical Attention Transformer for Interpretable Clinical Trial Duration Prediction",
      "abstract": "The clinical trial process, a critical phase in drug development, is essential for developing new treatments. The primary goal of interventional clinical trials is to evaluate the safety and efficacy of drug-based treatments for specific diseases. However, these trials are often lengthy, labor-intensive, and expensive. The duration of a clinical trial significantly impacts overall costs, making efficient timeline management crucial for controlling budgets and ensuring the economic feasibility of research. To address this issue, We propose TrialDura, a machine learning-based method that estimates the duration of clinical trials using multimodal data, including disease names, drug molecules, trial phases, and eligibility criteria. Then, we encode them into Bio-BERT embeddings specifically tuned for biomedical contexts to provide a deeper and more relevant semantic understanding of clinical trial data. Finally, the model's hierarchical attention mechanism connects all of the embeddings to capture their interactions and predict clinical trial duration. Our proposed model demonstrated superior performance with a mean absolute error (MAE) of 1.04 years and a root mean square error (RMSE) of 1.39 years compared to the other models, indicating more accurate clinical trial duration prediction. Publicly available code can be found at: https://anonymous.4open.science/r/TrialDura-F196.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ling Yue et al.",
      "keywords": "Duration (music); Transformer; Econometrics; Artificial intelligence; Computer science; Mathematics; Engineering; Voltage; Physics; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.13235",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394906448",
      "doi": "10.48550/arxiv.2404.10593",
      "title": "A Longitudinal Study of Child Wellbeing Assessment via Online Interactions with a Social Robot",
      "abstract": "Socially Assistive Robots are studied in different Child-Robot Interaction settings. However, logistical constraints limit accessibility, particularly affecting timely support for mental wellbeing. In this work, we have investigated whether online interactions with a robot can be used for the assessment of mental wellbeing in children. The children (N=40, 20 girls and 20 boys; 8-13 years) interacted with the Nao robot (30-45 mins) over three sessions, at least a week apart. Audio-visual recordings were collected throughout the sessions that concluded with the children answering user perception questionnaires pertaining to their anxiety towards the robot, and the robot's abilities. We divided the participants into three wellbeing clusters (low, med and high tertiles) using their responses to the Short Moods and Feelings Questionnaire (SMFQ) and further analysed how their wellbeing and their perceptions of the robot changed over the wellbeing tertiles, across sessions and across participants' gender. Our primary findings suggest that (I) online mediated-interactions with robots can be effective in assessing children's mental wellbeing over time, and (II) children's overall perception of the robot either improved or remained consistent across time. Supplementary exploratory analyses have also revealed that the gender of the children affected their wellbeing assessments with interactions effectively distinguishing between varying levels of wellbeing for both boys and girls for the first session and only for boys during the second session. The analyses have also revealed that girls have a higher opinion of the robot as a confidante as compared with boys. Findings from this work affirm the potential of using online mediated interactions with robots for the assessment of the mental wellbeing of children.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Nida Itrat Abbasi et al.",
      "keywords": "Psychology; Robot; Longitudinal study; Computer science; Human\u2013computer interaction; Applied psychology; Social psychology; Artificial intelligence; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.10593",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4405094849",
      "doi": "10.48550/arxiv.2412.03851",
      "title": "FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems",
      "abstract": "Personalized medication aims to tailor healthcare to individual patient characteristics. However, the heterogeneity of patient data across healthcare systems presents significant challenges to achieving accurate and effective personalized treatments. Ethical concerns further complicate the aggregation of large volumes of data from diverse institutions. Federated Learning (FL) offers a promising decentralized solution by enabling collaborative model training through the exchange of client models rather than raw data, thus preserving privacy. However, existing FL methods often suffer from retrogression during server aggregation, leading to a decline in model performance in real-world medical FL settings. To address data variability in distributed healthcare systems, we introduce Federated Meta-Learning for Personalized Medication (FedMetaMed), which combines federated learning and meta-learning to create models that adapt to diverse patient data across healthcare systems. The FedMetaMed framework aims to produce superior personalized models for individual clients by addressing these limitations. Specifically, we introduce Cumulative Fourier Aggregation (CFA) at the server to improve stability and effectiveness in global knowledge aggregation. CFA achieves this by gradually integrating client models from low to high frequencies. At the client level, we implement a Collaborative Transfer Optimization (CTO) strategy with a three-step process - Retrieve, Reciprocate, and Refine - to enhance the personalized local model through seamless global knowledge transfer. Experiments on real-world medical imaging datasets demonstrate that FedMetaMed outperforms state-of-the-art FL methods, showing superior generalization even on out-of-distribution cohorts.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiechao Gao et al.",
      "keywords": "Federated learning; Healthcare system; Computer science; Health care; Knowledge management; Artificial intelligence; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.03851",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226139201",
      "doi": "10.48550/arxiv.2203.15935",
      "title": "Graph Neural Networks in IoT: A Survey",
      "abstract": "The Internet of Things (IoT) boom has revolutionized almost every corner of people's daily lives: healthcare, home, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technologies, IoT devices including smart wearables, cameras, smartwatches, and autonomous vehicles can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph Neural Networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source code from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at https://github.com/GuiminDong/GNN4IoT.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Guimin Dong et al.",
      "keywords": "Computer science; Deep learning; Internet of Things; Artificial neural network; Implementation; Wireless sensor network; Artificial intelligence; Wearable computer; Machine learning; Data science; Computer security; Embedded system; Computer network; Software engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.15935",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385327574",
      "doi": "10.48550/arxiv.2307.13704",
      "title": "eXplainable Artificial Intelligence (XAI) in aging clock models",
      "abstract": "eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of machine learning, aiming to unravel the predictions of complex models. XAI is especially required in sensitive applications, e.g. in health care, when diagnosis, recommendations and treatment choices might rely on the decisions made by artificial intelligence systems. AI approaches have become widely used in aging research as well, in particular, in developing biological clock models and identifying biomarkers of aging and age-related diseases. However, the potential of XAI here awaits to be fully appreciated. We discuss the application of XAI for developing the \"aging clocks\" and present a comprehensive analysis of the literature categorized by the focus on particular physiological systems.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Alena Kalyakulina et al.",
      "keywords": "Computer science; Field (mathematics); Artificial intelligence; Focus (optics); Data science; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.13704",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2952989312",
      "doi": "10.48550/arxiv.1406.5520",
      "title": "The Multidimensional Assessment of Scholarly Research Impact",
      "abstract": "This article introduces the Multidimensional Research Assessment Matrix of scientific output. Its base notion holds that the choice of metrics to be applied in a research assessment process depends upon the unit of assessment, the research dimension to be assessed, and the purposes and policy context of the assessment. An indicator may by highly useful within one assessment process, but less so in another. For instance, publication counts are useful tools to help discriminating between those staff members who are research active, and those who are not, but are of little value if active scientists are to be compared one another according to their research performance. This paper gives a systematic account of the potential usefulness and limitations of a set of 10 important metrics including altmetrics, applied at the level of individual articles, individual researchers, research groups and institutions. It presents a typology of research impact dimensions, and indicates which metrics are the most appropriate to measure each dimension. It introduces the concept of a meta-analysis of the units under assessment in which metrics are not used as tools to evaluate individual units, but to reach policy inferences regarding the objectives and general setup of an assessment process.",
      "year": "2014",
      "journal": "arXiv (Cornell University)",
      "authors": "Henk F. Moed et al.",
      "keywords": "Dimension (graph theory); Computer science; Context (archaeology); Process (computing); Typology; Set (abstract data type); Management science; Data science; Impact assessment; Altmetrics; Mathematics; Political science; Engineering; Sociology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1406.5520",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417170884",
      "doi": "10.48550/arxiv.2504.20635",
      "title": "Bridging the Generalisation Gap: Synthetic Data Generation for Multi-Site Clinical Model Validation",
      "abstract": "Ensuring the generalisability of clinical machine learning (ML) models across diverse healthcare settings remains a significant challenge due to variability in patient demographics, disease prevalence, and institutional practices. Existing model evaluation approaches often rely on real-world datasets, which are limited in availability, embed confounding biases, and lack the flexibility needed for systematic experimentation. Furthermore, while generative models aim for statistical realism, they often lack transparency and explicit control over factors driving distributional shifts. In this work, we propose a novel structured synthetic data framework designed for the controlled benchmarking of model robustness, fairness, and generalisability. Unlike approaches focused solely on mimicking observed data, our framework provides explicit control over the data generating process, including site-specific prevalence variations, hierarchical subgroup effects, and structured feature interactions. This enables targeted investigation into how models respond to specific distributional shifts and potential biases. Through controlled experiments, we demonstrate the framework's ability to isolate the impact of site variations, support fairness-aware audits, and reveal generalisation failures, particularly highlighting how model complexity interacts with site-specific effects. This work contributes a reproducible, interpretable, and configurable tool designed to advance the reliable deployment of ML in clinical settings.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Bradley Segal et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.20635",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4301324096",
      "doi": "10.48550/arxiv.1707.04958",
      "title": "An Ensemble Boosting Model for Predicting Transfer to the Pediatric\\n Intensive Care Unit",
      "abstract": "Our work focuses on the problem of predicting the transfer of pediatric\\npatients from the general ward of a hospital to the pediatric intensive care\\nunit. Using data collected over 5.5 years from the electronic health records of\\ntwo medical facilities, we develop classifiers based on adaptive boosting and\\ngradient tree boosting. We further combine these learned classifiers into an\\nensemble model and compare its performance to a modified pediatric early\\nwarning score (PEWS) baseline that relies on expert defined guidelines. To\\ngauge model generalizability, we perform an inter-facility evaluation where we\\ntrain our algorithm on data from one facility and perform evaluation on a\\nhidden test dataset from a separate facility. We show that improvements are\\nwitnessed over the PEWS baseline in accuracy (0.77 vs. 0.69), sensitivity (0.80\\nvs. 0.68), specificity (0.74 vs. 0.70) and AUROC (0.85 vs. 0.73).\\n",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Jonathan M. Rubin et al.",
      "keywords": "Boosting (machine learning); Generalizability theory; Gradient boosting; Decision tree; Computer science; Machine learning; Artificial intelligence; Intensive care unit; Baseline (sea); Medicine; Random forest; Emergency medicine; Medical emergency; Statistics; Intensive care medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1707.04958",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288091611",
      "doi": "10.48550/arxiv.1910.09356",
      "title": "Supervised Machine Learning based Ensemble Model for Accurate Prediction\\n of Type 2 Diabetes",
      "abstract": "According to the American Diabetes Association(ADA), 30.3 million people in\\nthe United States have diabetes, but only 7.2 million may be undiagnosed and\\nunaware of their condition. Type 2 diabetes is usually diagnosed for most\\npatients later on in life whereas the less common Type 1 diabetes is diagnosed\\nearly on in life. People can live healthy and happy lives while living with\\ndiabetes, but early detection produces a better overall outcome on most\\npatient's health. Thus, to test the accurate prediction of Type 2 diabetes, we\\nuse the patients' information from an electronic health records company called\\nPractice Fusion, which has about 10,000 patient records from 2009 to 2012. This\\ndata contains individual key biometrics, including age, diastolic and systolic\\nblood pressure, gender, height, and weight. We use this data on popular machine\\nlearning algorithms and for each algorithm, we evaluate the performance of\\nevery model based on their classification accuracy, precision, sensitivity,\\nspecificity/recall, negative predictive value, and F1 score. In our study, we\\nfind that all algorithms other than Naive Bayes suffered from very low\\nprecision. Hence, we take a step further and incorporate all the algorithms\\ninto a weighted average or soft voting ensemble model where each algorithm will\\ncount towards a majority vote towards the decision outcome of whether a patient\\nhas diabetes or not. The accuracy of the Ensemble model on Practice Fusion is\\n85\\\\%, by far our ensemble approach is new in this space. We firmly believe that\\nthe weighted average ensemble model not only performed well in overall metrics\\nbut also helped to recover wrong predictions and aid in accurate prediction of\\nType 2 diabetes. Our accurate novel model can be used as an alert for the\\npatients to seek medical evaluation in time.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Ramya Akula et al.",
      "keywords": "Artificial intelligence; Machine learning; Naive Bayes classifier; Type 2 diabetes; Ensemble forecasting; Ensemble learning; Majority rule; Computer science; Diabetes mellitus; Medicine; Support vector machine; Algorithm",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1910.09356",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415247854",
      "doi": "10.48550/arxiv.2505.03406",
      "title": "Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation",
      "abstract": "This research paper investigates the application of Large Language Models (LLMs) in healthcare, specifically focusing on enhancing medical decision support through Retrieval-Augmented Generation (RAG) integrated with hospital-specific data and fine-tuning using Quantized Low-Rank Adaptation (QLoRA). The system utilizes Llama 3.2-3B-Instruct as its foundation model. By embedding and retrieving context-relevant healthcare information, the system significantly improves response accuracy. QLoRA facilitates notable parameter efficiency and memory optimization, preserving the integrity of medical information through specialized quantization techniques. Our research also shows that our model performs relatively well on various medical benchmarks, indicating that it can be used to make basic medical suggestions. This paper details the system's technical components, including its architecture, quantization methods, and key healthcare applications such as enhanced disease prediction from patient symptoms and medical history, treatment suggestions, and efficient summarization of complex medical reports. We touch on the ethical considerations-patient privacy, data security, and the need for rigorous clinical validation-as well as the practical challenges of integrating such systems into real-world healthcare workflows. Furthermore, the lightweight quantized weights ensure scalability and ease of deployment even in low-resource hospital environments. Finally, the paper concludes with an analysis of the broader impact of LLMs on healthcare and outlines future directions for LLMs in medical settings.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mohammad Shoaib Ansari et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.03406",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388555401",
      "doi": "10.48550/arxiv.2311.04325",
      "title": "Extending Machine Learning-Based Early Sepsis Detection to Different Demographics",
      "abstract": "Sepsis requires urgent diagnosis, but research is predominantly focused on Western datasets. In this study, we perform a comparative analysis of two ensemble learning methods, LightGBM and XGBoost, using the public eICU-CRD dataset and a private South Korean St. Mary's Hospital's dataset. Our analysis reveals the effectiveness of these methods in addressing healthcare data imbalance and enhancing sepsis detection. Specifically, LightGBM shows a slight edge in computational efficiency and scalability. The study paves the way for the broader application of machine learning in critical care, thereby expanding the reach of predictive analytics in healthcare globally.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Surajsinh Parmar et al.",
      "keywords": "Scalability; Demographics; Big data; Computer science; Machine learning; Analytics; Sepsis; Health care; Artificial intelligence; Enhanced Data Rates for GSM Evolution; Data science; Predictive analytics; Data mining; Medicine; Political science; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.04325",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297808351",
      "doi": "10.48550/arxiv.2106.08889",
      "title": "Cardiovascular Disease Prediction using Recursive Feature Elimination and Gradient Boosting Classification Techniques",
      "abstract": "Cardiovascular diseases (CVDs) are one of the most common chronic illnesses that affect peoples health. Early detection of CVDs can reduce mortality rates by preventing or reducing the severity of the disease. Machine learning algorithms are a promising method for identifying risk factors. This paper proposes a proposed recursive feature elimination-based gradient boosting (RFE-GB) algorithm in order to obtain accurate heart disease prediction. The patients health record with important CVD features has been analyzed for the evaluation of the results. Several other machine learning methods were also used to build the prediction model, and the results were compared with the proposed model. The results of this proposed model infer that the combined recursive feature elimination and gradient boosting algorithm achieves the highest accuracy (89.7 %). Further, with an area under the curve of 0.84, the proposed RFE-GB algorithm was found superior and had obtained a substantial gain over other techniques. Thus, the proposed RFE-GB algorithm will serve as a prominent model for CVD estimation and treatment.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Prasannavenkatesan Theerthagiri et al.",
      "keywords": "Boosting (machine learning); Gradient boosting; Computer science; Artificial intelligence; Machine learning; Feature (linguistics); Disease; Pattern recognition (psychology); Algorithm; Data mining; Random forest; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.08889",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415037343",
      "doi": "10.48550/arxiv.2505.21324",
      "title": "Leveraging large language models and traditional machine learning ensembles for ADHD detection from narrative transcripts",
      "abstract": "Despite rapid advances in large language models (LLMs), their integration with traditional supervised machine learning (ML) techniques that have proven applicability to medical data remains underexplored. This is particularly true for psychiatric applications, where narrative data often exhibit nuanced linguistic and contextual complexity, and can benefit from the combination of multiple models with differing characteristics. In this study, we introduce an ensemble framework for automatically classifying Attention-Deficit/Hyperactivity Disorder (ADHD) diagnosis (binary) using narrative transcripts. Our approach integrates three complementary models: LLaMA3, an open-source LLM that captures long-range semantic structure; RoBERTa, a pre-trained transformer model fine-tuned on labeled clinical narratives; and a Support Vector Machine (SVM) classifier trained using TF-IDF-based lexical features. These models are aggregated through a majority voting mechanism to enhance predictive robustness. The dataset includes 441 instances, including 352 for training and 89 for validation. Empirical results show that the ensemble outperforms individual models, achieving an F$_1$ score of 0.71 (95\\% CI: [0.60-0.80]). Compared to the best-performing individual model (SVM), the ensemble improved recall while maintaining competitive precision. This indicates the strong sensitivity of the ensemble in identifying ADHD-related linguistic cues. These findings demonstrate the promise of hybrid architectures that leverage the semantic richness of LLMs alongside the interpretability and pattern recognition capabilities of traditional supervised ML, offering a new direction for robust and generalizable psychiatric text classification.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuxin Zhu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.21324",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404313873",
      "doi": "10.48550/arxiv.2410.20300",
      "title": "Predicting Mortality and Functional Status Scores of Traumatic Brain Injury Patients using Supervised Machine Learning",
      "abstract": "Traumatic brain injury (TBI) presents a significant public health challenge, often resulting in mortality or lasting disability. Predicting outcomes such as mortality and Functional Status Scale (FSS) scores can enhance treatment strategies and inform clinical decision-making. This study applies supervised machine learning (ML) methods to predict mortality and FSS scores using a real-world dataset of 300 pediatric TBI patients from the University of Colorado School of Medicine. The dataset captures clinical features, including demographics, injury mechanisms, and hospitalization outcomes. Eighteen ML models were evaluated for mortality prediction, and thirteen models were assessed for FSS score prediction. Performance was measured using accuracy, ROC AUC, F1-score, and mean squared error. Logistic regression and Extra Trees models achieved high precision in mortality prediction, while linear regression demonstrated the best FSS score prediction. Feature selection reduced 103 clinical variables to the most relevant, enhancing model efficiency and interpretability. This research highlights the role of ML models in identifying high-risk patients and supporting personalized interventions, demonstrating the potential of data-driven analytics to improve TBI care and integrate into clinical workflows.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "L. Steinmetz et al.",
      "keywords": "Traumatic brain injury; Machine learning; Artificial intelligence; Psychology; Medicine; Physical medicine and rehabilitation; Computer science; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.20300",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4301886615",
      "doi": "10.48550/arxiv.1602.00374",
      "title": "ConfidentCare: A Clinical Decision Support System for Personalized\\n Breast Cancer Screening",
      "abstract": "Breast cancer screening policies attempt to achieve timely diagnosis by the\\nregular screening of apparently healthy women. Various clinical decisions are\\nneeded to manage the screening process; those include: selecting the screening\\ntests for a woman to take, interpreting the test outcomes, and deciding whether\\nor not a woman should be referred to a diagnostic test. Such decisions are\\ncurrently guided by clinical practice guidelines (CPGs), which represent a\\none-size-fits-all approach that are designed to work well on average for a\\npopulation, without guaranteeing that it will work well uniformly over that\\npopulation. Since the risks and benefits of screening are functions of each\\npatients features, personalized screening policies that are tailored to the\\nfeatures of individuals are needed in order to ensure that the right tests are\\nrecommended to the right woman. In order to address this issue, we present\\nConfidentCare: a computer-aided clinical decision support system that learns a\\npersonalized screening policy from the electronic health record (EHR) data.\\nConfidentCare operates by recognizing clusters of similar patients, and\\nlearning the best screening policy to adopt for each cluster. A cluster of\\npatients is a set of patients with similar features (e.g. age, breast density,\\nfamily history, etc.), and the screening policy is a set of guidelines on what\\nactions to recommend for a woman given her features and screening test scores.\\nConfidentCare algorithm ensures that the policy adopted for every cluster of\\npatients satisfies a predefined accuracy requirement with a high level of\\nconfidence. We show that our algorithm outperforms the current CPGs in terms of\\ncost-efficiency and false positive rates.\\n",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Ahmed M. Alaa et al.",
      "keywords": "Test (biology); Set (abstract data type); Breast cancer screening; Medicine; Population; Breast cancer; Clinical decision support system; Cluster (spacecraft); Cancer screening; Personalized medicine; Screening test; Computer science; Family medicine; Decision support system; Mammography; Artificial intelligence; Cancer; Bioinformatics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1602.00374",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415135904",
      "doi": "10.48550/arxiv.2506.03068",
      "title": "Causal Explainability of Machine Learning in Heart Failure Prediction from Electronic Health Records",
      "abstract": "The importance of clinical variables in the prognosis of the disease is explained using statistical correlation or machine learning (ML). However, the predictive importance of these variables may not represent their causal relationships with diseases. This paper uses clinical variables from a heart failure (HF) patient cohort to investigate the causal explainability of important variables obtained in statistical and ML contexts. Due to inherent regression modeling, popular causal discovery methods strictly assume that the cause and effect variables are numerical and continuous. This paper proposes a new computational framework to enable causal structure discovery (CSD) and score the causal strength of mixed-type (categorical, numerical, binary) clinical variables for binary disease outcomes. In HF classification, we investigate the association between the importance rank order of three feature types: correlated features, features important for ML predictions, and causal features. Our results demonstrate that CSD modeling for nonlinear causal relationships is more meaningful than its linear counterparts. Feature importance obtained from nonlinear classifiers (e.g., gradient-boosting trees) strongly correlates with the causal strength of variables without differentiating cause and effect variables. Correlated variables can be causal for HF, but they are rarely identified as effect variables. These results can be used to add the causal explanation of variables important for ML-based prediction modeling.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Y. R. Hou et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.03068",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417172220",
      "doi": "10.48550/arxiv.2504.20908",
      "title": "MOSIC: Model-Agnostic Optimal Subgroup Identification with Multi-Constraint for Improved Reliability",
      "abstract": "Current subgroup identification methods typically follow a two-step approach: first estimate conditional average treatment effects and then apply thresholding or rule-based procedures to define subgroups. While intuitive, this decoupled approach fails to incorporate key constraints essential for real-world clinical decision-making, such as subgroup size and propensity overlap. These constraints operate on fundamentally different axes than CATE estimation and are not naturally accommodated within existing frameworks, thereby limiting the practical applicability of these methods. We propose a unified optimization framework that directly solves the primal constrained optimization problem to identify optimal subgroups. Our key innovation is a reformulation of the constrained primal problem as an unconstrained differentiable min-max objective, solved via a gradient descent-ascent algorithm. We theoretically establish that our solution converges to a feasible and locally optimal solution. Unlike threshold-based CATE methods that apply constraints as post-hoc filters, our approach enforces them directly during optimization. The framework is model-agnostic, compatible with a wide range of CATE estimators, and extensible to additional constraints like cost limits or fairness criteria. Extensive experiments on synthetic and real-world datasets demonstrate its effectiveness in identifying high-benefit subgroups while maintaining better satisfaction of constraints.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Wenxin Chen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.20908",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4406030928",
      "doi": "10.48550/arxiv.2501.00190",
      "title": "SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction",
      "abstract": "Sepsis is an organ dysfunction caused by a deregulated immune response to an infection. Early sepsis prediction and identification allow for timely intervention, leading to improved clinical outcomes. Clinical calculators (e.g., the six-organ dysfunction assessment of SOFA) play a vital role in sepsis identification within clinicians' workflow, providing evidence-based risk assessments essential for sepsis diagnosis. However, artificial intelligence (AI) sepsis prediction models typically generate a single sepsis risk score without incorporating clinical calculators for assessing organ dysfunctions, making the models less convincing and transparent to clinicians. To bridge the gap, we propose to mimic clinicians' workflow with a novel framework SepsisCalc to integrate clinical calculators into the predictive model, yielding a clinically transparent and precise model for utilization in clinical settings. Practically, clinical calculators usually combine information from multiple component variables in Electronic Health Records (EHR), and might not be applicable when the variables are (partially) missing. We mitigate this issue by representing EHRs as temporal graphs and integrating a learning module to dynamically add the accurately estimated calculator to the graphs. Experimental results on real-world datasets show that the proposed model outperforms state-of-the-art methods on sepsis prediction tasks. Moreover, we developed a system to identify organ dysfunctions and potential sepsis risks, providing a human-AI interaction tool for deployment, which can help clinicians understand the prediction outputs and prepare timely interventions for the corresponding dysfunctions, paving the way for actionable clinical decision-making support for early intervention.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Changchang Yin et al.",
      "keywords": "Computer science; Graph; Sepsis; Data science; Medicine; Theoretical computer science; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2501.00190",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287865954",
      "doi": "10.48550/arxiv.2002.08627",
      "title": "A Comprehensive Scoping Review of Bayesian Networks in Healthcare: Past,\\n Present and Future",
      "abstract": "No comprehensive review of Bayesian networks (BNs) in healthcare has been\\npublished in the past, making it difficult to organize the research\\ncontributions in the present and identify challenges and neglected areas that\\nneed to be addressed in the future. This unique and novel scoping review of BNs\\nin healthcare provides an analytical framework for comprehensively\\ncharacterizing the domain and its current state. The review shows that: (1) BNs\\nin healthcare are not used to their full potential; (2) a generic BN\\ndevelopment process is lacking; (3) limitations exists in the way BNs in\\nhealthcare are presented in the literature, which impacts understanding,\\nconsensus towards systematic methodologies, practice and adoption of BNs; and\\n(4) a gap exists between having an accurate BN and a useful BN that impacts\\nclinical practice. This review empowers researchers and clinicians with an\\nanalytical framework and findings that will enable understanding of the need to\\naddress the problems of restricted aims of BNs, ad hoc BN development methods,\\nand the lack of BN adoption in practice. To map the way forward, the paper\\nproposes future research directions and makes recommendations regarding BN\\ndevelopment methods and adoption in practice.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Evangelia Kyrimi et al.",
      "keywords": "Health care; Bayesian network; Computer science; Process (computing); Management science; Domain (mathematical analysis); Data science; Knowledge management; Risk analysis (engineering); Artificial intelligence; Medicine; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2002.08627",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414587193",
      "doi": "10.48550/arxiv.2505.19785",
      "title": "medDreamer: Model-Based Reinforcement Learning with Latent Imagination on Complex EHRs for Clinical Decision Support",
      "abstract": "Timely and personalized treatment decisions are essential across a wide range of healthcare settings where patient responses can vary significantly and evolve over time. Clinical data used to support these treatment decisions are often irregularly sampled, where missing data frequencies may implicitly convey information about the patient's condition. Existing Reinforcement Learning (RL) based clinical decision support systems often ignore the missing patterns and distort them with coarse discretization and simple imputation. They are also predominantly model-free and largely depend on retrospective data, which could lead to insufficient exploration and bias by historical behaviors. To address these limitations, we propose medDreamer, a novel model-based reinforcement learning framework for personalized treatment recommendation. medDreamer contains a world model with an Adaptive Feature Integration module that simulates latent patient states from irregular data and a two-phase policy trained on a hybrid of real and imagined trajectories. This enables learning optimal policies that go beyond the sub-optimality of historical clinical decisions, while remaining close to real clinical data. We evaluate medDreamer on both sepsis and mechanical ventilation treatment tasks using two large-scale Electronic Health Records (EHRs) datasets. Comprehensive evaluations show that medDreamer significantly outperforms model-free and model-based baselines in both clinical outcomes and off-policy metrics.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Qianyi Xu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.19785",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4306884575",
      "doi": "10.48550/arxiv.2210.08016",
      "title": "Prediction of drug effectiveness in rheumatoid arthritis patients based on machine learning algorithms",
      "abstract": "Rheumatoid arthritis (RA) is an autoimmune condition caused when patients' immune system mistakenly targets their own tissue. Machine learning (ML) has the potential to identify patterns in patient electronic health records (EHR) to forecast the best clinical treatment to improve patient outcomes. This study introduced a Drug Response Prediction (DRP) framework with two main goals: 1) design a data processing pipeline to extract information from tabular clinical data, and then preprocess it for functional use, and 2) predict RA patient's responses to drugs and evaluate classification models' performance. We propose a novel two-stage ML framework based on European Alliance of Associations for Rheumatology (EULAR) criteria cutoffs to model drug effectiveness. Our model Stacked-Ensemble DRP was developed and cross-validated using data from 425 RA patients. The evaluation used a subset of 124 patients (30%) from the same data source. In the evaluation of the test set, two-stage DRP leads to improved classification accuracy over other end-to-end classification models for binary classification. Our proposed method provides a complete pipeline to predict disease activity scores and identify the group that does not respond well to anti-TNF treatments, thus showing promise in supporting clinical decisions based on EHR information.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Shengjia Chen et al.",
      "keywords": "Machine learning; Rheumatoid arthritis; Pipeline (software); Medicine; Artificial intelligence; Support vector machine; Stage (stratigraphy); Binary classification; Computer science; Algorithm; Data mining; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.08016",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415200263",
      "doi": "10.48550/arxiv.2505.10360",
      "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation",
      "abstract": "There are now a multitude of AI-scribing solutions for healthcare promising the utilization of large language models for ambient documentation. However, these AI scribes still rely on one-shot, or few-shot prompts for generating notes after the consultation has ended, employing little to no reasoning. This risks long notes with an increase in hallucinations, misrepresentation of the intent of the clinician, and reliance on the proofreading of the clinician to catch errors. A dangerous combination for patient safety if vigilance is compromised by workload and fatigue. In this paper, we introduce a method for extracting salient clinical information in real-time alongside the healthcare consultation, denoted Facts, and use that information recursively to generate the final note. The FactsR method results in more accurate and concise notes by placing the clinician-in-the-loop of note generation, while opening up new use cases within real-time decision support.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Vibeke Hansen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.10360",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3007718448",
      "doi": "10.48550/arxiv.2003.00655",
      "title": "Uncertainty-Gated Stochastic Sequential Model for EHR Mortality Prediction",
      "abstract": "Electronic health records (EHR) are characterized as non-stationary, heterogeneous, noisy, and sparse data; therefore, it is challenging to learn the regularities or patterns inherent within them. In particular, sparseness caused mostly by many missing values has attracted the attention of researchers, who have attempted to find a better use of all available samples for determining the solution of a primary target task through the defining a secondary imputation problem. Methodologically, existing methods, either deterministic or stochastic, have applied different assumptions to impute missing values. However, once the missing values are imputed, most existing methods do not consider the fidelity or confidence of the imputed values in the modeling of downstream tasks. Undoubtedly, an erroneous or improper imputation of missing variables can cause difficulties in modeling as well as a degraded performance. In this study, we present a novel variational recurrent network that (i) estimates the distribution of missing variables allowing to represent uncertainty in the imputed values, (ii) updates hidden states by explicitly applying fidelity based on a variance of the imputed values during a recurrence (i.e., uncertainty propagation over time), and (iii) predicts the possibility of in-hospital mortality. It is noteworthy that our model can conduct these procedures in a single stream and learn all network parameters jointly in an end-to-end manner. We validated the effectiveness of our method using the public datasets of MIMIC-III and PhysioNet challenge 2012 by comparing with and outperforming other state-of-the-art methods for mortality prediction considered in our experiments. In addition, we identified the behavior of the model that well represented the uncertainties for the imputed estimates, which indicated a high correlation between the calculated MAE and the uncertainty.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Eunji Jun et al.",
      "keywords": "Imputation (statistics); Missing data; Computer science; Fidelity; Variance (accounting); Data mining; Machine learning; Statistics; Artificial intelligence; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2003.00655",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4324297978",
      "doi": "10.48550/arxiv.2303.07067",
      "title": "Cross-device Federated Learning for Mobile Health Diagnostics: A First Study on COVID-19 Detection",
      "abstract": "Federated learning (FL) aided health diagnostic models can incorporate data from a large number of personal edge devices (e.g., mobile phones) while keeping the data local to the originating devices, largely ensuring privacy. However, such a cross-device FL approach for health diagnostics still imposes many challenges due to both local data imbalance (as extreme as local data consists of a single disease class) and global data imbalance (the disease prevalence is generally low in a population). Since the federated server has no access to data distribution information, it is not trivial to solve the imbalance issue towards an unbiased model. In this paper, we propose FedLoss, a novel cross-device FL framework for health diagnostics. Here the federated server averages the models trained on edge devices according to the predictive loss on the local data, rather than using only the number of samples as weights. As the predictive loss better quantifies the data distribution at a device, FedLoss alleviates the impact of data imbalance. Through a real-world dataset on respiratory sound and symptom-based COVID-$19$ detection task, we validate the superiority of FedLoss. It achieves competitive COVID-$19$ detection performance compared to a centralised model with an AUC-ROC of $79\\%$. It also outperforms the state-of-the-art FL baselines in sensitivity and convergence speed. Our work not only demonstrates the promise of federated COVID-$19$ detection but also paves the way to a plethora of mobile health model development in a privacy-preserving fashion.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xia Tong et al.",
      "keywords": "Computer science; Mobile device; Coronavirus disease 2019 (COVID-19); Crowdsensing; Enhanced Data Rates for GSM Evolution; Population; Edge device; Convergence (economics); Data mining; Machine learning; Artificial intelligence; Computer security; Disease; Cloud computing; Medicine; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.07067",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393026943",
      "doi": "10.48550/arxiv.2403.12090",
      "title": "Foundation Models and Information Retrieval in Digital Pathology",
      "abstract": "The paper reviews the state-of-the-art of foundation models, LLMs, generative AI, information retrieval and CBIR in digital pathology",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Hamid R. Tizhoosh",
      "keywords": "Foundation (evidence); Digital pathology; Information retrieval; Computer science; Data science; Artificial intelligence; History; Archaeology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.12090",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387994988",
      "doi": "10.48550/arxiv.2310.16936",
      "title": "Diagnosing Alzheimer's Disease using Early-Late Multimodal Data Fusion with Jacobian Maps",
      "abstract": "Alzheimer's disease (AD) is a prevalent and debilitating neurodegenerative disorder impacting a large aging population. Detecting AD in all its presymptomatic and symptomatic stages is crucial for early intervention and treatment. An active research direction is to explore machine learning methods that harness multimodal data fusion to outperform human inspection of medical scans. However, existing multimodal fusion models have limitations, including redundant computation, complex architecture, and simplistic handling of missing data. Moreover, the preprocessing pipelines of medical scans remain inadequately detailed and are seldom optimized for individual subjects. In this paper, we propose an efficient early-late fusion (ELF) approach, which leverages a convolutional neural network for automated feature extraction and random forests for their competitive performance on small datasets. Additionally, we introduce a robust preprocessing pipeline that adapts to the unique characteristics of individual subjects and makes use of whole brain images rather than slices or patches. Moreover, to tackle the challenge of detecting subtle changes in brain volume, we transform images into the Jacobian domain (JD) to enhance both accuracy and robustness in our classification. Using MRI and CT images from the OASIS-3 dataset, our experiments demonstrate the effectiveness of the ELF approach in classifying AD into four stages with an accuracy of 97.19%.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yasmine Mustafa et al.",
      "keywords": "Computer science; Preprocessor; Artificial intelligence; Robustness (evolution); Convolutional neural network; Random forest; Feature extraction; Machine learning; Deep learning; Population; Sensor fusion; Pattern recognition (psychology); Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.16936",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396945568",
      "doi": "10.48550/arxiv.2405.08373",
      "title": "PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles",
      "abstract": "This paper describes our approach to the MEDIQA-CORR shared task, which involves error detection and correction in clinical notes curated by medical professionals. This task involves handling three subtasks: detecting the presence of errors, identifying the specific sentence containing the error, and correcting it. Through our work, we aim to assess the capabilities of Large Language Models (LLMs) trained on a vast corpora of internet data that contain both factual and unreliable information. We propose to comprehensively address all subtasks together, and suggest employing a unique prompt-based in-context learning strategy. We will evaluate its efficacy in this specialized task demanding a combination of general reasoning and medical knowledge. In medical systems where prediction errors can have grave consequences, we propose leveraging self-consistency and ensemble methods to enhance error correction and error detection performance.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Satya Kesav Gundabathula et al.",
      "keywords": "Categorization; Natural language processing; Computer science; Artificial intelligence; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.08373",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4290646586",
      "doi": "10.48550/arxiv.1605.02948",
      "title": "Different approaches for identifying important concepts in probabilistic\\n biomedical text summarization",
      "abstract": "Automatic text summarization tools help users in biomedical domain to acquire\\ntheir intended information from various textual resources more efficiently.\\nSome of the biomedical text summarization systems put the basis of their\\nsentence selection approach on the frequency of concepts extracted from the\\ninput text. However, it seems that exploring other measures rather than the\\nfrequency for identifying the valuable content of the input document, and\\nconsidering the correlations existing between concepts may be more useful for\\nthis type of summarization. In this paper, we describe a Bayesian summarizer\\nfor biomedical text documents. The Bayesian summarizer initially maps the input\\ntext to the Unified Medical Language System (UMLS) concepts, then it selects\\nthe important ones to be used as classification features. We introduce\\ndifferent feature selection approaches to identify the most important concepts\\nof the text and to select the most informative content according to the\\ndistribution of these concepts. We show that with the use of an appropriate\\nfeature selection approach, the Bayesian biomedical summarizer can improve the\\nperformance of summarization. We perform extensive evaluations on a corpus of\\nscientific papers in biomedical domain. The results show that the Bayesian\\nsummarizer outperforms the biomedical summarizers that rely on the frequency of\\nconcepts, the domain-independent and baseline methods based on the\\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics. Moreover,\\nthe results suggest that using the meaningfulness measure and considering the\\ncorrelations of concepts in the feature selection step lead to a significant\\nincrease in the performance of summarization.\\n",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Milad Moradi et al.",
      "keywords": "Automatic summarization; Computer science; Selection (genetic algorithm); Domain (mathematical analysis); Natural language processing; Feature selection; Artificial intelligence; Information retrieval; Unified Medical Language System; Multi-document summarization; Feature (linguistics); Sentence; Bayesian probability; Probabilistic logic; Linguistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1605.02948",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400335115",
      "doi": "10.48550/arxiv.2407.01004",
      "title": "CURLS: Causal Rule Learning for Subgroups with Significant Treatment Effect",
      "abstract": "In causal inference, estimating heterogeneous treatment effects (HTE) is critical for identifying how different subgroups respond to interventions, with broad applications in fields such as precision medicine and personalized advertising. Although HTE estimation methods aim to improve accuracy, how to provide explicit subgroup descriptions remains unclear, hindering data interpretation and strategic intervention management. In this paper, we propose CURLS, a novel rule learning method leveraging HTE, which can effectively describe subgroups with significant treatment effects. Specifically, we frame causal rule learning as a discrete optimization problem, finely balancing treatment effect with variance and considering the rule interpretability. We design an iterative procedure based on the minorize-maximization algorithm and solve a submodular lower bound as an approximation for the original. Quantitative experiments and qualitative case studies verify that compared with state-of-the-art methods, CURLS can find subgroups where the estimated and true effects are 16.1% and 13.8% higher and the variance is 12.0% smaller, while maintaining similar or better estimation accuracy and rule interpretability. Code is available at https://osf.io/zwp2k/.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiehui Zhou et al.",
      "keywords": "Psychology; Econometrics; Cognitive psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.01004",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385292123",
      "doi": "10.48550/arxiv.2307.13219",
      "title": "A Primer on the Data Cleaning Pipeline",
      "abstract": "The availability of both structured and unstructured databases, such as electronic health data, social media data, patent data, and surveys that are often updated in real time, among others, has grown rapidly over the past decade. With this expansion, the statistical and methodological questions around data integration, or rather merging multiple data sources, has also grown. Specifically, the science of the ``data cleaning pipeline'' contains four stages that allow an analyst to perform downstream tasks, predictive analyses, or statistical analyses on ``cleaned data.'' This article provides a review of this emerging field, introducing technical terminology and commonly used methods.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Rebecca C. Steorts",
      "keywords": "Terminology; Pipeline (software); Data science; Computer science; Field (mathematics); Downstream (manufacturing); Data mining; Database; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.13219",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4288562841",
      "doi": "10.48550/arxiv.1902.08935",
      "title": "Non-compliance and missing data in health economic evaluation",
      "abstract": "Health economic evaluations face the issues of non-compliance and missing data. Here, non-compliance is defined as non-adherence to a specific treatment, and occurs within randomised controlled trials (RCTs) when participants depart from their random assignment. Missing data arises if, for example, there is loss to follow-up, survey non-response, or the information available from routine data sources is incomplete. Appropriate statistical methods for handling non-compliance and missing data have been developed, but they have rarely been applied in health economics studies. Here, we illustrate the issues and outline some of the appropriate methods to handle these with an application to a health economic evaluation that uses data from an RCT. In an RCT the random assignment can be used as an instrument for treatment receipt, to obtain consistent estimates of the complier average causal effect, provided the underlying assumptions are met. Instrumental variable methods can accommodate essential features of the health economic context such as the correlation between individuals' costs and outcomes in cost-effectiveness studies. Methodological guidance for handling missing data encourages approaches such as multiple imputation or inverse probability weighting, that assume the data are Missing At Random, but also sensitivity analyses that recognise the data may be missing according to the true, unobserved values, that is, Missing Not at Random. Future studies should subject the assumptions behind methods for handling non-compliance and missing data to thorough sensitivity analyses. Modern machine learning methods can help reduce reliance on correct model specification. Further research is required to develop flexible methods for handling more complex forms of non-compliance and missing data.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Karla D\u00edaz-Ordaz et al.",
      "keywords": "Missing data; Inverse probability weighting; Imputation (statistics); Weighting; Receipt; Context (archaeology); Computer science; Randomized experiment; Econometrics; Data mining; Statistics; Medicine; Machine learning; Propensity score matching; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1902.08935",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297578175",
      "doi": "10.48550/arxiv.2201.12936",
      "title": "Pigeonhole Design: Balancing Sequential Experiments from an Online Matching Perspective",
      "abstract": "Practitioners and academics have long appreciated the benefits of covariate balancing when they conduct randomized experiments. For web-facing firms running online A/B tests, however, it still remains challenging in balancing covariate information when experimental subjects arrive sequentially. In this paper, we study an online experimental design problem, which we refer to as the \"Online Blocking Problem.\" In this problem, experimental subjects with heterogeneous covariate information arrive sequentially and must be immediately assigned into either the control or the treated group. The objective is to minimize the total discrepancy, which is defined as the minimum weight perfect matching between the two groups. To solve this problem, we propose a randomized design of experiment, which we refer to as the \"Pigeonhole Design.\" The pigeonhole design first partitions the covariate space into smaller spaces, which we refer to as pigeonholes, and then, when the experimental subjects arrive at each pigeonhole, balances the number of control and treated subjects for each pigeonhole. We analyze the theoretical performance of the pigeonhole design and show its effectiveness by comparing against two well-known benchmark designs: the match-pair design and the completely randomized design. We identify scenarios when the pigeonhole design demonstrates more benefits over the benchmark design. To conclude, we conduct extensive simulations using Yahoo! data to show a 10.2% reduction in variance if we use the pigeonhole design to estimate the average treatment effect.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Jinglong Zhao et al.",
      "keywords": "Pigeonhole principle; Matching (statistics); Covariate; Benchmark (surveying); Computer science; Variance (accounting); Control (management); Mathematical optimization; Mathematics; Statistics; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2201.12936",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416453488",
      "doi": "10.48550/arxiv.2505.16931",
      "title": "PIIvot: A Lightweight NLP Anonymization Framework for Question-Anchored Tutoring Dialogues",
      "abstract": "Personally identifiable information (PII) anonymization is a high-stakes task that poses a barrier to many open-science data sharing initiatives. While PII identification has made large strides in recent years, in practice, error thresholds and the recall/precision trade-off still limit the uptake of these anonymization pipelines. We present PIIvot, a lighter-weight framework for PII anonymization that leverages knowledge of the data context to simplify the PII detection problem. To demonstrate its effectiveness, we also contribute QATD-2k, the largest open-source real-world tutoring dataset of its kind, to support the demand for quality educational dialogue data.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Matthew Zent et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.16931",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4383175857",
      "doi": "10.48550/arxiv.2307.00190",
      "title": "Estimands in Real-World Evidence Studies",
      "abstract": "A Real-World Evidence (RWE) Scientific Working Group (SWG) of the American Statistical Association Biopharmaceutical Section (ASA BIOP) has been reviewing statistical considerations for the generation of RWE to support regulatory decision-making. As part of the effort, the working group is addressing estimands in RWE studies. Constructing the right estimand -- the target of estimation -- which reflects the research question and the study objective, is one of the key components in formulating a clinical study. ICH E9(R1) describes statistical principles for constructing estimands in clinical trials with a focus on five attributes -- population, treatment, endpoints, intercurrent events, and population-level summary. However, defining estimands for clinical studies using real-world data (RWD), i.e., RWE studies, requires additional considerations due to, for example, heterogeneity of study population, complexity of treatment regimes, different types and patterns of intercurrent events, and complexities in choosing study endpoints. This paper reviews the essential components of estimands and causal inference framework, discusses considerations in constructing estimands for RWE studies, highlights similarities and differences in traditional clinical trial and RWE study estimands, and provides a roadmap for choosing appropriate estimands for RWE studies.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie Chen et al.",
      "keywords": "Statistical inference; Causal inference; Inference; Population; Clinical trial; Biopharmaceutical; Management science; Computer science; Actuarial science; Econometrics; Medicine; Business; Economics; Statistics; Artificial intelligence; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2307.00190",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4327810455",
      "doi": "10.48550/arxiv.2303.09007",
      "title": "Machine Learning for Flow Cytometry Data Analysis",
      "abstract": "Flow cytometry mainly used for detecting the characteristics of a number of biochemical substances based on the expression of specific markers in cells. It is particularly useful for detecting membrane surface receptors, antigens, ions, or during DNA/RNA expression. Not only can it be employed as a biomedical research tool for recognising distinctive types of cells in mixed populations, but it can also be used as a diagnostic tool for classifying abnormal cell populations connected with disease. Modern flow cytometers can rapidly analyse tens of thousands of cells at the same time while also measuring multiple parameters from a single cell. However, the rapid development of flow cytometers makes it challenging for conventional analysis methods to interpret flow cytometry data. Researchers need to be able to distinguish interesting-looking cell populations manually in multi-dimensional data collected from millions of cells. Thus, it is essential to find a robust approach for analysing flow cytometry data automatically, specifically in identifying cell populations automatically. This thesis mainly concerns discover the potential shortcoming of current automated-gating algorithms in both real datasets and synthetic datasets. Three representative automated clustering algorithms are selected to be applied, compared and evaluated by completely and partially automated gating. A subspace clustering ProClus also implemented in this thesis. The performance of ProClus in flow cytometry is not well, but it is still a useful algorithm to detect noise.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Yanhua Xu",
      "keywords": "Cluster analysis; Flow cytometry; Computer science; Noise (video); Data mining; Pattern recognition (psychology); Cytometry; Artificial intelligence; Flow (mathematics); Gating; Expression (computer science); Computational biology; Biology; Mathematics; Immunology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.09007",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287207044",
      "doi": "10.48550/arxiv.2104.09091",
      "title": "Strategies for Democratization of Supercomputing: Availability, Accessibility and Usability of High Performance Computing for Education and Practice of Big Data Analytics",
      "abstract": "There has been an increasing interest in and growing need for high performance computing (HPC), popularly known as supercomputing, in domains such as textual analytics, business domains analytics, forecasting and natural language processing (NLP), in addition to the relatively mature supercomputing domains of quantum physics and biology. HPC has been widely used in computer science (CS) and other traditionally computation intensive disciplines, but has remained largely siloed away from the vast array of social, behavioral, business and economics disciplines. However, with ubiquitous big data, there is a compelling need to make HPC technologically and economically accessible, easy to use, and operationally democratized. Therefore, this research focuses on making two key contributions, the first is the articulation of strategies based on availability, accessibility and usability for the demystification and democratization of HPC, based on an analytical review of Caliburn, a notable supercomputer at its inception. The second contribution is a set of principles for HPC adoption based on an experiential narrative of HPC usage for textual analytics and NLP of social media data from a first time user perspective. Both, the HPC usage process and the output of the early stage analytics are summarized. This research study synthesizes expert input on HPC democratization strategies, and chronicles the challenges and opportunities from a multidisciplinary perspective, of a case of rapid adoption of supercomputing for textual analytics and NLP. Deductive logic is used to identify strategies which can lead to efficacious engagement, adoption, production and sustained usage for research, teaching, application and innovation by researchers, faculty, professionals and students across a broad range of disciplines.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Jim Samuel et al.",
      "keywords": "Supercomputer; Computer science; Analytics; Data science; Usability; Big data; Cognitive computing; Democratization; Cognition; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2104.09091",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395443295",
      "doi": "10.48550/arxiv.2404.14689",
      "title": "Interpretable Prediction and Feature Selection for Survival Analysis",
      "abstract": "Survival analysis is widely used as a technique to model time-to-event data when some data is censored, particularly in healthcare for predicting future patient risk. In such settings, survival models must be both accurate and interpretable so that users (such as doctors) can trust the model and understand model predictions. While most literature focuses on discrimination, interpretability is equally as important. A successful interpretable model should be able to describe how changing each feature impacts the outcome, and should only use a small number of features. In this paper, we present DyS (pronounced ``dice''), a new survival analysis model that achieves both strong discrimination and interpretability. DyS is a feature-sparse Generalized Additive Model, combining feature selection and interpretable prediction into one model. While DyS works well for all survival analysis problems, it is particularly useful for large (in $n$ and $p$) survival datasets such as those commonly found in observational healthcare studies. Empirical studies show that DyS competes with other state-of-the-art machine learning models for survival analysis, while being highly interpretable.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Mike Van Ness et al.",
      "keywords": "Feature selection; Feature (linguistics); Selection (genetic algorithm); Computer science; Artificial intelligence; Machine learning; Statistics; Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.14689",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287774121",
      "doi": "10.48550/arxiv.2006.00073",
      "title": "Infectious Disease Forecasting for Public Health",
      "abstract": "Forecasting transmission of infectious diseases, especially for vector-borne diseases, poses unique challenges for researchers. Behaviors of and interactions between viruses, vectors, hosts, and the environment each play a part in determining the transmission of a disease. Public health surveillance systems and other sources provide valuable data that can be used to accurately forecast disease incidence. However, many aspects of common infectious disease surveillance data are imperfect: cases may be reported with a delay or in some cases not at all, data on vectors may not be available, and case data may not be available at high geographical or temporal resolution. In the face of these challenges, researchers must make assumptions to either account for these underlying processes in a mechanistic model or to justify their exclusion altogether in a statistical model. Whether a model is mechanistic or statistical, researchers should evaluate their model using accepted best practices from the emerging field of infectious disease forecasting while adopting conventions from other fields that have been developing forecasting methods for decades. Accounting for assumptions and properly evaluating models will allow researchers to generate forecasts that have the potential to provide valuable insights for public health officials. This chapter provides a background to the practice of forecasting in general, discusses the biological and statistical models used for infectious disease forecasting, presents technical details about making and evaluating forecasting models, and explores the issues in communicating forecasting results in a public health context.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Stephen A. Lauer et al.",
      "keywords": "Infectious disease (medical specialty); Data science; Computer science; Public health; Context (archaeology); Disease; Risk analysis (engineering); Imperfect; Field (mathematics); Statistical model; Management science; Artificial intelligence; Geography; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2006.00073",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4306893387",
      "doi": "10.48550/arxiv.2210.09894",
      "title": "Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches and Future Directions",
      "abstract": "Abstractive dialogue summarization is to generate a concise and fluent summary covering the salient information in a dialogue among two or more interlocutors. It has attracted great attention in recent years based on the massive emergence of social communication platforms and an urgent requirement for efficient dialogue information understanding and digestion. Different from news or articles in traditional document summarization, dialogues bring unique characteristics and additional challenges, including different language styles and formats, scattered information, flexible discourse structures and unclear topic boundaries. This survey provides a comprehensive investigation on existing work for abstractive dialogue summarization from scenarios, approaches to evaluations. It categorizes the task into two broad categories according to the type of input dialogues, i.e., open-domain and task-oriented, and presents a taxonomy of existing techniques in three directions, namely, injecting dialogue features, designing auxiliary training tasks and using additional data.A list of datasets under different scenarios and widely-accepted evaluation metrics are summarized for completeness. After that, the trends of scenarios and techniques are summarized, together with deep insights on correlations between extensively exploited features and different scenarios. Based on these analyses, we recommend future directions including more controlled and complicated scenarios, technical innovations and comparisons, publicly available datasets in special domains, etc.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Qi Jia et al.",
      "keywords": "Automatic summarization; Computer science; Salient; Taxonomy (biology); Task (project management); Data science; Domain (mathematical analysis); Information retrieval; Artificial intelligence; Natural language processing; Systems engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.09894",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4409738291",
      "doi": "10.48550/arxiv.2504.02285",
      "title": "Tree-based Models for Vertical Federated Learning: A Survey",
      "abstract": "Tree-based models have achieved great success in a wide range of real-world applications due to their effectiveness, robustness, and interpretability, which inspired people to apply them in vertical federated learning (VFL) scenarios in recent years. In this paper, we conduct a comprehensive study to give an overall picture of applying tree-based models in VFL, from the perspective of their communication and computation protocols. We categorize tree-based models in VFL into two types, i.e., feature-gathering models and label-scattering models, and provide a detailed discussion regarding their characteristics, advantages, privacy protection mechanisms, and applications. This study also focuses on the implementation of tree-based models in VFL, summarizing several design principles for better satisfying various requirements from both academic research and industrial deployment. We conduct a series of experiments to provide empirical observations on the differences and advances of different types of tree-based models.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Bingchen Qian et al.",
      "keywords": "Tree (set theory); Computer science; Forestry; Geography; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.02285",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4327525863",
      "doi": "10.48550/arxiv.2303.07862",
      "title": "An Evidence-based Roadmap for IoT Software Systems Engineering",
      "abstract": "Context: The Internet of Things (IoT) has brought expectations for software inclusion in everyday objects. However, it has challenges and requires multidisciplinary technical knowledge involving different areas that should be combined to enable IoT software systems engineering. Goal: To present an evidence-based roadmap for IoT development to support developers in specifying, designing, and implementing IoT systems. Method: An iterative approach based on experimental studies to acquire evidence to define the IoT Roadmap. Next, the Systems Engineering Body of Knowledge life cycle was used to organize the roadmap and set temporal dimensions for IoT software systems engineering. Results: The studies revealed seven IoT Facets influencing IoT development. The IoT Roadmap comprises 117 items organized into 29 categories representing different concerns for each Facet. In addition, an experimental study was conducted observing a real case of a healthcare IoT project, indicating the roadmap applicability. Conclusions: The IoT Roadmap can be a feasible instrument to assist IoT software systems engineering because it can (a) support researchers and practitioners in understanding and characterizing the IoT and (b) provide a checklist to identify the applicable recommendations for engineering IoT software systems.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Rebeca Campos Motta et al.",
      "keywords": "Internet of Things; Computer science; Context (archaeology); Software engineering; Multidisciplinary approach; Software; Systems engineering; Engineering management; Engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.07862",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4224939691",
      "doi": "10.48550/arxiv.2204.11716",
      "title": "Masked Image Modeling Advances 3D Medical Image Analysis",
      "abstract": "Recently, masked image modeling (MIM) has gained considerable attention due to its capacity to learn from vast amounts of unlabeled data and has been demonstrated to be effective on a wide variety of vision tasks involving natural images. Meanwhile, the potential of self-supervised learning in modeling 3D medical images is anticipated to be immense due to the high quantities of unlabeled images, and the expense and difficulty of quality labels. However, MIM's applicability to medical images remains uncertain. In this paper, we demonstrate that masked image modeling approaches can also advance 3D medical images analysis in addition to natural images. We study how masked image modeling strategies leverage performance from the viewpoints of 3D medical image segmentation as a representative downstream task: i) when compared to naive contrastive learning, masked image modeling approaches accelerate the convergence of supervised training even faster (1.40$\\times$) and ultimately produce a higher dice score; ii) predicting raw voxel values with a high masking ratio and a relatively smaller patch size is non-trivial self-supervised pretext-task for medical images modeling; iii) a lightweight decoder or projection head design for reconstruction is powerful for masked image modeling on 3D medical images which speeds up training and reduce cost; iv) finally, we also investigate the effectiveness of MIM methods under different practical scenarios where different image resolutions and labeled data ratios are applied.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Zekai Chen et al.",
      "keywords": "Computer science; Artificial intelligence; Leverage (statistics); Segmentation; Computer vision; Image (mathematics); Task (project management); Image segmentation; Medical imaging; Voxel; Pattern recognition (psychology); Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.11716",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415158886",
      "doi": "10.48550/arxiv.2504.09967",
      "title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data",
      "abstract": "The emergence of medical generalist foundation models has revolutionized conventional task-specific model development paradigms, aiming to better handle multiple tasks through joint training on large-scale medical datasets. However, recent advances prioritize simple data scaling or architectural component enhancement, while neglecting to re-examine multi-task learning from a data-centric perspective. Critically, simply aggregating existing data resources leads to decentralized image-task alignment, which fails to cultivate comprehensive image understanding or align with clinical needs for multi-dimensional image interpretation. In this paper, we introduce the image-centric multi-annotation X-ray dataset (IMAX), the first attempt to enhance the multi-task learning capabilities of medical multi-modal large language models (MLLMs) from the data construction level. To be specific, IMAX is featured from the following attributes: 1) High-quality data curation. A comprehensive collection of more than 354K entries applicable to seven different medical tasks. 2) Image-centric dense annotation. Each X-ray image is associated with an average of 4.10 tasks and 7.46 training entries, ensuring multi-task representation richness per image. Compared to the general decentralized multi-annotation X-ray dataset (DMAX), IMAX consistently demonstrates significant multi-task average performance gains ranging from 3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs. Moreover, we investigate differences in statistical patterns exhibited by IMAX and DMAX training processes, exploring potential correlations between optimization dynamics and multi-task performance. Finally, leveraging the core concept of IMAX data construction, we propose an optimized DMAX-based training strategy to alleviate the dilemma of obtaining high-quality IMAX data in practical scenarios.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Xun Zhu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.09967",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3204950554",
      "doi": "10.48550/arxiv.2101.05224",
      "title": "Big Self-Supervised Models Advance Medical Image Classification",
      "abstract": "Self-supervised pretraining followed by supervised fine-tuning has seen success in image recognition, especially when labeled examples are scarce, but has received limited attention in medical image analysis. This paper studies the effectiveness of self-supervised learning as a pretraining strategy for medical image classification. We conduct experiments on two distinct tasks: dermatology skin condition classification from digital camera images and multi-label chest X-ray classification, and demonstrate that self-supervised learning on ImageNet, followed by additional self-supervised learning on unlabeled domain-specific medical images significantly improves the accuracy of medical image classifiers. We introduce a novel Multi-Instance Contrastive Learning (MICLe) method that uses multiple images of the underlying pathology per patient case, when available, to construct more informative positive pairs for self-supervised learning. Combining our contributions, we achieve an improvement of 6.7% in top-1 accuracy and an improvement of 1.1% in mean AUC on dermatology and chest X-ray classification respectively, outperforming strong supervised baselines pretrained on ImageNet. In addition, we show that big self-supervised models are robust to distribution shift and can learn efficiently with a small number of labeled medical images.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Shekoofeh Azizi et al.",
      "keywords": "Artificial intelligence; Computer science; Supervised learning; Semi-supervised learning; Machine learning; Pattern recognition (psychology); Construct (python library); Contextual image classification; Image (mathematics); Medical imaging; Deep learning; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.48550/arxiv.2101.05224",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3163935534",
      "doi": "10.48550/arxiv.2105.07495",
      "title": "Capsule GAN for Prostate MRI Super-Resolution",
      "abstract": "Prostate cancer is a very common disease among adult men. One in seven Canadian men is diagnosed with this cancer in their lifetime. Super-Resolution (SR) can facilitate early diagnosis and potentially save many lives. In this paper, a robust and accurate model is proposed for prostate MRI SR. The model is trained on the Prostate-Diagnosis and PROSTATEx datasets. The proposed model outperformed the state-of-the-art prostate SR model in all similarity metrics with notable margins. A new task-specific similarity assessment is introduced as well. A classifier is trained for severe cancer detection and the drop in the accuracy of this model when dealing with super-resolved images is used for evaluating the ability of medical detail reconstruction of the SR models. The proposed SR model is a step towards an efficient and accurate general medical SR platform.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Mahdiyar Molahasani Majdabadi et al.",
      "keywords": "Prostate cancer; Classifier (UML); Prostate; Computer science; Similarity (geometry); Artificial intelligence; High resolution; Medical physics; Medicine; Machine learning; Cancer; Internal medicine; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2105.07495",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2963466151",
      "doi": "10.48550/arxiv.1611.08373",
      "title": "Bidirectional LSTM-CRF for Clinical Concept Extraction",
      "abstract": "Automated extraction of concepts from patient clinical records is an essential facilitator of clinical research. For this reason, the 2010 i2b2/VA Natural Language Processing Challenges for Clinical Records introduced a concept extraction task aimed at identifying and classifying concepts into predefined categories (i.e., treatments, tests and problems). State-of-the-art concept extraction approaches heavily rely on handcrafted features and domain-specific resources which are hard to collect and define. For this reason, this paper proposes an alternative, streamlined approach: a recurrent neural network (the bidirectional LSTM with CRF decoding) initialized with general-purpose, off-the-shelf word embeddings. The experimental results achieved on the 2010 i2b2/VA reference corpora using the proposed framework outperform all recent methods and ranks closely to the best submission from the original 2010 i2b2/VA challenge.",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Raghavendra Chalapathy et al.",
      "keywords": "Computer science; Task (project management); Facilitator; Natural language processing; Artificial intelligence; Recurrent neural network; Word (group theory); Decoding methods; Domain (mathematical analysis); F1 score; Machine learning; Artificial neural network; Linguistics; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.48550/arxiv.1611.08373",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W1799078166",
      "doi": "10.48550/arxiv.1503.01190",
      "title": "Statistical modality tagging from rule-based annotations and crowdsourcing",
      "abstract": "We explore training an automatic modality tagger. Modality is the attitude that a speaker might have toward an event or state. One of the main hurdles for training a linguistic tagger is gathering training data. This is particularly problematic for training a tagger for modality because modality triggers are sparse for the overwhelming majority of sentences. We investigate an approach to automatically training a modality tagger where we first gathered sentences based on a high-recall simple rule-based modality tagger and then provided these sentences to Mechanical Turk annotators for further annotation. We used the resulting set of training data to train a precise modality tagger using a multi-class SVM that delivers good performance.",
      "year": "2015",
      "journal": "arXiv (Cornell University)",
      "authors": "Vinodkumar Prabhakaran et al.",
      "keywords": "Modality (human\u2013computer interaction); Computer science; Natural language processing; Artificial intelligence; Set (abstract data type); Training set; Annotation; Crowdsourcing; Class (philosophy); Conjunction (astronomy); World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.48550/arxiv.1503.01190",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388481772",
      "doi": "10.48550/arxiv.2311.02205",
      "title": "An Introduction to Natural Language Processing Techniques and Framework for Clinical Implementation in Radiation Oncology",
      "abstract": "Natural Language Processing (NLP) is a key technique for developing Medical Artificial Intelligence (AI) systems that leverage Electronic Health Record (EHR) data to build diagnostic and prognostic models. NLP enables the conversion of unstructured clinical text into structured data that can be fed into AI algorithms. The emergence of the transformer architecture and large language models (LLMs) has led to remarkable advances in NLP for various healthcare tasks, such as entity recognition, relation extraction, sentence similarity, text summarization, and question answering. In this article, we review the major technical innovations that underpin modern NLP models and present state-of-the-art NLP applications that employ LLMs in radiation oncology research. However, these LLMs are prone to many errors such as hallucinations, biases, and ethical violations, which necessitate rigorous evaluation and validation before clinical deployment. As such, we propose a comprehensive framework for assessing the NLP models based on their purpose and clinical fit, technical performance, bias and trust, legal and ethical implications, and quality assurance, prior to implementation in clinical radiation oncology. Our article aims to provide guidance and insights for researchers and clinicians who are interested in developing and using NLP models in clinical radiation oncology.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Reza Khanmohammadi et al.",
      "keywords": "Artificial intelligence; Computer science; Automatic summarization; Leverage (statistics); Natural language processing; Named-entity recognition; Data science; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.02205",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4367623619",
      "doi": "10.48550/arxiv.2304.14516",
      "title": "pyBibX -- A Python Library for Bibliometric and Scientometric Analysis Powered with Artificial Intelligence Tools",
      "abstract": "Bibliometric and Scientometric analyses offer invaluable perspectives on the complex research terrain and collaborative dynamics spanning diverse academic disciplines. This paper presents pyBibX, a python library devised to conduct comprehensive bibliometric and scientometric analyses on raw data files sourced from Scopus, Web of Science, and PubMed, seamlessly integrating state of the art AI capabilities into its core functionality. The library executes a comprehensive EDA, presenting outcomes via visually appealing graphical illustrations. Network capabilities have been deftly integrated, encompassing Citation, Collaboration, and Similarity Analysis. Furthermore, the library incorporates AI capabilities, including Embedding vectors, Topic Modeling, Text Summarization, and other general Natural Language Processing tasks, employing models such as Sentence-BERT, BerTopic, BERT, chatGPT, and PEGASUS. As a demonstration, we have analyzed 184 documents associated with multiple-criteria decision analysis published between 1984 and 2023. The EDA emphasized a growing fascination with decision-making and fuzzy logic methodologies. Next, Network Analysis further accentuated the significance of central authors and intra-continental collaboration, identifying Canada and China as crucial collaboration hubs. Finally, AI Analysis distinguished two primary topics and chatGPT preeminence in Text Summarization. It also proved to be an indispensable instrument for interpreting results, as our library enables researchers to pose inquiries to chatGPT regarding bibliometric outcomes. Even so, data homogeneity remains a daunting challenge due to database inconsistencies. PyBibX is the first application integrating cutting-edge AI capabilities for analyzing scientific publications, enabling researchers to examine and interpret these outcomes more effectively.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Valdecy Pereira et al.",
      "keywords": "Automatic summarization; Computer science; Python (programming language); Data science; Scopus; Information retrieval; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.14516",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4225918920",
      "doi": "10.48550/arxiv.2201.09873",
      "title": "Transformers in Medical Imaging: A Survey",
      "abstract": "Following unprecedented success on the natural language tasks, Transformers have been successfully applied to several computer vision problems, achieving state-of-the-art results and prompting researchers to reconsider the supremacy of convolutional neural networks (CNNs) as {de facto} operators. Capitalizing on these advances in computer vision, the medical imaging field has also witnessed growing interest for Transformers that can capture global context compared to CNNs with local receptive fields. Inspired from this transition, in this survey, we attempt to provide a comprehensive review of the applications of Transformers in medical imaging covering various aspects, ranging from recently proposed architectural designs to unsolved issues. Specifically, we survey the use of Transformers in medical image segmentation, detection, classification, reconstruction, synthesis, registration, clinical report generation, and other tasks. In particular, for each of these applications, we develop taxonomy, identify application-specific challenges as well as provide insights to solve them, and highlight recent trends. Further, we provide a critical discussion of the field's current state as a whole, including the identification of key challenges, open problems, and outlining promising future directions. We hope this survey will ignite further interest in the community and provide researchers with an up-to-date reference regarding applications of Transformer models in medical imaging. Finally, to cope with the rapid development in this field, we intend to regularly update the relevant latest papers and their open-source implementations at \\url{https://github.com/fahadshamshad/awesome-transformers-in-medical-imaging}.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Fahad Shamshad et al.",
      "keywords": "Computer science; Implementation; Data science; Medical imaging; Convolutional neural network; Transformer; Artificial intelligence; De facto; Software engineering; Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2201.09873",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391631243",
      "doi": "10.48550/arxiv.2402.01801",
      "title": "Large Language Models for Time Series: A Survey",
      "abstract": "Large Language Models (LLMs) have seen significant use in domains such as natural language processing and computer vision. Going beyond text, image and graphics, LLMs present a significant potential for analysis of time series data, benefiting domains such as climate, IoT, healthcare, traffic, audio and finance. This survey paper provides an in-depth exploration and a detailed taxonomy of the various methodologies employed to harness the power of LLMs for time series analysis. We address the inherent challenge of bridging the gap between LLMs' original text data training and the numerical nature of time series data, and explore strategies for transferring and distilling knowledge from LLMs to numerical time series analysis. We detail various methodologies, including (1) direct prompting of LLMs, (2) time series quantization, (3) aligning techniques, (4) utilization of the vision modality as a bridging mechanism, and (5) the combination of LLMs with tools. Additionally, this survey offers a comprehensive overview of the existing multimodal time series and text datasets and delves into the challenges and future opportunities of this emerging field. We maintain an up-to-date Github repository which includes all the papers and datasets discussed in the survey.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiyuan Zhang et al.",
      "keywords": "Series (stratigraphy); Computer science; Time series; Geology; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.01801",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4381714872",
      "doi": "10.48550/arxiv.2306.12420",
      "title": "LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models",
      "abstract": "Foundation models have demonstrated a great ability to achieve general human-level intelligence far beyond traditional approaches. As the technique keeps attracting attention from the AI community, an increasing number of foundation models are becoming publicly accessible. However, a significant shortcoming of most of these models lies in their performance in specialized-domain and task-specific applications, necessitating domain- and task-aware fine-tuning to develop effective scientific language models. As the number of available foundation models and specialized tasks keeps growing, the job of training scientific language models becomes highly nontrivial. In this paper, we initiate steps to tackle this issue. We introduce an extensible and lightweight toolkit, LMFlow, which aims to simplify the domain- and task-aware finetuning of general foundation models. LMFlow offers a complete finetuning workflow for a foundation model to support specialized training with limited computing resources. Furthermore, it supports continuous pretraining, instruction tuning, parameter-efficient finetuning, alignment tuning, inference acceleration, long context generalization, model customization, and even multimodal finetuning, along with carefully designed and extensible APIs. This toolkit has been thoroughly tested and is available at https://github.com/OptimalScale/LMFlow.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shizhe Diao et al.",
      "keywords": "Computer science; Inference; Workflow; Foundation (evidence); Artificial intelligence; Task (project management); Machine learning; Software engineering; Database; Systems engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.12420",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3196232261",
      "doi": "10.48550/arxiv.1910.07419",
      "title": "Comprehend Medical: a Named Entity Recognition and Relationship\\n Extraction Web Service",
      "abstract": "Comprehend Medical is a stateless and Health Insurance Portability and\\nAccountability Act (HIPAA) eligible Named Entity Recognition (NER) and\\nRelationship Extraction (RE) service launched under Amazon Web Services (AWS)\\ntrained using state-of-the-art deep learning models. Contrary to many existing\\nopen source tools, Comprehend Medical is scalable and does not require steep\\nlearning curve, dependencies, pipeline configurations, or installations.\\nCurrently, Comprehend Medical performs NER in five medical categories: Anatomy,\\nMedical Condition, Medications, Protected Health Information (PHI) and\\nTreatment, Test and Procedure (TTP). Additionally, the service provides\\nrelationship extraction for the detected entities as well as contextual\\ninformation such as negation and temporality in the form of traits. Comprehend\\nMedical provides two Application Programming Interfaces (API): 1) the NERe API\\nwhich returns all the extracted named entities, their traits and the\\nrelationships between them and 2) the PHId API which returns just the protected\\nhealth information contained in the text. Furthermore, Comprehend Medical is\\naccessible through AWS Console, Java and Python Software Development Kit (SDK),\\nmaking it easier for non-developers and developers to use.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Parminder Bhatia et al.",
      "keywords": "Computer science; Health Insurance Portability and Accountability Act; Software portability; World Wide Web; JavaScript; Web service; Python (programming language); Java; Named-entity recognition; Cloud computing; Computer security; Programming language; Engineering; Operating system",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1910.07419",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4200632416",
      "doi": "10.48550/arxiv.2112.05596",
      "title": "Automated tabulation of clinical trial results: A joint entity and relation extraction approach with transformer-based language representations",
      "abstract": "Evidence-based medicine, the practice in which healthcare professionals refer to the best available evidence when making decisions, forms the foundation of modern healthcare. However, it relies on labour-intensive systematic reviews, where domain specialists must aggregate and extract information from thousands of publications, primarily of randomised controlled trial (RCT) results, into evidence tables. This paper investigates automating evidence table generation by decomposing the problem across two language processing tasks: \\textit{named entity recognition}, which identifies key entities within text, such as drug names, and \\textit{relation extraction}, which maps their relationships for separating them into ordered tuples. We focus on the automatic tabulation of sentences from published RCT abstracts that report the results of the study outcomes. Two deep neural net models were developed as part of a joint extraction pipeline, using the principles of transfer learning and transformer-based language representations. To train and test these models, a new gold-standard corpus was developed, comprising almost 600 result sentences from six disease areas. This approach demonstrated significant advantages, with our system performing well across multiple natural language processing tasks and disease areas, as well as in generalising to disease domains unseen during training. Furthermore, we show these results were achievable through training our models on as few as 200 example sentences. The final system is a proof of concept that the generation of evidence tables can be semi-automated, representing a step towards fully automating systematic reviews.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Jetsun Whitton et al.",
      "keywords": "Computer science; Natural language processing; Relationship extraction; Transformer; Artificial intelligence; Tuple; Information extraction; Pipeline (software); Natural language; Table (database); Machine learning; Information retrieval; Data mining; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.05596",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4307313182",
      "doi": "10.48550/arxiv.2210.12770",
      "title": "Exploring the Value of Pre-trained Language Models for Clinical Named Entity Recognition",
      "abstract": "The practice of fine-tuning Pre-trained Language Models (PLMs) from general or domain-specific data to a specific task with limited resources, has gained popularity within the field of natural language processing (NLP). In this work, we re-visit this assumption and carry out an investigation in clinical NLP, specifically Named Entity Recognition on drugs and their related attributes. We compare Transformer models that are trained from scratch to fine-tuned BERT-based LLMs namely BERT, BioBERT, and ClinicalBERT. Furthermore, we examine the impact of an additional CRF layer on such models to encourage contextual learning. We use n2c2-2018 shared task data for model development and evaluations. The experimental outcomes show that 1) CRF layers improved all language models; 2) referring to BIO-strict span level evaluation using macro-average F1 score, although the fine-tuned LLMs achieved 0.83+ scores, the TransformerCRF model trained from scratch achieved 0.78+, demonstrating comparable performances with much lower cost - e.g. with 39.80\\% less training parameters; 3) referring to BIO-strict span-level evaluation using weighted-average F1 score, ClinicalBERT-CRF, BERT-CRF, and TransformerCRF exhibited lower score differences, with 97.59\\%/97.44\\%/96.84\\% respectively. 4) applying efficient training by down-sampling for better data distribution further reduced the training cost and need for data, while maintaining similar scores - i.e. around 0.02 points lower compared to using the full dataset. Our models will be hosted at \\url{https://github.com/HECTA-UoM/TransformerCRF}",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuping Wu et al.",
      "keywords": "Computer science; Named-entity recognition; Popularity; F1 score; Natural language processing; Artificial intelligence; Task (project management); Language model; Machine learning; Transformer; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.12770",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4404313963",
      "doi": "10.48550/arxiv.2410.20266",
      "title": "Limitations of the LLM-as-a-Judge Approach for Evaluating LLM Outputs in Expert Knowledge Tasks",
      "abstract": "The potential of using Large Language Models (LLMs) themselves to evaluate LLM outputs offers a promising method for assessing model performance across various contexts. Previous research indicates that LLM-as-a-judge exhibits a strong correlation with human judges in the context of general instruction following. However, for instructions that require specialized knowledge, the validity of using LLMs as judges remains uncertain. In our study, we applied a mixed-methods approach, conducting pairwise comparisons in which both subject matter experts (SMEs) and LLMs evaluated outputs from domain-specific tasks. We focused on two distinct fields: dietetics, with registered dietitian experts, and mental health, with clinical psychologist experts. Our results showed that SMEs agreed with LLM judges 68% of the time in the dietetics domain and 64% in mental health when evaluating overall preference. Additionally, the results indicated variations in SME-LLM agreement across domain-specific aspect questions. Our findings emphasize the importance of keeping human experts in the evaluation process, as LLMs alone may not provide the depth of understanding required for complex, knowledge specific tasks. We also explore the implications of LLM evaluations across different domains and discuss how these insights can inform the design of evaluation workflows that ensure better alignment between human experts and LLMs in interactive systems.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Annalisa Szymanski et al.",
      "keywords": "Computer science; Psychology; Engineering ethics; Management science; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.20266",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394838929",
      "doi": "10.48550/arxiv.2404.08359",
      "title": "Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval",
      "abstract": "In today's digital world, seeking answers to health questions on the Internet is a common practice. However, existing question answering (QA) systems often rely on using pre-selected and annotated evidence documents, thus making them inadequate for addressing novel questions. Our study focuses on the open-domain QA setting, where the key challenge is to first uncover relevant evidence in large knowledge bases. By utilizing the common retrieve-then-read QA pipeline and PubMed as a trustworthy collection of medical research documents, we answer health questions from three diverse datasets. We modify different retrieval settings to observe their influence on the QA pipeline's performance, including the number of retrieved documents, sentence selection process, the publication year of articles, and their number of citations. Our results reveal that cutting down on the amount of retrieved documents and favoring more recent and highly cited documents can improve the final macro F1 score up to 10%. We discuss the results, highlight interesting examples, and outline challenges for future research, like managing evidence disagreement and crafting user-friendly explanations.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Juraj Vladika et al.",
      "keywords": "Computer science; Pipeline (software); Question answering; Information retrieval; Sentence; Selection (genetic algorithm); Process (computing); Domain (mathematical analysis); The Internet; Trustworthiness; Data science; World Wide Web; Natural language processing; Artificial intelligence; Internet privacy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.08359",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399597520",
      "doi": "10.48550/arxiv.2406.06636",
      "title": "LLM Questionnaire Completion for Automatic Psychiatric Assessment",
      "abstract": "We employ a Large Language Model (LLM) to convert unstructured psychological interviews into structured questionnaires spanning various psychiatric and personality domains. The LLM is prompted to answer these questionnaires by impersonating the interviewee. The obtained answers are coded as features, which are used to predict standardized psychiatric measures of depression (PHQ-8) and PTSD (PCL-C), using a Random Forest regressor. Our approach is shown to enhance diagnostic accuracy compared to multiple baselines. It thus establishes a novel framework for interpreting unstructured psychological interviews, bridging the gap between narrative-driven and data-driven approaches for mental health assessment.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Gony Rosenman et al.",
      "keywords": "Psychology; Psychiatry; Completion (oil and gas wells); Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.06636",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394710902",
      "doi": "10.48550/arxiv.2404.06503",
      "title": "Comparing Two Model Designs for Clinical Note Generation; Is an LLM a Useful Evaluator of Consistency?",
      "abstract": "Following an interaction with a patient, physicians are responsible for the submission of clinical documentation, often organized as a SOAP note. A clinical note is not simply a summary of the conversation but requires the use of appropriate medical terminology. The relevant information can then be extracted and organized according to the structure of the SOAP note. In this paper we analyze two different approaches to generate the different sections of a SOAP note based on the audio recording of the conversation, and specifically examine them in terms of note consistency. The first approach generates the sections independently, while the second method generates them all together. In this work we make use of PEGASUS-X Transformer models and observe that both methods lead to similar ROUGE values (less than 1% difference) and have no difference in terms of the Factuality metric. We perform a human evaluation to measure aspects of consistency and demonstrate that LLMs like Llama2 can be used to perform the same tasks with roughly the same agreement as the human annotators. Between the Llama2 analysis and the human reviewers we observe a Cohen Kappa inter-rater reliability of 0.79, 1.00, and 0.32 for consistency of age, gender, and body part injury, respectively. With this we demonstrate the usefulness of leveraging an LLM to measure quality indicators that can be identified by humans but are not currently captured by automatic metrics. This allows scaling evaluation to larger data sets, and we find that clinical note consistency improves by generating each new section conditioned on the output of all previously generated sections.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Nathan Brake et al.",
      "keywords": "Consistency (knowledge bases); Computer science; Econometrics; Reliability engineering; Artificial intelligence; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.06503",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399597223",
      "doi": "10.48550/arxiv.2406.06558",
      "title": "Enhancing Text Authenticity: A Novel Hybrid Approach for AI-Generated Text Detection",
      "abstract": "The rapid advancement of Large Language Models (LLMs) has ushered in an era where AI-generated text is increasingly indistinguishable from human-generated content. Detecting AI-generated text has become imperative to combat misinformation, ensure content authenticity, and safeguard against malicious uses of AI. In this paper, we propose a novel hybrid approach that combines traditional TF-IDF techniques with advanced machine learning models, including Bayesian classifiers, Stochastic Gradient Descent (SGD), Categorical Gradient Boosting (CatBoost), and 12 instances of Deberta-v3-large models. Our approach aims to address the challenges associated with detecting AI-generated text by leveraging the strengths of both traditional feature extraction methods and state-of-the-art deep learning models. Through extensive experiments on a comprehensive dataset, we demonstrate the effectiveness of our proposed method in accurately distinguishing between human and AI-generated text. Our approach achieves superior performance compared to existing methods. This research contributes to the advancement of AI-generated text detection techniques and lays the foundation for developing robust solutions to mitigate the challenges posed by AI-generated content.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ye Zhang et al.",
      "keywords": "Computer science; Natural language processing; Artificial intelligence; Information retrieval",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.06558",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399794583",
      "doi": "10.48550/arxiv.2406.10833",
      "title": "A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery",
      "abstract": "In many scientific fields, large language models (LLMs) have revolutionized the way text and other modalities of data (e.g., molecules and proteins) are handled, achieving superior performance in various applications and augmenting the scientific discovery process. Nevertheless, previous surveys on scientific LLMs often concentrate on one or two fields or a single modality. In this paper, we aim to provide a more holistic view of the research landscape by unveiling cross-field and cross-modal connections between scientific LLMs regarding their architectures and pre-training techniques. To this end, we comprehensively survey over 260 scientific LLMs, discuss their commonalities and differences, as well as summarize pre-training datasets and evaluation tasks for each field and modality. Moreover, we investigate how LLMs have been deployed to benefit scientific discovery. Resources related to this survey are available at https://github.com/yuzhimanhua/Awesome-Scientific-Language-Models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yu Zhang et al.",
      "keywords": "Scientific discovery; Data science; Computer science; Psychology; Cognitive science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.10833",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4309201974",
      "doi": "10.48550/arxiv.2211.07837",
      "title": "An Ontology for the Social Determinants of Health Domain",
      "abstract": "Social determinants of health are societal factors, such as where a person was born, grew up, works, lives, etc, along with socioeconomic and community factors that affect individual health. Social Determinants of Health are correlated with many clinical outcomes, hence it is desirable to record SDOH data in Electronic Health Records (EHRs). Besides storing images, text, etc., EHRs rely on coded terms available in standard ontologies and terminologies to record observations and analyses. There is a substantial amount of research on understanding the clinical impact of SDOH, ranging from screening tools to practice based interventions. However, there is no comprehensive collection of terms for recording SDOH observations in EHRs. Our research goal is to develop an ontology that covers the terms describing SDOH. We present a prototype ontology called Social Determinant of Health Ontology (SOHO) that covers relevant concepts and IS--A relationships describing impacts and associations of social determinants. We describe the evaluation techniques that we applied to SOHO, including human experts review and algorithmic evaluation.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Navya Martin Kollapally et al.",
      "keywords": "Ontology; Social determinants of health; Socioeconomic status; Domain (mathematical analysis); Health records; Data science; Social ontology; Psychological intervention; Computer science; Political science; Public health; Medicine; Health care; Environmental health; Nursing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2211.07837",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399695450",
      "doi": "10.48550/arxiv.2406.08930",
      "title": "Efficient Multi-View Fusion and Flexible Adaptation to View Missing in Cardiovascular System Signals",
      "abstract": "The progression of deep learning and the widespread adoption of sensors have facilitated automatic multi-view fusion (MVF) about the cardiovascular system (CVS) signals. However, prevalent MVF model architecture often amalgamates CVS signals from the same temporal step but different views into a unified representation, disregarding the asynchronous nature of cardiovascular events and the inherent heterogeneity across views, leading to catastrophic view confusion. Efficient training strategies specifically tailored for MVF models to attain comprehensive representations need simultaneous consideration. Crucially, real-world data frequently arrives with incomplete views, an aspect rarely noticed by researchers. Thus, the View-Centric Transformer (VCT) and Multitask Masked Autoencoder (M2AE) are specifically designed to emphasize the centrality of each view and harness unlabeled data to achieve superior fused representations. Additionally, we systematically define the missing-view problem for the first time and introduce prompt techniques to aid pretrained MVF models in flexibly adapting to various missing-view scenarios. Rigorous experiments involving atrial fibrillation detection, blood pressure estimation, and sleep staging-typical health monitoring tasks-demonstrate the remarkable advantage of our method in MVF compared to prevailing methodologies. Notably, the prompt technique requires finetuning less than 3% of the entire model's data, substantially fortifying the model's resilience to view missing while circumventing the need for complete retraining. The results demonstrate the effectiveness of our approaches, highlighting their potential for practical applications in cardiovascular health monitoring. Codes and models are released at URL.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Qihan Hu et al.",
      "keywords": "Adaptation (eye); Fusion; Computer science; Sensor fusion; Artificial intelligence; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.08930",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386436384",
      "doi": "10.48550/arxiv.2309.00543",
      "title": "Curating Naturally Adversarial Datasets for Learning-Enabled Medical Cyber-Physical Systems",
      "abstract": "Deep learning models have shown promising predictive accuracy for time-series healthcare applications. However, ensuring the robustness of these models is vital for building trustworthy AI systems. Existing research predominantly focuses on robustness to synthetic adversarial examples, crafted by adding imperceptible perturbations to clean input data. However, these synthetic adversarial examples do not accurately reflect the most challenging real-world scenarios, especially in the context of healthcare data. Consequently, robustness to synthetic adversarial examples may not necessarily translate to robustness against naturally occurring adversarial examples, which is highly desirable for trustworthy AI. We propose a method to curate datasets comprised of natural adversarial examples to evaluate model robustness. The method relies on probabilistic labels obtained from automated weakly-supervised labeling that combines noisy and cheap-to-obtain labeling heuristics. Based on these labels, our method adversarially orders the input data and uses this ordering to construct a sequence of increasingly adversarial datasets. Our evaluation on six medical case studies and three non-medical case studies demonstrates the efficacy and statistical validity of our approach to generating naturally adversarial datasets",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Sydney Pugh et al.",
      "keywords": "Adversarial system; Robustness (evolution); Computer science; Artificial intelligence; Machine learning; Heuristics; Probabilistic logic; Trustworthiness; Synthetic data; Data mining; Data science; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.00543",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285563034",
      "doi": "10.48550/arxiv.2108.10808",
      "title": "Greenformers: Improving Computation and Memory Efficiency in Transformer Models via Low-Rank Approximation",
      "abstract": "In this thesis, we introduce Greenformers, a collection of model efficiency methods to improve the model efficiency of the recently renowned transformer models with a low-rank approximation approach. The development trend of deep learning models tends to results in a more complex and larger model. Although it leads to a better and more accurate prediction, the resulting model becomes even more costly, as it requires weeks of training with a huge amount of GPU resources. Particularly, the size and computational cost of transformer-based models have increased tremendously since its first debut in 2017 from ~100 million parameters up to ~1.6 trillion parameters in early 2021. This computationally hungry model also incurs a substantial cost to the environment and even reaches an alarming level of carbon footprint. Some of these models are so massive that it is even impossible to run the model without a GPU cluster. Greenformers improve the model efficiency of transformer models by applying low-rank approximation approaches. Specifically, we propose a low-rank factorization approach to improve the efficiency of the transformer model called Low-Rank Transformer. We further compare our model with an existing low-rank factorization approach called Linformer. Based on our analysis, the Low-Rank Transformer model is suitable for improving both the time and memory efficiency in processing short-sequence (&lt;= 512) input data, while the Linformer model is suitable for improving the efficiency in processing long-sequence input data (&gt;= 512). We also show that Low-Rank Transformer is more suitable for on-device deployment, as it significantly reduces the model size. Additionally, we estimate that applying LRT to the existing BERT-base model can significantly reduce the computational, economical, and environmental costs for developing such models by more than 30% of its original costs.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Samuel Cahyawijaya",
      "keywords": "Computer science; Transformer; Software deployment; Memory footprint; Computation; Factorization; Algorithm; Voltage; Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2108.10808",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4405622208",
      "doi": "10.48550/arxiv.2408.12128",
      "title": "Diffusion-Based Visual Art Creation: A Survey and New Perspectives",
      "abstract": "The integration of generative AI in visual art has revolutionized not only how visual content is created but also how AI interacts with and reflects the underlying domain knowledge. This survey explores the emerging realm of diffusion-based visual art creation, examining its development from both artistic and technical perspectives. We structure the survey into three phases, data feature and framework identification, detailed analyses using a structured coding process, and open-ended prospective outlooks. Our findings reveal how artistic requirements are transformed into technical challenges and highlight the design and application of diffusion-based methods within visual art creation. We also provide insights into future directions from technical and synergistic perspectives, suggesting that the confluence of generative AI and art has shifted the creative paradigm and opened up new possibilities. By summarizing the development and trends of this emerging interdisciplinary area, we aim to shed light on the mechanisms through which AI systems emulate and possibly, enhance human capacities in artistic perception and creativity.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Bingyuan Wang et al.",
      "keywords": "Diffusion; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.12128",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4404314493",
      "doi": "10.48550/arxiv.2410.20792",
      "title": "Deep Learning for Medical Text Processing: BERT Model Fine-Tuning and Comparative Study",
      "abstract": "This paper proposes a medical literature summary generation method based on the BERT model to address the challenges brought by the current explosion of medical information. By fine-tuning and optimizing the BERT model, we develop an efficient summary generation system that can quickly extract key information from medical literature and generate coherent, accurate summaries. In the experiment, we compared various models, including Seq-Seq, Attention, Transformer, and BERT, and demonstrated that the improved BERT model offers significant advantages in the Rouge and Recall metrics. Furthermore, the results of this study highlight the potential of knowledge distillation techniques to further enhance model performance. The system has demonstrated strong versatility and efficiency in practical applications, offering a reliable tool for the rapid screening and analysis of medical literature.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiacheng Hu et al.",
      "keywords": "Computer science; Artificial intelligence; Fine-tuning; Natural language processing; Deep learning; Data science; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.20792",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416118141",
      "doi": "10.48550/arxiv.2504.05020",
      "title": "Batch Aggregation: An Approach to Enhance Text Classification with Correlated Augmented Data",
      "abstract": "Natural language processing models often face challenges due to limited labeled data, especially in domain specific areas, e.g., clinical trials. To overcome this, text augmentation techniques are commonly used to increases sample size by transforming the original input data into artificial ones with the label preserved. However, traditional text classification methods ignores the relationship between augmented texts and treats them as independent samples which may introduce classification error. Therefore, we propose a novel approach called 'Batch Aggregation' (BAGG) which explicitly models the dependence of text inputs generated through augmentation by incorporating an additional layer that aggregates results from correlated texts. Through studying multiple benchmark data sets across different domains, we found that BAGG can improve classification accuracy. We also found that the increase of performance with BAGG is more obvious in domain specific data sets, with accuracy improvements of up to 10-29%. Through the analysis of benchmark data, the proposed method addresses limitations of traditional techniques and improves robustness in text classification tasks. Our result demonstrates that BAGG offers more robust results and outperforms traditional approaches when training data is limited.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Chi-kwong Hui et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.05020",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4327989645",
      "doi": "10.48550/arxiv.2303.09601",
      "title": "Psychotherapy AI Companion with Reinforcement Learning Recommendations and Interpretable Policy Dynamics",
      "abstract": "We introduce a Reinforcement Learning Psychotherapy AI Companion that generates topic recommendations for therapists based on patient responses. The system uses Deep Reinforcement Learning (DRL) to generate multi-objective policies for four different psychiatric conditions: anxiety, depression, schizophrenia, and suicidal cases. We present our experimental results on the accuracy of recommended topics using three different scales of working alliance ratings: task, bond, and goal. We show that the system is able to capture the real data (historical topics discussed by the therapists) relatively well, and that the best performing models vary by disorder and rating scale. To gain interpretable insights into the learned policies, we visualize policy trajectories in a 2D principal component analysis space and transition matrices. These visualizations reveal distinct patterns in the policies trained with different reward signals and trained on different clinical diagnoses. Our system's success in generating DIsorder-Specific Multi-Objective Policies (DISMOP) and interpretable policy dynamics demonstrates the potential of DRL in providing personalized and efficient therapeutic recommendations.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Baihan Lin et al.",
      "keywords": "Reinforcement learning; Task (project management); Artificial intelligence; Dynamics (music); Alliance; Psychology; Rating scale; Schizophrenia (object-oriented programming); Computer science; Anxiety; Cognitive psychology; Machine learning; Psychotherapist; Psychiatry; Developmental psychology; Management; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.09601",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400064409",
      "doi": "10.48550/arxiv.2406.16252",
      "title": "Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis",
      "abstract": "Health monitoring systems have revolutionized modern healthcare by enabling the continuous capture of physiological and behavioral data, essential for preventive measures and early health intervention. While integrating this data with Large Language Models (LLMs) has shown promise in delivering interactive health advice, traditional methods like Retrieval-Augmented Generation (RAG) and fine-tuning often fail to fully utilize the complex, multi-dimensional, and temporally relevant data from wearable devices. These conventional approaches typically provide limited actionable and personalized health insights due to their inadequate capacity to dynamically integrate and interpret diverse health data streams. In response, this paper introduces a graph-augmented LLM framework designed to significantly enhance the personalization and clarity of health insights. Utilizing a hierarchical graph structure, the framework captures inter and intra-patient relationships, enriching LLM prompts with dynamic feature importance scores derived from a Random Forest Model. The effectiveness of this approach is demonstrated through a sleep analysis case study involving 20 college students during the COVID-19 lockdown, highlighting the potential of our model to generate actionable and personalized health insights efficiently. We leverage another LLM to evaluate the insights for relevance, comprehensiveness, actionability, and personalization, addressing the critical need for models that process and interpret complex health data effectively. Our findings show that augmenting prompts with our framework yields significant improvements in all 4 criteria. Through our framework, we can elicit well-crafted, more thoughtful responses tailored to a specific patient.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ajan Subramanian et al.",
      "keywords": "Sleep (system call); Graph; Personalized medicine; Data science; Psychology; Medicine; Computer science; Bioinformatics; Theoretical computer science; Biology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.16252",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400375746",
      "doi": "10.48550/arxiv.2407.02723",
      "title": "e-Health CSIRO at \"Discharge Me!\" 2024: Generating Discharge Summary Sections with Fine-tuned Language Models",
      "abstract": "Clinical documentation is an important aspect of clinicians' daily work and often demands a significant amount of time. The BioNLP 2024 Shared Task on Streamlining Discharge Documentation (Discharge Me!) aims to alleviate this documentation burden by automatically generating discharge summary sections, including brief hospital course and discharge instruction, which are often time-consuming to synthesize and write manually. We approach the generation task by fine-tuning multiple open-sourced language models (LMs), including both decoder-only and encoder-decoder LMs, with various configurations on input context. We also examine different setups for decoding algorithms, model ensembling or merging, and model specialization. Our results show that conditioning on the content of discharge summary prior to the target sections is effective for the generation task. Furthermore, we find that smaller encoder-decoder LMs can work as well or even slightly better than larger decoder based LMs fine-tuned through LoRA. The model checkpoints from our team (aehrc) are openly available.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jinghui Liu et al.",
      "keywords": "Water discharge; Streamer discharge; Partial discharge; Environmental science; Geology; Engineering; Electrical engineering; Geotechnical engineering; Voltage",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.02723",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396606226",
      "doi": "10.48550/arxiv.2405.00321",
      "title": "DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data Perturbations and MinMax Training",
      "abstract": "The NLI4CT task at SemEval-2024 emphasizes the development of robust models for Natural Language Inference on Clinical Trial Reports (CTRs) using large language models (LLMs). This edition introduces interventions specifically targeting the numerical, vocabulary, and semantic aspects of CTRs. Our proposed system harnesses the capabilities of the state-of-the-art Mistral model, complemented by an auxiliary model, to focus on the intricate input space of the NLI4CT dataset. Through the incorporation of numerical and acronym-based perturbations to the data, we train a robust system capable of handling both semantic-altering and numerical contradiction interventions. Our analysis on the dataset sheds light on the challenging sections of the CTRs for reasoning.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Bhuvanesh Verma et al.",
      "keywords": "SemEval; Task (project management); Minimax; Artificial intelligence; Computer science; Natural language processing; Training set; Training (meteorology); Machine learning; Mathematics; Mathematical optimization; Economics; Geography; Management",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.00321",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417516775",
      "doi": "10.48550/arxiv.2505.07430",
      "title": "Comparative sentiment analysis of public perception: Monkeypox vs. COVID-19 behavioral insights",
      "abstract": "The emergence of global health crises, such as COVID-19 and Monkeypox (mpox), has underscored the importance of understanding public sentiment to inform effective public health strategies. This study conducts a comparative sentiment analysis of public perceptions surrounding COVID-19 and mpox by leveraging extensive datasets of 147,475 and 106,638 tweets, respectively. Advanced machine learning models, including Logistic Regression, Naive Bayes, RoBERTa, DistilRoBERTa and XLNet, were applied to perform sentiment classification, with results indicating key trends in public emotion and discourse. The analysis highlights significant differences in public sentiment driven by disease characteristics, media representation, and pandemic fatigue. Through the lens of sentiment polarity and thematic trends, this study offers valuable insights into tailoring public health messaging, mitigating misinformation, and fostering trust during concurrent health crises. The findings contribute to advancing sentiment analysis applications in public health informatics, setting the groundwork for enhanced real-time monitoring and multilingual analysis in future research.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Mostafa Mohaimen Akand Faisal et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07430",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403780427",
      "doi": "10.48550/arxiv.2409.14988",
      "title": "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs",
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in transforming clinical applications. In this study, we investigate the efficacy of four techniques in adapting LLMs for clinical use-cases: continuous pretraining, instruct fine-tuning, NEFTune, and prompt engineering. We employ these methods on Mistral 7B and Mixtral 8x7B models, leveraging a large-scale clinical pretraining dataset of 50 billion tokens and an instruct fine-tuning dataset of 500 million tokens. Our evaluation across various clinical tasks reveals the impact of each technique. While continuous pretraining beyond 250 billion tokens yields marginal improvements on its own, it establishes a strong foundation for instruct fine-tuning. Notably, NEFTune, designed primarily to enhance generation quality, surprisingly demonstrates additional gains on our benchmark. Complex prompt engineering methods further enhance performance. These findings show the importance of tailoring fine-tuning strategies and exploring innovative techniques to optimize LLM performance in the clinical domain.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Christophe Cl\u00e9ment et al.",
      "keywords": "Fine-tuning; Medicine; Business; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.14988",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414580846",
      "doi": "10.48550/arxiv.2505.16102",
      "title": "Continually Self-Improving Language Models for Bariatric Surgery Question--Answering",
      "abstract": "While bariatric and metabolic surgery (MBS) is considered the gold standard treatment for severe and morbid obesity, its therapeutic efficacy hinges upon active and longitudinal engagement with multidisciplinary providers, including surgeons, dietitians/nutritionists, psychologists, and endocrinologists. This engagement spans the entire patient journey, from preoperative preparation to long-term postoperative management. However, this process is often hindered by numerous healthcare disparities, such as logistical and access barriers, which impair easy patient access to timely, evidence-based, clinician-endorsed information. To address these gaps, we introduce bRAGgen, a novel adaptive retrieval-augmented generation (RAG)-based model that autonomously integrates real-time medical evidence when response confidence dips below dynamic thresholds. This self-updating architecture ensures that responses remain current and accurate, reducing the risk of misinformation. Additionally, we present bRAGq, a curated dataset of 1,302 bariatric surgery--related questions, validated by an expert bariatric surgeon. bRAGq constitutes the first large-scale, domain-specific benchmark for comprehensive MBS care. In a two-phase evaluation, bRAGgen is benchmarked against state-of-the-art models using both large language model (LLM)--based metrics and expert surgeon review. Across all evaluation dimensions, bRAGgen demonstrates substantially superior performance in generating clinically accurate and relevant responses.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yash Kumar Atri et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.16102",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297950329",
      "doi": "10.48550/arxiv.2209.13444",
      "title": "Design Perspectives of Multitask Deep Learning Models and Applications",
      "abstract": "In recent years, multi-task learning has turned out to be of great success in various applications. Though single model training has promised great results throughout these years, it ignores valuable information that might help us estimate a metric better. Under learning-related tasks, multi-task learning has been able to generalize the models even better. We try to enhance the feature mapping of the multi-tasking models by sharing features among related tasks and inductive transfer learning. Also, our interest is in learning the task relationships among various tasks for acquiring better benefits from multi-task learning. In this chapter, our objective is to visualize the existing multi-tasking models, compare their performances, the methods used to evaluate the performance of the multi-tasking models, discuss the problems faced during the design and implementation of these models in various domains, and the advantages and milestones achieved by them",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yeshwant Singh et al.",
      "keywords": "Multi-task learning; Computer science; Task (project management); Artificial intelligence; Machine learning; Transfer of learning; Feature (linguistics); Metric (unit); Deep learning; Human\u2013computer interaction; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.13444",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416118802",
      "doi": "10.48550/arxiv.2504.05227",
      "title": "A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?",
      "abstract": "Vision-language pre-training has recently gained popularity as it allows learning rich feature representations using large-scale data sources. This paradigm has quickly made its way into the medical image analysis community. In particular, there is an impressive amount of recent literature developing vision-language models for radiology. However, the available medical datasets with image-text supervision are scarce, and medical concepts are fine-grained, involving expert knowledge that existing vision-language models struggle to encode. In this paper, we propose to take a prudent step back from the literature and revisit supervised, unimodal pre-training, using fine-grained labels instead. We conduct an extensive comparison demonstrating that unimodal pre-training is highly competitive and better suited to integrating heterogeneous data sources. Our results also question the potential of recent vision-language models for open-vocabulary generalization, which have been evaluated using optimistic experimental settings. Finally, we study novel alternatives to better integrate fine-grained labels and noisy text supervision.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Julio Silva-Rodr\u00edguez et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.05227",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387226199",
      "doi": "10.48550/arxiv.2309.16656",
      "title": "Visual In-Context Learning for Few-Shot Eczema Segmentation",
      "abstract": "Automated diagnosis of eczema from digital camera images is crucial for developing applications that allow patients to self-monitor their recovery. An important component of this is the segmentation of eczema region from such images. Current methods for eczema segmentation rely on deep neural networks such as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While effective, these methods require high volume of annotated data, which can be difficult to obtain. Here, we investigate the capabilities of visual in-context learning that can perform few-shot eczema segmentation with just a handful of examples and without any need for retraining models. Specifically, we propose a strategy for applying in-context learning for eczema segmentation with a generalist vision model called SegGPT. When benchmarked on a dataset of annotated eczema images, we show that SegGPT with just 2 representative example images from the training dataset performs better (mIoU: 36.69) than a CNN U-Net trained on 428 images (mIoU: 32.60). We also discover that using more number of examples for SegGPT may in fact be harmful to its performance. Our result highlights the importance of visual in-context learning in developing faster and better solutions to skin imaging tasks. Our result also paves the way for developing inclusive solutions that can cater to minorities in the demographics who are typically heavily under-represented in the training data.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Neelesh Kumar et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Convolutional neural network; Deep learning; Context (archaeology); Machine learning; Image segmentation; Market segmentation; Retraining; Pattern recognition (psychology); Computer vision; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2309.16656",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416012379",
      "doi": "10.48550/arxiv.2505.04152",
      "title": "Can Language Models Understand Social Behavior in Clinical Conversations?",
      "abstract": "Effective communication between providers and their patients influences health and care outcomes. The effectiveness of such conversations has been linked not only to the exchange of clinical information, but also to a range of interpersonal behaviors; commonly referred to as social signals, which are often conveyed through non-verbal cues and shape the quality of the patient-provider relationship. Recent advances in large language models (LLMs) have demonstrated an increasing ability to infer emotional and social behaviors even when analyzing only textual information. As automation increases also in clinical settings, such as for transcription of patient-provider conversations, there is growing potential for LLMs to automatically analyze and extract social behaviors from these interactions. To explore the foundational capabilities of LLMs in tracking social signals in clinical dialogue, we designed task-specific prompts and evaluated model performance across multiple architectures and prompting styles using a highly imbalanced, annotated dataset spanning 20 distinct social signals such as provider dominance, patient warmth, etc. We present the first system capable of tracking all these 20 coded signals, and uncover patterns in LLM behavior. Further analysis of model configurations and clinical context provides insights for enhancing LLM performance on social signal processing tasks in healthcare settings.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Manas Satish Bedmutha et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.04152",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396650764",
      "doi": "10.48550/arxiv.2405.00948",
      "title": "Modeling Empathetic Alignment in Conversation",
      "abstract": "Empathy requires perspective-taking: empathetic responses require a person to reason about what another has experienced and communicate that understanding in language. However, most NLP approaches to empathy do not explicitly model this alignment process. Here, we introduce a new approach to recognizing alignment in empathetic speech, grounded in Appraisal Theory. We introduce a new dataset of over 9.2K span-level annotations of different types of appraisals of a person's experience and over 3K empathetic alignments between a speaker's and observer's speech. Through computational experiments, we show that these appraisals and alignments can be accurately recognized. In experiments in over 9.2M Reddit conversations, we find that appraisals capture meaningful groupings of behavior but that most responses have minimal alignment. However, we find that mental health professionals engage with substantially more empathetic alignment.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiamin Yang et al.",
      "keywords": "Conversation; Psychology; Computer science; Cognitive science; Linguistics; Communication; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.00948",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388684471",
      "doi": "10.48550/arxiv.2311.06300",
      "title": "AI Chatbot for Generating Episodic Future Thinking (EFT) Cue Texts for Health",
      "abstract": "We describe an AI-powered chatbot to aid with health improvement by generating Episodic Future Thinking (EFT) cue texts that should reduce delay discounting. In prior studies, EFT has been shown to address maladaptive health behaviors. Those studies involved participants, working with researchers, vividly imagining future events, and writing a description that they subsequently will frequently review, to ensure a shift from an inclination towards immediate rewards. That should promote behavior change, aiding in health tasks such as treatment adherence and lifestyle modifications. The AI chatbot is designed to guide users in generating personalized EFTs, automating the current labor-intensive interview-based process. This can enhance the efficiency of EFT interventions and make them more accessible, targeting specifically those with limited educational backgrounds or communication challenges. By leveraging AI for EFT intervention, we anticipate broadened access and improved health outcomes across diverse populations",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Sareh Ahmadi et al.",
      "keywords": "Chatbot; Psychological intervention; Intervention (counseling); Process (computing); Computer science; Psychology; Knowledge management; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.06300",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391800891",
      "doi": "10.48550/arxiv.2402.07234",
      "title": "CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain",
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential and effectiveness across multiple application domains. To assess the performance of mainstream LLMs in public security tasks, this study aims to construct a specialized evaluation benchmark tailored to the Chinese public security domain--CPSDbench. CPSDbench integrates datasets related to public security collected from real-world scenarios, supporting a comprehensive assessment of LLMs across four key dimensions: text classification, information extraction, question answering, and text generation. Furthermore, this study introduces a set of innovative evaluation metrics designed to more precisely quantify the efficacy of LLMs in executing tasks related to public security. Through the in-depth analysis and evaluation conducted in this research, we not only enhance our understanding of the performance strengths and limitations of existing models in addressing public security issues but also provide references for the future development of more accurate and customized LLM models targeted at applications in this field.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Xin Tong et al.",
      "keywords": "Baseline (sea); Benchmark (surveying); Computer science; Public domain; Domain (mathematical analysis); Language model; Chinese language; Public security; Natural language processing; Artificial intelligence; Political science; Linguistics; Geography; Mathematics; Public relations; Cartography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.07234",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4286605101",
      "doi": "10.48550/arxiv.2106.06822",
      "title": "A Pseudo Label-wise Attention Network for Automatic ICD Coding",
      "abstract": "Automatic International Classification of Diseases (ICD) coding is defined as a kind of text multi-label classification problem, which is difficult because the number of labels is very large and the distribution of labels is unbalanced. The label-wise attention mechanism is widely used in automatic ICD coding because it can assign weights to every word in full Electronic Medical Records (EMR) for different ICD codes. However, the label-wise attention mechanism is computational redundant and costly. In this paper, we propose a pseudo label-wise attention mechanism to tackle the problem. Instead of computing different attention modes for different ICD codes, the pseudo label-wise attention mechanism automatically merges similar ICD codes and computes only one attention mode for the similar ICD codes, which greatly compresses the number of attention modes and improves the predicted accuracy. In addition, we apply a more convenient and effective way to obtain the ICD vectors, and thus our model can predict new ICD codes by calculating the similarities between EMR vectors and ICD vectors. Extensive experiments show the superior performance of our model. On the public MIMIC-III dataset and private Xiangya dataset, our model achieves micro f1 of 0.583 and 0.806, respectively, which outperforms other competing models. Furthermore, we verify the ability of our model in predicting new ICD codes. The case study shows how pseudo label-wise attention works, and demonstrates the effectiveness of pseudo label-wise attention mechanism.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Yifan Wu et al.",
      "keywords": "Computer science; Coding (social sciences); Mechanism (biology); Artificial intelligence; Data mining; ICD-10; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2106.06822",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415145303",
      "doi": "10.48550/arxiv.2505.19501",
      "title": "Toward Scientific Reasoning in LLMs: Training from Expert Discussions via Reinforcement Learning",
      "abstract": "We investigate how to teach large language models (LLMs) to perform scientific reasoning by leveraging expert discussions as a learning signal. Focusing on the genomics domain, we develop an automated pipeline to extract trainable data and introduce Genome-Bench, a new benchmark constructed from over a decade of scientific forum discussions on genome engineering. Our pipeline transforms raw interactions into a reinforcement learning-friendly multiple-choice questions format, supported by 3000+ high-quality question-answer pairs spanning foundational biology, experimental troubleshooting, tool usage, and beyond. We fine-tune an LLM using RL with a rule-based reward signal derived from the synthetic MCQ dataset to enhance domain-specific reasoning. Our results show that reinforcement learning from scientific discussions improves model performance by over 15% compared to the base model on Genome-Bench, narrowing the gap between open-source LLMs and expert-level reasoning. To our knowledge, this is the first end-to-end pipeline for teaching LLMs to reason from scientific discussions, with promising potential for generalization across scientific domains beyond biology.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Ming Yin et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.19501",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399454129",
      "doi": "10.48550/arxiv.2406.03699",
      "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
      "abstract": "There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high-stakes domains such as healthcare. Despite their popularity, there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it with presented information in the clinical and biomedical domain: a fundamental pre-requisite for success on down-stream tasks. Addressing this gap, we use Multiple Choice and Abstractive Question Answering to conduct a large-scale empirical study on 22 datasets in three generalist and three specialist biomedical sub-domains. Our multifaceted analysis of the performance of 15 LLMs, further broken down by sub-domain, source of knowledge and model architecture, uncovers success factors such as instruction tuning that lead to improved recall and comprehension. We further show that while recently proposed domain-adapted models may lack adequate knowledge, directly fine-tuning on our collected medical knowledge datasets shows encouraging results, even generalising to unseen specialist sub-domains. We complement the quantitative results with a skill-oriented manual error analysis, which reveals a significant gap between the models' capabilities to simply recall necessary knowledge and to integrate it with the presented context. To foster research and collaboration in this field we share M-QALM, our resources, standardised methodology, and evaluation results, with the research community to facilitate further advancements in clinical knowledge representation learning within language models.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Anand Subramanian et al.",
      "keywords": "Question answering; Recall; Benchmark (surveying); Computer science; Comprehension; Reading comprehension; Reading (process); Natural language processing; Language model; Artificial intelligence; Psychology; Linguistics; Cognitive psychology; Philosophy; Programming language; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.03699",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402346082",
      "doi": "10.48550/arxiv.2407.12826",
      "title": "Assessing the Effectiveness of GPT-4o in Climate Change Evidence Synthesis and Systematic Assessments: Preliminary Insights",
      "abstract": "In this research short, we examine the potential of using GPT-4o, a state-of-the-art large language model (LLM) to undertake evidence synthesis and systematic assessment tasks. Traditional workflows for such tasks involve large groups of domain experts who manually review and synthesize vast amounts of literature. The exponential growth of scientific literature and recent advances in LLMs provide an opportunity to complementing these traditional workflows with new age tools. We assess the efficacy of GPT-4o to do these tasks on a sample from the dataset created by the Global Adaptation Mapping Initiative (GAMI) where we check the accuracy of climate change adaptation related feature extraction from the scientific literature across three levels of expertise. Our results indicate that while GPT-4o can achieve high accuracy in low-expertise tasks like geographic location identification, their performance in intermediate and high-expertise tasks, such as stakeholder identification and assessment of depth of the adaptation response, is less reliable. The findings motivate the need for designing assessment workflows that utilize the strengths of models like GPT-4o while also providing refinements to improve their performance on these tasks.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Elphin Tom Joe et al.",
      "keywords": "Climate change; Systematic review; Environmental science; Environmental resource management; Political science; MEDLINE; Biology; Ecology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.12826",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4301400705",
      "doi": "10.48550/arxiv.2204.10080",
      "title": "Identifying and Characterizing Active Citizens who Refute Misinformation in Social Media",
      "abstract": "The phenomenon of misinformation spreading in social media has developed a new form of active citizens who focus on tackling the problem by refuting posts that might contain misinformation. Automatically identifying and characterizing the behavior of such active citizens in social media is an important task in computational social science for complementing studies in misinformation analysis. In this paper, we study this task across different social media platforms (i.e., Twitter and Weibo) and languages (i.e., English and Chinese) for the first time. To this end, (1) we develop and make publicly available a new dataset of Weibo users mapped into one of the two categories (i.e., misinformation posters or active citizens); (2) we evaluate a battery of supervised models on our new Weibo dataset and an existing Twitter dataset which we repurpose for the task; and (3) we present an extensive analysis of the differences in language use between the two user categories.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yida Mu et al.",
      "keywords": "Misinformation; Social media; Task (project management); Computer science; Focus (optics); Data science; Internet privacy; World Wide Web; Computer security; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.10080",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4402696887",
      "doi": "10.48550/arxiv.2408.11609",
      "title": "Xinyu: An Efficient LLM-based System for Commentary Generation",
      "abstract": "Commentary provides readers with a deep understanding of events by presenting diverse arguments and evidence. However, creating commentary is a time-consuming task, even for skilled commentators. Large language models (LLMs) have simplified the process of natural language generation, but their direct application in commentary creation still faces challenges due to unique task requirements. These requirements can be categorized into two levels: 1) fundamental requirements, which include creating well-structured and logically consistent narratives, and 2) advanced requirements, which involve generating quality arguments and providing convincing evidence. In this paper, we introduce Xinyu, an efficient LLM-based system designed to assist commentators in generating Chinese commentaries. To meet the fundamental requirements, we deconstruct the generation process into sequential steps, proposing targeted strategies and supervised fine-tuning (SFT) for each step. To address the advanced requirements, we present an argument ranking model for arguments and establish a comprehensive evidence database that includes up-to-date events and classic books, thereby strengthening the substantiation of the evidence with retrieval augmented generation (RAG) technology. To evaluate the generated commentaries more fairly, corresponding to the two-level requirements, we introduce a comprehensive evaluation metric that considers five distinct perspectives in commentary generation. Our experiments confirm the effectiveness of our proposed system. We also observe a significant increase in the efficiency of commentators in real-world scenarios, with the average time spent on creating a commentary dropping from 4 hours to 20 minutes. Importantly, such an increase in efficiency does not compromise the quality of the commentaries.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yiquan Wu et al.",
      "keywords": "Environmental science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.11609",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416047848",
      "doi": "10.48550/arxiv.2505.22137",
      "title": "Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments",
      "abstract": "Identifying arguments is a necessary prerequisite for various tasks in automated discourse analysis, particularly within contexts such as political debates, online discussions, and scientific reasoning. In addition to theoretical advances in understanding the constitution of arguments, a significant body of research has emerged around practical argument mining, supported by a growing number of publicly available datasets. On these benchmarks, BERT-like transformers have consistently performed best, reinforcing the belief that such models are broadly applicable across diverse contexts of debate. This study offers the first large-scale re-evaluation of such state-of-the-art models, with a specific focus on their ability to generalize in identifying arguments. We evaluate four transformers, three standard and one enhanced with contrastive pre-training for better generalization, on 17 English sentence-level datasets as most relevant to the task. Our findings show that, to varying degrees, these models tend to rely on lexical shortcuts tied to content words, suggesting that apparent progress may often be driven by dataset-specific cues rather than true task alignment. While the models achieve strong results on familiar benchmarks, their performance drops markedly when applied to unseen datasets. Nonetheless, incorporating both task-specific pre-training and joint benchmark training proves effective in enhancing both robustness and generalization.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Marc Feger et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.22137",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399447627",
      "doi": "10.48550/arxiv.2406.02919",
      "title": "MultifacetEval: Multifaceted Evaluation to Probe LLMs in Mastering Medical Knowledge",
      "abstract": "Large language models (LLMs) have excelled across domains, also delivering notable performance on the medical evaluation benchmarks, such as MedQA. However, there still exists a significant gap between the reported performance and the practical effectiveness in real-world medical scenarios. In this paper, we aim to explore the causes of this gap by employing a multifaceted examination schema to systematically probe the actual mastery of medical knowledge by current LLMs. Specifically, we develop a novel evaluation framework MultifacetEval to examine the degree and coverage of LLMs in encoding and mastering medical knowledge at multiple facets (comparison, rectification, discrimination, and verification) concurrently. Based on the MultifacetEval framework, we construct two multifaceted evaluation datasets: MultiDiseK (by producing questions from a clinical disease knowledge base) and MultiMedQA (by rephrasing each question from a medical benchmark MedQA into multifaceted questions). The experimental results on these multifaceted datasets demonstrate that the extent of current LLMs in mastering medical knowledge is far below their performance on existing medical benchmarks, suggesting that they lack depth, precision, and comprehensiveness in mastering medical knowledge. Consequently, current LLMs are not yet ready for application in real-world medical tasks. The codes and datasets are available at https://github.com/THUMLP/MultifacetEval.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuxuan Zhou et al.",
      "keywords": "Engineering ethics; Knowledge management; Business; Political science; Psychology; Computer science; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.02919",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4281659354",
      "doi": "10.48550/arxiv.2205.12466",
      "title": "Eye-gaze-guided Vision Transformer for Rectifying Shortcut Learning",
      "abstract": "Learning harmful shortcuts such as spurious correlations and biases prevents deep neural networks from learning the meaningful and useful representations, thus jeopardizing the generalizability and interpretability of the learned representation. The situation becomes even more serious in medical imaging, where the clinical data (e.g., MR images with pathology) are limited and scarce while the reliability, generalizability and transparency of the learned model are highly required. To address this problem, we propose to infuse human experts' intelligence and domain knowledge into the training of deep neural networks. The core idea is that we infuse the visual attention information from expert radiologists to proactively guide the deep model to focus on regions with potential pathology and avoid being trapped in learning harmful shortcuts. To do so, we propose a novel eye-gaze-guided vision transformer (EG-ViT) for diagnosis with limited medical image data. We mask the input image patches that are out of the radiologists' interest and add an additional residual connection in the last encoder layer of EG-ViT to maintain the correlations of all patches. The experiments on two public datasets of INbreast and SIIM-ACR demonstrate our EG-ViT model can effectively learn/transfer experts' domain knowledge and achieve much better performance than baselines. Meanwhile, it successfully rectifies the harmful shortcut learning and significantly improves the EG-ViT model's interpretability. In general, EG-ViT takes the advantages of both human expert's prior knowledge and the power of deep neural networks. This work opens new avenues for advancing current artificial intelligence paradigms by infusing human intelligence.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Chong Ma et al.",
      "keywords": "Interpretability; Generalizability theory; Computer science; Artificial intelligence; Deep learning; Machine learning; Artificial neural network; Gaze; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2205.12466",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403963971",
      "doi": "10.48550/arxiv.2410.04501",
      "title": "Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels",
      "abstract": "The increasing frequency of suicidal thoughts highlights the importance of early detection and intervention. Social media platforms, where users often share personal experiences and seek help, could be utilized to identify individuals at risk. However, the large volume of daily posts makes manual review impractical. This paper explores the use of Large Language Models (LLMs) to automatically detect suicidal content in text-based social media posts. We propose a novel method for generating pseudo-labels for unlabeled data by prompting LLMs, along with traditional classification fine-tuning techniques to enhance label accuracy. To create a strong suicide detection model, we develop an ensemble approach involving prompting with Qwen2-72B-Instruct, and using fine-tuned models such as Llama3-8B, Llama3.1-8B, and Gemma2-9B. We evaluate our approach on the dataset of the Suicide Ideation Detection on Social Media Challenge, a track of the IEEE Big Data 2024 Big Data Cup. Additionally, we conduct a comprehensive analysis to assess the impact of different models and fine-tuning strategies on detection performance. Experimental results show that the ensemble model significantly improves the detection accuracy, by 5% points compared with the individual models. It achieves a weight F1 score of 0.770 on the public test set, and 0.731 on the private test set, providing a promising solution for identifying suicidal content in social media. Our analysis shows that the choice of LLMs affects the prompting performance, with larger models providing better accuracy. Our code and checkpoints are publicly available at https://github.com/khanhvynguyen/Suicide_Detection_LLMs.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Vy Nguyen et al.",
      "keywords": "Social media; Computer science; Natural language processing; Data science; Psychology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.04501",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4300931000",
      "doi": "10.48550/arxiv.1802.00948",
      "title": "Resset: A Recurrent Model for Sequence of Sets with Applications to\\n Electronic Medical Records",
      "abstract": "Modern healthcare is ripe for disruption by AI. A game changer would be\\nautomatic understanding the latent processes from electronic medical records,\\nwhich are being collected for billions of people worldwide. However, these\\nhealthcare processes are complicated by the interaction between at least three\\ndynamic components: the illness which involves multiple diseases, the care\\nwhich involves multiple treatments, and the recording practice which is biased\\nand erroneous. Existing methods are inadequate in capturing the dynamic\\nstructure of care. We propose Resset, an end-to-end recurrent model that reads\\nmedical record and predicts future risk. The model adopts the algebraic view in\\nthat discrete medical objects are embedded into continuous vectors lying in the\\nsame space. We formulate the problem as modeling sequences of sets, a novel\\nsetting that have rarely, if not, been addressed. Within Resset, the bag of\\ndiseases recorded at each clinic visit is modeled as function of sets. The same\\nhold for the bag of treatments. The interaction between the disease bag and the\\ntreatment bag at a visit is modeled in several, one of which as residual of\\ndiseases minus the treatments. Finally, the health trajectory, which is a\\nsequence of visits, is modeled using a recurrent neural network. We report\\nresults on over a hundred thousand hospital visits by patients suffered from\\ntwo costly chronic diseases -- diabetes and mental health. Resset shows\\npromises in multiple predictive tasks such as readmission prediction,\\ntreatments recommendation and diseases progression.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Phuoc Nguyen et al.",
      "keywords": "Recurrent neural network; Sequence (biology); Medical record; Computer science; Health care; Function (biology); Disease; Trajectory; Space (punctuation); Artificial intelligence; Medicine; Medical emergency; Artificial neural network; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1802.00948",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417515433",
      "doi": "10.48550/arxiv.2505.07157",
      "title": "HAMLET: Healthcare-focused Adaptive Multilingual Learning Embedding-based Topic Modeling",
      "abstract": "Traditional topic models often struggle with contextual nuances and fail to adequately handle polysemy and rare words. This limitation typically results in topics that lack coherence and quality. Large Language Models (LLMs) can mitigate this issue by generating an initial set of topics. However, these raw topics frequently lack refinement and representativeness, which leads to redundancy without lexical similarity and reduced interpretability. This paper introduces HAMLET, a graph-driven architecture for cross-lingual healthcare topic modeling that uses LLMs. The proposed approach leverages neural-enhanced semantic fusion to refine the embeddings of topics generated by the LLM. Instead of relying solely on statistical co-occurrence or human interpretation to extract topics from a document corpus, this method introduces a topic embedding refinement that uses Bidirectional Encoder Representations from Transformers (BERT) and Graph Neural Networks (GNN). After topic generation, a hybrid technique that involves BERT and Sentence-BERT (SBERT) is employed for embedding. The topic representations are further refined using a GNN, which establishes connections between documents, topics, words, similar topics, and similar words. A novel method is introduced to compute similarities. Consequently, the topic embeddings are refined, and the top k topics are extracted. Experiments were conducted using two healthcare datasets, one in English and one in French, from which six sets were derived. The results demonstrate the effectiveness of HAMLET.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Hajar Sakai et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07157",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399116030",
      "doi": "10.48550/arxiv.2405.16818",
      "title": "Advancing Behavior Generation in Mobile Robotics through High-Fidelity Procedural Simulations",
      "abstract": "This paper introduces YamaS, a simulator integrating Unity3D Engine with Robotic Operating System for robot navigation research and aims to facilitate the development of both Deep Reinforcement Learning (Deep-RL) and Natural Language Processing (NLP). It supports single and multi-agent configurations with features like procedural environment generation, RGB vision, and dynamic obstacle navigation. Unique to YamaS is its ability to construct single and multi-agent environments, as well as generating agent's behaviour through textual descriptions. The simulator's fidelity is underscored by comparisons with the real-world Yamabiko Beego robot, demonstrating high accuracy in sensor simulations and spatial reasoning. Moreover, YamaS integrates Virtual Reality (VR) to augment Human-Robot Interaction (HRI) studies, providing an immersive platform for developers and researchers. This fusion establishes YamaS as a versatile and valuable tool for the development and testing of autonomous systems, contributing to the fields of robot simulation and AI-driven training methodologies.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Victor Augusto Kich et al.",
      "keywords": "Robotics; Artificial intelligence; High fidelity; Fidelity; Computer science; Human\u2013computer interaction; Engineering; Robot; Telecommunications; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.16818",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417515437",
      "doi": "10.48550/arxiv.2505.07162",
      "title": "KDH-MLTC: Knowledge Distillation for Healthcare Multi-Label Text Classification",
      "abstract": "The increasing volume of healthcare textual data requires computationally efficient, yet highly accurate classification approaches able to handle the nuanced and complex nature of medical terminology. This research presents Knowledge Distillation for Healthcare Multi-Label Text Classification (KDH-MLTC), a framework leveraging model compression and Large Language Models (LLMs). The proposed approach addresses conventional healthcare Multi-Label Text Classification (MLTC) challenges by integrating knowledge distillation and sequential fine-tuning, subsequently optimized through Particle Swarm Optimization (PSO) for hyperparameter tuning. KDH-MLTC transfers knowledge from a more complex teacher LLM (i.e., BERT) to a lighter student LLM (i.e., DistilBERT) through sequential training adapted to MLTC that preserves the teacher's learned information while significantly reducing computational requirements. As a result, the classification is enabled to be conducted locally, making it suitable for healthcare textual data characterized by sensitivity and, therefore, ensuring HIPAA compliance. The experiments conducted on three medical literature datasets of different sizes, sampled from the Hallmark of Cancer (HoC) dataset, demonstrate that KDH-MLTC achieves superior performance compared to existing approaches, particularly for the largest dataset, reaching an F1 score of 82.70%. Additionally, statistical validation and an ablation study are carried out, proving the robustness of KDH-MLTC. Furthermore, the PSO-based hyperparameter optimization process allowed the identification of optimal configurations. The proposed approach contributes to healthcare text classification research, balancing efficiency requirements in resource-constrained healthcare settings with satisfactory accuracy demands.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Hajar Sakai et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07162",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403580672",
      "doi": "10.48550/arxiv.2410.09770",
      "title": "'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews",
      "abstract": "The integrity of the peer-review process is vital for maintaining scientific rigor and trust within the academic community. With the steady increase in the usage of large language models (LLMs) like ChatGPT in academic writing, there is a growing concern that AI-generated texts could compromise scientific publishing, including peer-reviews. Previous works have focused on generic AI-generated text detection or have presented an approach for estimating the fraction of peer-reviews that can be AI-generated. Our focus here is to solve a real-world problem by assisting the editor or chair in determining whether a review is written by ChatGPT or not. To address this, we introduce the Term Frequency (TF) model, which posits that AI often repeats tokens, and the Review Regeneration (RR) model, which is based on the idea that ChatGPT generates similar outputs upon re-prompting. We stress test these detectors against token attack and paraphrasing. Finally, we propose an effective defensive strategy to reduce the effect of paraphrasing on our models. Our findings suggest both our proposed methods perform better than the other AI text detectors. Our RR model is more robust, although our TF model performs better than the RR model without any attacks. We make our code, dataset, and model public.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Sandeep Kumar et al.",
      "keywords": "Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.09770",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285069144",
      "doi": "10.48550/arxiv.1905.13294",
      "title": "A Review of Deep Learning with Special Emphasis on Architectures,\\n Applications and Recent Trends",
      "abstract": "Deep learning has solved a problem that as little as five years ago was\\nthought by many to be intractable - the automatic recognition of patterns in\\ndata; and it can do so with accuracy that often surpasses human beings. It has\\nsolved problems beyond the realm of traditional, hand-crafted machine learning\\nalgorithms and captured the imagination of practitioners trying to make sense\\nout of the flood of data that now inundates our society. As public awareness of\\nthe efficacy of DL increases so does the desire to make use of it. But even for\\nhighly trained professionals it can be daunting to approach the rapidly\\nincreasing body of knowledge produced by experts in the field. Where does one\\nstart? How does one determine if a particular model is applicable to their\\nproblem? How does one train and deploy such a network? A primer on the subject\\ncan be a good place to start. With that in mind, we present an overview of some\\nof the key multilayer ANNs that comprise DL. We also discuss some new automatic\\narchitecture optimization protocols that use multi-agent approaches. Further,\\nsince guaranteeing system uptime is becoming critical to many computer\\napplications, we include a section on using neural networks for fault detection\\nand subsequent mitigation. This is followed by an exploratory survey of several\\napplication areas where DL has emerged as a game-changing technology: anomalous\\nbehavior detection in financial applications or in financial time-series\\nforecasting, predictive and prescriptive analytics, medical image processing\\nand analysis and power systems research. The thrust of this review is to\\noutline emerging areas of application-oriented research within the DL community\\nas well as to provide a reference to researchers seeking to use it in their\\nwork for what it does best: statistical pattern recognition with unparalleled\\nlearning capacity with the ability to scale with information.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Saptarshi Sengupta et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Field (mathematics); Data science; Analytics; Machine learning; Realm; Subject-matter expert; Predictive analytics; Big data; Expert system; Data mining",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.1905.13294",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416047753",
      "doi": "10.48550/arxiv.2505.22032",
      "title": "Retweets, Receipts, and Resistance: Discourse, Sentiment, and Credibility in Public Health Crisis Twitter",
      "abstract": "As the COVID-19 pandemic evolved, the Centers for Disease Control and Prevention (CDC) used Twitter to disseminate safety guidance and updates, reaching millions of users. This study analyzes two years of tweets from, to, and about the CDC using a mixed methods approach to examine discourse characteristics, credibility, and user engagement. We found that the CDCs communication remained largely one directional and did not foster reciprocal interaction, while discussions around COVID19 were deeply shaped by political and ideological polarization. Users frequently cited earlier CDC messages to critique new and sometimes contradictory guidance. Our findings highlight the role of sentiment, media richness, and source credibility in shaping the spread of public health messages. We propose design strategies to help the CDC tailor communications to diverse user groups and manage misinformation more effectively during high-stakes health crises.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Tawfiq Ammari et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.22032",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403578876",
      "doi": "10.48550/arxiv.2410.12926",
      "title": "DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation",
      "abstract": "Integrating low-rank adaptation (LoRA) with federated learning (FL) has received widespread attention recently, aiming to adapt pretrained foundation models (FMs) to downstream medical tasks via privacy-preserving decentralized training. However, owing to the direct combination of LoRA and FL, current methods generally undergo two problems, i.e., aggregation deviation, and differential privacy (DP) noise amplification effect. To address these problems, we propose a novel privacy-preserving federated finetuning framework called \\underline{D}eviation \\underline{E}liminating and Nois\\underline{e} \\underline{R}egulating (DEeR). Specifically, we firstly theoretically prove that the necessary condition to eliminate aggregation deviation is guaranteing the equivalence between LoRA parameters of clients. Based on the theoretical insight, a deviation eliminator is designed to utilize alternating minimization algorithm to iteratively optimize the zero-initialized and non-zero-initialized parameter matrices of LoRA, ensuring that aggregation deviation always be zeros during training. Furthermore, we also conduct an in-depth analysis of the noise amplification effect and find that this problem is mainly caused by the ``linear relationship'' between DP noise and LoRA parameters. To suppress the noise amplification effect, we propose a noise regulator that exploits two regulator factors to decouple relationship between DP and LoRA, thereby achieving robust privacy protection and excellent finetuning performance. Additionally, we perform comprehensive ablated experiments to verify the effectiveness of the deviation eliminator and noise regulator. DEeR shows better performance on public medical datasets in comparison with state-of-the-art approaches. The code is available at https://github.com/CUHK-AIM-Group/DEeR.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Meilu Zhu et al.",
      "keywords": "Adaptation (eye); Noise (video); Rank (graph theory); Computer science; Internet privacy; Computer security; Business; Mathematics; Artificial intelligence; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.12926",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394591987",
      "doi": "10.48550/arxiv.2404.04103",
      "title": "Improving Factual Accuracy of Neural Table-to-Text Output by Addressing Input Problems in ToTTo",
      "abstract": "Neural Table-to-Text models tend to hallucinate, producing texts that contain factual errors. We investigate whether such errors in the output can be traced back to problems with the input. We manually annotated 1,837 texts generated by multiple models in the politics domain of the ToTTo dataset. We identify the input problems that are responsible for many output errors and show that fixing these inputs reduces factual errors by between 52% and 76% (depending on the model). In addition, we observe that models struggle in processing tabular inputs that are structured in a non-standard way, particularly when the input lacks distinct row and column values or when the column headers are not correctly mapped to corresponding values.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Barkavi Sundararajan et al.",
      "keywords": "Table (database); Computer science; Artificial intelligence; Arithmetic; Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.04103",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4400373587",
      "doi": "10.48550/arxiv.2407.01488",
      "title": "LEXI: Large Language Models Experimentation Interface",
      "abstract": "The recent developments in Large Language Models (LLM), mark a significant moment in the research and development of social interactions with artificial agents. These agents are widely deployed in a variety of settings, with potential impact on users. However, the study of social interactions with agents powered by LLM is still emerging, limited by access to the technology and to data, the absence of standardised interfaces, and challenges to establishing controlled experimental setups using the currently available business-oriented platforms. To answer these gaps, we developed LEXI, LLMs Experimentation Interface, an open-source tool enabling the deployment of artificial agents powered by LLM in social interaction behavioural experiments. Using a graphical interface, LEXI allows researchers to build agents, and deploy them in experimental setups along with forms and questionnaires while collecting interaction logs and self-reported data. The outcomes of usability testing indicate LEXI's broad utility, high usability and minimum mental workload requirement, with distinctive benefits observed across disciplines. A proof-of-concept study exploring the tool's efficacy in evaluating social HAIs was conducted, resulting in high-quality data. A comparison of empathetic versus neutral agents indicated that people perceive empathetic agents as more social, and write longer and more positive messages towards them.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Guy Laban et al.",
      "keywords": "Interface (matter); Computer science; Natural language processing; Psychology; Human\u2013computer interaction; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.01488",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414899302",
      "doi": "10.48550/arxiv.2506.02679",
      "title": "Poster: FedBlockParadox -- A Framework for Simulating and Securing Decentralized Federated Learning",
      "abstract": "A significant body of research in decentralized federated learning focuses on combining the privacy-preserving properties of federated learning with the resilience and transparency offered by blockchain-based systems. While these approaches are promising, they often lack flexible tools to evaluate system robustness under adversarial conditions. To fill this gap, we present FedBlockParadox, a modular framework for modeling and evaluating decentralized federated learning systems built on blockchain technologies, with a focus on resilience against a broad spectrum of adversarial attack scenarios. It supports multiple consensus protocols, validation methods, aggregation strategies, and configurable attack models. By enabling controlled experiments, FedBlockParadox provides a valuable resource for researchers developing secure, decentralized learning solutions. The framework is open-source and built to be extensible by the community.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Gabriele Digregorio et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.02679",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320170098",
      "doi": "10.48550/arxiv.2204.09272",
      "title": "Is Non-IID Data a Threat in Federated Online Learning to Rank?",
      "abstract": "In this perspective paper we study the effect of non independent and identically distributed (non-IID) data on federated online learning to rank (FOLTR) and chart directions for future work in this new and largely unexplored research area of Information Retrieval. In the FOLTR process, clients participate in a federation to jointly create an effective ranker from the implicit click signal originating in each client, without the need to share data (documents, queries, clicks). A well-known factor that affects the performance of federated learning systems, and that poses serious challenges to these approaches, is that there may be some type of bias in the way data is distributed across clients. While FOLTR systems are on their own rights a type of federated learning system, the presence and effect of non-IID data in FOLTR has not been studied. To this aim, we first enumerate possible data distribution settings that may showcase data bias across clients and thus give rise to the non-IID problem. Then, we study the impact of each setting on the performance of the current state-of-the-art FOLTR approach, the Federated Pairwise Differentiable Gradient Descent (FPDGD), and we highlight which data distributions may pose a problem for FOLTR methods. We also explore how common approaches proposed in the federated learning literature address non-IID issues in FOLTR. This allows us to unveil new research gaps that, we argue, future research in FOLTR should consider. This is an important contribution to the current state of FOLTR field because, for FOLTR systems to be deployed, the factors affecting their performance, including the impact of non-IID data, need to be thoroughly understood.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuyi Wang et al.",
      "keywords": "Computer science; Pairwise comparison; Independent and identically distributed random variables; Rank (graph theory); Learning to rank; Perspective (graphical); State (computer science); Federated learning; Information retrieval; Data mining; Data science; Machine learning; Artificial intelligence; Algorithm; Random variable",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2204.09272",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417517054",
      "doi": "10.48550/arxiv.2505.07575",
      "title": "Personalized Federated Learning under Model Dissimilarity Constraints",
      "abstract": "One of the defining challenges in federated learning is that of statistical heterogeneity among clients. We address this problem with KARULA, a regularized strategy for personalized federated learning, which constrains the pairwise model dissimilarities between clients based on the difference in their distributions, as measured by a surrogate for the 1-Wasserstein distance adapted for the federated setting. This allows the strategy to adapt to highly complex interrelations between clients, that e.g., clustered approaches fail to capture. We propose an inexact projected stochastic gradient algorithm to solve the constrained problem that the strategy defines, and show theoretically that it converges with smooth, possibly non-convex losses to a neighborhood of a stationary point with rate O(1/K). We demonstrate the effectiveness of KARULA on synthetic and real federated data sets.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "S J Erickson et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07575",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404450644",
      "doi": "10.48550/arxiv.2411.09339",
      "title": "Re-Parameterization of Lightweight Transformer for On-Device Speech Emotion Recognition",
      "abstract": "With the increasing implementation of machine learning models on edge or Internet-of-Things (IoT) devices, deploying advanced models on resource-constrained IoT devices remains challenging. Transformer models, a currently dominant neural architecture, have achieved great success in broad domains but their complexity hinders its deployment on IoT devices with limited computation capability and storage size. Although many model compression approaches have been explored, they often suffer from notorious performance degradation. To address this issue, we introduce a new method, namely Transformer Re-parameterization, to boost the performance of lightweight Transformer models. It consists of two processes: the High-Rank Factorization (HRF) process in the training stage and the deHigh-Rank Factorization (deHRF) process in the inference stage. In the former process, we insert an additional linear layer before the Feed-Forward Network (FFN) of the lightweight Transformer. It is supposed that the inserted HRF layers can enhance the model learning capability. In the later process, the auxiliary HRF layer will be merged together with the following FFN layer into one linear layer and thus recover the original structure of the lightweight model. To examine the effectiveness of the proposed method, we evaluate it on three widely used Transformer variants, i.e., ConvTransformer, Conformer, and SpeechFormer networks, in the application of speech emotion recognition on the IEMOCAP, M3ED and DAIC-WOZ datasets. Experimental results show that our proposed method consistently improves the performance of lightweight Transformers, even making them comparable to large models. The proposed re-parameterization approach enables advanced Transformer models to be deployed on resource-constrained IoT devices.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zixing Zhang et al.",
      "keywords": "Transformer; Speech recognition; Computer science; Emotion recognition; Engineering; Electrical engineering; Voltage",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.09339",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417171385",
      "doi": "10.48550/arxiv.2504.20823",
      "title": "Hybrid Quantum Recurrent Neural Network For Remaining Useful Life Prediction",
      "abstract": "Predictive maintenance in aerospace heavily relies on accurate estimation of the remaining useful life of jet engines. In this paper, we introduce a Hybrid Quantum Recurrent Neural Network framework, combining Quantum Long Short-Term Memory layers with classical dense layers for Remaining Useful Life forecasting on NASA's Commercial Modular Aero-Propulsion System Simulation dataset. Each Quantum Long Short-Term Memory gate replaces conventional linear transformations with Quantum Depth-Infused circuits, allowing the network to learn high-frequency components more effectively. Experimental results demonstrate that, despite having fewer trainable parameters, the Hybrid Quantum Recurrent Neural Network achieves up to a 5% improvement over a Recurrent Neural Network based on stacked Long Short-Term Memory layers in terms of mean root mean squared error and mean absolute error. Moreover, a thorough comparison of our method with established techniques, including Random Forest, Convolutional Neural Network, and Multilayer Perceptron, demonstrates that our approach, which achieves a Root Mean Squared Error of 15.46, surpasses these baselines by approximately 13.68%, 16.21%, and 7.87%, respectively. Nevertheless, it remains outperformed by certain advanced joint architectures. Our findings highlight the potential of hybrid quantum-classical approaches for robust time-series forecasting under limited data conditions, offering new avenues for enhancing reliability in predictive maintenance tasks.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Olga Tsurkan et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.20823",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396914156",
      "doi": "10.48550/arxiv.2405.07960",
      "title": "AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments",
      "abstract": "Evaluating large language models (LLM) in clinical scenarios is crucial to assessing their potential clinical utility. Existing benchmarks rely heavily on static question-answering, which does not accurately depict the complex, sequential nature of clinical decision-making. Here, we introduce AgentClinic, a multimodal agent benchmark for evaluating LLMs in simulated clinical environments that include patient interactions, multimodal data collection under incomplete information, and the usage of various tools, resulting in an in-depth evaluation across nine medical specialties and seven languages. We find that solving MedQA problems in the sequential decision-making format of AgentClinic is considerably more challenging, resulting in diagnostic accuracies that can drop to below a tenth of the original accuracy. Overall, we observe that agents sourced from Claude-3.5 outperform other LLM backbones in most settings. Nevertheless, we see stark differences in the LLMs' ability to make use of tools, such as experiential learning, adaptive retrieval, and reflection cycles. Strikingly, Llama-3 shows up to 92% relative improvements with the notebook tool that allows for writing and editing notes that persist across cases. To further scrutinize our clinical simulations, we leverage real-world electronic health records, perform a clinical reader study, perturb agents with biases, and explore novel patient-centric metrics that this interactive environment firstly enables.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Samuel Schmidgall et al.",
      "keywords": "Benchmark (surveying); Computer science; Artificial intelligence; Machine learning; Geography; Cartography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.07960",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403784788",
      "doi": "10.48550/arxiv.2409.17054",
      "title": "Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia: A Proof-of-Concept Study",
      "abstract": "One of the critical issues contributing to inefficiency in Puskesmas (Indonesian community health centers) is the time-consuming nature of documenting doctor-patient interactions. Doctors must conduct thorough consultations and manually transcribe detailed notes into ePuskesmas electronic health records (EHR), which creates substantial administrative burden to already overcapacitated physicians. This paper presents a proof-of-concept framework using large language models (LLMs) to automate real-time transcription and summarization of doctor-patient conversations in Bahasa Indonesia. Our system combines Whisper model for transcription with GPT-3.5 for medical summarization, implemented as a browser extension that automatically populates ePuskesmas forms. Through controlled roleplay experiments with medical validation, we demonstrate the technical feasibility of processing detailed 300+ seconds trimmed consultations in under 30 seconds while maintaining clinical accuracy. This work establishes the foundation for AI-assisted clinical documentation in resource-constrained healthcare environments. However, concerns have also been raised regarding privacy compliance and large-scale clinical evaluation addressing language and cultural biases for LLMs.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Azmul Asmar Irfan et al.",
      "keywords": "Automatic summarization; Transcription (linguistics); Computer science; World Wide Web; Information retrieval",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.17054",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4401201662",
      "doi": "10.48550/arxiv.2407.19256",
      "title": "Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review",
      "abstract": "With the rapid development of artificial intelligence (AI), large language models (LLMs) have shown strong capabilities in natural language understanding, reasoning, and generation, attracting amounts of research interest in applying LLMs to health and medicine. Critical care medicine (CCM) provides diagnosis and treatment for critically ill patients who often require intensive monitoring and interventions in intensive care units (ICUs). Can LLMs be applied to CCM? Are LLMs just like stochastic parrots or ICU experts in assisting clinical decision-making? This scoping review aims to provide a panoramic portrait of the application of LLMs in CCM. Literature in seven databases, including PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE Xplore, and ACM Digital Library, were searched from January 1, 2019, to June 10, 2024. Peer-reviewed journal and conference articles that discussed the application of LLMs in critical care settings were included. From an initial 619 articles, 24 were selected for final review. This review grouped applications of LLMs in CCM into three categories: clinical decision support, medical documentation and reporting, and medical education and doctor-patient communication. LLMs have advantages in handling unstructured data and do not require manual feature engineering. Meanwhile, applying LLMs to CCM faces challenges, including hallucinations, poor interpretability, bias and alignment challenges, and privacy and ethics issues. Future research should enhance model reliability and interpretability, integrate up-to-date medical knowledge, and strengthen privacy and ethical guidelines. As LLMs evolve, they could become key tools in CCM to help improve patient outcomes and optimize healthcare delivery. This study is the first review of LLMs in CCM, aiding researchers, clinicians, and policymakers to understand the current status and future potentials of LLMs in CCM.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Tongyue Shi et al.",
      "keywords": "Computer science; Medicine; Management science; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2407.19256",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4362508481",
      "doi": "10.48550/arxiv.2303.17807",
      "title": "GPT-4 can pass the Korean National Licensing Examination for Korean Medicine Doctors",
      "abstract": "Traditional Korean medicine (TKM) emphasizes individualized diagnosis and treatment. This uniqueness makes AI modeling difficult due to limited data and implicit processes. Large language models (LLMs) have demonstrated impressive medical inference, even without advanced training in medical texts. This study assessed the capabilities of GPT-4 in TKM, using the Korean National Licensing Examination for Korean Medicine Doctors (K-NLEKMD) as a benchmark. The K-NLEKMD, administered by a national organization, encompasses 12 major subjects in TKM. We optimized prompts with Chinese-term annotation, English translation for questions and instruction, exam-optimized instruction, and self-consistency. GPT-4 with optimized prompts achieved 66.18% accuracy, surpassing both the examination's average pass mark of 60% and the 40% minimum for each subject. The gradual introduction of language-related prompts and prompting techniques enhanced the accuracy from 51.82% to its maximum accuracy. GPT-4 showed low accuracy in subjects including public health &amp; medicine-related law, internal medicine (2) which are localized in Korea and TKM. The model's accuracy was lower for questions requiring TKM-specialized knowledge. It exhibited higher accuracy in diagnosis-based and recall-based questions than in intervention-based questions. A positive correlation was observed between the consistency and accuracy of GPT-4's responses. This study unveils both the potential and challenges of applying LLMs to TKM. These findings underline the potential of LLMs like GPT-4 in culturally adapted medicine, especially TKM, for tasks such as clinical assistance, medical education, and research. But they also point towards the necessity for the development of methods to mitigate cultural bias inherent in large language models and validate their efficacy in real-world clinical settings.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Dongyeop Jang et al.",
      "keywords": "Consistency (knowledge bases); Psychology; Medicine; Medical education; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.17807",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4298187106",
      "doi": "10.48550/arxiv.2209.14901",
      "title": "DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing",
      "abstract": "The meaningful use of electronic health records (EHR) continues to progress in the digital era with clinical decision support systems augmented by artificial intelligence. A priority in improving provider experience is to overcome information overload and reduce the cognitive burden so fewer medical errors and cognitive biases are introduced during patient care. One major type of medical error is diagnostic error due to systematic or predictable errors in judgment that rely on heuristics. The potential for clinical natural language processing (cNLP) to model diagnostic reasoning in humans with forward reasoning from data to diagnosis and potentially reduce the cognitive burden and medical error has not been investigated. Existing tasks to advance the science in cNLP have largely focused on information extraction and named entity recognition through classification tasks. We introduce a novel suite of tasks coined as Diagnostic Reasoning Benchmarks, DR.BENCH, as a new benchmark for developing and evaluating cNLP models with clinical diagnostic reasoning ability. The suite includes six tasks from ten publicly available datasets addressing clinical text understanding, medical knowledge reasoning, and diagnosis generation. DR.BENCH is the first clinical suite of tasks designed to be a natural language generation framework to evaluate pre-trained language models. Experiments with state-of-the-art pre-trained generative language models using large general domain models and models that were continually trained on a medical corpus demonstrate opportunities for improvement when evaluated in DR. BENCH. We share DR. BENCH as a publicly available GitLab repository with a systematic approach to load and evaluate models for the cNLP community.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yanjun Gao et al.",
      "keywords": "Computer science; Heuristics; Suite; Artificial intelligence; Benchmark (surveying); Machine learning; Cognition; Natural language processing; Natural language generation; Data science; Natural language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.14901",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403578817",
      "doi": "10.48550/arxiv.2410.12793",
      "title": "Environment Scan of Generative AI Infrastructure for Clinical and Translational Science",
      "abstract": "This study reports a comprehensive environmental scan of the generative AI (GenAI) infrastructure in the national network for clinical and translational science across 36 institutions supported by the Clinical and Translational Science Award (CTSA) Program led by the National Center for Advancing Translational Sciences (NCATS) of the National Institutes of Health (NIH) at the United States. With the rapid advancement of GenAI technologies, including large language models (LLMs), healthcare institutions face unprecedented opportunities and challenges. This research explores the current status of GenAI integration, focusing on stakeholder roles, governance structures, and ethical considerations by administering a survey among leaders of health institutions (i.e., representing academic medical centers and health systems) to assess the institutional readiness and approach towards GenAI adoption. Key findings indicate a diverse range of institutional strategies, with most organizations in the experimental phase of GenAI deployment. The study highlights significant variations in governance models, with a strong preference for centralized decision-making but notable gaps in workforce training and ethical oversight. Moreover, the results underscore the need for a more coordinated approach to GenAI governance, emphasizing collaboration among senior leaders, clinicians, information technology staff, and researchers. Our analysis also reveals concerns regarding GenAI bias, data security, and stakeholder trust, which must be addressed to ensure the ethical and effective implementation of GenAI technologies. This study offers valuable insights into the challenges and opportunities of GenAI integration in healthcare, providing a roadmap for institutions aiming to leverage GenAI for improved quality of care and operational efficiency.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Betina Idnay et al.",
      "keywords": "Generative grammar; Translational science; Translational medicine; Computer science; Business; Artificial intelligence; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.12793",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4406030918",
      "doi": "10.48550/arxiv.2501.00208",
      "title": "An Empirical Evaluation of Large Language Models on Consumer Health Questions",
      "abstract": "This study evaluates the performance of several Large Language Models (LLMs) on MedRedQA, a dataset of consumer-based medical questions and answers by verified experts extracted from the AskDocs subreddit. While LLMs have shown proficiency in clinical question answering (QA) benchmarks, their effectiveness on real-world, consumer-based, medical questions remains less understood. MedRedQA presents unique challenges, such as informal language and the need for precise responses suited to non-specialist queries. To assess model performance, responses were generated using five LLMs: GPT-4o mini, Llama 3.1: 70B, Mistral-123B, Mistral-7B, and Gemini-Flash. A cross-evaluation method was used, where each model evaluated its responses as well as those of others to minimize bias. The results indicated that GPT-4o mini achieved the highest alignment with expert responses according to four out of the five models' judges, while Mistral-7B scored lowest according to three out of five models' judges. This study highlights the potential and limitations of current LLMs for consumer health medical question answering, indicating avenues for further development.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Muhammad Abrar et al.",
      "keywords": "Empirical research; Computer science; Business; Psychology; Marketing; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2501.00208",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416039618",
      "doi": "10.48550/arxiv.2503.10486",
      "title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions",
      "abstract": "Large Language Models (LLMs) are revolutionizing medical diagnostics by enhancing both disease classification and clinical decision-making. In this study, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek R1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We assessed their predictive accuracy at both the disease and category levels, as well as the reliability of their confidence scores. DeepSeek R1 achieved a disease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3 Mini, which attained 72% and 75% respectively. Notably, DeepSeek R1 demonstrated exceptional performance in Mental Health, Neurological Disorders, and Oncology, where it reached 100% accuracy, while O3 Mini excelled in Autoimmune Disease classification with 100% accuracy. Both models, however, struggled with Respiratory Disease classification, recording accuracies of only 40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of confidence scores revealed that DeepSeek R1 provided high-confidence predictions in 92% of cases, compared to 68% for O3 Mini. Ethical considerations regarding bias, model interpretability, and data privacy are also discussed to ensure the responsible integration of LLMs into clinical practice. Overall, our findings offer valuable insights into the strengths and limitations of LLM-based diagnostic systems and provide a roadmap for future enhancements in AI-driven healthcare.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Gaurav Kumar Gupta et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2503.10486",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4302805728",
      "doi": "10.48550/arxiv.1205.4251",
      "title": "Scientific Utopia: II. Restructuring incentives and practices to promote truth over publishability",
      "abstract": "An academic scientist's professional success depends on publishing. Publishing norms emphasize novel, positive results. As such, disciplinary incentives encourage design, analysis, and reporting decisions that elicit positive results and ignore negative results. Prior reports demonstrate how these incentives inflate the rate of false effects in published science. When incentives favor novelty over replication, false results persist in the literature unchallenged, reducing efficiency in knowledge accumulation. Previous suggestions to address this problem are unlikely to be effective. For example, a journal of negative results publishes otherwise unpublishable reports. This enshrines the low status of the journal and its content. The persistence of false findings can be meliorated with strategies that make the fundamental but abstract accuracy motive - getting it right - competitive with the more tangible and concrete incentive - getting it published. We develop strategies for improving scientific practices and knowledge accumulation that account for ordinary human motivations and self-serving biases.",
      "year": "2012",
      "journal": "arXiv (Cornell University)",
      "authors": "Brian A. Nosek et al.",
      "keywords": "Incentive; Restructuring; Novelty; Publishing; Discipline; Utopia; Psychology; Positive economics; Public relations; Political science; Social psychology; Economics; Law; Microeconomics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1205.4251",
      "cited_by_count": 221,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4225753362",
      "doi": "10.1371/journal.pone.0263001",
      "title": "The Impact of the COVID-19 Pandemic on Scientific Research in the Life Sciences",
      "abstract": "The COVID-19 outbreak has posed an unprecedented challenge to humanity and science. On the one side, public and private incentives have been put in place to promptly allocate resources toward research areas strictly related to the COVID-19 emergency. But on the flip side, research in many fields not directly related to the pandemic has lagged behind. In this paper, we assess the impact of COVID-19 on world scientific production in the life sciences. We investigate how the usage of medical subject headings (MeSH) has changed following the outbreak. We estimate through a difference-in-differences approach the impact of COVID-19 on scientific production through PubMed. We find that COVID-related research topics have risen to prominence, displaced clinical publications, diverted funds away from research areas not directly related to COVID-19 and that the number of publications on clinical trials in unrelated fields has contracted. Our results call for urgent targeted policy interventions to reactivate biomedical research in areas that have been neglected by the COVID-19 emergency.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Massimo Riccaboni et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); Pandemic; Incentive; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); 2019-20 coronavirus outbreak; Outbreak; Political science; Medicine; Economics; Virology; Infectious disease (medical specialty); Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1371/journal.pone.0263001",
      "cited_by_count": 210,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3104705690",
      "doi": "10.1007/s11192-016-2115-y",
      "title": "Which early works are cited most frequently in climate change research literature? A bibliometric approach based on Reference Publication Year Spectroscopy",
      "abstract": "This bibliometric analysis focuses on the general history of climate change research and, more specifically, on the discovery of the greenhouse effect. First, the Reference Publication Year Spectroscopy (RPYS) is applied to a large publication set on climate change of 222,060 papers published between 1980 and 2014. The references cited therein were extracted and analyzed with regard to publications, which are cited most frequently. Second, a new method for establishing a more subject-specific publication set for applying RPYS (based on the co-citations of a marker reference) is proposed (RPYS-CO). The RPYS of the climate change literature focuses on the history of climate change research in total. We identified 35 highly-cited publications across all disciplines, which include fundamental early scientific works of the 19th century (with a weak connection to climate change) and some cornerstones of science with a stronger connection to climate change. By using the Arrhenius (1896) paper as a RPYS-CO marker paper, we selected only publications specifically discussing the discovery of the greenhouse effect and the role of carbon dioxide. Also, we focused on the time period 1800-1850 to reveal the contributions of J.B.J Fourier in terms of cited references. Using different RPYS approaches in this study, we were able to identify the complete range of works of the celebrated icons as well as many less known works relevant for the history of climate change research. The analyses confirmed the potential of the RPYS method for historical studies: Seminal papers are detected on the basis of the references cited by the overall community without any further assumptions.",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Lutz Bornmann et al.",
      "keywords": "Climate change; Set (abstract data type); Subject (documents); History; Regional science; Social science; Computer science; Sociology; Library science; Ecology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1007/s11192-016-2115-y",
      "cited_by_count": 123,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4320342216",
      "doi": "10.48550/arxiv.2302.03495",
      "title": "Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?",
      "abstract": "Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Shuai Wang et al.",
      "keywords": "Systematic review; Computer science; Information retrieval; Construct (python library); Data science; MEDLINE; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.03495",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4301117789",
      "doi": "10.48550/arxiv.1708.01104",
      "title": "A glass-box interactive machine learning approach for solving NP-hard\\n problems with the human-in-the-loop",
      "abstract": "The goal of Machine Learning to automatically learn from data, extract\\nknowledge and to make decisions without any human intervention. Such automatic\\n(aML) approaches show impressive success. Recent results even demonstrate\\nintriguingly that deep learning applied for automatic classification of skin\\nlesions is on par with the performance of dermatologists, yet outperforms the\\naverage. As human perception is inherently limited, such approaches can\\ndiscover patterns, e.g. that two objects are similar, in arbitrarily\\nhigh-dimensional spaces what no human is able to do. Humans can deal only with\\nlimited amounts of data, whilst big data is beneficial for aML; however, in\\nhealth informatics, we are often confronted with a small number of data sets,\\nwhere aML suffer of insufficient training samples and many problems are\\ncomputationally hard. Here, interactive machine learning (iML) may be of help,\\nwhere a human-in-the-loop contributes to reduce the complexity of NP-hard\\nproblems. A further motivation for iML is that standard black-box approaches\\nlack transparency, hence do not foster trust and acceptance of ML among\\nend-users. Rising legal and privacy aspects, e.g. with the new European General\\nData Protection Regulations, make black-box approaches difficult to use,\\nbecause they often are not able to explain why a decision has been made. In\\nthis paper, we present some experiments to demonstrate the effectiveness of the\\nhuman-in-the-loop approach, particularly in opening the black-box to a\\nglass-box and thus enabling a human directly to interact with an learning\\nalgorithm. We selected the Ant Colony Optimization framework, and applied it on\\nthe Traveling Salesman Problem, which is a good example, due to its relevance\\nfor health informatics, e.g. for the study of protein folding. From studies of\\nhow humans extract so much from so little data, fundamental ML-research also\\nmay benefit.\\n",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Andreas Holzinger et al.",
      "keywords": "Computer science; Black box; Machine learning; Artificial intelligence; Human-in-the-loop; Deep learning; Perception; Big data; Informatics; Transparency (behavior); Data mining; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1708.01104",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323927226",
      "doi": "10.48550/arxiv.2303.05349",
      "title": "Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data",
      "abstract": "Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Anna\u2010Carolina Haensch et al.",
      "keywords": "Grading (engineering); CLIPS; Social media; Content analysis; Psychology; Focus (optics); Mathematics education; Computer science; Pedagogy; Sociology; Engineering; World Wide Web; Artificial intelligence; Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.05349",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4367000196",
      "doi": "10.48550/arxiv.2304.12008",
      "title": "CHEAT: A Large-scale Dataset for Detecting ChatGPT-writtEn AbsTracts",
      "abstract": "The powerful ability of ChatGPT has caused widespread concern in the academic community. Malicious users could synthesize dummy academic content through ChatGPT, which is extremely harmful to academic rigor and originality. The need to develop ChatGPT-written content detection algorithms call for large-scale datasets. In this paper, we initially investigate the possible negative impact of ChatGPT on academia,and present a large-scale CHatGPT-writtEn AbsTract dataset (CHEAT) to support the development of detection algorithms. In particular, the ChatGPT-written abstract dataset contains 35,304 synthetic abstracts, with Generation, Polish, and Mix as prominent representatives. Based on these data, we perform a thorough analysis of the existing text synthesis detection algorithms. We show that ChatGPT-written abstracts are detectable, while the detection difficulty increases with human involvement.Our dataset is available in https://github.com/botianzhe/CHEAT.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Peipeng Yu et al.",
      "keywords": "Computer science; Scale (ratio); Originality; Data science; Plagiarism detection; Information retrieval; Data mining; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.12008",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4399317154",
      "doi": "10.48550/arxiv.2405.20582",
      "title": "The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes",
      "abstract": "Negative patient descriptions and stigmatizing language can contribute to generating healthcare disparities in two ways: (1) read by patients, they can harm their trust and engagement with the medical center; (2) read by physicians, they may negatively influence their perspective of a future patient. In psychiatry, the patient-clinician therapeutic alliance is a major determinant of clinical outcomes. Therefore, language usage in psychiatric clinical notes may not only create healthcare disparities, but also perpetuate them. Recent advances in NLP systems have facilitated the efforts to detect discriminatory language in healthcare. However, such attempts have only focused on the perspectives of the medical center and its physicians. Considering both physicians and non-physicians' point of view is a more translatable approach to identifying potentially harmful language in clinical notes. By leveraging pre-trained and large language models (PLMs and LLMs), this work aims to characterize potentially harmful language usage in psychiatric notes by identifying the sentiment expressed in sentences describing patients based on the reader's point of view. Extracting 39 sentences from the Mount Sinai Health System containing psychiatric lexicon, we fine-tuned three PLMs (RoBERTa, GatorTron, and GatorTron + Task Adaptation) and implemented zero-shot and few-shot ICL approaches for three LLMs (GPT-3.5, Llama-3.1, and Mistral) to classify the sentiment of the sentences according to the physician or non-physician point of view. Results showed that GPT-3.5 aligned best to physician point of view and Mistral aligned best to non-physician point of view. These results underline the importance of recognizing the reader's point of view, not only for improving the note writing process, but also for the quantification, identification, and reduction of bias in computational systems for downstream analyses.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Alissa A. Valentine et al.",
      "keywords": "Point (geometry); Psychiatry; Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.20582",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Human cognitive biases only"
    },
    {
      "openalex_id": "https://openalex.org/W4361865652",
      "doi": "10.48550/arxiv.2303.17071",
      "title": "DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents",
      "abstract": "Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks. In safety-critical applications such as healthcare, the utility of these models is governed by their ability to generate outputs that are factually accurate and complete. In this work, we present dialog-enabled resolving agents (DERA). DERA is a paradigm made possible by the increased conversational abilities of LLMs, namely GPT-4. It provides a simple, interpretable forum for models to communicate feedback and iteratively improve output. We frame our dialog as a discussion between two agent types - a Researcher, who processes information and identifies crucial problem components, and a Decider, who has the autonomy to integrate the Researcher's information and makes judgments on the final output. We test DERA against three clinically-focused tasks. For medical conversation summarization and care plan generation, DERA shows significant improvement over the base GPT-4 performance in both human expert preference evaluations and quantitative metrics. In a new finding, we also show that GPT-4's performance (70%) on an open-ended version of the MedQA question-answering (QA) dataset (Jin et al. 2021, USMLE) is well above the passing level (60%), with DERA showing similar performance. We release the open-ended MEDQA dataset at https://github.com/curai/curai-research/tree/main/DERA.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Varun Nair et al.",
      "keywords": "Dialog box; Computer science; Conversation; Automatic summarization; Autonomy; Natural language; Frame (networking); Natural language processing; Artificial intelligence; Psychology; World Wide Web; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.17071",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4375958655",
      "doi": "10.48550/arxiv.2305.04400",
      "title": "Do Large Language Models Show Decision Heuristics Similar to Humans? A Case Study Using GPT-3.5",
      "abstract": "A Large Language Model (LLM) is an artificial intelligence system that has been trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. GPT-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics, biases, and other decision effects. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (Anchoring Heuristic, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was erroneously influenced by salient anecdotal information (Representativeness and Availability Heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively - even though both presentations contained identical information (Framing Effect, Study 3); and it valued an owned item more than a newly found item even though the two items were identical (Endowment Effect, Study 4). In each study, human participants showed similar effects. Heuristics and related decision effects in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM - which lacks these processes - also shows such effects invites consideration of the possibility that language may play a role in generating these effects in humans.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Gaurav Suri et al.",
      "keywords": "Heuristics; Representativeness heuristic; Cognitive psychology; Cognition; Psychology; Heuristic; Computer science; Salient; Framing effect; Artificial intelligence; Natural language processing; Social psychology; Persuasion",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.04400",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388843580",
      "doi": "10.48550/arxiv.2311.10537",
      "title": "MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning",
      "abstract": "Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we propose MedAgents, a novel multi-disciplinary collaboration framework for the medical domain. MedAgents leverages LLM-based agents in a role-playing setting that participate in a collaborative multi-round discussion, thereby enhancing LLM proficiency and reasoning capabilities. This training-free framework encompasses five critical steps: gathering domain experts, proposing individual analyses, summarising these analyses into a report, iterating over discussions until a consensus is reached, and ultimately making a decision. Our work focuses on the zero-shot setting, which is applicable in real-world scenarios. Experimental results on nine datasets (MedQA, MedMCQA, PubMedQA, and six subtasks from MMLU) establish that our proposed MedAgents framework excels at mining and harnessing the medical expertise within LLMs, as well as extending its reasoning abilities. Our code can be found at https://github.com/gersteinlab/MedAgents.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiangru Tang et al.",
      "keywords": "Domain (mathematical analysis); Computer science; Field (mathematics); Code (set theory); Work (physics); Discipline; Data science; Knowledge management; Political science; Engineering; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.10537",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2737061368",
      "doi": "10.48550/arxiv.1707.06315",
      "title": "FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference",
      "abstract": "A classical problem in causal inference is that of matching, where treatment units need to be matched to control units based on covariate information. In this work, we propose a method that computes high quality almost-exact matches for high-dimensional categorical datasets. This method, called FLAME (Fast Large-scale Almost Matching Exactly), learns a distance metric for matching using a hold-out training data set. In order to perform matching efficiently for large datasets, FLAME leverages techniques that are natural for query processing in the area of database management, and two implementations of FLAME are provided: the first uses SQL queries and the second uses bit-vector techniques. The algorithm starts by constructing matches of the highest quality (exact matches on all covariates), and successively eliminates variables in order to match exactly on as many variables as possible, while still maintaining interpretable high-quality matches and balance between treatment and control groups. We leverage these high quality matches to estimate conditional average treatment effects (CATEs). Our experiments show that FLAME scales to huge datasets with millions of observations where existing state-of-the-art methods fail, and that it achieves significantly better performance than other matching methods.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Sudeepa Roy et al.",
      "keywords": "Causal inference; Matching (statistics); Inference; Scale (ratio); Computer science; Econometrics; Mathematics; Statistics; Artificial intelligence; Geography; Cartography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1707.06315",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417183405",
      "doi": "10.48550/arxiv.2507.02628",
      "title": "Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data",
      "abstract": "Background: The use of Electronic Health Records (EHRs) for epidemiological studies and artificial intelligence (AI) training is increasing rapidly. The reliability of the results depends on the accuracy and completeness of EHR data. However, EHR data often contain significant quality issues, including misrepresentations of subpopulations, biases, and systematic errors, as they are primarily collected for clinical and billing purposes. Existing quality assessment methods remain insufficient, lacking systematic procedures to assess data fitness for research. Methods: We present the Medical Data Pecking approach, which adapts unit testing and coverage concepts from software engineering to identify data quality concerns. We demonstrate our approach using the Medical Data Pecking Tool (MDPT), which consists of two main components: (1) an automated test generator that uses large language models and grounding techniques to create a test suite from data and study descriptions, and (2) a data testing framework that executes these tests, reporting potential errors and coverage. Results: We evaluated MDPT on three datasets: All of Us (AoU), MIMIC-III, and SyntheticMass, generating 55-73 tests per cohort across four conditions. These tests correctly identified 20-43 non-aligned or non-conforming data issues. We present a detailed analysis of the LLM-generated test suites in terms of reference grounding and value accuracy. Conclusion: Our approach incorporates external medical knowledge to enable context-sensitive data quality testing as part of the data analysis workflow to improve the validity of its outcomes. Our approach tackles these challenges from a quality assurance perspective, laying the foundation for further development such as additional data modalities and improved grounding methods.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Irena Girshovitz et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2507.02628",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2787404918",
      "doi": "10.48550/arxiv.1805.04558",
      "title": "NRC-Canada at SMM4H Shared Task: Classifying Tweets Mentioning Adverse Drug Reactions and Medication Intake",
      "abstract": "Our team, NRC-Canada, participated in two shared tasks at the AMIA-2017 Workshop on Social Media Mining for Health Applications (SMM4H): Task 1 - classification of tweets mentioning adverse drug reactions, and Task 2 - classification of tweets describing personal medication intake. For both tasks, we trained Support Vector Machine classifiers using a variety of surface-form, sentiment, and domain-specific features. With nine teams participating in each task, our submissions ranked first on Task 1 and third on Task 2. Handling considerable class imbalance proved crucial for Task 1. We applied an under-sampling technique to reduce class imbalance (from about 1:10 to 1:2). Standard n-gram features, n-grams generalized over domain terms, as well as general-domain and domain-specific word embeddings had a substantial impact on the overall performance in both tasks. On the other hand, including sentiment lexicon features did not result in any improvement.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Svetlana Kiritchenko et al.",
      "keywords": "Lexicon; Task (project management); Computer science; Class (philosophy); Domain (mathematical analysis); Variety (cybernetics); Support vector machine; Natural language processing; Artificial intelligence; Sentiment analysis; Social media; Word (group theory); Machine learning; World Wide Web; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1805.04558",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3131469478",
      "doi": "10.48550/arxiv.2102.09437",
      "title": "hesim: Health Economic Simulation Modeling and Decision Analysis",
      "abstract": "Health economic models simulate the costs and effects of health technologies for use in health technology assessment (HTA) to inform efficient use of scarce resources. Models have historically been developed using spreadsheet software (e.g., Microsoft Excel) and while use of R is growing, general purpose modeling software is still limited. hesim is an R package that helps fill this gap by facilitating parameterization, simulation, and analysis of economic models in an integrated manner. Supported model types include cohort discrete time state transition models (cDTSTMs), individual continuous time state transition models (iCTSTMs), and partitioned survival models (PSMs), encompassing Markov (time-homogeneous and time-inhomogeneous) and semi-Markov processes. A modular design based on R6 and S3 classes allows users to combine separate submodels for disease progression, costs, and utility in a flexible way. Probabilistic sensitivity analysis (PSA) is used to propagate uncertainty in model parameters to model outputs. Simulation code is written in C++ so complex simulations such as those combining PSA and individual simulation can be run much more quickly than previously possible. Decision analysis within a cost-effectiveness framework is performed using simulated costs and quality-adjusted life years (QALYs) from a PSA.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Devin Incerti et al.",
      "keywords": "Modular design; Computer science; Markov model; Markov chain; Probabilistic logic; Software; Sensitivity (control systems); Decision model; Economic model; Operations research; Machine learning; Engineering; Artificial intelligence; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2102.09437",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4401201171",
      "doi": "10.48550/arxiv.2407.19096",
      "title": "AI Companions Reduce Loneliness",
      "abstract": "Chatbots are now able to engage in sophisticated conversations with consumers in the domain of relationships, providing a potential coping solution to widescale societal loneliness. Behavioral research provides little insight into whether these applications are effective at alleviating loneliness. We address this question by focusing on AI companions applications designed to provide consumers with synthetic interaction partners. Studies 1 and 2 find suggestive evidence that consumers use AI companions to alleviate loneliness, by employing a novel methodology for fine tuning large language models to detect loneliness in conversations and reviews. Study 3 finds that AI companions successfully alleviate loneliness on par only with interacting with another person, and more than other activities such watching YouTube videos. Moreover, consumers underestimate the degree to which AI companions improve their loneliness. Study 4 uses a longitudinal design and finds that an AI companion consistently reduces loneliness over the course of a week. Study 5 provides evidence that both the chatbots' performance and, especially, whether it makes users feel heard, explain reductions in loneliness. Study 6 provides an additional robustness check for the loneliness alleviating benefits of AI companions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Julian De Freitas et al.",
      "keywords": "Loneliness; Psychology; Computer science; Cognitive psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.19096",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4305033734",
      "doi": "10.48550/arxiv.2210.05558",
      "title": "Causal and Counterfactual Views of Missing Data Models",
      "abstract": "It is often said that the fundamental problem of causal inference is a missing data problem -- the comparison of responses to two hypothetical treatment assignments is made difficult because for every experimental unit only one potential response is observed. In this paper, we consider the implications of the converse view: that missing data problems are a form of causal inference. We make explicit how the missing data problem of recovering the complete data law from the observed law can be viewed as identification of a joint distribution over counterfactual variables corresponding to values had we (possibly contrary to fact) been able to observe them. Drawing analogies with causal inference, we show how identification assumptions in missing data can be encoded in terms of graphical models defined over counterfactual and observed variables. We review recent results in missing data identification from this viewpoint. In doing so, we note interesting similarities and differences between missing data and causal identification theories.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Razieh Nabi et al.",
      "keywords": "Counterfactual thinking; Missing data; Causal inference; Identification (biology); Inference; Computer science; Converse; Causal model; Causal structure; Econometrics; Mathematics; Artificial intelligence; Machine learning; Statistics; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.05558",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4298324485",
      "doi": "10.48550/arxiv.2103.08310",
      "title": "EmoNet: A Transfer Learning Framework for Multi-Corpus Speech Emotion Recognition",
      "abstract": "In this manuscript, the topic of multi-corpus Speech Emotion Recognition (SER) is approached from a deep transfer learning perspective. A large corpus of emotional speech data, EmoSet, is assembled from a number of existing SER corpora. In total, EmoSet contains 84181 audio recordings from 26 SER corpora with a total duration of over 65 hours. The corpus is then utilised to create a novel framework for multi-corpus speech emotion recognition, namely EmoNet. A combination of a deep ResNet architecture and residual adapters is transferred from the field of multi-domain visual recognition to multi-corpus SER on EmoSet. Compared against two suitable baselines and more traditional training and transfer settings for the ResNet, the residual adapter approach enables parameter efficient training of a multi-domain SER model on all 26 corpora. A shared model with only $3.5$ times the number of parameters of a model trained on a single database leads to increased performance for 21 of the 26 corpora in EmoSet. Measured by McNemar's test, these improvements are further significant for ten datasets at $p&lt;0.05$ while there are just two corpora that see only significant decreases across the residual adapter transfer experiments. Finally, we make our EmoNet framework publicly available for users and developers at https://github.com/EIHW/EmoNet. EmoNet provides an extensive command line interface which is comprehensively documented and can be used in a variety of multi-corpus transfer learning settings.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Maurice Gerczuk et al.",
      "keywords": "Computer science; Transfer of learning; Adapter (computing); Natural language processing; Residual; Artificial intelligence; Speech recognition; Deep learning; Perspective (graphical)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2103.08310",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4400341328",
      "doi": "10.48550/arxiv.2407.00870",
      "title": "Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles",
      "abstract": "Recent works leverage LLMs to roleplay realistic social scenarios, aiding novices in practicing their social skills. However, simulating sensitive interactions, such as in mental health, is challenging. Privacy concerns restrict data access, and collecting expert feedback, although vital, is laborious. To address this, we develop Roleplay-doh, a novel human-LLM collaboration pipeline that elicits qualitative feedback from a domain-expert, which is transformed into a set of principles, or natural language rules, that govern an LLM-prompted roleplay. We apply this pipeline to enable senior mental health supporters to create customized AI patients for simulated practice partners for novice counselors. After uncovering issues in GPT-4 simulations not adhering to expert-defined principles, we also introduce a novel principle-adherence prompting pipeline which shows 30% improvements in response quality and principle following for the downstream task. Via a user study with 25 counseling experts, we demonstrate that the pipeline makes it easy and effective to create AI patients that more faithfully resemble real patients, as judged by creators and third-party counselors. See our project website at https://roleplay-doh.github.io/ for code and data.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ryan Louie et al.",
      "keywords": "Domain (mathematical analysis); Computer science; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.00870",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4406058762",
      "doi": "10.48550/arxiv.2407.13067",
      "title": "Large Language Model Agents for Improving Engagement with Behavior Change Interventions: Application to Digital Mindfulness",
      "abstract": "Although engagement in self-directed wellness exercises typically declines over time, integrating social support such as coaching can sustain it. However, traditional forms of support are often inaccessible due to the high costs and complex coordination. Large Language Models (LLMs) show promise in providing human-like dialogues that could emulate social support. Yet, in-depth, in situ investigations of LLMs to support behavior change remain underexplored. We conducted two randomized experiments to assess the impact of LLM agents on user engagement with mindfulness exercises. First, a single-session study, involved 502 crowdworkers; second, a three-week study, included 54 participants. We explored two types of LLM agents: one providing information and another facilitating self-reflection. Both agents enhanced users' intentions to practice mindfulness. However, only the information-providing LLM, featuring a friendly persona, significantly improved engagement with the exercises. Our findings suggest that specific LLM agents may bridge the social support gap in digital health interventions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Harsh Kumar et al.",
      "keywords": "Mindfulness; Psychological intervention; Psychology; Cognitive psychology; Computer science; Psychotherapist; Applied psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.13067",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293064627",
      "doi": "10.48550/arxiv.1902.10073",
      "title": "Diagnosis of Autism Spectrum Disorder by Causal Influence Strength Learned from Resting-State fMRI Data",
      "abstract": "Autism spectrum disorder (ASD) is one of the major developmental disorders affecting children. Recently, it has been hypothesized that ASD is associated with atypical brain connectivities. A substantial body of researches use Pearson's correlation coefficients, mutual information, or partial correlation to investigate the differences in brain connectivities between ASD and typical controls from functional Magnetic Resonance Imaging (fMRI). However, correlation or partial correlation does not directly reveal causal influences - the information flow - between brain regions. Comparing to correlation, causality pinpoints the key connectivity characteristics and removes redundant features for diagnosis. In this paper, we propose a two-step method for large-scale and cyclic causal discovery from fMRI. It can identify brain causal structures without doing interventional experiments. The learned causal structure, as well as the causal influence strength, provides us the path and effectiveness of information flow. With the recovered causal influence strength as candidate features, we then perform ASD diagnosis by further doing feature selection and classification. We apply our methods to three datasets from Autism Brain Imaging Data Exchange (ABIDE). From experimental results, it shows that with causal connectivities, the diagnostic accuracy largely improves. A closer examination shows that information flows starting from the superior front gyrus to default mode network and posterior areas are largely reduced. Moreover, all enhanced information flows are from posterior to anterior or in local areas. Overall, it shows that long-range influences have a larger proportion of reductions than local ones, while local influences have a larger proportion of increases than long-range ones. By examining the graph properties of brain causal structure, the group of ASD shows reduced small-worldness.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Biwei Huang et al.",
      "keywords": "Correlation; Resting state fMRI; Partial correlation; Functional magnetic resonance imaging; Default mode network; Causal model; Autism spectrum disorder; Autism; Psychology; Causality (physics); Cognitive psychology; Neuroscience; Computer science; Artificial intelligence; Developmental psychology; Mathematics; Statistics; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1902.10073",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319165809",
      "doi": "10.48550/arxiv.2302.00901",
      "title": "Longformer: Longitudinal Transformer for Alzheimer's Disease Classification with Structural MRIs",
      "abstract": "Structural magnetic resonance imaging (sMRI) is widely used for brain neurological disease diagnosis; while longitudinal MRIs are often collected to monitor and capture disease progression, as clinically used in diagnosing Alzheimer's disease (AD). However, most current methods neglect AD's progressive nature and only take a single sMRI for recognizing AD. In this paper, we consider the problem of leveraging the longitudinal MRIs of a subject for AD identification. To capture longitudinal changes in sMRIs, we propose a novel model Longformer, a spatiotemporal transformer network that performs attention mechanisms spatially on sMRIs at each time point and integrates brain region features over time to obtain longitudinal embeddings for classification. Our Longformer achieves state-of-the-art performance on two binary classification tasks of separating different stages of AD using the ADNI dataset. Our source code is available at https://github.com/Qybc/LongFormer.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Qiuhui Chen et al.",
      "keywords": "Computer science; Artificial intelligence; Magnetic resonance imaging; Disease; Transformer; Machine learning; Neuroscience; Medicine; Psychology; Pathology; Radiology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.00901",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4307079183",
      "doi": "10.48550/arxiv.2210.11408",
      "title": "Hierarchical Deep Learning with Generative Adversarial Network for Automatic Cardiac Diagnosis from ECG Signals",
      "abstract": "Cardiac disease is the leading cause of death in the US. Accurate heart disease detection is of critical importance for timely medical treatment to save patients' lives. Routine use of electrocardiogram (ECG) is the most common method for physicians to assess the electrical activities of the heart and detect possible abnormal cardiac conditions. Fully utilizing the ECG data for reliable heart disease detection depends on developing effective analytical models. In this paper, we propose a two-level hierarchical deep learning framework with Generative Adversarial Network (GAN) for automatic diagnosis of ECG signals. The first-level model is composed of a Memory-Augmented Deep auto-Encoder with GAN (MadeGAN), which aims to differentiate abnormal signals from normal ECGs for anomaly detection. The second-level learning aims at robust multi-class classification for different arrhythmias identification, which is achieved by integrating the transfer learning technique to transfer knowledge from the first-level learning with the multi-branching architecture to handle the data-lacking and imbalanced data issue. We evaluate the performance of the proposed framework using real-world medical data from the MIT-BIH arrhythmia database. Experimental results show that our proposed model outperforms existing methods that are commonly used in current practice.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Zekai Wang et al.",
      "keywords": "Computer science; Deep learning; Artificial intelligence; Transfer of learning; Machine learning; Anomaly detection; Encoder; Identification (biology); Heart disease; Pattern recognition (psychology); Data mining; Medicine; Cardiology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2210.11408",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3046342149",
      "doi": "10.48550/arxiv.2008.00142",
      "title": "Bayesian-Assisted Inference from Visualized Data",
      "abstract": "A Bayesian view of data interpretation suggests that a visualization user should update their existing beliefs about a parameter's value in accordance with the amount of information about the parameter value captured by the new observations. Extending recent work applying Bayesian models to understand and evaluate belief updating from visualizations, we show how the predictions of Bayesian inference can be used to guide more rational belief updating. We design a Bayesian inference-assisted uncertainty analogy that numerically relates uncertainty in observed data to the user's subjective uncertainty, and a posterior visualization that prescribes how a user should update their beliefs given their prior beliefs and the observed data. In a pre-registered experiment on 4,800 people, we find that when a newly observed data sample is relatively small (N=158), both techniques reliably improve people's Bayesian updating on average compared to the current best practice of visualizing uncertainty in the observed data. For large data samples (N=5208), where people's updated beliefs tend to deviate more strongly from the prescriptions of a Bayesian model, we find evidence that the effectiveness of the two forms of Bayesian assistance may depend on people's proclivity toward trusting the source of the data. We discuss how our results provide insight into individual processes of belief updating and subjective uncertainty, and how understanding these aspects of interpretation paves the way for more sophisticated interactive visualizations for analysis and communication.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Yea\u2010Seul Kim et al.",
      "keywords": "Bayesian inference; Computer science; Inference; Bayesian probability; Interpretation (philosophy); Visualization; Bayesian statistics; Machine learning; Artificial intelligence; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2008.00142",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396819284",
      "doi": "10.48550/arxiv.2404.17912",
      "title": "SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models",
      "abstract": "Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large Language Models (MLLMs) can automate the creation of accurate and coherent radiological reports. Existing methods often hallucinate details in text-based reports that don't accurately reflect the image content. To mitigate this, we introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort GENeraTion using Vision Language Models), which improves the R2Gen task by integrating a self-refining mechanism into the MLLM framework. We employ a unique self-supervised loss that leverages similarity between pooled image representations and the contextual representations of the generated radiological text, alongside the standard Causal Language Modeling objective, to refine image-text representations. This allows the model to scrutinize and align the generated text through dynamic interaction between a given image and the generated text, therefore reducing hallucination and continuously enhancing nuanced report generation. SERPENT-VLM outperforms existing baselines such as LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and Radiology Objects in COntext (ROCO) datasets, and also proves to be robust against noisy images. A qualitative case study emphasizes the significant advancements towards more sophisticated MLLM frameworks for R2Gen, opening paths for further research into self-supervised refinement in the medical imaging domain.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Manav Nitin Kapadnis et al.",
      "keywords": "Refining (metallurgy); Serpent (symbolism); Computer science; Artificial intelligence; Computer vision; Astrobiology; Physics; Materials science; Metallurgy; Archaeology; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2404.17912",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4292957819",
      "doi": "10.48550/arxiv.2208.09590",
      "title": "Data-Driven Causal Effect Estimation Based on Graphical Causal Modelling: A Survey",
      "abstract": "In many fields of scientific research and real-world applications, unbiased estimation of causal effects from non-experimental data is crucial for understanding the mechanism underlying the data and for decision-making on effective responses or interventions. A great deal of research has been conducted to address this challenging problem from different angles. For estimating causal effect in observational data, assumptions such as Markov condition, faithfulness and causal sufficiency are always made. Under the assumptions, full knowledge such as, a set of covariates or an underlying causal graph, is typically required. A practical challenge is that in many applications, no such full knowledge or only some partial knowledge is available. In recent years, research has emerged to use search strategies based on graphical causal modelling to discover useful knowledge from data for causal effect estimation, with some mild assumptions, and has shown promise in tackling the practical challenge. In this survey, we review these data-driven methods on causal effect estimation for a single treatment with a single outcome of interest and focus on the challenges faced by data-driven causal effect estimation. We concisely summarise the basic concepts and theories that are essential for data-driven causal effect estimation using graphical causal modelling but are scattered around the literature. We identify and discuss the challenges faced by data-driven causal effect estimation and characterise the existing methods by their assumptions and the approaches to tackling the challenges. We analyse the strengths and limitations of the different types of methods and present an empirical evaluation to support the discussions. We hope this review will motivate more researchers to design better data-driven methods based on graphical causal modelling for the challenging problem of causal effect estimation.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Debo Cheng et al.",
      "keywords": "Computer science; Causal structure; Causal inference; Causal model; Estimation; Data science; Graphical model; Causality (physics); Covariate; Machine learning; Management science; Data mining; Econometrics; Mathematics; Statistics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2208.09590",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4200630257",
      "doi": "10.48550/arxiv.2112.01639",
      "title": "Patient-Centered Appraisal of Race-Free Clinical Risk Assessment",
      "abstract": "Until recently, there has been a consensus that clinicians should condition patient risk assessments on all observed patient covariates with predictive power. The broad idea is that knowing more about patients enables more accurate predictions of their health risks and, hence, better clinical decisions. This consensus has recently unraveled with respect to a specific covariate, namely race. There have been increasing calls for race-free risk assessment, arguing that using race to predict patient outcomes contributes to racial disparities and inequities in health care. Writers calling for race-free risk assessment have not studied how it would affect the quality of clinical decisions. Considering the matter from the patient-centered perspective of medical economics yields a disturbing conclusion: Race-free risk assessment would harm patients of all races.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Charles F. Manski",
      "keywords": "Race (biology); Harm; Risk assessment; Affect (linguistics); Health care; Perspective (graphical); Predictive power; Medicine; Quality (philosophy); Covariate; Actuarial science; Psychology; Social psychology; Political science; Sociology; Computer science; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.01639",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4321593536",
      "doi": "10.48550/arxiv.2302.10571",
      "title": "SurvLIMEpy: A Python package implementing SurvLIME",
      "abstract": "In this paper we present SurvLIMEpy, an open-source Python package that implements the SurvLIME algorithm. This method allows to compute local feature importance for machine learning algorithms designed for modelling Survival Analysis data. Our implementation takes advantage of the parallelisation paradigm as all computations are performed in a matrix-wise fashion which speeds up execution time. Additionally, SurvLIMEpy assists the user with visualization tools to better understand the result of the algorithm. The package supports a wide variety of survival models, from the Cox Proportional Hazards Model to deep learning models such as DeepHit or DeepSurv. Two types of experiments are presented in this paper. First, by means of simulated data, we study the ability of the algorithm to capture the importance of the features. Second, we use three open source survival datasets together with a set of survival algorithms in order to demonstrate how SurvLIMEpy behaves when applied to different models.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Cristian Pach\u00f3n-Garc\u00eda et al.",
      "keywords": "Python (programming language); Computer science; R package; Computation; Open source; Visualization; Data mining; Artificial intelligence; Machine learning; Algorithm; Computational science; Programming language; Software",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.10571",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3005485911",
      "doi": "10.48550/arxiv.2002.02353",
      "title": "Conversational Structure Aware and Context Sensitive Topic Model for Online Discussions",
      "abstract": "Millions of online discussions are generated everyday on social media platforms. Topic modelling is an efficient way of better understanding large text datasets at scale. Conventional topic models have had limited success in online discussions, and to overcome their limitations, we use the discussion thread tree structure and propose a \"popularity\" metric to quantify the number of replies to a comment to extend the frequency of word occurrences, and the \"transitivity\" concept to characterize topic dependency among nodes in a nested discussion thread. We build a Conversational Structure Aware Topic Model (CSATM) based on popularity and transitivity to infer topics and their assignments to comments. Experiments on real forum datasets are used to demonstrate improved performance for topic extraction with six different measurements of coherence and impressive accuracy for topic assignments.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Yingcheng Sun et al.",
      "keywords": "Computer science; Popularity; Transitive relation; Thread (computing); Data science; Social media; Topic model; Online discussion; Cohesion (chemistry); Coherence (philosophical gambling strategy); Information retrieval; World Wide Web; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2002.02353",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2768273870",
      "doi": "10.48550/arxiv.1711.05663",
      "title": "Semi-Supervised Approaches to Efficient Evaluation of Model Prediction Performance",
      "abstract": "In many modern machine learning applications, the outcome is expensive or time-consuming to collect while the predictor information is easy to obtain. Semi-supervised learning (SSL) aims at utilizing large amounts of `unlabeled' data along with small amounts of `labeled' data to improve the efficiency of a classical supervised approach. Though numerous SSL classification and prediction procedures have been proposed in recent years, no methods currently exist to evaluate the prediction performance of a working regression model. In the context of developing phenotyping algorithms derived from electronic medical records (EMR), we present an efficient two-step estimation procedure for evaluating a binary classifier based on various prediction performance measures in the semi-supervised (SS) setting. In step I, the labeled data is used to obtain a non-parametrically calibrated estimate of the conditional risk function. In step II, SS estimates of the prediction accuracy parameters are constructed based on the estimated conditional risk function and the unlabeled data. We demonstrate that under mild regularity conditions the proposed estimators are consistent and asymptotically normal. Importantly, the asymptotic variance of the SS estimators is always smaller than that of the supervised counterparts under correct model specification. We also correct for potential overfitting bias in the SS estimators in finite sample with cross-validation and develop a perturbation resampling procedure to approximate their distributions. Our proposals are evaluated through extensive simulation studies and illustrated with two real EMR studies aiming to develop phenotyping algorithms for rheumatoid arthritis and multiple sclerosis.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Jessica Gronsbell et al.",
      "keywords": "Overfitting; Estimator; Computer science; Resampling; Machine learning; Artificial intelligence; Classifier (UML); Binary classification; Supervised learning; Data mining; Support vector machine; Mathematics; Statistics; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1711.05663",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011910373",
      "doi": "10.48550/arxiv.2003.08745",
      "title": "On the Road with 16 Neurons: Mental Imagery with Bio-inspired Deep Neural Networks",
      "abstract": "This paper proposes a strategy for visual prediction in the context of autonomous driving. Humans, when not distracted or drunk, are still the best drivers you can currently find. For this reason we take inspiration from two theoretical ideas about the human mind and its neural organization. The first idea concerns how the brain uses a hierarchical structure of neuron ensembles to extract abstract concepts from visual experience and code them into compact representations. The second idea suggests that these neural perceptual representations are not neutral but functional to the prediction of the future state of affairs in the environment. Similarly, the prediction mechanism is not neutral but oriented to the current planning of a future action. We identify within the deep learning framework two artificial counterparts of the aforementioned neurocognitive theories. We find a correspondence between the first theoretical idea and the architecture of convolutional autoencoders, while we translate the second theory into a training procedure that learns compact representations which are not neutral but oriented to driving tasks, from two distinct perspectives. From a static perspective, we force groups of neural units in the compact representations to distinctly represent specific concepts crucial to the driving task. From a dynamic perspective, we encourage the compact representations to be predictive of how the current road scenario will change in the future. We successfully learn compact representations that use as few as 16 neural units for each of the two basic driving concepts we consider: car and lane. We prove the efficiency of our proposed perceptual representations on the SYNTHIA dataset. Our source code is available at https://github.com/3lis/rnn_vae",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Alice Plebe et al.",
      "keywords": "Computer science; Perception; Artificial intelligence; Perspective (graphical); Context (archaeology); Representation (politics); Artificial neural network; Task (project management); Neurocognitive; Action (physics); Code (set theory); Convolutional neural network; Cognitive science; Machine learning; Cognition; Psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2003.08745",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4221155108",
      "doi": "10.48550/arxiv.2203.12927",
      "title": "Modelling volume-outcome relationships in health care",
      "abstract": "Despite the ongoing strong interest in associations between quality of care and the volume of health care providers, a unified statistical framework for analyzing them is missing, and many studies suffer from poor statistical modelling choices. We propose a flexible, additive mixed model for studying volume-outcome associations in health care that takes into account individual patient characteristics as well as provider-specific effects through a multi-level approach. More specifically, we treat volume as a continuous variable, and its effect on the considered outcome is modelled as a smooth function. We take account of different case-mixes by including patient-specific risk factors and of clustering on the provider level through random intercepts. This strategy enables us to extract a smooth volume effect as well as volume-independent provider effects. These two quantities can be compared directly in terms of their magnitude, which gives insight into the sources of variability of quality of care. Based on a causal DAG, we derive conditions under which the volume-effect can be interpreted as a causal effect. The paper provides confidence sets for each of the estimated quantities relying on joint estimation of all effects and parameters. Our approach is illustrated through simulation studies and an application to German health care data. Keywords: health care quality measurement, volume-outcome analysis, minimum provider volume, additive regression models, random intercept",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Maurilio Gutzeit et al.",
      "keywords": "Outcome (game theory); Volume (thermodynamics); Quality (philosophy); Health care; Econometrics; Random effects model; Cluster analysis; Statistics; Computer science; Data mining; Medicine; Mathematics; Economics; Meta-analysis",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.12927",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392781073",
      "doi": "10.48550/arxiv.2403.07566",
      "title": "An Improved Strategy for Blood Glucose Control Using Multi-Step Deep Reinforcement Learning",
      "abstract": "Blood Glucose (BG) control involves keeping an individual's BG within a healthy range through extracorporeal insulin injections is an important task for people with type 1 diabetes. However,traditional patient self-management is cumbersome and risky. Recent research has been devoted to exploring individualized and automated BG control approaches, among which Deep Reinforcement Learning (DRL) shows potential as an emerging approach. In this paper, we use an exponential decay model of drug concentration to convert the formalization of the BG control problem, which takes into account the delay and prolongedness of drug effects, from a PAE-POMDP (Prolonged Action Effect-Partially Observable Markov Decision Process) to a MDP, and we propose a novel multi-step DRL-based algorithm to solve the problem. The Prioritized Experience Replay (PER) sampling method is also used in it. Compared to single-step bootstrapped updates, multi-step learning is more efficient and reduces the influence from biasing targets. Our proposed method converges faster and achieves higher cumulative rewards compared to the benchmark in the same training environment, and improves the time-in-range (TIR), the percentage of time the patient's BG is within the target range, in the evaluation phase. Our work validates the effectiveness of multi-step reinforcement learning in BG control, which may help to explore the optimal glycemic control measure and improve the survival of diabetic patients.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Weiwei Gu et al.",
      "keywords": "Reinforcement learning; Reinforcement; Control (management); Artificial intelligence; Computer science; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.07566",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3048403893",
      "doi": "10.48550/arxiv.2008.06723",
      "title": "Personality in Healthcare Human Robot Interaction (H-HRI): A Literature Review and Brief Critique",
      "abstract": "Robots are becoming an important way to deliver health care, and personality is vital to understanding their effectiveness. Despite this, there is a lack of a systematic overarching understanding of personality in health care human robot interaction (H-HRI). To address this, the authors conducted a review that identified 18 studies on personality in H-HRI. This paper presents the results of that systematic literature review. Insights are derived from this review regarding the methodologies, outcomes, and samples utilized. The authors of this review discuss findings across this literature while identifying several gaps worthy of attention. Overall, this paper is an important starting point in understanding personality in H-HRI.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Connor Esterwood et al.",
      "keywords": "Personality; Health care; Psychology; Human\u2013robot interaction; Systematic review; Robot; Applied psychology; Social psychology; Computer science; MEDLINE; Artificial intelligence; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2008.06723",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4367859862",
      "doi": "10.48550/arxiv.2305.01056",
      "title": "From Organizations to Individuals: Psychoactive Substance Use By Professional Programmers",
      "abstract": "Psychoactive substances, which influence the brain to alter perceptions and moods, have the potential to have positive and negative effects on critical software engineering tasks. They are widely used in software, but that use is not well understood. We present the results of the first qualitative investigation of the experiences of, and challenges faced by, psychoactive substance users in professional software communities. We conduct a thematic analysis of hour-long interviews with 26 professional programmers who use psychoactive substances at work. Our results provide insight into individual motivations and impacts, including mental health and the relationships between various substances and productivity. Our findings elaborate on socialization effects, including soft skills, stigma, and remote work. The analysis also highlights implications for organizational policy, including positive and negative impacts on recruitment and retention. By exploring individual usage motivations, social and cultural ramifications, and organizational policy, we demonstrate how substance use can permeate all levels of software development.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Kaia Newman et al.",
      "keywords": "Thematic analysis; Socialization; Perception; Psychology; Substance use; Psychoactive substance; Stigma (botany); Applied psychology; Qualitative research; Social psychology; Clinical psychology; Sociology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.01056",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287829773",
      "doi": "10.48550/arxiv.2003.01541",
      "title": "Explainable and Scalable Machine-Learning Algorithms for Detection of Autism Spectrum Disorder using fMRI Data",
      "abstract": "Diagnosing Autism Spectrum Disorder (ASD) is a challenging problem, and is based purely on behavioral descriptions of symptomology (DSM-5/ICD-10), and requires informants to observe children with disorder across different settings (e.g. home, school). Numerous limitations (e.g., informant discrepancies, lack of adherence to assessment guidelines, informant biases) to current diagnostic practices have the potential to result in over-, under-, or misdiagnosis of the disorder. Advances in neuroimaging technologies are providing a critical step towards a more objective assessment of the disorder. Prior research provides strong evidence that structural and functional magnetic resonance imaging (MRI) data collected from individuals with ASD exhibit distinguishing characteristics that differ in local and global spatial, and temporal neural-patterns of the brain. Our proposed deep-learning model ASD-DiagNet exhibits consistently high accuracy for classification of ASD brain scans from neurotypical scans. We have for the first time integrated traditional machine-learning and deep-learning techniques that allows us to isolate ASD biomarkers from MRI data sets. Our method, called Auto-ASD-Network, uses a combination of deep-learning and Support Vector Machines (SVM) to classify ASD scans from neurotypical scans. Such interpretable models would help explain the decisions made by deep-learning techniques leading to knowledge discovery for neuroscientists, and transparent analysis for clinicians.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Taban Eslami et al.",
      "keywords": "Neurotypical; Autism spectrum disorder; Neuroimaging; Artificial intelligence; Machine learning; Support vector machine; Deep learning; Computer science; Artificial neural network; Autism; Psychology; Neuroscience; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2003.01541",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392088230",
      "doi": "10.48550/arxiv.2402.13475",
      "title": "Multi-scale Spatio-temporal Transformer-based Imbalanced Longitudinal Learning for Glaucoma Forecasting from Irregular Time Series Images",
      "abstract": "Glaucoma is one of the major eye diseases that leads to progressive optic nerve fiber damage and irreversible blindness, afflicting millions of individuals. Glaucoma forecast is a good solution to early screening and intervention of potential patients, which is helpful to prevent further deterioration of the disease. It leverages a series of historical fundus images of an eye and forecasts the likelihood of glaucoma occurrence in the future. However, the irregular sampling nature and the imbalanced class distribution are two challenges in the development of disease forecasting approaches. To this end, we introduce the Multi-scale Spatio-temporal Transformer Network (MST-former) based on the transformer architecture tailored for sequential image inputs, which can effectively learn representative semantic information from sequential images on both temporal and spatial dimensions. Specifically, we employ a multi-scale structure to extract features at various resolutions, which can largely exploit rich spatial information encoded in each image. Besides, we design a time distance matrix to scale time attention in a non-linear manner, which could effectively deal with the irregularly sampled data. Furthermore, we introduce a temperature-controlled Balanced Softmax Cross-entropy loss to address the class imbalance issue. Extensive experiments on the Sequential fundus Images for Glaucoma Forecast (SIGF) dataset demonstrate the superiority of the proposed MST-former method, achieving an AUC of 98.6% for glaucoma forecasting. Besides, our method shows excellent generalization capability on the Alzheimer's Disease Neuroimaging Initiative (ADNI) MRI dataset, with an accuracy of 90.3% for mild cognitive impairment and Alzheimer's disease prediction, outperforming the compared method by a large margin.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Xikai Yang et al.",
      "keywords": "Transformer; Computer science; Artificial intelligence; Series (stratigraphy); Scale (ratio); Time series; Glaucoma; Machine learning; Pattern recognition (psychology); Cartography; Geography; Engineering; Geology; Neuroscience; Psychology; Electrical engineering; Voltage",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.13475",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2953283747",
      "doi": "10.48550/arxiv.1709.03453",
      "title": "Research Portfolio Analysis and Topic Prominence",
      "abstract": "Stakeholders in the science system need to decide where to place their bets. Example questions include: Which areas of research should get more funding? Who should we hire? Which projects should we abandon and which new projects should we start? Making informed choices requires knowledge about these research options. Unfortunately, to date research portfolio options have not been defined in a consistent, transparent and relevant manner. Furthermore, we don't know how to define demand for these options. In this article, we address the issues of consistency, transparency, relevance and demand by using a model of science consisting of 91,726 topics (or research options) that contain over 58 million documents. We present a new indicator of topic prominence - a measure of visibility, momentum and, ultimately, demand. We assign over $203 billion of project-level funding data from STAR METRICS to individual topics in science, and show that the indicator of topic prominence, explains over one-third of the variance in current (or future) funding by topic. We also show that highly prominent topics receive far more funding per researcher than topics that are not prominent. Implications of these results for research planning and portfolio analysis by institutions and researchers are emphasized.",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Richard Klavans et al.",
      "keywords": "Portfolio; Transparency (behavior); Consistency (knowledge bases); Relevance (law); Modern portfolio theory; Business; Computer science; Political science; Finance",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1709.03453",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392866719",
      "doi": "10.48550/arxiv.2403.08820",
      "title": "Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns",
      "abstract": "The opioid crisis has been one of the most critical society concerns in the United States. Although the medication assisted treatment (MAT) is recognized as the most effective treatment for opioid misuse and addiction, the various side effects can trigger opioid relapse. In addition to MAT, the dietary nutrition intervention has been demonstrated its importance in opioid misuse prevention and recovery. However, research on the alarming connections between dietary patterns and opioid misuse remain under-explored. In response to this gap, in this paper, we first establish a large-scale multifaceted dietary benchmark dataset related to opioid users at the first attempt and then develop a novel framework - i.e., namely Opioid Misuse Detection with Interpretable Dietary Patterns (Diet-ODIN) - to bridge heterogeneous graph (HG) and large language model (LLM) for the identification of users with opioid misuse and the interpretation of their associated dietary patterns. Specifically, in Diet-ODIN, we first construct an HG to comprehensively incorporate both dietary and health-related information, and then we devise a holistic graph learning framework with noise reduction to fully capitalize both users' individual dietary habits and shared dietary patterns for the detection of users with opioid misuse. To further delve into the intricate correlations between dietary patterns and opioid misuse, we exploit an LLM by utilizing the knowledge obtained from the graph learning model for interpretation. The extensive experimental results based on our established benchmark with quantitative and qualitative measures demonstrate the outstanding performance of Diet-ODIN in exploring the complex interplay between opioid misuse and dietary patterns, by comparison with state-of-the-art baseline methods.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Zheyuan Zhang et al.",
      "keywords": "Opioid; Computer science; Psychology; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.08820",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389983480",
      "doi": "10.48550/arxiv.2312.10620",
      "title": "Human AI Collaboration in Software Engineering: Lessons Learned from a Hands On Workshop",
      "abstract": "This paper investigates the dynamics of human AI collaboration in software engineering, focusing on the use of ChatGPT. Through a thematic analysis of a hands on workshop in which 22 professional software engineers collaborated for three hours with ChatGPT, we explore the transition of AI from a mere tool to a collaborative partner. The study identifies key themes such as the evolving nature of human AI interaction, the capabilities of AI in software engineering tasks, and the challenges and limitations of integrating AI in this domain. The findings show that while AI, particularly ChatGPT, improves the efficiency of code generation and optimization, human oversight remains crucial, especially in areas requiring complex problem solving and security considerations. This research contributes to the theoretical understanding of human AI collaboration in software engineering and provides practical insights for effectively integrating AI tools into development processes. It highlights the need for clear role allocation, effective communication, and balanced AI human collaboration to realize the full potential of AI in software engineering.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Muhammad Hamza et al.",
      "keywords": "Software engineering; Domain (mathematical analysis); Computer science; Software; Software development; Key (lock); Engineering management; Data science; Knowledge management; Engineering; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2312.10620",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3083286135",
      "doi": "10.48550/arxiv.2009.03163",
      "title": "Supporting the Problem-Solving Loop: Designing Highly Interactive Optimisation Systems",
      "abstract": "Efficient optimisation algorithms have become important tools for finding high-quality solutions to hard, real-world problems such as production scheduling, timetabling, or vehicle routing. These algorithms are typically \"black boxes\" that work on mathematical models of the problem to solve. However, many problems are difficult to fully specify, and require a \"human in the loop\" who collaborates with the algorithm by refining the model and guiding the search to produce acceptable solutions. Recently, the Problem-Solving Loop was introduced as a high-level model of such interactive optimisation. Here, we present and evaluate nine recommendations for the design of interactive visualisation tools supporting the Problem-Solving Loop. They range from the choice of visual representation for solutions and constraints to the use of a solution gallery to support exploration of alternate solutions. We first examined the applicability of the recommendations by investigating how well they had been supported in previous interactive optimisation tools. We then evaluated the recommendations in the context of the vehicle routing problem with time windows (VRPTW). To do so we built a sophisticated interactive visual system for solving VRPTW that was informed by the recommendations. Ten participants then used this system to solve a variety of routing problems. We report on participant comments and interaction patterns with the tool. These showed the tool was regarded as highly usable and the results generally supported the usefulness of the underlying recommendations.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie Liu et al.",
      "keywords": "Vehicle routing problem; Computer science; USable; Variety (cybernetics); Visualization; Scheduling (production processes); Representation (politics); Context (archaeology); Routing (electronic design automation); Human\u2013computer interaction; Mathematical optimization; Artificial intelligence; Multimedia; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2009.03163",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4324296975",
      "doi": "10.48550/arxiv.2303.06868",
      "title": "Deep Learning-based Eye-Tracking Analysis for Diagnosis of Alzheimer's Disease Using 3D Comprehensive Visual Stimuli",
      "abstract": "Alzheimer's Disease (AD) causes a continuous decline in memory, thinking, and judgment. Traditional diagnoses are usually based on clinical experience, which is limited by some realistic factors. In this paper, we focus on exploiting deep learning techniques to diagnose AD based on eye-tracking behaviors. Visual attention, as typical eye-tracking behavior, is of great clinical value to detect cognitive abnormalities in AD patients. To better analyze the differences in visual attention between AD patients and normals, we first conduct a 3D comprehensive visual task on a non-invasive eye-tracking system to collect visual attention heatmaps. We then propose a multi-layered comparison convolution neural network (MC-CNN) to distinguish the visual attention differences between AD patients and normals. In MC-CNN, the multi-layered representations of heatmaps are obtained by hierarchical convolution to better encode eye-movement behaviors, which are further integrated into a distance vector to benefit the comprehensive visual task. Extensive experimental results on the collected dataset demonstrate that MC-CNN achieves consistent validity in classifying AD patients and normals with eye-tracking data.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Fangyu Zuo et al.",
      "keywords": "Eye tracking; Computer science; Artificial intelligence; Convolutional neural network; Task (project management); Deep learning; Eye movement; Cognition; Convolution (computer science); Pattern recognition (psychology); Artificial neural network; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.06868",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403662060",
      "doi": "10.48550/arxiv.2409.08738",
      "title": "DataliVR: Transformation of Data Literacy Education through Virtual Reality with ChatGPT-Powered Enhancements",
      "abstract": "Data literacy is essential in today's data-driven world, emphasizing individuals' abilities to effectively manage data and extract meaningful insights. However, traditional classroom-based educational approaches often struggle to fully address the multifaceted nature of data literacy. As education undergoes digital transformation, innovative technologies such as Virtual Reality (VR) offer promising avenues for immersive and engaging learning experiences. This paper introduces DataliVR, a pioneering VR application aimed at enhancing the data literacy skills of university students within a contextual and gamified virtual learning environment. By integrating Large Language Models (LLMs) like ChatGPT as a conversational artificial intelligence (AI) chatbot embodied within a virtual avatar, DataliVR provides personalized learning assistance, enriching user learning experiences. Our study employed an experimental approach, with chatbot availability as the independent variable, analyzing learning experiences and outcomes as dependent variables with a sample of thirty participants. Our approach underscores the effectiveness and user-friendliness of ChatGPT-powered DataliVR in fostering data literacy skills. Moreover, our study examines the impact of the ChatGPT-based AI chatbot on users' learning, revealing significant effects on both learning experiences and outcomes. Our study presents a robust tool for fostering data literacy skills, contributing significantly to the digital advancement of data literacy education through cutting-edge VR and AI technologies. Moreover, our research provides valuable insights and implications for future research endeavors aiming to integrate LLMs (e.g., ChatGPT) into educational VR platforms.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Hong Gao et al.",
      "keywords": "Transformation (genetics); Virtual reality; Literacy; Computer science; Human\u2013computer interaction; Psychology; Pedagogy; Chemistry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.08738",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415330023",
      "doi": "10.48550/arxiv.2504.13002",
      "title": "The Role of Empathy in Software Engineering -- A Socio-Technical Grounded Theory",
      "abstract": "Empathy, defined as the ability to understand and share others' perspectives and emotions, is essential in software engineering (SE), where developers often collaborate with diverse stakeholders. It is also considered as a vital competency in many professional fields such as medicine, healthcare, nursing, animal science, education, marketing, and project management. Despite its importance, empathy remains under-researched in SE. To further explore this, we conducted a socio-technical grounded theory (STGT) study through in-depth semi-structured interviews with 22 software developers and stakeholders. Our study explored the role of empathy in SE and how SE activities and processes can be improved by considering empathy. Through applying the systematic steps of STGT data analysis and theory development, we developed a theory that explains the role of empathy in SE. Our theory details the contexts in which empathy arises, the conditions that shape it, the causes and consequences of its presence and absence. We also identified contingencies for enhancing empathy or overcoming barriers to its expression. Our findings provide practical implications for SE practitioners and researchers, offering a deeper understanding of how to effectively integrate empathy into SE processes.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Hashini Gunatilake et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.13002",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2950405756",
      "doi": "10.48550/arxiv.1902.08886",
      "title": "Risk Aversion to Parameter Uncertainty in Markov Decision Processes with an Application to Slow-Onset Disaster Relief",
      "abstract": "In classical Markov Decision Processes (MDPs), action costs and transition probabilities are assumed to be known, although an accurate estimation of these parameters is often not possible in practice. This study addresses MDPs under cost and transition probability uncertainty and aims to provide a mathematical framework to obtain policies minimizing the risk of high long-term losses due to not knowing the true system parameters. To this end, we utilize the risk measure value-at-risk associated with the expected performance of an MDP model with respect to parameter uncertainty. We provide mixed-integer linear and nonlinear programming formulations and heuristic algorithms for such risk-averse models of MDPs under a finite distribution of the uncertain parameters. Our proposed models and solution methods are illustrated on an inventory management problem for humanitarian relief operations during a slow-onset disaster. The results demonstrate the potential of our risk-averse modeling approach for reducing the risk of highly undesirable outcomes in uncertain/risky environments.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Merve Merakl\u0131 et al.",
      "keywords": "Markov decision process; Mathematical optimization; Heuristic; Computer science; Risk measure; Measure (data warehouse); Stochastic programming; Risk aversion (psychology); Markov process; Action (physics); Integer programming; Markov model; Probability distribution; Markov chain; Operations research; Expected utility hypothesis; Mathematics; Economics; Statistics; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1902.08886",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416453710",
      "doi": "10.48550/arxiv.2505.16982",
      "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine",
      "abstract": "Large Language Models (LLMs) show promise in biomedicine but lack true causal understanding, relying instead on correlations. This paper envisions causal LLM agents that integrate multimodal data (text, images, genomics, etc.) and perform intervention-based reasoning to infer cause-and-effect. Addressing this requires overcoming key challenges: designing safe, controllable agentic frameworks; developing rigorous benchmarks for causal evaluation; integrating heterogeneous data sources; and synergistically combining LLMs with structured knowledge (KGs) and formal causal inference tools. Such agents could unlock transformative opportunities, including accelerating drug discovery through automated hypothesis generation and simulation, enabling personalized medicine through patient-specific causal models. This research agenda aims to foster interdisciplinary efforts, bridging causal concepts and foundation models to develop reliable AI partners for biomedical progress.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Adib Bazgir et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.16982",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4302790774",
      "doi": "10.48550/arxiv.1805.09139",
      "title": "Demographic differences in search engine use with implications for\\n cohort selection",
      "abstract": "The correlation between the demographics of users and the text they write has\\nbeen investigated through literary texts and, more recently, social media.\\nHowever, differences pertaining to language use in search engines has not been\\nthoroughly analyzed, especially for age and gender differences. Such\\ndifferences are important especially due to the growing use of search engine\\ndata in the study of human health, where queries are used to identify patient\\npopulations.\\n Using data from multiple general-purpose Internet search engines gathered\\nover a period of one month we investigate the correlation between demography\\n(age, gender, and income) and the text of queries submitted to search engines.\\n Our results show that females and younger people use longer queries. This\\ndifference is such that females make approximately 25% more queries with 10 or\\nmore words. In the case of queries which identify users as having specific\\nmedical conditions we find that females make 50% more queries than expected,\\nand that this results in patient cohorts which are highly skewed in gender and\\nage, compared to known gender balance.\\n Our results indicate that studies where demographic representation is\\nimportant, such as in the study of health aspect of users or when search\\nengines are evaluated for fairness, care should be taken in the selection of\\nsearch engine data so as to create a representative dataset.\\n",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Elad Yom\u2010Tov",
      "keywords": "Search engine; Demographics; Selection (genetic algorithm); Representation (politics); Computer science; The Internet; Psychology; Demography; Information retrieval; World Wide Web; Artificial intelligence; Sociology; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1805.09139",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414895765",
      "doi": "10.48550/arxiv.2506.01305",
      "title": "VM14K: First Vietnamese Medical Benchmark",
      "abstract": "Medical benchmarks are indispensable for evaluating the capabilities of language models in healthcare for non-English-speaking communities,therefore help ensuring the quality of real-life applications. However, not every community has sufficient resources and standardized methods to effectively build and design such benchmark, and available non-English medical data is normally fragmented and difficult to verify. We developed an approach to tackle this problem and applied it to create the first Vietnamese medical question benchmark, featuring 14,000 multiple-choice questions across 34 medical specialties. Our benchmark was constructed using various verifiable sources, including carefully curated medical exams and clinical records, and eventually annotated by medical experts. The benchmark includes four difficulty levels, ranging from foundational biological knowledge commonly found in textbooks to typical clinical case studies that require advanced reasoning. This design enables assessment of both the breadth and depth of language models' medical understanding in the target language thanks to its extensive coverage and in-depth subject-specific expertise. We release the benchmark in three parts: a sample public set (4k questions), a full public set (10k questions), and a private set (2k questions) used for leaderboard evaluation. Each set contains all medical subfields and difficulty levels. Our approach is scalable to other languages, and we open-source our data construction pipeline to support the development of future multilingual benchmarks in the medical domain.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Thong Nguyen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01305",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4221151633",
      "doi": "10.48550/arxiv.2203.01643",
      "title": "Improving X-ray Diagnostics through Eye-Tracking and XR",
      "abstract": "There is a growing need to assist radiologists in performing X-ray readings and diagnoses fast, comfortably, and effectively. As radiologists strive to maximize productivity, it is essential to consider the impact of reading rooms in interpreting complex examinations and ensure that higher volume and reporting speeds do not compromise patient outcomes. Virtual Reality (VR) is a disruptive technology for clinical practice in assessing X-ray images. We argue that conjugating eye-tracking with VR devices and Machine Learning may overcome obstacles posed by inadequate ergonomic postures and poor room conditions that often cause erroneous diagnostics when professionals examine digital images.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Catarina Moreira et al.",
      "keywords": "Compromise; Eye tracking; Productivity; Medical diagnosis; Computer science; Reading (process); Tracking (education); Medical physics; Human\u2013computer interaction; Medicine; Psychology; Computer vision; Artificial intelligence; Radiology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2203.01643",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3113124659",
      "doi": "10.48550/arxiv.2012.08649",
      "title": "Effect of right censoring bias on survival analysis",
      "abstract": "Kaplan-Meier survival analysis represents the most objective measure of treatment efficacy in oncology, though subjected to potential bias, which is worrisome in an era of precision medicine. Independent of the bias inherent to the design and execution of clinical trials, bias may be the result of patient censoring, or incomplete observation. Unlike disease/progression free survival, overall survival is based on a well defined time point and thus avoids interval censoring, but right-censoring, due to incomplete follow-up, may still be a source of bias. We study three mechanisms of right-censoring and find that one of them, surrogate of patient lost to follow-up, is able to impact Kaplan-Meier survival, improving significantly the estimation of survival in comparison with complete follow-up datasets, as measured by the hazard ratio. We also present two bias indexes able to signal datasets with right-censoring associated overestimation of survival. These bias indexes can detect bias in public available datasets",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "E. Barraj\u00f3n et al.",
      "keywords": "Censoring (clinical trials); Hazard ratio; Survival analysis; Proportional hazards model; Statistics; Confidence interval; Medicine; Econometrics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2012.08649",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415160834",
      "doi": "10.48550/arxiv.2504.10397",
      "title": "Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?",
      "abstract": "Objective: This study investigates the potential of Large Language Models (LLMs) as an alternative to human expert elicitation for extracting structured causal knowledge and facilitating causal modeling in biometric and healthcare applications. Material and Methods: LLM-generated causal structures, specifically Bayesian networks (BNs), were benchmarked against traditional statistical methods (e.g., Bayesian Information Criterion) using healthcare datasets. Validation techniques included structural equation modeling (SEM) to verifying relationships, and measures such as entropy, predictive accuracy, and robustness to compare network structures. Results and Discussion: LLM-generated BNs demonstrated lower entropy than expert-elicited and statistically generated BNs, suggesting higher confidence and precision in predictions. However, limitations such as contextual constraints, hallucinated dependencies, and potential biases inherited from training data require further investigation. Conclusion: LLMs represent a novel frontier in expert elicitation for probabilistic causal modeling, promising to improve transparency and reduce uncertainty in the decision-making using such models.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "O. A. Shaposhnyk et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10397",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4301710678",
      "doi": "10.48550/arxiv.1711.06516",
      "title": "Classification of postoperative surgical site infections from blood\\n measurements with missing data using recurrent neural networks",
      "abstract": "Clinical measurements that can be represented as time series constitute an\\nimportant fraction of the electronic health records and are often both\\nuncertain and incomplete. Recurrent neural networks are a special class of\\nneural networks that are particularly suitable to process time series data but,\\nin their original formulation, cannot explicitly deal with missing data. In\\nthis paper, we explore imputation strategies for handling missing values in\\nclassifiers based on recurrent neural network (RNN) and apply a recently\\nproposed recurrent architecture, the Gated Recurrent Unit with Decay,\\nspecifically designed to handle missing data. We focus on the problem of\\ndetecting surgical site infection in patients by analyzing time series of their\\nblood sample measurements and we compare the results obtained with different\\nRNN-based classifiers.\\n",
      "year": "2017",
      "journal": "arXiv (Cornell University)",
      "authors": "Andreas Storvik Strauman et al.",
      "keywords": "Missing data; Recurrent neural network; Imputation (statistics); Computer science; Artificial intelligence; Artificial neural network; Time series; Machine learning; Data mining; Series (stratigraphy); Health records",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1711.06516",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415311888",
      "doi": "10.48550/arxiv.2506.14451",
      "title": "Adapting Lightweight Vision Language Models for Radiological Visual Question Answering",
      "abstract": "Recent advancements in vision-language systems have improved the accuracy of Radiological Visual Question Answering (VQA) Models. However, some challenges remain across each stage of model development: limited expert-labeled images hinders data procurement at scale; the intricate and nuanced patterns of radiological images make modeling inherently difficult; and the lack of evaluation evaluation efforts makes it difficult to identify cases where the model might be ill-conditioned. In this study, we fine-tune a lightweight 3B parameter vision-language model for Radiological VQA, demonstrating that small models, when appropriately tuned with curated data, can achieve robust performance across both open- and closed-ended questions. We propose a cost-effective training pipeline from synthetic question-answer pair generation to multi-stage fine-tuning on specialised radiological domain-targeted datasets (e.g., ROCO v2.0, MedPix v2.0). Our results show that despite operating at a fraction of the scale of state-of-the-art models such as LLaVA-Med, our model achieves promising performance given its small parameter size and the limited scale of training data. We introduce a lightweight saliency-based diagnostic tool that enables domain experts to inspect VQA model performance and identify ill-conditioned failure modes through saliency analysis.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Aditya Shourya et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.14451",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388963582",
      "doi": "10.48550/arxiv.2311.13307",
      "title": "Rethinking Radiology Report Generation via Causal Inspired Counterfactual Augmentation",
      "abstract": "Radiology Report Generation (RRG) draws attention as a vision-and-language interaction of biomedical fields. Previous works inherited the ideology of traditional language generation tasks, aiming to generate paragraphs with high readability as reports. Despite significant progress, the independence between diseases-a specific property of RRG-was neglected, yielding the models being confused by the co-occurrence of diseases brought on by the biased data distribution, thus generating inaccurate reports. In this paper, to rethink this issue, we first model the causal effects between the variables from a causal perspective, through which we prove that the co-occurrence relationships between diseases on the biased distribution function as confounders, confusing the accuracy through two backdoor paths, i.e. the Joint Vision Coupling and the Conditional Sequential Coupling. Then, we proposed a novel model-agnostic counterfactual augmentation method that contains two strategies, i.e. the Prototype-based Counterfactual Sample Synthesis (P-CSS) and the Magic-Cube-like Counterfactual Report Reconstruction (Cube), to intervene the backdoor paths, thus enhancing the accuracy and generalization of RRG models. Experimental results on the widely used MIMIC-CXR dataset demonstrate the effectiveness of our proposed method. Additionally, a generalization performance is evaluated on IU X-Ray dataset, which verifies our work can effectively reduce the impact of co-occurrences caused by different distributions on the results.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiao Song et al.",
      "keywords": "Counterfactual thinking; Spurious relationship; Causality (physics); Econometrics; Cognitive psychology; Computer science; Psychology; Endogeneity; Coherence (philosophical gambling strategy); Artificial intelligence; Epistemology; Machine learning; Social psychology; Statistics; Mathematics; Philosophy; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.13307",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416118766",
      "doi": "10.48550/arxiv.2504.05156",
      "title": "Blending Queries and Conversations: Understanding Tactics, Trust, Verification, and System Choice in Web Search and Chat Interactions",
      "abstract": "This paper presents a user study (N=22) where participants used an interface combining Web Search and a Generative AI-Chat feature to solve health-related information tasks. We study how people behaved with the interface, why they behaved in certain ways, and what the outcomes of these behaviours were. A think-aloud protocol captured their thought processes during searches. Our findings suggest that GenAI is neither a search panacea nor a major regression compared to standard Web Search interfaces. Qualitative and quantitative analyses identified 78 tactics across five categories and provided insight into how and why different interface features were used. We find evidence that pre-task confidence and trust both influenced which interface feature was used. In both systems, but particularly when using the chat feature, trust was often misplaced in favour of ease-of-use and seemingly perfect answers, leading to increased confidence post-search despite having incorrect results. We discuss what our findings mean in the context of our defined research questions and outline several open questions for future research.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Klaus Mayerhofer et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.05156",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4327810498",
      "doi": "10.48550/arxiv.2303.09041",
      "title": "A Multimodal Data-driven Framework for Anxiety Screening",
      "abstract": "Early screening for anxiety and appropriate interventions are essential to reduce the incidence of self-harm and suicide in patients. Due to limited medical resources, traditional methods that overly rely on physician expertise and specialized equipment cannot simultaneously meet the needs for high accuracy and model interpretability. Multimodal data can provide more objective evidence for anxiety screening to improve the accuracy of models. The large amount of noise in multimodal data and the unbalanced nature of the data make the model prone to overfitting. However, it is a non-differentiable problem when high-dimensional and multimodal feature combinations are used as model inputs and incorporated into model training. This causes existing anxiety screening methods based on machine learning and deep learning to be inapplicable. Therefore, we propose a multimodal data-driven anxiety screening framework, namely MMD-AS, and conduct experiments on the collected health data of over 200 seafarers by smartphones. The proposed framework's feature extraction, dimension reduction, feature selection, and anxiety inference are jointly trained to improve the model's performance. In the feature selection step, a feature selection method based on the Improved Fireworks Algorithm is used to solve the non-differentiable problem of feature combination to remove redundant features and search for the ideal feature subset. The experimental results show that our framework outperforms the comparison methods.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Haimiao Mo et al.",
      "keywords": "Overfitting; Computer science; Interpretability; Feature selection; Machine learning; Artificial intelligence; Feature (linguistics); Dimensionality reduction; Anxiety; Data mining; Medicine; Artificial neural network; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.09041",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4299427492",
      "doi": "10.48550/arxiv.1607.06359",
      "title": "#Sleep_as_Android: Feasibility of Using Sleep Logs on Twitter for Sleep\\n Studies",
      "abstract": "Social media enjoys a growing popularity as a platform to seek and share\\npersonal health information. For sleep studies using data from social media,\\nmost researchers focused on inferring sleep-related artifacts from\\nself-reported anecdotal pointers to sleep patterns or issues such as insomnia.\\nThe data shared by \"quantified-selfers\" on social media presents an opportunity\\nto study more quantitative and objective measures of sleep. We propose and\\nvalidate the approach of collecting and analyzing sleep logs that are generated\\nand shared through a sleep-tracking mobile application. We highlight the value\\nof this data by combining it with users' social media data. The results provide\\na validation of using social media for sleep studies as the collected sleep\\ndata is aligned with sleep data from other sources. The results of combining\\nsocial media data with sleep data provide preliminary evidence that higher\\nsocial media activity is associated with lower sleep duration and quality.\\n",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Fatema Akbar et al.",
      "keywords": "Social media; Popularity; Sleep (system call); Insomnia; Computer science; Sleep quality; Psychology; Internet privacy; Tracking (education); Android (operating system); Actigraphy; Data science; Applied psychology; World Wide Web; Social psychology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1607.06359",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403755033",
      "doi": "10.48550/arxiv.2407.11591",
      "title": "AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization",
      "abstract": "Despite the advances in the abstractive summarization task using Large Language Models (LLM), there is a lack of research that asses their abilities to easily adapt to different domains. We evaluate the domain adaptation abilities of a wide range of LLMs on the summarization task across various domains in both fine-tuning and in-context learning settings. We also present AdaptEval, the first domain adaptation evaluation suite. AdaptEval includes a domain benchmark and a set of metrics to facilitate the analysis of domain adaptation. Our results demonstrate that LLMs exhibit comparable performance in the in-context learning setting, regardless of their parameter scale.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Anum Afzal et al.",
      "keywords": "Automatic summarization; Computer science; Adaptation (eye); Domain adaptation; Natural language processing; Domain (mathematical analysis); Artificial intelligence; Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.11591",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4372273304",
      "doi": "10.48550/arxiv.2305.02691",
      "title": "PGB: A PubMed Graph Benchmark for Heterogeneous Network Representation Learning",
      "abstract": "There has been rapid growth in biomedical literature, yet capturing the heterogeneity of the bibliographic information of these articles remains relatively understudied. Although graph mining research via heterogeneous graph neural networks has taken center stage, it remains unclear whether these approaches capture the heterogeneity of the PubMed database, a vast digital repository containing over 33 million articles. We introduce PubMed Graph Benchmark (PGB), a new benchmark dataset for evaluating heterogeneous graph embeddings for biomedical literature. The benchmark contains rich metadata including abstract, authors, citations, MeSH terms, MeSH hierarchy, and some other information. The benchmark contains three different evaluation tasks encompassing systematic reviews, node classification, and node clustering. In PGB, we aggregate the metadata associated with the biomedical articles from PubMed into a unified source and make the benchmark publicly available for any future works.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Eric W. Lee et al.",
      "keywords": "Computer science; Benchmark (surveying); Metadata; Graph; Cluster analysis; Information retrieval; Node (physics); Data science; Data mining; Theoretical computer science; Artificial intelligence; World Wide Web; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.02691",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4406059502",
      "doi": "10.48550/arxiv.2407.13660",
      "title": "CogniVoice: Multimodal and Multilingual Fusion Networks for Mild Cognitive Impairment Assessment from Spontaneous Speech",
      "abstract": "Mild Cognitive Impairment (MCI) is a medical condition characterized by noticeable declines in memory and cognitive abilities, potentially affecting individual's daily activities. In this paper, we introduce CogniVoice, a novel multilingual and multimodal framework to detect MCI and estimate Mini-Mental State Examination (MMSE) scores by analyzing speech data and its textual transcriptions. The key component of CogniVoice is an ensemble multimodal and multilingual network based on ``Product of Experts'' that mitigates reliance on shortcut solutions. Using a comprehensive dataset containing both English and Chinese languages from TAUKADIAL challenge, CogniVoice outperforms the best performing baseline model on MCI classification and MMSE regression tasks by 2.8 and 4.1 points in F1 and RMSE respectively, and can effectively reduce the performance gap across different language groups by 0.7 points in F1.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jiali Cheng et al.",
      "keywords": "Cognitive impairment; Cognition; Fusion; Psychology; Computer science; Speech recognition; Cognitive psychology; Natural language processing; Linguistics; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2407.13660",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391591241",
      "doi": "10.48550/arxiv.2402.02656",
      "title": "RACER: An LLM-powered Methodology for Scalable Analysis of Semi-structured Mental Health Interviews",
      "abstract": "Semi-structured interviews (SSIs) are a commonly employed data-collection method in healthcare research, offering in-depth qualitative insights into subject experiences. Despite their value, the manual analysis of SSIs is notoriously time-consuming and labor-intensive, in part due to the difficulty of extracting and categorizing emotional responses, and challenges in scaling human evaluation for large populations. In this study, we develop RACER, a Large Language Model (LLM) based expert-guided automated pipeline that efficiently converts raw interview transcripts into insightful domain-relevant themes and sub-themes. We used RACER to analyze SSIs conducted with 93 healthcare professionals and trainees to assess the broad personal and professional mental health impacts of the COVID-19 crisis. RACER achieves moderately high agreement with two human evaluators (72%), which approaches the human inter-rater agreement (77%). Interestingly, LLMs and humans struggle with similar content involving nuanced emotional, ambivalent/dialectical, and psychological statements. Our study highlights the opportunities and challenges in using LLMs to improve research efficiency and opens new avenues for scalable analysis of SSIs in healthcare research.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Satpreet Singh et al.",
      "keywords": "Mental health; Scalability; Psychology; Computer science; Applied psychology; Psychotherapist",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.02656",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415065867",
      "doi": "10.48550/arxiv.2504.16489",
      "title": "Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based Multi-Agent Debate",
      "abstract": "Multi-Agent Debate (MAD), leveraging collaborative interactions among Large Language Models (LLMs), aim to enhance reasoning capabilities in complex tasks. However, the security implications of their iterative dialogues and role-playing characteristics, particularly susceptibility to jailbreak attacks eliciting harmful content, remain critically underexplored. This paper systematically investigates the jailbreak vulnerabilities of four prominent MAD frameworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo, and DeepSeek) without compromising internal agents. We introduce a novel structured prompt-rewriting framework specifically designed to exploit MAD dynamics via narrative encapsulation, role-driven escalation, iterative refinement, and rhetorical obfuscation. Our extensive experiments demonstrate that MAD systems are inherently more vulnerable than single-agent setups. Crucially, our proposed attack methodology significantly amplifies this fragility, increasing average harmfulness from 28.14% to 80.34% and achieving attack success rates as high as 80% in certain scenarios. These findings reveal intrinsic vulnerabilities in MAD architectures and underscore the urgent need for robust, specialized defenses prior to real-world deployment.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Senmao Qi et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.16489",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415134973",
      "doi": "10.48550/arxiv.2506.02856",
      "title": "Exploring listeners' perceptions of AI-generated and human-composed music for functional emotional applications",
      "abstract": "This work investigates how listeners perceive and evaluate AI-generated as compared to human-composed music in the context of emotional resonance and regulation. Across a mixed-methods design, participants were exposed to both AI and human music under various labeling conditions (music correctly labeled as AI- or human-origin, music incorrectly labeled as AI- or human-origin, and unlabeled music) and emotion cases (Calm and Upbeat), and were asked to rate preference, efficacy of target emotion elicitation, and emotional impact. Participants were significantly more likely to rate human-composed music, regardless of labeling, as more effective at eliciting target emotional states, though quantitative analyses revealed no significant differences in emotional response. However, participants were significantly more likely to indicate preference for AI-generated music, yielding further questions regarding the impact of emotional authenticity and perceived authorship on musical appraisal. Qualitative data underscored this, with participants associating humanness with qualities such as imperfection, flow, and 'soul.' These findings challenge the assumption that preference alone signals success in generative music systems. Rather than positioning AI tools as replacements for human creativity or emotional expression, they point toward a more careful design ethos that acknowledges the limits of replication and prioritizes human values such as authenticity, individuality, and emotion regulation in wellness and affective technologies.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Kimaya Lecamwasam et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.02856",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416609489",
      "doi": "10.48550/arxiv.2505.23132",
      "title": "Patient Domain Supervised Contrastive Learning for Lung Sound Classification Using Mobile Phone",
      "abstract": "Auscultation is crucial for diagnosing lung diseases. The COVID-19 pandemic has revealed the limitations of traditional, in-person lung sound assessments. To overcome these issues, advancements in digital stethoscopes and artificial intelligence (AI) have led to the development of new diagnostic methods. In this context, our study aims to use smartphone microphones to record and analyze lung sounds. We faced two major challenges: the difference in audio style between electronic stethoscopes and smartphone microphones, and the variability among patients. To address these challenges, we developed a method called Patient Domain Supervised Contrastive Learning (PD-SCL). By integrating this method with the Audio Spectrogram Transformer (AST) model, we significantly improved its performance by 2.4\\% compared to the original AST model. This progress demonstrates that smartphones can effectively diagnose lung sounds, addressing inconsistencies in patient data and showing potential for broad use beyond traditional clinical settings. Our research contributes to making lung disease detection more accessible in the post-COVID-19 world.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Seung Gyu Jeong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23132",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287236080",
      "doi": "10.48550/arxiv.2104.03739",
      "title": "CARRNN: A Continuous Autoregressive Recurrent Neural Network for Deep Representation Learning from Sporadic Temporal Data",
      "abstract": "Learning temporal patterns from multivariate longitudinal data is challenging especially in cases when data is sporadic, as often seen in, e.g., healthcare applications where the data can suffer from irregularity and asynchronicity as the time between consecutive data points can vary across features and samples, hindering the application of existing deep learning models that are constructed for complete, evenly spaced data with fixed sequence lengths. In this paper, a novel deep learning-based model is developed for modeling multiple temporal features in sporadic data using an integrated deep learning architecture based on a recurrent neural network (RNN) unit and a continuous-time autoregressive (CAR) model. The proposed model, called CARRNN, uses a generalized discrete-time autoregressive model that is trainable end-to-end using neural networks modulated by time lags to describe the changes caused by the irregularity and asynchronicity. It is applied to multivariate time-series regression tasks using data provided for Alzheimer's disease progression modeling and intensive care unit (ICU) mortality rate prediction, where the proposed model based on a gated recurrent unit (GRU) achieves the lowest prediction errors among the proposed RNN-based models and state-of-the-art methods using GRUs and long short-term memory (LSTM) networks in their architecture.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Mostafa Mehdipour Ghazi et al.",
      "keywords": "Autoregressive model; Recurrent neural network; Deep learning; Computer science; Artificial intelligence; Multivariate statistics; Time series; Artificial neural network; Temporal database; Data modeling; Pattern recognition (psychology); Machine learning; Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2104.03739",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2950963272",
      "doi": "10.48550/arxiv.1604.02018",
      "title": "ANOVA model for network meta-analysis of diagnostic test accuracy data",
      "abstract": "Network meta-analysis (NMA) allow combining efficacy information from multiple comparisons from trials assessing different therapeutic interventions for a given disease and to estimate unobserved comparisons from a network of observed comparisons. Applying NMA on diagnostic accuracy studies is a statistical challenge given the inherent correlation of sensitivity and specificity. A conceptually simple and novel hierarchical arm-based (AB) model which expresses the logit transformed sensitivity and specificity as sum of fixed effects for test, correlated study-effects and a random error associated with various tests evaluated in given study is proposed. We apply the model to previously published meta-analyses assessing the accuracy of diverse cytological and molecular tests used to triage women with minor cervical lesions to detect cervical precancer and the results compared with those from the contrast-based (CB) model which expresses the linear predictor as a contrast to a comparator test. The proposed AB model is more appealing than the CB model in that it yields the marginal means which are easily interpreted and makes use of all available data and easily accommodates more general variance-covariance matrix structures.",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Victoria Nyawira Nyaga et al.",
      "keywords": "Contrast (vision); Random effects model; Meta-analysis; Statistics; Covariance matrix; Computer science; Sensitivity (control systems); Linear model; Covariance; Mathematics; Data mining; Artificial intelligence; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1604.02018",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415328974",
      "doi": "10.48550/arxiv.2505.15471",
      "title": "CoLA: Collaborative Low-Rank Adaptation",
      "abstract": "The scaling law of Large Language Models (LLMs) reveals a power-law relationship, showing diminishing return on performance as model scale increases. While training LLMs from scratch is resource-intensive, fine-tuning a pre-trained model for specific tasks has become a practical alternative. Full fine-tuning (FFT) achieves strong performance; however, it is computationally expensive and inefficient. Parameter-efficient fine-tuning (PEFT) methods, like LoRA, have been proposed to address these challenges by freezing the pre-trained model and adding lightweight task-specific modules. LoRA, in particular, has proven effective, but its application to multi-task scenarios is limited by interference between tasks. Recent approaches, such as Mixture-of-Experts (MOE) and asymmetric LoRA, have aimed to mitigate these issues but still struggle with sample scarcity and noise interference due to their fixed structure. In response, we propose CoLA, a more flexible LoRA architecture with an efficient initialization scheme, and introduces three collaborative strategies to enhance performance by better utilizing the quantitative relationships between matrices $A$ and $B$. Our experiments demonstrate the effectiveness and robustness of CoLA, outperforming existing PEFT methods, especially in low-sample scenarios. Our data and code are fully publicly available at https://github.com/zyy-2001/CoLA.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yongquan Zhou et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.15471",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4379958233",
      "doi": "10.48550/arxiv.2306.04337",
      "title": "A study on the impact of Self-Supervised Learning on automatic dysarthric speech assessment",
      "abstract": "Automating dysarthria assessments offers the opportunity to develop practical, low-cost tools that address the current limitations of manual and subjective assessments. Nonetheless, the small size of most dysarthria datasets makes it challenging to develop automated assessment. Recent research showed that speech representations from models pre-trained on large unlabelled data can enhance Automatic Speech Recognition (ASR) performance for dysarthric speech. We are the first to evaluate the representations from pre-trained state-of-the-art Self-Supervised models across three downstream tasks on dysarthric speech: disease classification, word recognition and intelligibility classification, and under three noise scenarios on the UA-Speech dataset. We show that HuBERT is the most versatile feature extractor across dysarthria classification, word recognition, and intelligibility classification, achieving respectively $+24.7\\%, +61\\%, \\text{and} +7.2\\%$ accuracy compared to classical acoustic features.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xavier F. Cadet et al.",
      "keywords": "Reliability (semiconductor); Dysarthria; Reliability engineering; Speech recognition; Psychology; Computer science; Natural language processing; Audiology; Engineering; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.04337",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392019925",
      "doi": "10.48550/arxiv.2402.12676",
      "title": "Advancing Monocular Video-Based Gait Analysis Using Motion Imitation with Physics-Based Simulation",
      "abstract": "Gait analysis from videos obtained from a smartphone would open up many clinical opportunities for detecting and quantifying gait impairments. However, existing approaches for estimating gait parameters from videos can produce physically implausible results. To overcome this, we train a policy using reinforcement learning to control a physics simulation of human movement to replicate the movement seen in video. This forces the inferred movements to be physically plausible, while improving the accuracy of the inferred step length and walking velocity.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Nikolaos Smyrnakis et al.",
      "keywords": "Imitation; Monocular; Motion (physics); Computer vision; Motion analysis; Gait; Gait analysis; Artificial intelligence; Computer science; Computer graphics (images); Physical medicine and rehabilitation; Psychology; Neuroscience; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.12676",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4296945669",
      "doi": "10.48550/arxiv.1611.01373",
      "title": "Efficient Monte Carlo Estimation of the Expected Value of Sample\\n Information using Moment Matching",
      "abstract": "The Expected Value of Sample Information (EVSI) is used to calculate the\\neconomic value of a new research strategy. While this value would be important\\nto both researchers and funders, there are very few practical applications of\\nthe EVSI. In the main, this is due to computational difficulties associated\\nwith calculating the EVSI in practical health economic models using nested\\nsimulations. We present an approximation method for the EVSI that is based on\\nestimating the distribution of the posterior mean of the incremental net\\nbenefit across all the possible future samples, known as the distribution of\\nthe preposterior mean. Specifically, we suggest that this distribution is\\nestimated using moment matching coupled with simulations that are available for\\nprobabilistic sensitivity analysis, which is typically mandatory in health\\neconomic evaluation. We demonstrate that this method is successful using an\\nexample that has previously been applied to other EVSI approximation methods.\\nWe then conclude by discussing how our method fits in with other recent\\nadditions to the literature that detail approximation methods for the EVSI.\\n",
      "year": "2016",
      "journal": "arXiv (Cornell University)",
      "authors": "Anna Heath et al.",
      "keywords": "Moment (physics); Matching (statistics); Monte Carlo method; Sample (material); Computer science; Econometrics; Distribution (mathematics); Value (mathematics); Probabilistic logic; Mathematical optimization; Applied mathematics; Mathematics; Statistics; Physics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1611.01373",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416052253",
      "doi": "10.48550/arxiv.2504.11008",
      "title": "MediSee: Reasoning-based Pixel-level Perception in Medical Images",
      "abstract": "Despite remarkable advancements in pixel-level medical image perception, existing methods are either limited to specific tasks or heavily rely on accurate bounding boxes or text labels as input prompts. However, the medical knowledge required for input is a huge obstacle for general public, which greatly reduces the universality of these methods. Compared with these domain-specialized auxiliary information, general users tend to rely on oral queries that require logical reasoning. In this paper, we introduce a novel medical vision task: Medical Reasoning Segmentation and Detection (MedSD), which aims to comprehend implicit queries about medical images and generate the corresponding segmentation mask and bounding box for the target object. To accomplish this task, we first introduce a Multi-perspective, Logic-driven Medical Reasoning Segmentation and Detection (MLMR-SD) dataset, which encompasses a substantial collection of medical entity targets along with their corresponding reasoning. Furthermore, we propose MediSee, an effective baseline model designed for medical reasoning segmentation and detection. The experimental results indicate that the proposed method can effectively address MedSD with implicit colloquial queries and outperform traditional medical referring segmentation methods.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Qinyue Tong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.11008",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403747393",
      "doi": "10.48550/arxiv.2409.12493",
      "title": "ConvexECG: Lightweight and Explainable Neural Networks for Personalized, Continuous Cardiac Monitoring",
      "abstract": "We present ConvexECG, an explainable and resource-efficient method for reconstructing six-lead electrocardiograms (ECG) from single-lead data, aimed at advancing personalized and continuous cardiac monitoring. ConvexECG leverages a convex reformulation of a two-layer ReLU neural network, enabling the potential for efficient training and deployment in resource constrained environments, while also having deterministic and explainable behavior. Using data from 25 patients, we demonstrate that ConvexECG achieves accuracy comparable to larger neural networks while significantly reducing computational overhead, highlighting its potential for real-time, low-resource monitoring applications.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Rayan Ansari et al.",
      "keywords": "Artificial neural network; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.12493",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4320085936",
      "doi": "10.48550/arxiv.2207.07565",
      "title": "Variance as a predictor of health outcomes: Subject-level trajectories and variability of sex hormones to predict body fat changes in peri- and post-menopausal women",
      "abstract": "Longitudinal biomarker data and cross-sectional outcomes are routinely collected in modern epidemiology studies, often with the goal of informing tailored early intervention decisions. For example, hormones such as estradiol and follicle-stimulating hormone may predict changes in womens' health during the midlife. Most existing methods focus on constructing predictors from mean marker trajectories. However, subject-level biomarker variability may also provide critical information about disease risks and health outcomes. In this paper, we develop a joint model that estimates subject-level means and variances of longitudinal biomarkers to predict a cross-sectional health outcome. Simulations demonstrate excellent recovery of true model parameters. The proposed method provides less biased and more efficient estimates, relative to alternative approaches that either ignore subject-level differences in variances or perform two-stage estimation where estimated marker variances are treated as observed. Analyses of women's health data reveal larger variability of E2 or larger variability of FSH were associated with higher levels of fat mass change and higher levels of lean mass change across the menopausal transition.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Irena Chen et al.",
      "keywords": "Biomarker; Body mass index; Medicine; Demography; Variance (accounting); Hormone; Gerontology; Psychology; Statistics; Econometrics; Internal medicine; Biology; Mathematics; Economics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2207.07565",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4380136716",
      "doi": "10.48550/arxiv.2306.05297",
      "title": "Connectional-Style-Guided Contextual Representation Learning for Brain Disease Diagnosis",
      "abstract": "Structural magnetic resonance imaging (sMRI) has shown great clinical value and has been widely used in deep learning (DL) based computer-aided brain disease diagnosis. Previous approaches focused on local shapes and textures in sMRI that may be significant only within a particular domain. The learned representations are likely to contain spurious information and have a poor generalization ability in other diseases and datasets. To facilitate capturing meaningful and robust features, it is necessary to first comprehensively understand the intrinsic pattern of the brain that is not restricted within a single data/task domain. Considering that the brain is a complex connectome of interlinked neurons, the connectional properties in the brain have strong biological significance, which is shared across multiple domains and covers most pathological information. In this work, we propose a connectional style contextual representation learning model (CS-CRL) to capture the intrinsic pattern of the brain, used for multiple brain disease diagnosis. Specifically, it has a vision transformer (ViT) encoder and leverages mask reconstruction as the proxy task and Gram matrices to guide the representation of connectional information. It facilitates the capture of global context and the aggregation of features with biological plausibility. The results indicate that CS-CRL achieves superior accuracy in multiple brain disease diagnosis tasks across six datasets and three diseases and outperforms state-of-the-art models. Furthermore, we demonstrate that CS-CRL captures more brain-network-like properties, better aggregates features, is easier to optimize and is more robust to noise, which explains its superiority in theory. Our source code will be released soon.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Gongshu Wang et al.",
      "keywords": "Computer science; Artificial intelligence; Human Connectome Project; Machine learning; Spurious relationship; Representation (politics); Functional magnetic resonance imaging; Feature learning; Context (archaeology); Neuroscience; Functional connectivity; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.05297",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4406030934",
      "doi": "10.48550/arxiv.2501.00199",
      "title": "GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study",
      "abstract": "Depression has impacted millions of people worldwide and has become one of the most prevalent mental disorders. Early mental disorder detection can lead to cost savings for public health agencies and avoid the onset of other major comorbidities. Additionally, the shortage of specialized personnel is a critical issue because clinical depression diagnosis is highly dependent on expert professionals and is time consuming. In this study, we explore the use of GPT-4 for clinical depression assessment based on transcript analysis. We examine the model's ability to classify patient interviews into binary categories: depressed and not depressed. A comparative analysis is conducted considering prompt complexity (e.g., using both simple and complex prompts) as well as varied temperature settings to assess the impact of prompt complexity and randomness on the model's performance. Results indicate that GPT-4 exhibits considerable variability in accuracy and F1-Score across configurations, with optimal performance observed at lower temperature values (0.0-0.2) for complex prompts. However, beyond a certain threshold (temperature &gt;= 0.3), the relationship between randomness and performance becomes unpredictable, diminishing the gains from prompt complexity. These findings suggest that, while GPT-4 shows promise for clinical assessment, the configuration of the prompts and model parameters requires careful calibration to ensure consistent results. This preliminary study contributes to understanding the dynamics between prompt engineering and large language models, offering insights for future development of AI-powered tools in clinical settings.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Giuliano Lorenzoni et al.",
      "keywords": "Depression (economics); Medicine; Psychology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2501.00199",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2952312702",
      "doi": "10.48550/arxiv.1508.00375",
      "title": "360 Quantified Self",
      "abstract": "Wearable devices with a wide range of sensors have contributed to the rise of the Quantified Self movement, where individuals log everything ranging from the number of steps they have taken, to their heart rate, to their sleeping patterns. Sensors do not, however, typically sense the social and ambient environment of the users, such as general life style attributes or information about their social network. This means that the users themselves, and the medical practitioners, privy to the wearable sensor data, only have a narrow view of the individual, limited mainly to certain aspects of their physical condition. In this paper we describe a number of use cases for how social media can be used to complement the check-up data and those from sensors to gain a more holistic view on individuals' health, a perspective we call the 360 Quantified Self. Health-related information can be obtained from sources as diverse as food photo sharing, location check-ins, or profile pictures. Additionally, information from a person's ego network can shed light on the social dimension of wellbeing which is widely acknowledged to be of utmost importance, even though they are currently rarely used for medical diagnosis. We articulate a long-term vision describing the desirable list of technical advances and variety of data to achieve an integrated system encompassing Electronic Health Records (EHR), data from wearable devices, alongside information derived from social media data.",
      "year": "2015",
      "journal": "arXiv (Cornell University)",
      "authors": "Hamed Haddadi et al.",
      "keywords": "Wearable computer; Computer science; Wearable technology; Data science; Dimension (graph theory); Human\u2013computer interaction; Variety (cybernetics); Social media; Perspective (graphical); Internet privacy; World Wide Web; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1508.00375",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286894560",
      "doi": "10.48550/arxiv.2110.13262",
      "title": "Covariate Balancing Methods for Randomized Controlled Trials Are Not\\n Adversarially Robust",
      "abstract": "The first step towards investigating the effectiveness of a treatment via a\\nrandomized trial is to split the population into control and treatment groups\\nthen compare the average response of the treatment group receiving the\\ntreatment to the control group receiving the placebo.\\n In order to ensure that the difference between the two groups is caused only\\nby the treatment, it is crucial that the control and the treatment groups have\\nsimilar statistics. Indeed, the validity and reliability of a trial are\\ndetermined by the similarity of two groups' statistics. Covariate balancing\\nmethods increase the similarity between the distributions of the two groups'\\ncovariates. However, often in practice, there are not enough samples to\\naccurately estimate the groups' covariate distributions. In this paper, we\\nempirically show that covariate balancing with the Standardized Means\\nDifference (SMD) covariate balancing measure, as well as Pocock's sequential\\ntreatment assignment method, are susceptible to worst-case treatment\\nassignments. Worst-case treatment assignments are those admitted by the\\ncovariate balance measure, but result in highest possible ATE estimation\\nerrors. We developed an adversarial attack to find adversarial treatment\\nassignment for any given trial. Then, we provide an index to measure how close\\nthe given trial is to the worst-case. To this end, we provide an\\noptimization-based algorithm, namely Adversarial Treatment ASsignment in\\nTREatment Effect Trials (ATASTREET), to find the adversarial treatment\\nassignments.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Hossein Babaei et al.",
      "keywords": "Covariate; Statistics; Treatment and control groups; Mathematics; Randomized experiment; Measure (data warehouse); Randomized controlled trial; Average treatment effect; Econometrics; Computer science; Medicine; Data mining; Estimator; Surgery",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.13262",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415109430",
      "doi": "10.48550/arxiv.2506.14367",
      "title": "DGG-XNet: A Hybrid Deep Learning Framework for Multi-Class Brain Disease Classification with Explainable AI",
      "abstract": "Accurate diagnosis of brain disorders such as Alzheimer's disease and brain tumors remains a critical challenge in medical imaging. Conventional methods based on manual MRI analysis are often inefficient and error-prone. To address this, we propose DGG-XNet, a hybrid deep learning model integrating VGG16 and DenseNet121 to enhance feature extraction and classification. DenseNet121 promotes feature reuse and efficient gradient flow through dense connectivity, while VGG16 contributes strong hierarchical spatial representations. Their fusion enables robust multiclass classification of neurological conditions. Grad-CAM is applied to visualize salient regions, enhancing model transparency. Trained on a combined dataset from BraTS 2021 and Kaggle, DGG-XNet achieved a test accuracy of 91.33\\%, with precision, recall, and F1-score all exceeding 91\\%. These results highlight DGG-XNet's potential as an effective and interpretable tool for computer-aided diagnosis (CAD) of neurodegenerative and oncological brain disorders.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Sumshun Nahar Eity et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.14367",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287323717",
      "doi": "10.48550/arxiv.2102.12376",
      "title": "Relating Reading, Visualization, and Coding for New Programmers: A\\n Neuroimaging Study",
      "abstract": "Understanding how novices reason about coding at a neurological level has\\nimplications for training the next generation of software engineers. In recent\\nyears, medical imaging has been increasingly employed to investigate patterns\\nof neural activity associated with coding activity. However, such studies have\\nfocused on advanced undergraduates and professionals. In a human study of 31\\nparticipants, we use functional near-infrared spectroscopy to measure the\\nneural activity associated with introductory programming. In a controlled,\\ncontrast-based experiment, we relate brain activity when coding to that of\\nreading natural language or mentally rotating objects (a spatial visualization\\ntask). Our primary result is that all three tasks -- coding, prose reading, and\\nmental rotation -- are mentally distinct for novices. However, while those\\ntasks are neurally distinct, we find more significant differences between prose\\nand coding than between mental rotation and coding. Intriguingly, we generally\\nfind more activation in areas of the brain associated with spatial ability and\\ntask difficulty for novice coding compared to that reported in studies with\\nmore expert developers. Finally, in an exploratory analysis, we also find a\\nneural activation pattern predictive of programming performance 11 weeks later.\\nWhile preliminary, these findings both expand on previous results (e.g.,\\nrelating expertise to a similarity between coding and prose reading) and also\\nprovide a new understanding of the cognitive processes underlying novice\\nprogramming.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Madeline Endres et al.",
      "keywords": "Coding (social sciences); Computer science; Brain activity and meditation; Mental rotation; Cognition; Visualization; Neuroimaging; Cognitive psychology; Psychology; Artificial intelligence; Neuroscience; Electroencephalography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2102.12376",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2981191774",
      "doi": "10.48550/arxiv.1910.09444",
      "title": "Towards better healthcare: What could and should be automated?",
      "abstract": "While artificial intelligence (AI) and other automation technologies might lead to enormous progress in healthcare, they may also have undesired consequences for people working in the field. In this interdisciplinary study, we capture empirical evidence of not only what healthcare work could be automated, but also what should be automated. We quantitatively investigate these research questions by utilizing probabilistic machine learning models trained on thousands of ratings, provided by both healthcare practitioners and automation experts. Based on our findings, we present an analytical tool (Automatability-Desirability Matrix) to support policymakers and organizational leaders in developing practical strategies on how to harness the positive power of automation technologies, while accompanying change and empowering stakeholders in a participatory fashion.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Wolfgang Fr\u00fchwirt et al.",
      "keywords": "Automation; Health care; Knowledge management; Field (mathematics); Data science; Computer science; Citizen journalism; Work (physics); Engineering; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1910.09444",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288090420",
      "doi": "",
      "title": "Towards better healthcare: What could and should be automated?",
      "abstract": "While artificial intelligence (AI) and other automation technologies might lead to enormous progress in healthcare, they may also have undesired consequences for people working in the field. In this interdisciplinary study, we capture empirical evidence of not only what healthcare work could be automated, but also what should be automated. We quantitatively investigate these research questions by utilizing probabilistic machine learning models trained on thousands of ratings, provided by both healthcare practitioners and automation experts. Based on our findings, we present an analytical tool (Automatability-Desirability Matrix) to support policymakers and organizational leaders in developing practical strategies on how to harness the positive power of automation technologies, while accompanying change and empowering stakeholders in a participatory fashion.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Wolfgang Fr\u00fchwirt et al.",
      "keywords": "Automation; Health care; Knowledge management; Field (mathematics); Computer science; Data science; Citizen journalism; Work (physics); Artificial intelligence; Engineering; Political science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://openalex.org/W4288090420",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417172989",
      "doi": "10.48550/arxiv.2504.20970",
      "title": "SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features",
      "abstract": "Accurate and early diagnosis of pneumonia through X-ray imaging is essential for effective treatment and improved patient outcomes. Recent advancements in machine learning have enabled automated diagnostic tools that assist radiologists in making more reliable and efficient decisions. In this work, we propose a Singular Value Decomposition-based Least Squares (SVD-LS) framework for multi-class pneumonia classification, leveraging powerful feature representations from state-of-the-art self-supervised and transfer learning models. Rather than relying on computationally expensive gradient-based fine-tuning, we employ a closed-form, non-iterative classification approach that ensures efficiency without compromising accuracy. Experimental results demonstrate that SVD-LS achieves competitive performance while offering significantly reduced computational costs, making it a viable alternative for real-time medical imaging applications. The implementation is available at: github.com/meterdogan07/SVD-LS.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "M. Burak Erdo\u011fan et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.20970",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392933354",
      "doi": "10.48550/arxiv.2403.10420",
      "title": "Hearing-Loss Compensation Using Deep Neural Networks: A Framework and Results From a Listening Test",
      "abstract": "This article investigates the use of deep neural networks (DNNs) for hearing-loss compensation. Hearing loss is a prevalent issue affecting millions of people worldwide, and conventional hearing aids have limitations in providing satisfactory compensation. DNNs have shown remarkable performance in various auditory tasks, including speech recognition, speaker identification, and music classification. In this study, we propose a DNN-based approach for hearing-loss compensation, which is trained on the outputs of hearing-impaired and normal-hearing DNN-based auditory models in response to speech signals. First, we introduce a framework for emulating auditory models using DNNs, focusing on an auditory-nerve model in the auditory pathway. We propose a linearization of the DNN-based approach, which we use to analyze the DNN-based hearing-loss compensation. Additionally we develop a simple approach to choose the acoustic center frequencies of the auditory model used for the compensation strategy. Finally, we evaluate, to our knowledge for the first time, the DNN-based hearing-loss compensation strategies using listening tests with hearing impaired listeners. The results demonstrate that the proposed approach results in feasible hearing-loss compensation strategies. Our proposed approach was shown to provide an increase in speech intelligibility versus an unprocessed baseline and was found to outperform a conventional approach in terms of both intelligibility and preference.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Peter Leer et al.",
      "keywords": "Compensation (psychology); Artificial neural network; Audiology; Hearing loss; Speech recognition; Deep neural networks; Computer science; Psychology; Artificial intelligence; Medicine; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.10420",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390832372",
      "doi": "10.48550/arxiv.2401.04832",
      "title": "Group lasso priors for Bayesian accelerated failure time models with left-truncated and interval-censored data",
      "abstract": "An important task in health research is to characterize time-to-event outcomes such as disease onset or mortality in terms of a potentially high-dimensional set of risk factors. For example, prospective cohort studies of Alzheimer's disease typically enroll older adults for observation over several decades to assess the long-term impact of genetic and other factors on cognitive decline and mortality. The accelerated failure time model is particularly well-suited to such studies, structuring covariate effects as `horizontal' changes to the survival quantiles that conceptually reflect shifts in the outcome distribution due to lifelong exposures. However, this modeling task is complicated by the enrollment of adults at differing ages, and intermittent followup visits leading to interval censored outcome information. Moreover, genetic and clinical risk factors are not only high-dimensional, but characterized by underlying grouping structure, such as by function or gene location. Such grouped high-dimensional covariates require shrinkage methods that directly acknowledge this structure to facilitate variable selection and estimation. In this paper, we address these considerations directly by proposing a Bayesian accelerated failure time model with a group-structured lasso penalty, designed for left-truncated and interval-censored time-to-event data. We develop a custom Markov chain Monte Carlo sampler for efficient estimation, and investigate the impact of various methods of penalty tuning and thresholding for variable selection. We present a simulation study examining the performance of this method relative to models with an ordinary lasso penalty, and apply the proposed method to identify groups of predictive genetic and clinical risk factors for Alzheimer's disease in the Religious Orders Study and Memory and Aging Project (ROSMAP) prospective cohort studies of AD and dementia.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Harrison T. Reeder et al.",
      "keywords": "Covariate; Lasso (programming language); Bayesian probability; Computer science; Statistics; Accelerated failure time model; Econometrics; Feature selection; Prior probability; Event (particle physics); Markov chain Monte Carlo; Penalty method; Machine learning; Mathematics; Artificial intelligence; Mathematical optimization",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2401.04832",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387559092",
      "doi": "10.48550/arxiv.2310.04450",
      "title": "Investigating Large Language Models' Perception of Emotion Using Appraisal Theory",
      "abstract": "Large Language Models (LLM) like ChatGPT have significantly advanced in recent years and are now being used by the general public. As more people interact with these systems, improving our understanding of these black box models is crucial, especially regarding their understanding of human psychological aspects. In this work, we investigate their emotion perception through the lens of appraisal and coping theory using the Stress and Coping Process Questionaire (SCPQ). SCPQ is a validated clinical instrument consisting of multiple stories that evolve over time and differ in key appraisal variables such as controllability and changeability. We applied SCPQ to three recent LLMs from OpenAI, davinci-003, ChatGPT, and GPT-4 and compared the results with predictions from the appraisal theory and human data. The results show that LLMs' responses are similar to humans in terms of dynamics of appraisal and coping, but their responses did not differ along key appraisal dimensions as predicted by the theory and data. The magnitude of their responses is also quite different from humans in several variables. We also found that GPTs can be quite sensitive to instruction and how questions are asked. This work adds to the growing literature evaluating the psychological aspects of LLMs and helps enrich our understanding of the current models.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Nutchanon Yongsatianchot et al.",
      "keywords": "Coping (psychology); Appraisal theory; Perception; Cognitive appraisal; Psychology; Critical appraisal; Cognitive psychology; Social psychology; Applied psychology; Clinical psychology; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.04450",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2951375872",
      "doi": "10.48550/arxiv.1808.05209",
      "title": "Domain Knowledge Discovery Guided by Software Trace Links",
      "abstract": "Software-intensive projects are specified and modeled using domain terminology. Knowledge of the domain terminology is necessary for performing many Software Engineering tasks such as impact analysis, compliance verification, and safety certification. However, discovering domain terminology and reasoning about their interrelationships for highly technical software and system engineering domains is a complex task which requires significant domain expertise and human effort. In this paper, we present a novel approach for leveraging trace links in software intensive systems to guide the process of mining facts that contain domain knowledge. The trace links which drive our mining process, define relationships between artifacts such as regulations and requirements and enable a guided search through high-yield combinations of domain terms. Our proof-of-concept evaluation shows that our approach aids in the discovery of domain facts even in highly complex technical domains. These domain facts can provide support for a variety of Software Engineering activities. As a use case, we demonstrate how the mined facts can facilitate the task of project Q&amp;A.",
      "year": "2018",
      "journal": "arXiv (Cornell University)",
      "authors": "Jin Guo et al.",
      "keywords": "Computer science; Terminology; Domain (mathematical analysis); Domain engineering; Software engineering; Domain analysis; Domain knowledge; TRACE (psycholinguistics); Software mining; Process (computing); Feature-oriented domain analysis; Task (project management); Software system; Software; Software construction; Systems engineering; Engineering; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1808.05209",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4286900167",
      "doi": "10.48550/arxiv.2110.10266",
      "title": "Addressing Positivity Violations in Causal Effect Estimation using Gaussian Process Priors",
      "abstract": "In observational studies, causal inference relies on several key identifying assumptions. One identifiability condition is the positivity assumption, which requires the probability of treatment be bounded away from 0 and 1. That is, for every covariate combination, it should be possible to observe both treated and control subjects, i.e., the covariate distributions should overlap between treatment arms. If the positivity assumption is violated, population-level causal inference necessarily involves some extrapolation. Ideally, a greater amount of uncertainty about the causal effect estimate should be reflected in such situations. With that goal in mind, we construct a Gaussian process model for estimating treatment effects in the presence of practical violations of positivity. Advantages of our method include minimal distributional assumptions, a cohesive model for estimating treatment effects, and more uncertainty associated with areas in the covariate space where there is less overlap. We assess the performance of our approach with respect to bias and efficiency using simulation studies. The method is then applied to a study of critically ill female patients to examine the effect of undergoing right heart catheterization.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Yaqian Zhu et al.",
      "keywords": "Identifiability; Covariate; Causal inference; Econometrics; Inference; Prior probability; Observational study; Population; Mathematics; Statistics; Computer science; Artificial intelligence; Bayesian probability; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.10266",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366458437",
      "doi": "10.48550/arxiv.2304.08708",
      "title": "A Voice Disease Detection Method Based on MFCCs and Shallow CNN",
      "abstract": "The incidence rate of voice diseases is increasing year by year. The use of software for remote diagnosis is a technical development trend and has important practical value. Among voice diseases, common diseases that cause hoarseness include spasmodic dysphonia, vocal cord paralysis, vocal nodule, and vocal cord polyp. This paper presents a voice disease detection method that can be applied in a wide range of clinical. We cooperated with Xiangya Hospital of Central South University to collect voice samples from sixty-one different patients. The Mel Frequency Cepstrum Coefficient (MFCC) parameters are extracted as input features to describe the voice in the form of data. An innovative model combining MFCC parameters and single convolution layer CNN is proposed for fast calculation and classification. The highest accuracy we achieved was 92%, it is fully ahead of the original research results and internationally advanced. And we use Advanced Voice Function Assessment Databases (AVFAD) to evaluate the generalization ability of the method we proposed, which achieved an accuracy rate of 98%. Experiments on clinical and standard datasets show that for the pathological detection of voice diseases, our method has greatly improved in accuracy and computational efficiency.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiaoping Xie et al.",
      "keywords": "Mel-frequency cepstrum; Computer science; Generalization; Voice Disorder; Cepstrum; Speech recognition; Pattern recognition (psychology); Convolution (computer science); Range (aeronautics); Artificial intelligence; Feature extraction; Medicine; Artificial neural network; Mathematics; Audiology; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2304.08708",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4403883344",
      "doi": "10.48550/arxiv.2410.01114",
      "title": "AI Persuasion, Bayesian Attribution, and Career Concerns of Decision-Makers",
      "abstract": "This paper studies AI persuasion by distinguishing between two reasons for disagreement: attention differences, where the AI detects features the decision-maker missed, and comprehension differences, where the AI and the decision-maker interpret observed features differently. We show that AI is more effective in persuading the decision-maker when the disagreement is due to attention differences rather than comprehension differences. We also show that the AI's interpretability shapes how the decision-maker attributes the sources of disagreement and, in turn, whether they follow the AI's recommendation. Our main result is that making AI uninterpretable can actually enhance persuasion and, in the presence of career concerns, improve decision accuracy.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Hanzhe Li et al.",
      "keywords": "Persuasion; Attribution; Psychology; Bayesian probability; Applied psychology; Social psychology; Artificial intelligence; Computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.01114",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4300435897",
      "doi": "10.48550/arxiv.2112.07090",
      "title": "Methods for Eliciting Informative Prior Distributions: A Critical Review",
      "abstract": "Eliciting informative prior distributions for Bayesian inference can often be complex and challenging. While popular methods rely on asking experts probability based questions to quantify uncertainty, these methods are not without their drawbacks and many alternative elicitation methods exist. This paper explores methods for eliciting informative priors categorized by type and briefly discusses their strengths and limitations. Most of the review literature in this field focuses on a particular type of elicitation approach. The primary aim of this work, however, is to provide a more complete yet macro view of the state of the art by highlighting new (and old) approaches in one clear, easy to read article. Two representative applications are used throughout to explore the suitability, or lack thereof, of the existing methods; one of which, highlights a challenge that has not been addressed in the literature yet. We identify some of the gaps in the present work and discuss directions for future research.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Julia R. Falconer et al.",
      "keywords": "Prior probability; Computer science; Inference; Expert elicitation; Bayesian probability; Data science; Bayesian inference; Management science; Field (mathematics); Artificial intelligence; Machine learning; Mathematics; Statistics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2112.07090",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286952407",
      "doi": "10.48550/arxiv.2109.14648",
      "title": "A Study of Feature Selection and Extraction Algorithms for Cancer Subtype Prediction",
      "abstract": "In this work, we study and analyze different feature selection algorithms that can be used to classify cancer subtypes in case of highly varying high-dimensional data. We apply three different feature selection methods on five different types of cancers having two separate omics each. We show that the existing feature selection methods are computationally expensive when applied individually. Instead, we apply these algorithms sequentially which helps in lowering the computational cost and improving the predictive performance. We further show that reducing the number of features using some dimension reduction techniques can improve the performance of machine learning models in some cases. We support our findings through comprehensive data analysis and visualization.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Vaibhav B. Sinha et al.",
      "keywords": "Feature selection; Computer science; Selection (genetic algorithm); Dimensionality reduction; Feature (linguistics); Feature extraction; Data mining; Machine learning; Dimension (graph theory); Visualization; Artificial intelligence; Reduction (mathematics); Algorithm; Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2109.14648",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323925814",
      "doi": "10.48550/arxiv.2303.05223",
      "title": "LEAP: The latent exchangeability prior for borrowing information from historical data",
      "abstract": "It is becoming increasingly popular to elicit informative priors on the basis of historical data. Popular existing priors, including the power prior, commensurate prior, and robust meta-analytic prior provide blanket discounting. Thus, if only a subset of participants in the historical data are exchangeable with the current data, these priors may not be appropriate. In order to combat this issue, propensity score (PS) approaches have been proposed. However, PS approaches are only concerned with the covariate distribution, whereas exchangeability is typically assessed with parameters pertaining to the outcome. In this paper, we introduce the latent exchangeability prior (LEAP), where observations in the historical data are classified into exchangeable and non-exchangeable groups. The LEAP discounts the historical data by identifying the most relevant subjects from the historical data. We compare our proposed approach against alternative approaches in simulations and present a case study using our proposed prior to augment a control arm in a phase 3 clinical trial in plaque psoriasis with an unbalanced randomization scheme.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ethan M. Alt et al.",
      "keywords": "Prior probability; Covariate; Computer science; Econometrics; Prior information; Statistics; Artificial intelligence; Machine learning; Mathematics; Bayesian probability",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.05223",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415032488",
      "doi": "10.48550/arxiv.2505.02747",
      "title": "The use of Artificial Intelligence for Intervention and Assessment in Individuals with ASD",
      "abstract": "This paper explores the use of Artificial Intelligence (AI) as a tool for diagnosis, assessment, and intervention for individuals with Autism Spectrum Disorder (ASD). It focuses particularly on AI's role in early diagnosis, utilizing advanced machine learning techniques and data analysis. Recent studies demonstrate that deep learning algorithms can identify behavioral patterns through biometric data analysis, video-based interaction assessments, and linguistic feature extraction, providing a more accurate and timely diagnosis compared to traditional methods. Additionally, AI automates diagnostic tools, reducing subjective biases and enabling the development of personalized assessment protocols for ASD monitoring. At the same time, the paper examines AI-powered intervention technologies, emphasizing educational robots and adaptive communication tools. Social robotic assistants, such as NAO and Kaspar, have been shown to enhance social skills in children by offering structured, repetitive interactions that reinforce learning. Furthermore, AI-driven Augmentative and Alternative Communication (AAC) systems allow children with ASD to express themselves more effectively, while machine-learning chatbots provide language development support through personalized responses. The study presents research findings supporting the effectiveness of these AI applications while addressing challenges such as long-term evaluation and customization to individual needs. In conclusion, the paper highlights the significance of AI as an innovative tool in ASD diagnosis and intervention, advocating for further research to assess its long-term impact.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Aggeliki Sideraki et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.02747",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414897005",
      "doi": "10.48550/arxiv.2506.01498",
      "title": "Simulating Complex Crossectional and Longitudinal Data using the simDAG R Package",
      "abstract": "Generating artificial data is a crucial step when performing Monte-Carlo simulation studies. Depending on the planned study, complex data generation processes (DGP) containing multiple, possibly time-varying, variables with various forms of dependencies and data types may be required. Simulating data from such DGP may therefore become a difficult and time-consuming endeavor. The simDAG R package offers a standardized approach to generate data from simple and complex DGP based on the definition of structural equations in directed acyclic graphs using arbitrary functions or regression models. The package offers a clear syntax with an enhanced formula interface and directly supports generating binary, categorical, count and time-to-event data with arbitrary dependencies, possibly non-linear relationships and interactions. It additionally includes a framework to conduct discrete-time based simulations which allows the generation of longitudinal data on a semi-continuous time-scale. This approach may be used to generate time-to-event data with both recurrent or competing events and possibly multiple time-varying covariates, which may themselves have arbitrary data types. In this article we demonstrate the vast amount of features included in simDAG by replicating the DGP of multiple real Monte-Carlo simulation studies.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Robin Denz et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.01498",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388843379",
      "doi": "10.48550/arxiv.2311.10328",
      "title": "TransONet: Automatic Segmentation of Vasculature in Computed Tomographic Angiograms Using Deep Learning",
      "abstract": "Pathological alterations in the human vascular system underlie many chronic diseases, such as atherosclerosis and aneurysms. However, manually analyzing diagnostic images of the vascular system, such as computed tomographic angiograms (CTAs) is a time-consuming and tedious process. To address this issue, we propose a deep learning model to segment the vascular system in CTA images of patients undergoing surgery for peripheral arterial disease (PAD). Our study focused on accurately segmenting the vascular system (1) from the descending thoracic aorta to the iliac bifurcation and (2) from the descending thoracic aorta to the knees in CTA images using deep learning techniques. Our approach achieved average Dice accuracies of 93.5% and 80.64% in test dataset for (1) and (2), respectively, highlighting its high accuracy and potential clinical utility. These findings demonstrate the use of deep learning techniques as a valuable tool for medical professionals to analyze the health of the vascular system efficiently and accurately. Please visit the GitHub page for this paper at https://github.com/pip-alireza/TransOnet.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Alireza Bagheri Rajeoni et al.",
      "keywords": "Deep learning; Segmentation; Computed tomographic angiography; Thoracic aorta; Artificial intelligence; Medicine; Descending aorta; Computer science; Radiology; Computed tomographic; Aorta; Computed tomography; Angiography; Surgery",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.10328",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414632974",
      "doi": "10.48550/arxiv.2504.15586",
      "title": "Joint leave-group-out cross-validation in Bayesian spatial models",
      "abstract": "Cross-validation (CV) is a widely-used method of predictive assessment based on repeated model fits to different subsets of the available data. CV is applicable in a wide range of statistical settings. However, in cases where data are not exchangeable, the design of CV schemes should account for suspected correlation structures within the data. CV scheme designs include the selection of left-out blocks and the choice of scoring function for evaluating predictive performance. This paper focuses on the impact of two scoring strategies for block-wise CV applied to spatial models with Gaussian covariance structures. We investigate, through several experiments, whether evaluating the predictive performance of blocks of left-out observations jointly, rather than aggregating individual (pointwise) predictions, improves model selection performance. Extending recent findings for data with serial correlation (such as time-series data), our experiments suggest that joint scoring reduces the variability of CV estimates, leading to more reliable model selection, particularly when spatial dependence is strong and model differences are subtle.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Alex Cooper et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.15586",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4414546371",
      "doi": "10.48550/arxiv.2508.13728",
      "title": "BioGAP-Ultra: A Modular Edge-AI Platform for Wearable Multimodal Biosignal Acquisition and Processing",
      "abstract": "The growing demand for continuous physiological monitoring and human-machine interaction in real-world settings calls for wearable platforms that are flexible, low-power, and capable of on-device intelligence. This work presents BioGAP-Ultra, an advanced multimodal biosensing platform that supports synchronized acquisition of diverse electrophysiological and hemodynamic signals such as EEG, EMG, ECG, and PPG while enabling embedded AI processing at state-of-the-art energy efficiency. BioGAP-Ultra is a major extension of our previous BioGAP design aimed at meeting the rapidly growing requirements of wearable biosensing applications. It features (i) increased on-device storage (x2 SRAM, x4 FLASH), (ii) improved wireless connectivity (supporting up to 1.4 Mbit/s bandwidth, x4 higher than BioGAP), (iii) enhanced number of signal modalities (from 3 to 5) and analog input channels (x2). Further, it is accompanied by a real-time visualization and analysis software suite that supports the hardware design, providing access to raw data and real-time configurability on a mobile phone. Finally, we demonstrate the system's versatility through integration into various wearable form factors: an EEG-PPG headband consuming 32.8 mW, an EMG sleeve at 26.7 mW, and an ECG-PPG chestband requiring only 9.3 mW for continuous acquisition and streaming, tailored for diverse biosignal applications. To showcase its edge-AI capabilities, we further deploy two representative on-device applications: (1) ECG-PPG-based PAT estimation at 8.6 mW, and (2) EMG-ACC-based classification of reach-and-grasp motion phases, achieving 79.9 % $\\pm$ 5.7 % accuracy at 23.6 mW. All hardware and software design files are also released open-source with a permissive license.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Sebastian Frey et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2508.13728",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4361806549",
      "doi": "10.48550/arxiv.2303.16468",
      "title": "IMU-based Modularized Wearable Device for Human Motion Classification",
      "abstract": "Human motion analysis is used in many different fields and applications. Currently, existing systems either focus on one single limb or one single class of movements. Many proposed systems are designed to be used in an indoor controlled environment and must possess good technical know-how to operate. To improve mobility, a less restrictive, modularized, and simple Inertial Measurement units based system is proposed that can be worn separately and combined. This allows the user to measure singular limb movements separately and also monitor whole body movements over a prolonged period at any given time while not restricted to a controlled environment. For proper analysis, data is conditioned and pre-processed through possible five stages namely power-based, clustering index-based, Kalman filtering, distance-measure-based, and PCA-based dimension reduction. Different combinations of the above stages are analyzed using machine learning algorithms for selected case studies namely hand gesture recognition and environment and shoe parameter-based walking pattern analysis to validate the performance capability of the proposed wearable device and multi-stage algorithms. The results of the case studies show that distance-measure-based and PCA-based dimension reduction will significantly improve human motion identification accuracy. This is further improved with the introduction of the Kalman filter. An LSTM neural network is proposed as an alternate classifier and the results indicate that it is a robust classifier for human motion recognition. As the results indicate, the proposed wearable device architecture and multi-stage algorithms are cable of distinguishing between subtle human limb movements making it a viable tool for human motion analysis.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Sahan Wijethunga et al.",
      "keywords": "Computer science; Artificial intelligence; Inertial measurement unit; Wearable computer; Classifier (UML); Dimensionality reduction; Kalman filter; Computer vision; Cluster analysis; Similarity measure; Pattern recognition (psychology); Embedded system",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.16468",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287618426",
      "doi": "10.48550/arxiv.2011.00659",
      "title": "Survival prediction and risk estimation of Glioma patients using mRNA\\n expressions",
      "abstract": "Gliomas are lethal type of central nervous system tumors with a poor\\nprognosis. Recently, with the advancements in the micro-array technologies\\nthousands of gene expression related data of glioma patients are acquired,\\nleading for salient analysis in many aspects. Thus, genomics are been emerged\\ninto the field of prognosis analysis. In this work, we identify survival\\nrelated 7 gene signature and explore two approaches for survival prediction and\\nrisk estimation. For survival prediction, we propose a novel probabilistic\\nprogramming based approach, which outperforms the existing traditional machine\\nlearning algorithms. An average 4 fold accuracy of 74% is obtained with the\\nproposed algorithm. Further, we construct a prognostic risk model for risk\\nestimation of glioma patients. This model reflects the survival of glioma\\npatients, with high risk for low survival patients.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Navodini Wijethilake et al.",
      "keywords": "Glioma; Estimation; Computer science; Survival analysis; Construct (python library); Salient; Probabilistic logic; Machine learning; Artificial intelligence; Oncology; Internal medicine; Medicine; Engineering; Cancer research",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2011.00659",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4417088590",
      "doi": "10.48550/arxiv.2505.07498",
      "title": "Design Requirements for Patient-Centered Digital Health Applications: Supporting Patients' Values in Postoperative Delirium Prevention",
      "abstract": "Postoperative delirium (POD) is among the most common complications after surgeries for older adults and can entail long-term adverse health consequences. Active patient participation in POD prevention presents a central factor in reducing these risks. To support patient engagement through a digital health application, we use value sensitive design approaches to identify the requirements for a patient-centered digital health application supporting patient engagement in POD prevention. Through interviews with medical professionals and patient representatives, we construct a patient journey, which serves as the basis for twelve patient value journey interviews. In these interviews, patients from the high-risk group for POD revisit their recent experience of undergoing surgery to elicit barriers, needs, and values concerning POD prevention from a patient perspective. An analysis of the patient interviews derives four design requirements for a digital health application supporting patients regarding POD prevention: the adaptation of patient-centered communication, the provision of procedural transparency, fostering patient empowerment through consistent guidance, and explicitly addressing relatives as mediators and supporters for a patient after a POD occurrence.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "David Leimst\u00e4dtner et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07498",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4225616441",
      "doi": "10.48550/arxiv.2112.07890",
      "title": "Investigating myocardial infarction and its effects in patients with urgent medical problems using advanced data mining tools",
      "abstract": "In medical science, it is very important to gather multiple data on different diseases and one of the most important objectives of the data is to investigate the diseases. Myocardial infarction is a serious risk factor in mortality and in previous studies, the main emphasis has been on people with heart disease and measuring the likelihood of myocardial infarction in them through demographic features, echocardiography, and electrocardiogram. In contrast, the purpose of the present study is to utilize data analysis algorithms and compare their accuracy in patients with a heart attack in order to identify the heart muscle strength during myocardial infarction by taking into account emergency operations and consequently predict myocardial infarction. For this purpose, 105 medical records of myocardial infarction patients with fourteen features including age, the time of emergency operation, Creatine Phosphokinase (CPK) test, heart rate, blood sugar, and vein are gathered and investigated through classification techniques of data analysis including random decision forests, decision tree, support vector machine (SVM), k-nearest neighbor, and ordinal logistic regression. Finally, the model of random decision forests with an accuracy of 76% is selected as the best model in terms of the mean evaluation indicator. Also, seven features of the creatine Phosphokinase test, urea, white and red blood cell count, blood sugar, time, and hemoglobin are identified as the most effective features of the ejection fraction variable.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Tanya Aghazadeh et al.",
      "keywords": "Myocardial infarction; Medicine; Decision tree; Logistic regression; Internal medicine; Cardiology; Ejection fraction; Creatine kinase; Emergency medicine; Machine learning; Computer science; Heart failure",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.07890",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388890766",
      "doi": "10.48550/arxiv.2311.10912",
      "title": "Opportunities in Mental Health Support for Informal Dementia Caregivers Suffering from Verbal Agitation",
      "abstract": "People with dementia (PwD) often present verbal agitation such as cursing, screaming, and persistently complaining. Verbal agitation can impose mental distress on informal caregivers (e.g., family, friends), which may cause severe mental illnesses, such as depression and anxiety disorders. To improve informal caregivers' mental health, we explore design opportunities by interviewing 11 informal caregivers suffering from verbal agitation of PwD. In particular, we first characterize how the predictability of verbal agitation impacts informal caregivers' mental health and how caregivers' coping strategies vary before, during, and after verbal agitation. Based on our findings, we propose design opportunities to improve the mental health of informal caregivers suffering from verbal agitation: distracting PwD (in-situ support; before), prompting just-in-time maneuvers (information support; during), and comfort and education (social &amp; information support; after). We discuss our reflections on cultural disparities between participants. Our work envisions a broader design space for supporting informal caregivers' well-being and describes when and how that support could be provided.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Tae-Wook Kim et al.",
      "keywords": "Dementia; Mental health; Psychology; Anxiety; Screaming; Distress; Coping (psychology); Psychiatry; Social support; Nonverbal communication; Clinical psychology; Developmental psychology; Psychotherapist; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2311.10912",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416075203",
      "doi": "10.48550/arxiv.2506.04166",
      "title": "N$^2$: A Unified Python Package and Test Bench for Nearest Neighbor-Based Matrix Completion",
      "abstract": "Nearest neighbor (NN) methods have re-emerged as competitive tools for matrix completion, offering strong empirical performance and recent theoretical guarantees, including entry-wise error bounds, confidence intervals, and minimax optimality. Despite their simplicity, recent work has shown that NN approaches are robust to a range of missingness patterns and effective across diverse applications. This paper introduces N$^2$, a unified Python package and testbed that consolidates a broad class of NN-based methods through a modular, extensible interface. Built for both researchers and practitioners, N$^2$ supports rapid experimentation and benchmarking. Using this framework, we introduce a new NN variant that achieves state-of-the-art results in several settings. We also release a benchmark suite of real-world datasets, from healthcare and recommender systems to causal inference and LLM evaluation, designed to stress-test matrix completion methods beyond synthetic scenarios. Our experiments demonstrate that while classical methods excel on idealized data, NN-based techniques consistently outperform them in real-world settings.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Choon Jo Chin et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.04166",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396653584",
      "doi": "10.48550/arxiv.2405.00725",
      "title": "Federated Learning and Differential Privacy Techniques on Multi-hospital Population-scale Electrocardiogram Data",
      "abstract": "This research paper explores ways to apply Federated Learning (FL) and Differential Privacy (DP) techniques to population-scale Electrocardiogram (ECG) data. The study learns a multi-label ECG classification model using FL and DP based on 1,565,849 ECG tracings from 7 hospitals in Alberta, Canada. The FL approach allowed collaborative model training without sharing raw data between hospitals while building robust ECG classification models for diagnosing various cardiac conditions. These accurate ECG classification models can facilitate the diagnoses while preserving patient confidentiality using FL and DP techniques. Our results show that the performance achieved using our implementation of the FL approach is comparable to that of the pooled approach, where the model is trained over the aggregating data from all hospitals. Furthermore, our findings suggest that hospitals with limited ECGs for training can benefit from adopting the FL model compared to single-site training. In addition, this study showcases the trade-off between model performance and data privacy by employing DP during model training. Our code is available at https://github.com/vikhyatt/Hospital-FL-DP.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Vikhyat Agrawal et al.",
      "keywords": "Differential privacy; Scale (ratio); Computer science; Data mining; Geography; Cartography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.00725",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396913681",
      "doi": "10.48550/arxiv.2405.07458",
      "title": "Examining Humanness as a Metaphor to Design Voice User Interfaces",
      "abstract": "Voice User Interfaces (VUIs) increasingly leverage 'humanness' as a foundational design metaphor, adopting roles like 'assistants,' 'teachers,' and 'secretaries' to foster natural interactions. Yet, this approach can sometimes misalign user trust and reinforce societal stereotypes, leading to socio-technical challenges that might impede long-term engagement. This paper explores an alternative approach to navigate these challenges-incorporating non-human metaphors in VUI design. We report on a study with 240 participants examining the effects of human versus non-human metaphors on user perceptions within health and finance domains. Results indicate a preference for the human metaphor (doctor) over the non-human (health encyclopedia) in health contexts for its perceived enjoyability and likeability. In finance, however, user perceptions do not significantly differ between human (financial advisor) and non-human (calculator) metaphors. Importantly, our research reveals that the explicit awareness of a metaphor's use influences adoption intentions, with a marked preference for non-human metaphors when their metaphorical nature is not disclosed. These findings highlight context-specific conversation design strategies required in integrating non-human metaphors into VUI design, suggesting tradeoffs and design considerations that could enhance user engagement and adoption.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Smit Desai et al.",
      "keywords": "Metaphor; Human\u2013computer interaction; Computer science; Communication; Aesthetics; Psychology; Linguistics; Art; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.07458",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417298384",
      "doi": "10.48550/arxiv.2505.13425",
      "title": "Learnware of Language Models: Specialized Small Language Models Can Do Big",
      "abstract": "The learnware paradigm offers a novel approach to machine learning by enabling users to reuse a set of well-trained models for tasks beyond the models' original purposes. It eliminates the need to build models from scratch, instead relying on specifications (representations of a model's capabilities) to identify and leverage the most suitable models for new tasks. While learnware has proven effective in many scenarios, its application to language models has remained largely unexplored. At the same time, large language models (LLMs) have demonstrated remarkable universal question-answering abilities, yet they face challenges in specialized scenarios due to data scarcity, privacy concerns, and high computational costs, thus more and more specialized small language models (SLMs) are being trained for specific domains. To address these limitations systematically, the learnware paradigm provides a promising solution by enabling maximum utilization of specialized SLMs, and allowing users to identify and reuse them in a collaborative and privacy-preserving manner. This paper presents a preliminary attempt to apply the learnware paradigm to language models. We simulated a learnware system comprising approximately 100 learnwares of specialized SLMs with 8B parameters, fine-tuned across finance, healthcare, and mathematics domains. Each learnware contains an SLM and a specification, which enables users to identify the most relevant models without exposing their own data. Experimental results demonstrate promising performance: by selecting one suitable learnware for each task-specific inference, the system outperforms the base SLMs on all benchmarks. Compared to LLMs, the system outperforms Qwen1.5-110B, Qwen2.5-72B, and Llama3.1-70B-Instruct by at least 14% in finance domain tasks, and surpasses Flan-PaLM-540B (ranked 7th on the Open Medical LLM Leaderboard) in medical domain tasks.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhuang Tan et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.13425",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283014525",
      "doi": "10.48550/arxiv.2206.07573",
      "title": "AI and Pathology: Steering Treatment and Predicting Outcomes",
      "abstract": "The combination of data analysis methods, increasing computing capacity, and improved sensors enable quantitative granular, multi-scale, cell-based analyses. We describe the rich set of application challenges related to tissue interpretation and survey AI methods currently used to address these challenges. We focus on a particular class of targeted human tissue analysis - histopathology - aimed at quantitative characterization of disease state, patient outcome prediction and treatment steering.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Rajarsi Gupta et al.",
      "keywords": "Computer science; Class (philosophy); Focus (optics); Set (abstract data type); Outcome (game theory); Scale (ratio); Artificial intelligence; Data science; Mathematics; Cartography; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.07573",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4405253845",
      "doi": "10.48550/arxiv.2412.06088",
      "title": "A4-Unet: Deformable Multi-Scale Attention Network for Brain Tumor Segmentation",
      "abstract": "Brain tumor segmentation models have aided diagnosis in recent years. However, they face MRI complexity and variability challenges, including irregular shapes and unclear boundaries, leading to noise, misclassification, and incomplete segmentation, thereby limiting accuracy. To address these issues, we adhere to an outstanding Convolutional Neural Networks (CNNs) design paradigm and propose a novel network named A4-Unet. In A4-Unet, Deformable Large Kernel Attention (DLKA) is incorporated in the encoder, allowing for improved capture of multi-scale tumors. Swin Spatial Pyramid Pooling (SSPP) with cross-channel attention is employed in a bottleneck further to study long-distance dependencies within images and channel relationships. To enhance accuracy, a Combined Attention Module (CAM) with Discrete Cosine Transform (DCT) orthogonality for channel weighting and convolutional element-wise multiplication is introduced for spatial weighting in the decoder. Attention gates (AG) are added in the skip connection to highlight the foreground while suppressing irrelevant background information. The proposed network is evaluated on three authoritative MRI brain tumor benchmarks and a proprietary dataset, and it achieves a 94.4% Dice score on the BraTS 2020 dataset, thereby establishing multiple new state-of-the-art benchmarks. The code is available here: https://github.com/WendyWAAAAANG/A4-Unet.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ruoxin Wang et al.",
      "keywords": "Segmentation; Scale (ratio); Artificial intelligence; Computer science; Psychology; Cartography; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.06088",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391766869",
      "doi": "10.48550/arxiv.2402.06443",
      "title": "Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach",
      "abstract": "The rapid dissemination of misinformation through social media increased the importance of automated fact-checking. Furthermore, studies on what deep neural models pay attention to when making predictions have increased in recent years. While significant progress has been made in this field, it has not yet reached a level of reasoning comparable to human reasoning. To address these gaps, we propose a multi-task explainable neural model for misinformation detection. Specifically, this work formulates an explanation generation process of the model's veracity prediction as a text summarization problem. Additionally, the performance of the proposed model is discussed on publicly available datasets and the findings are evaluated with related studies.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Recep F\u0131rat \u00c7ekinel et al.",
      "keywords": "Automatic summarization; Task (project management); Computer science; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.06443",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404311187",
      "doi": "10.48550/arxiv.2410.19190",
      "title": "A novel longitudinal rank-sum test for multiple primary endpoints in clinical trials: Applications to neurodegenerative disorders",
      "abstract": "Neurodegenerative disorders such as Alzheimer's disease (AD) present a significant global health challenge, characterized by cognitive decline, functional impairment, and other debilitating effects. Current AD clinical trials often assess multiple longitudinal primary endpoints to comprehensively evaluate treatment efficacy. Traditional methods, however, may fail to capture global treatment effects, require larger sample sizes due to multiplicity adjustments, and may not fully exploit multivariate longitudinal data. To address these limitations, we introduce the Longitudinal Rank Sum Test (LRST), a novel nonparametric rank-based omnibus test statistic. The LRST enables a comprehensive assessment of treatment efficacy across multiple endpoints and time points without multiplicity adjustments, effectively controlling Type I error while enhancing statistical power. It offers flexibility against various data distributions encountered in AD research and maximizes the utilization of longitudinal data. Extensive simulations and real-data applications demonstrate the LRST's performance, underscoring its potential as a valuable tool in AD clinical trials.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Xiaoming Xu et al.",
      "keywords": "Test (biology); Clinical trial; Rank (graph theory); Clinical endpoint; Econometrics; Medicine; Psychology; Statistics; Mathematics; Internal medicine; Biology; Combinatorics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2410.19190",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399198070",
      "doi": "10.48550/arxiv.2405.18723",
      "title": "Conformal Depression Prediction",
      "abstract": "While existing depression prediction methods based on deep learning show promise, their practical application is hindered by the lack of trustworthiness, as these deep models are often deployed as black box models, leaving us uncertain on the confidence of their predictions. For high-risk clinical applications like depression prediction, uncertainty quantification is essential in decision-making. In this paper, we introduce conformal depression prediction (CDP), a depression prediction method with uncertainty quantification based on conformal prediction (CP), giving valid confidence intervals with theoretical coverage guarantees for the model predictions. CDP is a plug-and-play module that requires neither model retraining nor an assumption about the depression data distribution. As CDP provides only an average coverage guarantee across all inputs rather than per-input performance guarantee, we further propose CDP-ACC, an improved conformal prediction with approximate conditional coverage. CDP-ACC firstly estimates the prediction distribution through neighborhood relaxation, and then introduces a conformal score function by constructing nested sequences, so as to provide a tighter prediction interval adaptive to specific input. We empirically demonstrate the application of CDP in uncertainty-aware facial depression prediction, as well as the effectiveness and superiority of CDP-ACC on the AVEC 2013 and AVEC 2014 datasets. Our code is publicly available at https://github.com/PushineLee/CDP.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yonghong Li et al.",
      "keywords": "Depression (economics); Conformal map; Psychology; Economics; Mathematics; Keynesian economics; Geometry",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.18723",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286912069",
      "doi": "10.48550/arxiv.2110.00864",
      "title": "Probabilistic Prediction for Binary Treatment Choice: with focus on\\n personalized medicine",
      "abstract": "This paper extends my research applying statistical decision theory to\\ntreatment choice with sample data, using maximum regret to evaluate the\\nperformance of treatment rules. The specific new contribution is to study as-if\\noptimization using estimates of illness probabilities in clinical choice\\nbetween surveillance and aggressive treatment. Beyond its specifics, the paper\\nsends a broad message. Statisticians and computer scientists have addressed\\nconditional prediction for decision making in indirect ways, the former\\napplying classical statistical theory and the latter measuring prediction\\naccuracy in test samples. Neither approach is satisfactory. Statistical\\ndecision theory provides a coherent, generally applicable methodology.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Charles F. Manski",
      "keywords": "Regret; Probabilistic logic; Computer science; Machine learning; Statistical theory; Artificial intelligence; Binary number; Sample (material); Test (biology); Statistical hypothesis testing; Data mining; Management science; Econometrics; Statistics; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.00864",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297644051",
      "doi": "10.48550/arxiv.2209.02395",
      "title": "On Effectively Predicting Autism Spectrum Disorder Using an Ensemble of Classifiers",
      "abstract": "An ensemble of classifiers combines several single classifiers to deliver a final prediction or classification decision. An increasingly provoking question is whether such systems can outperform the single best classifier. If so, what form of an ensemble of classifiers (also known as multiple classifier learning systems or multiple classifiers) yields the most significant benefits in the size or diversity of the ensemble itself? Given that the tests used to detect autism traits are time-consuming and costly, developing a system that will provide the best outcome and measurement of autism spectrum disorder (ASD) has never been critical. In this paper, several single and later multiple classifiers learning systems are evaluated in terms of their ability to predict and identify factors that influence or contribute to ASD for early screening purposes. A dataset of behavioural data and robot-enhanced therapy of 3,000 sessions and 300 hours, recorded from 61 children are utilised for this task. Simulation results show the superior predictive performance of multiple classifier learning systems (especially those with three classifiers per ensemble) compared to individual classifiers, with bagging and boosting achieving excellent results. It also appears that social communication gestures remain the critical contributing factor to the ASD problem among children.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Bhekisipho Twala et al.",
      "keywords": "Autism spectrum disorder; Random subspace method; Cascading classifiers; Ensemble learning; Boosting (machine learning); Classifier (UML); Artificial intelligence; Machine learning; Computer science; Autism; Psychology; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.02395",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4308167030",
      "doi": "10.48550/arxiv.2211.01015",
      "title": "Self-assess Momentary Mood in Mobile Devices: a Case Study with Mature Female Participants",
      "abstract": "Starting from the assumption that mood has a central role in domain-specific persuasion systems for well-being, the main goal of this study was to investigate the feasibility and acceptability of single-input methods to assess momentary mood as a medium for further interventions in health-related mobile apps destined for mature women. To this aim, we designed a very simple android App providing four user interfaces, each one showing one interactive widget to self-assess mood. Two widgets report a hint about the momentary mood they represent; the last two do not have the hints but were previously refined through questionnaires administered to 63 women (age 45-65) in order to reduce their expressive ambiguity. Next, fifteen women (age 45-65 years) were recruited to use the app for 15 days. Participants were polled about their mood four times a day and data were saved in a remote database. Moreover, users were asked to fill out a preliminary questionnaire, at the first access to the app, and a feedback questionnaire at the end of the testing period. Results appear to prove the feasibility and acceptability of this approach to self-assess momentary mood in the target population and provides some potential input methods to be used in this context.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Caterina Senette et al.",
      "keywords": "Mood; Mobile apps; Context (archaeology); Psychology; Polling; Population; Ambiguity; Psychological intervention; Applied psychology; Computer science; Clinical psychology; Medicine; World Wide Web; Psychiatry; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2211.01015",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2950338764",
      "doi": "10.48550/arxiv.1312.2798",
      "title": "OntoVerbal: a Generic Tool and Practical Application to SNOMED CT",
      "abstract": "Ontology development is a non-trivial task requiring expertise in the chosen ontological language. We propose a method for making the content of ontologies more transparent by presenting, through the use of natural language generation, naturalistic descriptions of ontology classes as textual paragraphs. The method has been implemented in a proof-of- concept system, OntoVerbal, that automatically generates paragraph-sized textual descriptions of ontological classes expressed in OWL. OntoVerbal has been applied to ontologies that can be loaded into Prot\u00e9g\u00e9 and been evaluated with SNOMED CT, showing that it provides coherent, well-structured and accurate textual descriptions of ontology classes.",
      "year": "2013",
      "journal": "arXiv (Cornell University)",
      "authors": "Shao Fen Liang et al.",
      "keywords": "SNOMED CT; Paragraph; Computer science; Ontology; Natural language processing; Prot\u00e9g\u00e9; Open Biomedical Ontologies; Task (project management); Web Ontology Language; Information retrieval; Artificial intelligence; Natural language; Upper ontology; World Wide Web; Linguistics; Suggested Upper Merged Ontology; Domain knowledge; Terminology; Semantic Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1312.2798",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416048702",
      "doi": "10.48550/arxiv.2505.22609",
      "title": "Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method",
      "abstract": "In this work, we investigate the performance across multiple classification models to classify chest X-ray images into four categories of COVID-19, pneumonia, tuberculosis (TB), and normal cases. We leveraged transfer learning techniques with state-of-the-art pre-trained Convolutional Neural Networks (CNNs) models. We fine-tuned these pre-trained architectures on a labeled medical x-ray images. The initial results are promising with high accuracy and strong performance in key classification metrics such as precision, recall, and F1 score. We applied Gradient-weighted Class Activation Mapping (Grad-CAM) for model interpretability to provide visual explanations for classification decisions, improving trust and transparency in clinical applications.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Alanna Hazlett et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.22609",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4396716058",
      "doi": "10.48550/arxiv.2405.02560",
      "title": "A Pilot Study on the Comparison of Prefrontal Cortex Activities of Robotic Therapies on Elderly with Mild Cognitive Impairment",
      "abstract": "Demographic shifts have led to an increase in mild cognitive impairment (MCI), and this study investigates the effects of cognitive training (CT) and reminiscence therapy (RT) conducted by humans or socially assistive robots (SARs) on prefrontal cortex activation in elderly individuals with MCI, aiming to determine the most effective therapy-modality combination for promoting cognitive function. This pilot study employs a randomized control trial (RCT) design. Additionally, the study explores the efficacy of Reminiscence Therapy (RT) in comparison to Cognitive Training (CT). Eight MCI subjects, with a mean age of 70.125 years, were randomly assigned to ``human-led'' or ``SAR-led'' groups. Utilizing Functional Near-infrared Spectroscopy (fNIRS) to measure oxy-hemoglobin concentration changes in the dorsolateral prefrontal cortex (DLPFC), the study found no significant differences in the effects of human-led and SAR-led cognitive training on DLPFC activation. However, distinct patterns emerged in memory encoding and retrieval phases between RT and CT, shedding light on the impacts of these interventions on brain activation in the context of MCI.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "King Tai Henry Au-Yeung et al.",
      "keywords": "Prefrontal cortex; Cognitive impairment; Cognition; Neuroscience; Psychology; Medicine; Physical medicine and rehabilitation",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.02560",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4414940310",
      "doi": "10.48550/arxiv.2505.10034",
      "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection",
      "abstract": "Depression is a widespread mental health issue affecting diverse age groups, with notable prevalence among college students and the elderly. However, existing datasets and detection methods primarily focus on young adults, neglecting the broader age spectrum and individual differences that influence depression manifestation. Current approaches often establish a direct mapping between multimodal data and depression indicators, failing to capture the complexity and diversity of depression across individuals. This challenge includes two tracks based on age-specific subsets: Track 1 uses the MPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses the MPDD-Young dataset for detecting depression in younger participants. The Multimodal Personality-aware Depression Detection (MPDD) Challenge aims to address this gap by incorporating multimodal data alongside individual difference factors. We provide a baseline model that fuses audio and video modalities with individual difference information to detect depression manifestations in diverse populations. This challenge aims to promote the development of more personalized and accurate de pression detection methods, advancing mental health research and fostering inclusive detection systems. More details are available on the official challenge website: https://hacilab.github.io/MPDDChallenge.github.io.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Changzeng Fu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.10034",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399114819",
      "doi": "10.48550/arxiv.2405.15830",
      "title": "Diff-DTI: Fast Diffusion Tensor Imaging Using A Feature-Enhanced Joint Diffusion Model",
      "abstract": "Magnetic resonance diffusion tensor imaging (DTI) is a critical tool for neural disease diagnosis. However, long scan time greatly hinders the widespread clinical use of DTI. To accelerate image acquisition, a feature-enhanced joint diffusion model (Diff-DTI) is proposed to obtain accurate DTI parameter maps from a limited number of diffusion-weighted images (DWIs). Diff-DTI introduces a joint diffusion model that directly learns the joint probability distribution of DWIs with DTI parametric maps for conditional generation. Additionally, a feature enhancement fusion mechanism (FEFM) is designed and incorporated into the generative process of Diff-DTI to preserve fine structures in the generated DTI maps. A comprehensive evaluation of the performance of Diff-DTI was conducted on the Human Connectome Project dataset. The results demonstrate that Diff-DTI outperforms existing state-of-the-art fast DTI imaging methods in terms of visual quality and quantitative metrics. Furthermore, Diff-DTI has shown the ability to produce high-fidelity DTI maps with only three DWIs, thus overcoming the requirement of a minimum of six DWIs for DTI.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Lang Zhang et al.",
      "keywords": "Diffusion MRI; Feature (linguistics); Diffusion; Joint (building); Tensor (intrinsic definition); Computer science; Physics; Medicine; Magnetic resonance imaging; Mathematics; Geometry; Radiology; Engineering; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.15830",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4409878642",
      "doi": "10.48550/arxiv.2504.02377",
      "title": "Research Paper Recommender System by Considering Users' Information Seeking Behaviors",
      "abstract": "With the rapid growth of scientific publications, researchers need to spend more time and effort searching for papers that align with their research interests. To address this challenge, paper recommendation systems have been developed to help researchers in effectively identifying relevant paper. One of the leading approaches to paper recommendation is content-based filtering method. Traditional content-based filtering methods recommend relevant papers to users based on the overall similarity of papers. However, these approaches do not take into account the information seeking behaviors that users commonly employ when searching for literature. Such behaviors include not only evaluating the overall similarity among papers, but also focusing on specific sections, such as the method section, to ensure that the approach aligns with the user's interests. In this paper, we propose a content-based filtering recommendation method that takes this information seeking behavior into account. Specifically, in addition to considering the overall content of a paper, our approach also takes into account three specific sections (background, method, and results) and assigns weights to them to better reflect user preferences. We conduct offline evaluations on the publicly available DBLP dataset, and the results demonstrate that the proposed method outperforms six baseline methods in terms of precision, recall, F1-score, MRR, and MAP.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Zhelin Xu et al.",
      "keywords": "Recommender system; Computer science; Information seeking; Information retrieval; World Wide Web; Internet privacy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.02377",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392737159",
      "doi": "10.48550/arxiv.2403.06033",
      "title": "Predicting Depression and Anxiety: A Multi-Layer Perceptron for Analyzing the Mental Health Impact of COVID-19",
      "abstract": "We introduce a multi-layer perceptron (MLP) called the COVID-19 Depression and Anxiety Predictor (CoDAP) to predict mental health trends, particularly anxiety and depression, during the COVID-19 pandemic. Our method utilizes a comprehensive dataset, which tracked mental health symptoms weekly over ten weeks during the initial COVID-19 wave (April to June 2020) in a diverse cohort of U.S. adults. This period, characterized by a surge in mental health symptoms and conditions, offers a critical context for our analysis. Our focus was to extract and analyze patterns of anxiety and depression through a unique lens of qualitative individual attributes using CoDAP. This model not only predicts patterns of anxiety and depression during the pandemic but also unveils key insights into the interplay of demographic factors, behavioral changes, and social determinants of mental health. These findings contribute to a more nuanced understanding of the complexity of mental health issues in times of global health crises, potentially guiding future early interventions.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "David Fong et al.",
      "keywords": "Anxiety; Mental health; Coronavirus disease 2019 (COVID-19); Depression (economics); Psychology; Perceptron; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); 2019-20 coronavirus outbreak; Layer (electronics); Clinical psychology; Psychiatry; Medicine; Artificial intelligence; Computer science; Artificial neural network; Virology; Materials science; Internal medicine; Economics; Nanotechnology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2403.06033",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391833599",
      "doi": "10.48550/arxiv.2402.08217",
      "title": "Springboard, Roadblock or \"Crutch\"?: How Transgender Users Leverage Voice Changers for Gender Presentation in Social Virtual Reality",
      "abstract": "Social virtual reality (VR) serves as a vital platform for transgender individuals to explore their identities through avatars and foster personal connections within online communities. However, it presents a challenge: the disconnect between avatar embodiment and voice representation, often leading to misgendering and harassment. Prior research acknowledges this issue but overlooks the potential solution of voice changers. We interviewed 13 transgender and gender-nonconforming users of social VR platforms, focusing on their experiences with and without voice changers. We found that using a voice changer not only reduces voice-related harassment, but also allows them to experience gender euphoria through both hearing their modified voice and the reactions of others to their modified voice, motivating them to pursue voice training and medication to achieve desired voices. Furthermore, we identified the technical barriers to current voice changer technology and potential improvements to alleviate the problems that transgender and gender-nonconforming users face.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Kassie Povinelli et al.",
      "keywords": "Crutch; Leverage (statistics); Transgender; Presentation (obstetrics); Psychology; Computer science; Medicine; Engineering; Artificial intelligence; Obstetrics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2402.08217",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283720585",
      "doi": "10.48550/arxiv.2206.13959",
      "title": "Comparing and extending the use of defeasible argumentation with quantitative data in real-world contexts",
      "abstract": "Dealing with uncertain, contradicting, and ambiguous information is still a central issue in Artificial Intelligence (AI). As a result, many formalisms have been proposed or adapted so as to consider non-monotonicity, with only a limited number of works and researchers performing any sort of comparison among them. A non-monotonic formalism is one that allows the retraction of previous conclusions or claims, from premises, in light of new evidence, offering some desirable flexibility when dealing with uncertainty. This research article focuses on evaluating the inferential capacity of defeasible argumentation, a formalism particularly envisioned for modelling non-monotonic reasoning. In addition to this, fuzzy reasoning and expert systems, extended for handling non-monotonicity of reasoning, are selected and employed as baselines, due to their vast and accepted use within the AI community. Computational trust was selected as the domain of application of such models. Trust is an ill-defined construct, hence, reasoning applied to the inference of trust can be seen as non-monotonic. Inference models were designed to assign trust scalars to editors of the Wikipedia project. In particular, argument-based models demonstrated more robustness than those built upon the baselines despite the knowledge bases or datasets employed. This study contributes to the body of knowledge through the exploitation of defeasible argumentation and its comparison to similar approaches. The practical use of such approaches coupled with a modular design that facilitates similar experiments was exemplified and their respective implementations made publicly available on GitHub [120, 121]. This work adds to previous works, empirically enhancing the generalisability of defeasible argumentation as a compelling approach to reason with quantitative data and uncertain knowledge.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Lucas B. Rizzo et al.",
      "keywords": "Computer science; Rotation formalisms in three dimensions; Inference; Defeasible estate; Argumentation theory; Formalism (music); Non-monotonic logic; Artificial intelligence; Robustness (evolution); Theoretical computer science; Data science; Machine learning; Epistemology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2206.13959",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286749407",
      "doi": "10.48550/arxiv.1905.07596",
      "title": "Causal Inference for Multiple Treatments using Fractional Factorial Designs",
      "abstract": "We consider the design and analysis of multi-factor experiments using fractional factorial and incomplete designs within the potential outcome framework. These designs are particularly useful when limited resources make running a full factorial design infeasible. We connect our design-based methods to standard regression methods. We further motivate the usefulness of these designs in multi-factor observational studies, where certain treatment combinations may be so rare that there are no measured outcomes in the observed data corresponding to them. Therefore, conceptualizing a hypothetical fractional factorial experiment instead of a full factorial experiment allows for appropriate analysis in those settings. We illustrate our approach using biomedical data from the 2003-2004 cycle of the National Health and Nutrition Examination Survey to examine the effects of four common pesticides on body mass index.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Nicole E. Pashley et al.",
      "keywords": "Fractional factorial design; Factorial experiment; Causal inference; Observational study; Factorial; Plackett\u2013Burman design; Inference; Statistics; Design of experiments; Computer science; Regression; Main effect; Mathematics; Econometrics; Artificial intelligence; Response surface methodology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1905.07596",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3192314250",
      "doi": "10.48550/arxiv.2107.14345",
      "title": "Modeling User Empathy Elicited by a Robot Storyteller",
      "abstract": "Virtual and robotic agents capable of perceiving human empathy have the potential to participate in engaging and meaningful human-machine interactions that support human well-being. Prior research in computational empathy has focused on designing empathic agents that use verbal and nonverbal behaviors to simulate empathy and attempt to elicit empathic responses from humans. The challenge of developing agents with the ability to automatically perceive elicited empathy in humans remains largely unexplored. Our paper presents the first approach to modeling user empathy elicited during interactions with a robotic agent. We collected a new dataset from the novel interaction context of participants listening to a robot storyteller (46 participants, 6.9 hours of video). After each storytelling interaction, participants answered a questionnaire that assessed their level of elicited empathy during the interaction with the robot. We conducted experiments with 8 classical machine learning models and 2 deep learning models (long short-term memory networks and temporal convolutional networks) to detect empathy by leveraging patterns in participants' visual behaviors while they were listening to the robot storyteller. Our highest-performing approach, based on XGBoost, achieved an accuracy of 69% and AUC of 72% when detecting empathy in videos. We contribute insights regarding modeling approaches and visual features for automated empathy detection. Our research informs and motivates future development of empathy perception models that can be leveraged by virtual and robotic agents during human-machine interactions.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Leena Mathur et al.",
      "keywords": "Empathy; Active listening; Context (archaeology); Human\u2013robot interaction; Perception; Cognitive psychology; Computer science; Human\u2013computer interaction; Psychology; Virtual agent; Simulation theory of empathy; Robot; Artificial intelligence; Storytelling; Communication; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2107.14345",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4405715370",
      "doi": "10.48550/arxiv.2412.15716",
      "title": "Towards Secure AI-driven Industrial Metaverse with NFT Digital Twins",
      "abstract": "The rise of the industrial metaverse has brought digital twins (DTs) to the forefront. Blockchain-powered non-fungible tokens (NFTs) offer a decentralized approach to creating and owning these cloneable DTs. However, the potential for unauthorized duplication, or counterfeiting, poses a significant threat to the security of NFT-DTs. Existing NFT clone detection methods often rely on static information like metadata and images, which can be easily manipulated. To address these limitations, we propose a novel deep-learning-based solution as a combination of an autoencoder and RNN-based classifier. This solution enables real-time pattern recognition to detect fake NFT-DTs. Additionally, we introduce the concept of dynamic metadata, providing a more reliable way to verify authenticity through AI-integrated smart contracts. By effectively identifying counterfeit DTs, our system contributes to strengthening the security of NFT-based assets in the metaverse.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Ravi Prakash et al.",
      "keywords": "Metaverse; Computer science; Human\u2013computer interaction; Virtual reality",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2412.15716",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287801628",
      "doi": "10.48550/arxiv.2005.00405",
      "title": "Optical wireless communications for in-body and transdermal biomedical\\n applications",
      "abstract": "This article discusses the fundamental architectures for optical wireless\\nsystems for biomedical applications. After summarizing the main applications\\nand reporting their requirements, {we describe the characteristics of the\\ntransdermal and in-body optical channels as well as the challenges that they\\nimpose in the design of communication systems.} In more detail, we provide\\nthree possible architectures for transdermal communications, namely\\nelectro-optical (EO) monitoring, opto-electrical (OE), and all-optical (AO) for\\nneural stimulation, which are currently under investigation, whereas for\\nin-body communications, we provide a nano-scale AO (NAO) concept. For each\\narchitecture, we discuss the main operation principles, the technology\\nenablers, and research directions for their development. Finally, we highlight\\nthe necessity of designing an information-theoretic framework for the analysis\\nand design of the physical (PHY) and medium access control (MAC) layers, which\\ntakes into account the channels'~characteristics.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Alexandros\u2013Apostolos A. Boulogeorgos et al.",
      "keywords": "Transdermal; PHY; Wireless; Computer science; Optical wireless; Optical communication; Physical layer; Computer architecture; Electronic engineering; Telecommunications; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2005.00405",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287868163",
      "doi": "10.48550/arxiv.2002.05746",
      "title": "Using Simulation to Analyze Interrupted Time Series Designs",
      "abstract": "We are sometimes forced to use the Interrupted Time Series (ITS) design as an identification strategy for potential policy change, such as when we only have a single treated unit and no comparable controls. For example, with recent county- and state-wide criminal justice reform efforts, where judicial bodies have changed bail setting practices for everyone in their jurisdiction in order to reduce rates of pre-trial detention while maintaining court order and public safety, we have no natural comparison group other than the past. In these contexts, it is imperative to model pre-policy trends with a light touch, allowing for structures such as autoregressive departures from any pre-existing trend, in order to accurately and realistically assess the statistical uncertainty of our projections (beyond the stringent assumptions necessary for the subsequent causal inferences). To tackle this problem we provide a methodological approach rooted in commonly understood and used modeling approaches that better captures uncertainty. We quantify uncertainty with simulation, generating a distribution of plausible counterfactual trajectories to compare to the observed; this approach naturally allows for incorporating seasonality and other time varying covariates, and provides confidence intervals along with point estimates for the potential impacts of policy change. We find simulation provides a natural framework to capture and show uncertainty in the ITS designs. It also allows for easy extensions such as nonparametric smoothing in order to handle multiple post-policy time points or more structural models to account for seasonality.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Luke Miratrix",
      "keywords": "Counterfactual thinking; Computer science; Econometrics; Autoregressive model; Nonparametric statistics; Identification (biology); Smoothing; Series (stratigraphy); Order (exchange); Time series; Economics; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2002.05746",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4402386094",
      "doi": "10.48550/arxiv.2408.04749",
      "title": "DaedalusData: Exploration, Knowledge Externalization and Labeling of Particles in Medical Manufacturing -- A Design Study",
      "abstract": "In medical diagnostics of both early disease detection and routine patient care, particle-based contamination of in-vitro diagnostics consumables poses a significant threat to patients. Objective data-driven decision-making on the severity of contamination is key for reducing patient risk, while saving time and cost in quality assessment. Our collaborators introduced us to their quality control process, including particle data acquisition through image recognition, feature extraction, and attributes reflecting the production context of particles. Shortcomings in the current process are limitations in exploring thousands of images, data-driven decision making, and ineffective knowledge externalization. Following the design study methodology, our contributions are a characterization of the problem space and requirements, the development and validation of DaedalusData, a comprehensive discussion of our study's learnings, and a generalizable framework for knowledge externalization. DaedalusData is a visual analytics system that enables domain experts to explore particle contamination patterns, label particles in label alphabets, and externalize knowledge through semi-supervised label-informed data projections. The results of our case study and user study show high usability of DaedalusData and its efficient support of experts in generating comprehensive overviews of thousands of particles, labeling of large quantities of particles, and externalizing knowledge to augment the dataset further. Reflecting on our approach, we discuss insights on dataset augmentation via human knowledge externalization, and on the scalability and trade-offs that come with the adoption of this approach in practice.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Alexander Wyss et al.",
      "keywords": "Externalization; Knowledge management; Business; Computer science; Manufacturing engineering; Engineering; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2408.04749",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287822921",
      "doi": "10.48550/arxiv.2004.00005",
      "title": "Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish\\n Internet",
      "abstract": "We study the perception of COVID-2019 epidemic in Polish society using\\nquantitative analysis of its digital footprints on the Internet (on Twitter,\\nGoogle, YouTube, Wikipedia and electronic media represented by Event Registry)\\nfrom January 2020 to 12.03.2020 (before and after official introduction to\\nPoland on 04.03.2020). To this end we utilize data mining, social network\\nanalysis, natural language processing techniques. Each examined internet\\nplatform was analyzed for representativeness and composition of the target\\ngroup. We identified three temporal major cluster of the interest before\\ndisease introduction on the topic COVID-2019: China- and Italy-related peaks on\\nall platforms, as well as a peak on social media related to the recent special\\nlaw on combating COVID-2019. Besides, there was a peak in interest on the day\\nof officially confirmed introduction as well as an exponential increase of\\ninterest when the Polish government declared war against disease with a massive\\nmitigation program. From sociolingistic perspective, we found that concepts and\\nissues of threat, fear and prevention prevailed before introduction. After\\nintroduction, practical concepts about disease and epidemic dominate. We have\\nfound out that Twitter reflected the structural division of the Polish\\npolitical sphere. We were able to identify clear communities of governing\\nparty, mainstream oppostition and protestant group and potential sources of\\nmisinformation. We have also detected bluring boundaries between comminities\\nafter disease introduction.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Andrzej Jarynowski et al.",
      "keywords": "Misinformation; Social media; The Internet; Pandemic; Politics; Political science; Government (linguistics); Coronavirus disease 2019 (COVID-19); Geography; Disease; World Wide Web; Medicine; Computer science; Law",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2004.00005",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415160742",
      "doi": "10.48550/arxiv.2504.10371",
      "title": "Brain-Machine Interfaces &amp; Information Retrieval Challenges and Opportunities",
      "abstract": "The fundamental goal of Information Retrieval (IR) systems lies in their capacity to effectively satisfy human information needs - a challenge that encompasses not just the technical delivery of information, but the nuanced understanding of human cognition during information seeking. Contemporary IR platforms rely primarily on observable interaction signals, creating a fundamental gap between system capabilities and users' cognitive processes. Brain-Machine Interface (BMI) technologies now offer unprecedented potential to bridge this gap through direct measurement of previously inaccessible aspects of information-seeking behaviour. This perspective paper offers a broad examination of the IR landscape, providing a comprehensive analysis of how BMI technology could transform IR systems, drawing from advances at the intersection of both neuroscience and IR research. We present our analysis through three identified fundamental vertices: (1) understanding the neural correlates of core IR concepts to advance theoretical models of search behaviour, (2) enhancing existing IR systems through contextual integration of neurophysiological signals, and (3) developing proactive IR capabilities through direct neurophysiological measurement. For each vertex, we identify specific research opportunities and propose concrete directions for developing BMI-enhanced IR systems. We conclude by examining critical technical and ethical challenges in implementing these advances, providing a structured roadmap for future research at the intersection of neuroscience and IR.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yashar Moshfeghi et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10371",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2951487809",
      "doi": "10.1184/r1/6586337",
      "title": "A Generalized Fellegi-Sunter Framework for Multiple Record Linkage With Application to Homicide Record Systems",
      "abstract": "We present a probabilistic method for linking multiple datafiles. This task is not trivial in the absence of unique identifiers for the individuals recorded. This is a common scenario when linking census data to coverage measurement surveys for census coverage evaluation, and in general when multiple record-systems need to be integrated for posterior analysis. Our method generalizes the Fellegi-Sunter theory for linking records from two datafiles and its modern implementations. The multiple record linkage goal is to classify the record K-tuples coming from K datafiles according to the different matching patterns. Our method incorporates the transitivity of agreement in the computation of the data used to model matching probabilities. We use a mixture model to fit matching probabilities via maximum likelihood using the EM algorithm. We present a method to decide the record K-tuples membership to the subsets of matching patterns and we prove its optimality. We apply our method to the integration of three Colombian homicide record systems and we perform a simulation study in order to explore the performance of the method under measurement error and different scenarios. The proposed method works well and opens some directions for future research.",
      "year": "2006",
      "journal": "arXiv (Cornell University)",
      "authors": "Mauricio Sadinle et al.",
      "keywords": "Record linkage; Matching (statistics); Computer science; Probabilistic logic; Data mining; Linkage (software); Transitive relation; Task (project management); Identifier; Intersection (aeronautics); Theoretical computer science; Statistics; Mathematics; Artificial intelligence; Geography; Population",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1184/r1/6586337",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4416609129",
      "doi": "10.48550/arxiv.2505.23137",
      "title": "An open-source Modular Online Psychophysics Platform (MOPP)",
      "abstract": "In recent years, there is a growing need and opportunity to use online platforms for psychophysics research. Online experiments make it possible to evaluate large and diverse populations remotely and quickly, complementing laboratory-based research. However, developing and running online psychophysics experiments poses several challenges: i) a high barrier-to-entry for researchers who often need to learn complex code-based platforms, ii) an uncontrolled experimental environment, and iii) questionable credibility of the participants. Here, we introduce an open-source Modular Online Psychophysics Platform (MOPP) to address these challenges. Through the simple web-based interface of MOPP, researchers can build modular experiments, share them with others, and copy or modify tasks from each others environments. MOPP provides built-in features to calibrate for viewing distance and to measure visual acuity. It also includes email-based and IP-based authentication, and reCAPTCHA verification. We developed five example psychophysics tasks, that come preloaded in the environment, and ran a pilot experiment which was hosted on the AWS (Amazon Web Services) cloud. Pilot data collected for these tasks yielded similar results to those reported in laboratory settings. MOPP can thus help researchers collect large psychophysics datasets online, with reduced turnaround time, and in a standardized manner.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuval Samoilov-Kats et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23137",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4416609185",
      "doi": "10.48550/arxiv.2505.23147",
      "title": "Eye-tracking-Driven Shared Control for Robotic Arms:Wizard of Oz Studies to Assess Design Choices",
      "abstract": "Advances in eye-tracking control for assistive robotic arms provide intuitive interaction opportunities for people with physical disabilities. Shared control has gained interest in recent years by improving user satisfaction through partial automation of robot control. We present an eye-tracking-guided shared control design based on insights from state-of-the-art literature. A Wizard of Oz setup was used in which automation was simulated by an experimenter to evaluate the concept without requiring full implementation. This approach allowed for rapid exploration of user needs and expectations to inform future iterations. Two studies were conducted to assess user experience, identify design challenges, and find improvements to ensure usability and accessibility. The first study involved people with disabilities by providing a survey, and the second study used the Wizard of Oz design in person to gain technical insights, leading to a comprehensive picture of findings.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Anke Fischer-Janzen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.23147",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4381714413",
      "doi": "10.48550/arxiv.2306.12320",
      "title": "Prognostic Biomarker Identification for Pancreatic Cancer by Analyzing Multiple mRNA Microarray and microRNA Expression Datasets",
      "abstract": "Possessing the five-year durability rate of nearly 5%, currently, the fourth leading cause for cancer-related deaths is pancreatic cancer. Previously, several works have resolved that early diagnosis performs a meaningful function in enhancing the durability rate and diverse online tools have been utilized to distinguish prognostic biomarker which is a lengthy process. We believe that the statistical feature selection method can produce a better and faster result here. To authenticate our statement, we picked three different mRNA microarray (GSE15471, GSE28735, and GSE16515) and a microRNA (GSE41372) dataset for identification of differentially expressed genes (DEGs) and differentially expressed microRNAs (DEMs). By adopting some feature selecting methods, 178 DEGs and 16 DEMs were elected. After identifying target genes of DEMs, we selected two DEGs (ECT2 and NRP2) which were also identified among DEMs target genes. Moreover, overall durability report established that ECT2 and NRP2 were associated with poor overall survival. Hence, we concluded that for pancreatic cancer, statistical feature selection approaches certainly perform better for biomarker identification than pre-defined online programs, and here, ECT2 and NRP2 can act as possible prognostic biomarkers. All the resources, programs and snippets of our literature can be discovered at https://github.com/Srizon143005/PancreaticCancerBiomarkers.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Azmain Yakin Srizon",
      "keywords": "Identification (biology); Biomarker; microRNA; Pancreatic cancer; Microarray; Computational biology; Feature selection; Cancer; Gene; Computer science; Bioinformatics; Biology; Medicine; Gene expression; Internal medicine; Artificial intelligence; Genetics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2306.12320",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416891296",
      "doi": "10.48550/arxiv.2507.00963",
      "title": "Social Robots for People with Dementia: A Literature Review on Deception from Design to Perception",
      "abstract": "As social robots increasingly enter dementia care, concerns about deception, intentional or not, are gaining attention. Yet, how robotic design cues might elicit misleading perceptions in people with dementia, and how these perceptions arise, remains insufficiently understood. In this scoping review, we examined 26 empirical studies on interactions between people with dementia and physical social robots. We identify four key design cue categories that may influence deceptive impressions: cues resembling physiological signs (e.g., simulated breathing), social intentions (e.g., playful movement), familiar beings (e.g., animal-like form and sound), and, to a lesser extent, cues that reveal artificiality. Thematic analysis of user responses reveals that people with dementia often attribute biological, social, and mental capacities to robots, dynamically shifting between awareness and illusion. These findings underscore the fluctuating nature of ontological perception in dementia contexts. Existing definitions of robotic deception often rest on philosophical or behaviorist premises, but rarely engage with the cognitive mechanisms involved. We propose an empirically grounded definition: robotic deception occurs when Type 1 (automatic, heuristic) processing dominates over Type 2 (deliberative, analytic) reasoning, leading to misinterpretation of a robot's artificial nature. This dual-process perspective highlights the ethical complexity of social robots in dementia care and calls for design approaches that are not only engaging, but also epistemically respectful.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Fan Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2507.00963",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4415160882",
      "doi": "10.48550/arxiv.2504.10428",
      "title": "Learning with Positive and Imperfect Unlabeled Data",
      "abstract": "We study the problem of learning binary classifiers from positive and unlabeled data when the unlabeled data distribution is shifted, which we call Positive and Imperfect Unlabeled (PIU) Learning. In the absence of covariate shifts, i.e., with perfect unlabeled data, Denis (1998) reduced this problem to learning under Massart noise; however, that reduction fails under even slight shifts. Our main results on PIU learning are the characterizations of the sample complexity of PIU learning and a computationally and sample-efficient algorithm achieving a misclassification error $\\varepsilon$. We further show that our results lead to new algorithms for several related problems. 1. Learning from smooth distributions: We give algorithms that learn interesting concept classes from only positive samples under smooth feature distributions, bypassing known existing impossibility results and contributing to recent advances in smoothened learning (Haghtalab et al, J.ACM'24) (Chandrasekaran et al., COLT'24). 2. Learning with a list of unlabeled distributions: We design new algorithms that apply to a broad class of concept classes under the assumption that we are given a list of unlabeled distributions, one of which--unknown to the learner--is $O(1)$-close to the true feature distribution. 3. Estimation in the presence of unknown truncation: We give the first polynomial sample and time algorithm for estimating the parameters of an exponential family distribution from samples truncated to an unknown set approximable by polynomials in $L_1$-norm. This improves the algorithm by Lee et al. (FOCS'24) that requires approximation in $L_2$-norm. 4. Detecting truncation: We present new algorithms for detecting whether given samples have been truncated (or not) for a broad class of non-product distributions, including non-product distributions, improving the algorithm by De et al. (STOC'24).",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Jane H. Lee et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.10428",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3167954679",
      "doi": "10.1002/ecm.1470",
      "title": "A guide to state-space modeling of ecological time series",
      "abstract": "State-space models (SSMs) are an important modeling framework for analyzing\\necological time series. These hierarchical models are commonly used to model\\npopulation dynamics, animal movement, and capture-recapture data, and are now\\nincreasingly being used to model other ecological processes. SSMs are popular\\nbecause they are flexible and they model the natural variation in ecological\\nprocesses separately from observation error. Their flexibility allows\\necologists to model continuous, count, binary, and categorical data with linear\\nor nonlinear processes that evolve in discrete or continuous time. Modeling the\\ntwo sources of stochasticity separately allows researchers to differentiate\\nbetween biological variation (e.g., in birth processes) and imprecision in the\\nsampling methodology, and generally provides better estimates of the ecological\\nquantities of interest than if only one source of stochasticity is directly\\nmodeled. Since the introduction of SSMs, a broad range of fitting procedures\\nhave been proposed. However, the variety and complexity of these procedures can\\nlimit the ability of ecologists to formulate and fit their own SSMs. We provide\\nthe knowledge for ecologists to create SSMs that are robust to common, and\\noften hidden, estimation problems, and the model selection and validation tools\\nthat can help them assess how well their models fit their data. In this paper,\\nwe present a review of SSMs that will provide a strong foundation to ecologists\\ninterested in learning about SSMs, introduce new tools to veteran SSM users,\\nand highlight promising research directions for statisticians interested in\\necological applications. The review is accompanied by an in-depth tutorial that\\ndemonstrates how SSMs models can be fitted and validated in R. Together, the\\nreview and tutorial present an introduction to SSMs that will help ecologists\\nto formulate, fit, and validate their models.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Marie Auger\u2010M\u00e9th\u00e9 et al.",
      "keywords": "Ecology; Series (stratigraphy); State space; State (computer science); Environmental science; Computer science; Mathematics; Biology; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1002/ecm.1470",
      "cited_by_count": 240,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3207212569",
      "doi": "10.1007/s40593-021-00271-1",
      "title": "Equality of Learning Opportunity via Individual Fairness in Personalized Recommendations",
      "abstract": "Online educational platforms are playing a primary role in mediating the success of individuals' careers. Therefore, while building overlying content recommendation services, it becomes essential to guarantee that learners are provided with equal recommended learning opportunities, according to the platform values, context, and pedagogy. Though the importance of ensuring equality of learning opportunities has been well investigated in traditional institutions, how this equality can be operationalized in online learning ecosystems through recommender systems is still under-explored. In this paper, we formalize educational principles that model recommendations' learning properties, and a novel fairness metric that combines them in order to monitor the equality of recommended learning opportunities among learners. Then, we envision a scenario wherein an educational platform should be arranged in such a way that the generated recommendations meet each principle to a certain degree for all learners, constrained to their individual preferences. Under this view, we explore the learning opportunities provided by recommender systems in a large-scale course platform, uncovering systematic inequalities. To reduce this effect, we propose a novel post-processing approach that balances personalization and equality of recommended opportunities. Experiments show that our approach leads to higher equality, with a negligible loss in personalization. Our study moves a step forward in operationalizing the ethics of human learning in recommendations, a core unit of intelligent educational systems.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Mirko Marras et al.",
      "keywords": "Operationalization; Personalization; Computer science; Context (archaeology); Blueprint; Knowledge management; World Wide Web; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1007/s40593-021-00271-1",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4224911935",
      "doi": "10.48550/arxiv.2204.00419",
      "title": "Artificial Intelligence and work: a critical review of recent research from the social sciences",
      "abstract": "This review seeks to present a comprehensive picture of recent discussions in the social sciences of the anticipated impact of AI on the world of work. Issues covered include technological unemployment, algorithmic management, platform work an the politics of AI work. The review identifies the major disciplinary and methodological perspectives on AI's impact on work, and the obstacles they face in making predictions. Two parameters influencing the development and deployment of AI in the economy are highlighted, the capitalist imperative and nationalistic pressures.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Jean\u2010Philippe Deranty et al.",
      "keywords": "Work (physics); Software deployment; Face (sociological concept); Politics; Discipline; Sociology; Unemployment; Engineering ethics; Social science; Political science; Management science; Engineering; Economics; Economic growth",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.48550/arxiv.2204.00419",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3035140518",
      "doi": "10.4230/lipics.forc.2021.7",
      "title": "Causal Intersectionality and Fair Ranking",
      "abstract": "In this paper we propose a causal modeling approach to intersectional fairness, and a flexible, task-specific method for computing intersectionally fair rankings. Rankings are used in many contexts, ranging from Web search to college admissions, but causal inference for fair rankings has received limited attention. Additionally, the growing literature on causal fairness has directed little attention to intersectionality. By bringing these issues together in a formal causal framework we make the application of intersectionality in algorithmic fairness explicit, connected to important real world effects and domain knowledge, and transparent about technical limitations. We experimentally evaluate our approach on real and synthetic datasets, exploring its behavior under different structural assumptions.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Ke Yang et al.",
      "keywords": "Intersectionality; Ranking (information retrieval); Sociology; Political science; Computer science; Gender studies; Information retrieval",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.4230/lipics.forc.2021.7",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3203995112",
      "doi": "10.1051/0004-6361/202040086",
      "title": "The Aperture Array Verification System 1: System overview and early commissioning results",
      "abstract": "The design and development process for the Square Kilometre Array (SKA) radio\\ntelescope, the Low Frequency Aperture Array component, was progressed during\\nthe SKA pre-construction phase by an international consortium, with the goal of\\nmeeting requirements for a critical design review. As part of the development\\nprocess a full-sized prototype SKA Low station was deployed, the Aperture Array\\nVerification System 1 (AAVS1). We provide a system overview and describe the\\ncommissioning results of AAVS1, which is a low frequency radio telescope with\\n256 dual-polarisation log-periodic dipole antennas working as a phased array. A\\ndetailed system description is provided, including an in-depth overview of\\nrelevant sub-systems, ranging from hardware, firmware, software,\\ncalibration,and control sub-systems. Early commissioning results cover initial\\nbootstrapping, array calibration, stability testing, beam-forming,and on-sky\\nsensitivity validation. Lessons learned are presented, along with future\\ndevelopments.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "P. Benthem et al.",
      "keywords": "Firmware; Radio telescope; Aperture (computer memory); Physics; Phased array; Calibration; Telescope; Radio astronomy; Software; Process (computing); Computer hardware; Remote sensing; Computer science; Optics; Astrophysics; Telecommunications; Acoustics; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1051/0004-6361/202040086",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226207853",
      "doi": "10.48550/arxiv.2112.09245",
      "title": "Automated Deep Learning: Neural Architecture Search Is Not the End",
      "abstract": "Deep learning (DL) has proven to be a highly effective approach for developing models in diverse contexts, including visual perception, speech recognition, and machine translation. However, the end-to-end process for applying DL is not trivial. It requires grappling with problem formulation and context understanding, data engineering, model development, deployment, continuous monitoring and maintenance, and so on. Moreover, each of these steps typically relies heavily on humans, in terms of both knowledge and interactions, which impedes the further advancement and democratization of DL. Consequently, in response to these issues, a new field has emerged over the last few years: automated deep learning (AutoDL). This endeavor seeks to minimize the need for human involvement and is best known for its achievements in neural architecture search (NAS), a topic that has been the focus of several surveys. That stated, NAS is not the be-all and end-all of AutoDL. Accordingly, this review adopts an overarching perspective, examining research efforts into automation across the entirety of an archetypal DL workflow. In so doing, this work also proposes a comprehensive set of ten criteria by which to assess existing work in both individual publications and broader research areas. These criteria are: novelty, solution quality, efficiency, stability, interpretability, reproducibility, engineering quality, scalability, generalizability, and eco-friendliness. Thus, ultimately, this review provides an evaluative overview of AutoDL in the early 2020s, identifying where future opportunities for progress may exist.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Xuanyi Dong et al.",
      "keywords": "Computer science; Artificial intelligence; Interpretability; Workflow; Data science; Software deployment; Context (archaeology); Deep learning; Generalizability theory; Novelty; End user; Scalability; Machine learning; Knowledge management; Software engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.09245",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4286850774",
      "doi": "10.48550/arxiv.2111.12823",
      "title": "Fairness for AUC via Feature Augmentation",
      "abstract": "We study fairness in the context of classification where the performance is measured by the area under the curve (AUC) of the receiver operating characteristic. AUC is commonly used to measure the performance of prediction models. The same classifier can have significantly varying AUCs for different protected groups and, in real-world applications, it is often desirable to reduce such cross-group differences. We address the problem of how to acquire additional features to most greatly improve AUC for the disadvantaged group. We develop a novel approach, fairAUC, based on feature augmentation (adding features) to mitigate bias between identifiable groups. The approach requires only a few summary statistics to offer provable guarantees on AUC improvement, and allows managers flexibility in determining where in the fairness-accuracy tradeoff they would like to be. We evaluate fairAUC on synthetic and real-world datasets and find that it significantly improves AUC for the disadvantaged group relative to benchmarks maximizing overall AUC and minimizing bias between groups.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Hortense Fong et al.",
      "keywords": "Receiver operating characteristic; Computer science; Disadvantaged; Classifier (UML); Feature (linguistics); Area under curve; Context (archaeology); Artificial intelligence; Machine learning; Flexibility (engineering); Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2111.12823",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3202444514",
      "doi": "10.48550/arxiv.2110.01109",
      "title": "FairMask: Better Fairness via Model-based Rebalancing of Protected Attributes",
      "abstract": "Context: Machine learning software can generate models that inappropriately discriminate against specific protected social groups (e.g., groups based on gender, ethnicity, etc). Motivated by those results, software engineering researchers have proposed many methods for mitigating those discriminatory effects. While those methods are effective in mitigating bias, few of them can provide explanations on what is the root cause of bias. Objective: We aim at better detection and mitigation of algorithmic discrimination in machine learning software problems. Method: Here we propose xFAIR, a model-based extrapolation method, that is capable of both mitigating bias and explaining the cause. In our xFAIR approach, protected attributes are represented by models learned from the other independent variables (and these models offer extrapolations over the space between existing examples). We then use the extrapolation models to relabel protected attributes later seen in testing data or deployment time. Our approach aims to offset the biased predictions of the classification model via rebalancing the distribution of protected attributes. Results: The experiments of this paper show that, without compromising (original) model performance, xFAIR can achieve significantly better group and individual fairness (as measured in different metrics) than benchmark methods. Moreover, when compared to another instance-based rebalancing method, our model-based approach shows faster runtime and thus better scalability. Conclusion: Algorithmic decision bias can be removed via extrapolation that smooths away outlier points. As evidence for this, our proposed xFAIR is not only performance-wise better (measured by fairness and performance metrics) than two state-of-the-art fairness algorithms.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Kewen Peng et al.",
      "keywords": "Extrapolation; Computer science; Scalability; Offset (computer science); Machine learning; Benchmark (surveying); Outlier; Context (archaeology); Software; Artificial intelligence; Data mining; Statistics; Database; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2110.01109",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287871840",
      "doi": "10.48550/arxiv.2002.01111",
      "title": "Do I Look Like a Criminal? Examining how Race Presentation Impacts Human\\n Judgement of Recidivism",
      "abstract": "Understanding how racial information impacts human decision making in online\\nsystems is critical in today's world. Prior work revealed that race information\\nof criminal defendants, when presented as a text field, had no significant\\nimpact on users' judgements of recidivism. We replicated and extended this work\\nto explore how and when race information influences users' judgements, with\\nrespect to the saliency of presentation. Our results showed that adding photos\\nto the race labels had a significant impact on recidivism predictions for users\\nwho identified as female, but not for those who identified as male. The race of\\nthe defendant also impacted these results, with black defendants being less\\nlikely to be predicted to recidivate compared to white defendants. These\\nresults have strong implications for how system-designers choose to display\\nrace information, and cautions researchers to be aware of gender and race\\neffects when using Amazon Mechanical Turk workers.\\n",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Keri Mallari et al.",
      "keywords": "Recidivism; Race (biology); Judgement; Presentation (obstetrics); Psychology; White (mutation); Criminology; Social psychology; Sociology; Political science; Law; Gender studies",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2002.01111",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4297630727",
      "doi": "10.48550/arxiv.2209.01340",
      "title": "Federated XGBoost on Sample-Wise Non-IID Data",
      "abstract": "Federated Learning (FL) is a paradigm for jointly training machine learning algorithms in a decentralized manner which allows for parties to communicate with an aggregator to create and train a model, without exposing the underlying raw data distribution of the local parties involved in the training process. Most research in FL has been focused on Neural Network-based approaches, however Tree-Based methods, such as XGBoost, have been underexplored in Federated Learning due to the challenges in overcoming the iterative and additive characteristics of the algorithm. Decision tree-based models, in particular XGBoost, can handle non-IID data, which is significant for algorithms used in Federated Learning frameworks since the underlying characteristics of the data are decentralized and have risks of being non-IID by nature. In this paper, we focus on investigating the effects of how Federated XGBoost is impacted by non-IID distributions by performing experiments on various sample size-based data skew scenarios and how these models perform under various non-IID scenarios. We conduct a set of extensive experiments across multiple different datasets and different data skew partitions. Our experimental results demonstrate that despite the various partition ratios, the performance of the models stayed consistent and performed close to or equally well against models that were trained in a centralized manner.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Katelinh Jones et al.",
      "keywords": "Computer science; Skew; Raw data; News aggregator; Partition (number theory); Data mining; Machine learning; Sample (material); Artificial intelligence; Process (computing); Tree (set theory); Decision tree; Training set; Artificial neural network; Set (abstract data type); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2209.01340",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323557336",
      "doi": "10.48550/arxiv.2303.02580",
      "title": "Estimating Racial Disparities When Race is Not Observed",
      "abstract": "The estimation of racial disparities in various fields is often hampered by the lack of individual-level racial information. In many cases, the law prohibits the collection of such information to prevent direct racial discrimination. As a result, analysts have frequently adopted Bayesian Improved Surname Geocoding (BISG) and its variants, which combine individual names and addresses with Census data to predict race. Unfortunately, the residuals of BISG are often correlated with the outcomes of interest, generally attenuating estimates of racial disparities. To correct this bias, we propose an alternative identification strategy under the assumption that surname is conditionally independent of the outcome given (unobserved) race, residence location, and other observed characteristics. We introduce a new class of models, Bayesian Instrumental Regression for Disparity Estimation (BIRDiE), that take BISG probabilities as inputs and produce racial disparity estimates by using surnames as an instrumental variable for race. Our estimation method is scalable, making it possible to analyze large-scale administrative data. We also show how to address potential violations of the key identification assumptions. A validation study based on the North Carolina voter file shows that BISG+BIRDiE reduces error by up to 84% when estimating racial differences in party registration. Finally, we apply the proposed methodology to estimate racial differences in who benefits from the home mortgage interest deduction using individual-level tax data from the U.S. Internal Revenue Service. Open-source software is available which implements the proposed methodology.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Cory McCartan et al.",
      "keywords": "Race (biology); Econometrics; Mathematics; Sociology; Gender studies",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.02580",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4287551384",
      "doi": "10.48550/arxiv.2012.09400",
      "title": "Stochastic Compositional Gradient Descent under Compositional Constraints",
      "abstract": "This work studies constrained stochastic optimization problems where the objective and constraint functions are convex and expressed as compositions of stochastic functions. The problem arises in the context of fair classification, fair regression, and the design of queuing systems. Of particular interest is the large-scale setting where an oracle provides the stochastic gradients of the constituent functions, and the goal is to solve the problem with a minimal number of calls to the oracle. Owing to the compositional form, the stochastic gradients provided by the oracle do not yield unbiased estimates of the objective or constraint gradients. Instead, we construct approximate gradients by tracking the inner function evaluations, resulting in a quasi-gradient saddle point algorithm. We prove that the proposed algorithm is guaranteed to find the optimal and feasible solution almost surely. We further establish that the proposed algorithm requires $\\mathcal{O}(1/\u03b5^4)$ data samples in order to obtain an $\u03b5$-approximate optimal point while also ensuring zero constraint violation. The result matches the sample complexity of the stochastic compositional gradient descent method for unconstrained problems and improves upon the best-known sample complexity results for the constrained settings. The efficacy of the proposed algorithm is tested on both fair classification and fair regression problems. The numerical results show that the proposed algorithm outperforms the state-of-the-art algorithms in terms of the convergence rate.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Srujan Teja Thomdapu et al.",
      "keywords": "Oracle; Stochastic gradient descent; Mathematical optimization; Saddle point; Mathematics; Constraint (computer-aided design); Context (archaeology); Convergence (economics); Stochastic approximation; Convex function; Stochastic optimization; Rate of convergence; Stationary point; Algorithm; Computer science; Regular polygon",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2012.09400",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4321592862",
      "doi": "10.48550/arxiv.2302.10395",
      "title": "Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience",
      "abstract": "Despite the widespread use of artificial intelligence (AI), designing user experiences (UX) for AI-powered systems remains challenging. UX designers face hurdles understanding AI technologies, such as pre-trained language models, as design materials. This limits their ability to ideate and make decisions about whether, where, and how to use AI. To address this problem, we bridge the literature on AI design and AI transparency to explore whether and how frameworks for transparent model reporting can support design ideation with pre-trained models. By interviewing 23 UX practitioners, we find that practitioners frequently work with pre-trained models, but lack support for UX-led ideation. Through a scenario-based design task, we identify common goals that designers seek model understanding for and pinpoint their model transparency information needs. Our study highlights the pivotal role that UX designers can play in Responsible AI and calls for supporting their understanding of AI limitations through model transparency and interrogation.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Q. Vera Liao et al.",
      "keywords": "Transparency (behavior); Computer science; Interrogation; Ideation; Human\u2013computer interaction; User experience design; Knowledge management; Psychology; Computer security; Cognitive science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2302.10395",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4377299057",
      "doi": "10.48550/arxiv.2305.11250",
      "title": "Towards Intersectional Moderation: An Alternative Model of Moderation Built on Care and Power",
      "abstract": "Shortcomings of current models of moderation have driven policy makers, scholars, and technologists to speculate about alternative models of content moderation. While alternative models provide hope for the future of online spaces, they can fail without proper scaffolding. Community moderators are routinely confronted with similar issues and have therefore found creative ways to navigate these challenges. Learning more about the decisions these moderators make, the challenges they face, and where they are successful can provide valuable insight into how to ensure alternative moderation models are successful. In this study, I perform a collaborative ethnography with moderators of r/AskHistorians, a community that uses an alternative moderation model, highlighting the importance of accounting for power in moderation. Drawing from Black feminist theory, I call this \"intersectional moderation.\" I focus on three controversies emblematic of r/AskHistorians' alternative model of moderation: a disagreement over a moderation decision; a collaboration to fight racism on Reddit; and a period of intense turmoil and its impact on policy. Through this evidence I show how volunteer moderators navigated multiple layers of power through care work. To ensure the successful implementation of intersectional moderation, I argue that designers should support decision-making processes and policy makers should account for the impact of the sociotechnical systems in which moderators work.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Sarah Gilbert",
      "keywords": "Moderation; Explanatory power; Sociotechnical system; Power (physics); Psychology; Social psychology; Intersectionality; Public relations; Sociology; Political science; Computer science; Knowledge management; Epistemology; Gender studies",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.11250",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399872132",
      "doi": "10.48550/arxiv.2406.11844",
      "title": "Prompting the E-Brushes: Users as Authors in Generative AI",
      "abstract": "Since its introduction in 2022, Generative AI has significantly impacted the art world, from winning state art fairs to creating complex videos from simple prompts. Amid this renaissance, a pivotal issue emerges: should users of Generative AI be recognized as authors eligible for copyright protection? The Copyright Office, in its March 2023 Guidance, argues against this notion. By comparing the prompts to clients' instructions for commissioned art, the Office denies users authorship due to their limited role in the creative process. This Article challenges this viewpoint and advocates for the recognition of Generative AI users who incorporate these tools into their creative endeavors. It argues that the current policy fails to consider the intricate and dynamic interaction between Generative AI users and the models, where users actively influence the output through a process of adjustment, refinement, selection, and arrangement. Rather than dismissing the contributions generated by AI, this Article suggests a simplified and streamlined registration process that acknowledges the role of AI in creation. This approach not only aligns with the constitutional goal of promoting the progress of science and useful arts but also encourages public engagement in the creative process, which contributes to the pool of training data for AI. Moreover, it advocates for a flexible framework that evolves alongside technological advancements while ensuring safety and public interest. In conclusion, by examining text-to-image generators and addressing misconceptions about Generative AI and user interaction, this Article calls for a regulatory framework that adapts to technological developments and safeguards public interests",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yiyang Mei",
      "keywords": "Generative grammar; Psychology; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2406.11844",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226150629",
      "doi": "10.48550/arxiv.2112.11374",
      "title": "Data-Driven Outage Restoration Time Prediction via Transfer Learning with Cluster Ensembles",
      "abstract": "This paper develops a data-driven approach to accurately predict the restoration time of outages under different scales and factors. To achieve the goal, the proposed method consists of three stages. First, given the unprecedented amount of data collected by utilities, a sparse dictionary-based ensemble spectral clustering (SDESC) method is proposed to decompose historical outage datasets, which enjoys good computational efficiency and scalability. Specifically, each outage sample is represented by a linear combination of a small number of selected dictionary samples using a density-based method. Then, the dictionary-based representation is utilized to perform the spectral analysis to group the data samples with similar features into the same subsets. In the second stage, a knowledge-transfer-added restoration time prediction model is trained for each subset by combining weather information and outage-related features. The transfer learning technology is introduced with the aim of dealing with the underestimation problem caused by data imbalance in different subsets, thus improving the model performance. Furthermore, to connect unseen outages with the learned outage subsets, a t-distributed stochastic neighbor embedding-based strategy is applied. The proposed method fully builds on and is also tested on a large real-world outage dataset from a utility provider with a time span of six consecutive years. The numerical results validate that our method has high prediction accuracy while showing good stability against real-world data limitations.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Dingwei Wang et al.",
      "keywords": "Computer science; Cluster analysis; Scalability; Stability (learning theory); Representation (politics); Data mining; Embedding; Artificial intelligence; Transfer of learning; Machine learning; Transfer (computing); Sample (material)",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2112.11374",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4399151237",
      "doi": "10.48550/arxiv.2405.17495",
      "title": "Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey",
      "abstract": "Vertical Federated Learning (VFL) is a privacy-preserving distributed learning paradigm where different parties collaboratively learn models using partitioned features of shared samples, without leaking private data. Recent research has shown promising results addressing various challenges in VFL, highlighting its potential for practical applications in cross-domain collaboration. However, the corresponding research is scattered and lacks organization. To advance VFL research, this survey offers a systematic overview of recent developments. First, we provide a history and background introduction, along with a summary of the general training protocol of VFL. We then revisit the taxonomy in recent reviews and analyze limitations in-depth. For a comprehensive and structured discussion, we synthesize recent research from three fundamental perspectives: effectiveness, security, and applicability. Finally, we discuss several critical future research directions in VFL, which will facilitate the developments in this field. We provide a collection of research lists and periodically update them at https://github.com/shentt67/VFL_Survey.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Mang Ye et al.",
      "keywords": "Computer science; Federated learning; Computer security; Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.17495",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3098131419",
      "doi": "10.48550/arxiv.2011.09003",
      "title": "Emotions in Online Content Diffusion",
      "abstract": "Social media-transmitted online information, which is associated with emotional expressions, shapes our thoughts and actions. In this study, we incorporate social network theories and analyses and use a computational approach to investigate how emotional expressions, particularly \\textit{negative discrete emotional expressions} (i.e., anxiety, sadness, anger, and disgust), lead to differential diffusion of online content in social media networks. We rigorously quantify diffusion cascades' structural properties (i.e., size, depth, maximum breadth, and structural virality) and analyze the individual characteristics (i.e., age, gender, and network degree) and social ties (i.e., strong and weak) involved in the cascading process. In our sample, more than six million unique individuals transmitted 387,486 randomly selected articles in a massive-scale online social network, WeChat. We detect the expression of discrete emotions embedded in these articles, using a newly generated domain-specific and up-to-date emotion lexicon. We apply a partial-linear instrumental variable approach with a double machine learning framework to causally identify the impact of the negative discrete emotions on online content diffusion. We find that articles with more expressions of anxiety spread to a larger number of individuals and diffuse more deeply, broadly, and virally. Expressions of anger and sadness, however, reduce cascades' size and maximum breadth. We further show that the articles with different degrees of negative emotional expressions tend to spread differently based on individual characteristics and social ties. Our results shed light on content marketing and regulation, utilizing negative emotional expressions.",
      "year": "2020",
      "journal": "arXiv (Cornell University)",
      "authors": "Yifan Yu et al.",
      "keywords": "Sadness; Anger; Disgust; Psychology; Social media; Emotional expression; Interpersonal ties; Social psychology; Content (measure theory); Anxiety; Socioemotional selectivity theory; Cognitive psychology; Computer science; Developmental psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2011.09003",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4416544199",
      "doi": "10.48550/arxiv.2504.12587",
      "title": "Software Engineering Principles for Fairer Systems: Experiments with GroupCART",
      "abstract": "Discrimination-aware classification aims to make accurate predictions while satisfying fairness constraints. Traditional decision tree learners typically optimize for information gain in the target attribute alone, which can result in models that unfairly discriminate against protected social groups (e.g., gender, ethnicity). Motivated by these shortcomings, we propose GroupCART, a tree-based ensemble optimizer that avoids bias during model construction by optimizing not only for decreased entropy in the target attribute but also for increased entropy in protected attributes. Our experiments show that GroupCART achieves fairer models without data transformation and with minimal performance degradation. Furthermore, the method supports customizable weighting, offering a smooth and flexible trade-off between predictive performance and fairness based on user requirements. These results demonstrate that algorithmic bias in decision tree models can be mitigated through multi-task, fairness-aware learning. All code and datasets used in this study are available at: https://github.com/anonymous12138/groupCART.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Kewen Peng et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2504.12587",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387355807",
      "doi": "10.48550/arxiv.2310.01679",
      "title": "Estimating and Implementing Conventional Fairness Metrics With Probabilistic Protected Features",
      "abstract": "The vast majority of techniques to train fair models require access to the protected attribute (e.g., race, gender), either at train time or in production. However, in many important applications this protected attribute is largely unavailable. In this paper, we develop methods for measuring and reducing fairness violations in a setting with limited access to protected attribute labels. Specifically, we assume access to protected attribute labels on a small subset of the dataset of interest, but only probabilistic estimates of protected attribute labels (e.g., via Bayesian Improved Surname Geocoding) for the rest of the dataset. With this setting in mind, we propose a method to estimate bounds on common fairness metrics for an existing model, as well as a method for training a model to limit fairness violations by solving a constrained non-convex optimization problem. Unlike similar existing approaches, our methods take advantage of contextual information -- specifically, the relationships between a model's predictions and the probabilistic prediction of protected attributes, given the true protected attribute, and vice versa -- to provide tighter bounds on the true disparity. We provide an empirical illustration of our methods using voting data. First, we show our measurement method can bound the true disparity up to 5.5x tighter than previous methods in these applications. Then, we demonstrate that our training technique effectively reduces disparity while incurring lesser fairness-accuracy trade-offs than other fair optimization methods with limited access to protected attributes.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Hadi Elzayn et al.",
      "keywords": "Computer science; Probabilistic logic; Voting; Bayesian probability; Data mining; Limit (mathematics); Geocoding; Machine learning; Artificial intelligence; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2310.01679",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4372283126",
      "doi": "10.48550/arxiv.2305.02942",
      "title": "Incentivising the federation: gradient-based metrics for data selection and valuation in private decentralised training",
      "abstract": "Obtaining high-quality data for collaborative training of machine learning models can be a challenging task due to A) regulatory concerns and B) a lack of data owner incentives to participate. The first issue can be addressed through the combination of distributed machine learning techniques (e.g. federated learning) and privacy enhancing technologies (PET), such as the differentially private (DP) model training. The second challenge can be addressed by rewarding the participants for giving access to data which is beneficial to the training model, which is of particular importance in federated settings, where the data is unevenly distributed. However, DP noise can adversely affect the underrepresented and the atypical (yet often informative) data samples, making it difficult to assess their usefulness. In this work, we investigate how to leverage gradient information to permit the participants of private training settings to select the data most beneficial for the jointly trained model. We assess two such methods, namely variance of gradients (VoG) and the privacy loss-input susceptibility score (PLIS). We show that these techniques can provide the federated clients with tools for principled data selection even in stricter privacy settings.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Dmitrii Usynin et al.",
      "keywords": "Valuation (finance); Computer science; Selection (genetic algorithm); Training set; Training (meteorology); Data mining; Data science; Artificial intelligence; Business; Finance; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2305.02942",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287065174",
      "doi": "10.48550/arxiv.2107.13734",
      "title": "An Ethical Framework for Guiding the Development of Affectively-Aware\\n Artificial Intelligence",
      "abstract": "The recent rapid advancements in artificial intelligence research and\\ndeployment have sparked more discussion about the potential ramifications of\\nsocially- and emotionally-intelligent AI. The question is not if research can\\nproduce such affectively-aware AI, but when it will. What will it mean for\\nsociety when machines -- and the corporations and governments they serve -- can\\n\"read\" people's minds and emotions? What should developers and operators of\\nsuch AI do, and what should they not do? The goal of this article is to\\npre-empt some of the potential implications of these developments, and propose\\na set of guidelines for evaluating the (moral and) ethical consequences of\\naffectively-aware AI, in order to guide researchers, industry professionals,\\nand policy-makers. We propose a multi-stakeholder analysis framework that\\nseparates the ethical responsibilities of AI Developers vis-\\\\`a-vis the\\nentities that deploy such AI -- which we term Operators. Our analysis produces\\ntwo pillars that clarify the responsibilities of each of these stakeholders:\\nProvable Beneficence, which rests on proving the effectiveness of the AI, and\\nResponsible Stewardship, which governs responsible collection, use, and storage\\nof data and the decisions made from such data. We end with recommendations for\\nresearchers, developers, operators, as well as regulators and law-makers.\\n",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Desmond C. Ong",
      "keywords": "Software deployment; Stewardship (theology); Stakeholder; Order (exchange); Set (abstract data type); Artificial intelligence; Engineering ethics; Computer science; Beneficence; Knowledge management; Political science; Autonomy; Business; Public relations; Law; Engineering; Finance",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2107.13734",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4286859996",
      "doi": "10.48550/arxiv.2111.01496",
      "title": "Quality change: norm or exception? Measurement, Analysis and Detection of Quality Change in Wikipedia",
      "abstract": "Wikipedia has been turned into an immensely popular crowd-sourced encyclopedia for information dissemination on numerous versatile topics in the form of subscription free content. It allows anyone to contribute so that the articles remain comprehensive and updated. For enrichment of content without compromising standards, the Wikipedia community enumerates a detailed set of guidelines, which should be followed. Based on these, articles are categorized into several quality classes by the Wikipedia editors with increasing adherence to guidelines. This quality assessment task by editors is laborious as well as demands platform expertise. As a first objective, in this paper, we study evolution of a Wikipedia article with respect to such quality scales. Our results show novel non-intuitive patterns emerging from this exploration. As a second objective we attempt to develop an automated data driven approach for the detection of the early signals influencing the quality change of articles. We posit this as a change point detection problem whereby we represent an article as a time series of consecutive revisions and encode every revision by a set of intuitive features. Finally, various change point detection algorithms are used to efficiently and accurately detect the future change points. We also perform various ablation studies to understand which group of features are most effective in identifying the change points. To the best of our knowledge, this is the first work that rigorously explores English Wikipedia article quality life cycle from the perspective of quality indicators and provides a novel unsupervised page level approach to detect quality switch, which can help in automatic content monitoring in Wikipedia thus contributing significantly to the CSCW community.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Paramita Das et al.",
      "keywords": "Computer science; Encyclopedia; Change detection; Quality (philosophy); Set (abstract data type); Perspective (graphical); Data science; Point (geometry); Information retrieval; Norm (philosophy); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2111.01496",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4417515835",
      "doi": "10.48550/arxiv.2505.07188",
      "title": "Securing Genomic Data Against Inference Attacks in Federated Learning Environments",
      "abstract": "Federated Learning (FL) offers a promising framework for collaboratively training machine learning models across decentralized genomic datasets without direct data sharing. While this approach preserves data locality, it remains susceptible to sophisticated inference attacks that can compromise individual privacy. In this study, we simulate a federated learning setup using synthetic genomic data and assess its vulnerability to three key attack vectors: Membership Inference Attack (MIA), Gradient-Based Membership Inference Attack, and Label Inference Attack (LIA). Our experiments reveal that Gradient-Based MIA achieves the highest effectiveness, with a precision of 0.79 and F1-score of 0.87, underscoring the risk posed by gradient exposure in federated updates. Additionally, we visualize comparative attack performance through radar plots and quantify model leakage across clients. The findings emphasize the inadequacy of na\u00efve FL setups in safeguarding genomic privacy and motivate the development of more robust privacy-preserving mechanisms tailored to the unique sensitivity of genomic data.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Chetan Pathade et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2505.07188",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4415333609",
      "doi": "10.48550/arxiv.2506.15218",
      "title": "DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder",
      "abstract": "Multimodal medical image fusion (MMIF) extracts the most meaningful information from multiple source images, enabling a more comprehensive and accurate diagnosis. Achieving high-quality fusion results requires a careful balance of brightness, color, contrast, and detail; this ensures that the fused images effectively display relevant anatomical structures and reflect the functional status of the tissues. However, existing MMIF methods have limited capacity to capture detailed features during conventional training and suffer from insufficient cross-modal feature interaction, leading to suboptimal fused image quality. To address these issues, this study proposes a two-stage diffusion model-based fusion network (DM-FNet) to achieve unified MMIF. In Stage I, a diffusion process trains UNet for image reconstruction. UNet captures detailed information through progressive denoising and represents multilevel data, providing a rich set of feature representations for the subsequent fusion network. In Stage II, noisy images at various steps are input into the fusion network to enhance the model's feature recognition capability. Three key fusion modules are also integrated to process medical images from different modalities adaptively. Ultimately, the robust network structure and a hybrid loss function are integrated to harmonize the fused image's brightness, color, contrast, and detail, enhancing its quality and information density. The experimental results across various medical image types demonstrate that the proposed method performs exceptionally well regarding objective evaluation metrics. The fused image preserves appropriate brightness, a comprehensive distribution of radioactive tracers, rich textures, and clear edges. The code is available at https://github.com/HeDan-11/DM-FNet.",
      "year": "2025",
      "journal": "arXiv (Cornell University)",
      "authors": "Dan He et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2506.15218",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4403621931",
      "doi": "10.48550/arxiv.2409.07308",
      "title": "Non-Invasive Glucose Prediction System Enhanced by Mixed Linear Models and Meta-Forests for Domain Generalization",
      "abstract": "In this study, we present a non-invasive glucose prediction system that integrates Near-Infrared (NIR) spectroscopy and millimeter-wave (mm-wave) sensing. We employ a Mixed Linear Model (MixedLM) to analyze the association between mm-wave frequency S_21 parameters and blood glucose levels within a heterogeneous dataset. The MixedLM method considers inter-subject variability and integrates multiple predictors, offering a more comprehensive analysis than traditional correlation analysis. Additionally, we incorporate a Domain Generalization (DG) model, Meta-forests, to effectively handle domain variance in the dataset, enhancing the model's adaptability to individual differences. Our results demonstrate promising accuracy in glucose prediction for unseen subjects, with a mean absolute error (MAE) of 17.47 mg/dL, a root mean square error (RMSE) of 31.83 mg/dL, and a mean absolute percentage error (MAPE) of 10.88%, highlighting its potential for clinical application. This study marks a significant step towards developing accurate, personalized, and non-invasive glucose monitoring systems, contributing to improved diabetes management.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Yuyang Sun et al.",
      "keywords": "Generalization; Domain (mathematical analysis); Computer science; Mathematics; Biological system; Biology; Mathematical analysis",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2409.07308",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4385825306",
      "doi": "10.48550/arxiv.2308.05832",
      "title": "FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks",
      "abstract": "Federated learning (FL) is revolutionizing how we learn from data. With its growing popularity, it is now being used in many safety-critical domains such as autonomous vehicles and healthcare. Since thousands of participants can contribute in this collaborative setting, it is, however, challenging to ensure security and reliability of such systems. This highlights the need to design FL systems that are secure and robust against malicious participants' actions while also ensuring high utility, privacy of local data, and efficiency. In this paper, we propose a novel FL framework dubbed as FLShield that utilizes benign data from FL participants to validate the local models before taking them into account for generating the global model. This is in stark contrast with existing defenses relying on server's access to clean datasets -- an assumption often impractical in real-life scenarios and conflicting with the fundamentals of FL. We conduct extensive experiments to evaluate our FLShield framework in different settings and demonstrate its effectiveness in thwarting various types of poisoning and backdoor attacks including a defense-aware one. FLShield also preserves privacy of local data against gradient inversion attacks.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Ehsanul Kabir et al.",
      "keywords": "Backdoor; Computer science; Federated learning; Popularity; Computer security; Reliability (semiconductor); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2308.05832",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288376244",
      "doi": "10.48550/arxiv.1904.01778",
      "title": "Recognition of Advertisement Emotions with Application to Computational\\n Advertising",
      "abstract": "Advertisements (ads) often contain strong affective content to capture viewer\\nattention and convey an effective message to the audience. However, most\\ncomputational affect recognition (AR) approaches examine ads via the text\\nmodality, and only limited work has been devoted to decoding ad emotions from\\naudiovisual or user cues. This work (1) compiles an affective ad dataset\\ncapable of evoking coherent emotions across users; (2) explores the efficacy of\\ncontent-centric convolutional neural network (CNN) features for AR vis-\\\\~a-vis\\nhandcrafted audio-visual descriptors; (3) examines user-centric ad AR from\\nElectroencephalogram (EEG) responses acquired during ad-viewing, and (4)\\ndemonstrates how better affect predictions facilitate effective computational\\nadvertising as determined by a study involving 18 users. Experiments reveal\\nthat (a) CNN features outperform audiovisual descriptors for content-centric\\nAR; (b) EEG features are able to encode ad-induced emotions better than\\ncontent-based features; (c) Multi-task learning performs best among a slew of\\nclassification algorithms to achieve optimal AR, and (d) Pursuant to (b), EEG\\nfeatures also enable optimized ad insertion onto streamed video, as compared to\\ncontent-based or manual insertion techniques in terms of ad memorability and\\noverall user experience.\\n",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Abhinav Shukla et al.",
      "keywords": "Computer science; Convolutional neural network; ENCODE; Task (project management); Affect (linguistics); Affective computing; Decoding methods; Speech recognition; Human\u2013computer interaction; Artificial intelligence; Psychology; Communication",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1904.01778",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3211095677",
      "doi": "10.48550/arxiv.2102.08132",
      "title": "Towards an accountable Internet of Things: A call for reviewability",
      "abstract": "As the IoT becomes increasingly ubiquitous, concerns are being raised about how IoT systems are being built and deployed. Connected devices will generate vast quantities of data, which drive algorithmic systems and result in real-world consequences. Things will go wrong, and when they do, how do we identify what happened, why they happened, and who is responsible? Given the complexity of such systems, where do we even begin? This chapter outlines aspects of accountability as they relate to IoT, in the context of the increasingly interconnected and data-driven nature of such systems. Specifically, we argue the urgent need for mechanisms - legal, technical, and organisational - that facilitate the review of IoT systems. Such mechanisms work to support accountability, by enabling the relevant stakeholders to better understand, assess, interrogate and challenge the connected environments that increasingly pervade our world.",
      "year": "2021",
      "journal": "arXiv (Cornell University)",
      "authors": "Chris Norval et al.",
      "keywords": "Internet of Things; Accountability; Context (archaeology); Computer science; Work (physics); Computer security; Internet privacy; Data science; Political science; Engineering; Geography; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.48550/arxiv.2102.08132",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404401156",
      "doi": "10.48550/arxiv.2411.06193",
      "title": "Large Language Models and Artificial Intelligence Generated Content Technologies Meet Communication Networks",
      "abstract": "Artificial intelligence generated content (AIGC) technologies, with a predominance of large language models (LLMs), have demonstrated remarkable performance improvements in various applications, which have attracted great interests from both academia and industry. Although some noteworthy advancements have been made in this area, a comprehensive exploration of the intricate relationship between AIGC and communication networks remains relatively limited. To address this issue, this paper conducts an exhaustive survey from dual standpoints: firstly, it scrutinizes the integration of LLMs and AIGC technologies within the domain of communication networks; secondly, it investigates how the communication networks can further bolster the capabilities of LLMs and AIGC. Additionally, this research explores the promising applications along with the challenges encountered during the incorporation of these AI technologies into communication networks. Through these detailed analyses, our work aims to deepen the understanding of how LLMs and AIGC can synergize with and enhance the development of advanced intelligent communication networks, contributing to a more profound comprehension of next-generation intelligent communication networks.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Jie Guo et al.",
      "keywords": "Computer science; Content (measure theory); Artificial intelligence; Natural language processing; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2411.06193",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2951559704",
      "doi": "10.48550/arxiv.1309.7414",
      "title": "The Beer Can Theory of Creativity",
      "abstract": "This chapter explores the cognitive mechanisms underlying the emergence and evolution of cultural novelty. Section Two summarizes the rationale for viewing the process by which the fruits of the mind take shape as they spread from one individual to another as a form of evolution, and briefly discusses a computer model of this process. Section Three presents theoretical and empirical evidence that the sudden proliferation of human culture approximately two million years ago began with the capacity for creativity: that is, the ability to generate novelty strategically and contextually. The next two sections take a closer look at the creative process. Section Four examines the mechanisms underlying the fluid, associative thought that constitutes the inspirational component of creativity. Section Five explores how that initial flicker of inspiration crystallizes into a solid, workable idea as it gets mulled over in light of the various constraints and affordances of the world into which it will be born. Finally, Section Six wraps things up with a few speculative thoughts about the overall unfolding of this evolutionary process.",
      "year": "2013",
      "journal": "arXiv (Cornell University)",
      "authors": "Liane Gabora",
      "keywords": "Novelty; Creativity; Section (typography); Process (computing); Affordance; Cognitive science; Cognition; Epistemology; Empirical evidence; Psychology; Computer science; Cognitive psychology; Aesthetics; Sociology; Social psychology; Art; Philosophy",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1309.7414",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399252826",
      "doi": "10.48550/arxiv.2405.20024",
      "title": "Applications of Generative AI (GAI) for Mobile and Wireless Networking: A Survey",
      "abstract": "The success of Artificial Intelligence (AI) in multiple disciplines and vertical domains in recent years has promoted the evolution of mobile networking and the future Internet toward an AI-integrated Internet-of-Things (IoT) era. Nevertheless, most AI techniques rely on data generated by physical devices (e.g., mobile devices and network nodes) or specific applications (e.g., fitness trackers and mobile gaming). Therefore, Generative AI (GAI), a.k.a. AI-generated content (AIGC), has emerged as a powerful AI paradigm; thanks to its ability to efficiently learn complex data distributions and generate synthetic data to represent the original data in various forms. This impressive feature is projected to transform the management of mobile networking and diversify the current services and applications provided. On this basis, this work presents a concise tutorial on the role of GAIs in mobile and wireless networking. In particular, this survey first provides the fundamentals of GAI and representative GAI models, serving as an essential preliminary to the understanding of GAI's applications in mobile and wireless networking. Then, this work provides a comprehensive review of state-of-the-art studies and GAI applications in network management, wireless security, semantic communication, and lessons learned from the open literature. Finally, this work summarizes the current research on GAI for mobile and wireless networking by outlining important challenges that need to be resolved to facilitate the development and applicability of GAI in this edge-cutting area.",
      "year": "2024",
      "journal": "arXiv (Cornell University)",
      "authors": "Thai-Hoc Vu et al.",
      "keywords": "Generative grammar; Computer science; Wireless network; Wireless; Telecommunications; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2405.20024",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2024340928",
      "doi": "10.48550/arxiv.1403.1210",
      "title": "Predicting patient risk of readmission with frailty models in the Department of Veteran Affairs",
      "abstract": "Reducing potentially preventable readmissions has been identified as an important issue for decreasing Medicare costs and improving quality of care provided by hospitals. Based on previous research by medical professionals, preventable readmissions are caused by such factors as flawed patient discharging process, inadequate follow-ups after discharging, and noncompliance of patients on discharging and follow up instructions. It is also found that the risk of preventable readmission also may relate to some patient's characteristics, such as age, health condition, diagnosis, and even treatment specialty. In this study, using both general demographic information and individual past history of readmission records, we develop a risk prediction model based on hierarchical nonlinear mixed effect framework to extract significant prognostic factors associated with patient risk of 30-day readmission. The effectiveness of our proposed approach is validated based on a real dataset from four VA facilities in the State of Michigan. Simultaneously explaining both patient and population based variations of readmission process, such an accurate model can be used to recognize patients with high likelihood of discharging non-compliances, and then targeted post-care actions can be designed to reduce further rehospitalization.",
      "year": "2014",
      "journal": "arXiv (Cornell University)",
      "authors": "Saeede Ajorlou et al.",
      "keywords": "Medicine; Specialty; Medical record; Medical emergency; Health care; Population; Emergency medicine; Family medicine; Environmental health; Internal medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1403.1210",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2983258588",
      "doi": "10.48550/arxiv.1911.04168",
      "title": "Does hospital cooperation increase the quality of healthcare?",
      "abstract": "Motivated by reasons such as altruism, managers from different hospitals may engage in cooperative behaviours, which shape the networked healthcare economy. In this paper we study the determinants of hospital cooperation and its association with the quality delivered by hospitals, using Italian administrative data. We explore the impact on patient transfers between hospitals (cooperation/network) of a set of demand-supply factors, as well as distance-based centrality measures. We then use this framework to assess how such cooperation is related to the overall quality for the hospital of origin and of destination of the patient transfer. The over-dispersed Poisson mixed model that we propose, inspired by the literature on social relations models, is suitably defined to handle network data, which are rarely used in health economics. The results show that distance plays an important role in hospital cooperation, though there are other factors that matter such as geographical centrality. Another empirical finding is the existence of a positive relationship between hospital cooperation and the overall quality of the connected hospitals. The absence of a source of information on the quality of hospitals accessible to all providers, such as in the form of star ratings, may prevent some hospitals to engage and cooperate with other hospitals of potentially higher quality. This may result in a lower degree of cooperation among hospitals and a reduction in quality overall.",
      "year": "2019",
      "journal": "arXiv (Cornell University)",
      "authors": "Paolo Berta et al.",
      "keywords": "Centrality; Quality (philosophy); Business; Health care; Altruism (biology); Set (abstract data type); Marketing; Industrial organization; Psychology; Computer science; Economics; Social psychology; Economic growth",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.1911.04168",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226217020",
      "doi": "10.48550/arxiv.2202.13402",
      "title": "Concept Graph Neural Networks for Surgical Video Understanding",
      "abstract": "We constantly integrate our knowledge and understanding of the world to enhance our interpretation of what we see. This ability is crucial in application domains which entail reasoning about multiple entities and concepts, such as AI-augmented surgery. In this paper, we propose a novel way of integrating conceptual knowledge into temporal analysis tasks via temporal concept graph networks. In the proposed networks, a global knowledge graph is incorporated into the temporal analysis of surgical instances, learning the meaning of concepts and relations as they apply to the data. We demonstrate our results in surgical video data for tasks such as verification of critical view of safety, as well as estimation of Parkland grading scale. The results show that our method improves the recognition and detection of complex benchmarks as well as enables other analytic applications of interest.",
      "year": "2022",
      "journal": "arXiv (Cornell University)",
      "authors": "Yutong Ban et al.",
      "keywords": "Computer science; Graph; Knowledge graph; Artificial intelligence; Data science; Machine learning; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2202.13402",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4353114103",
      "doi": "10.48550/arxiv.2303.11563",
      "title": "Dynamic Healthcare Embeddings for Improving Patient Care",
      "abstract": "As hospitals move towards automating and integrating their computing systems, more fine-grained hospital operations data are becoming available. These data include hospital architectural drawings, logs of interactions between patients and healthcare professionals, prescription data, procedures data, and data on patient admission, discharge, and transfers. This has opened up many fascinating avenues for healthcare-related prediction tasks for improving patient care. However, in order to leverage off-the-shelf machine learning software for these tasks, one needs to learn structured representations of entities involved from heterogeneous, dynamic data streams. Here, we propose DECENT, an auto-encoding heterogeneous co-evolving dynamic neural network, for learning heterogeneous dynamic embeddings of patients, doctors, rooms, and medications from diverse data streams. These embeddings capture similarities among doctors, rooms, patients, and medications based on static attributes and dynamic interactions. DECENT enables several applications in healthcare prediction, such as predicting mortality risk and case severity of patients, adverse events (e.g., transfer back into an intensive care unit), and future healthcare-associated infections. The results of using the learned patient embeddings in predictive modeling show that DECENT has a gain of up to 48.1% on the mortality risk prediction task, 12.6% on the case severity prediction task, 6.4% on the medical intensive care unit transfer task, and 3.8% on the Clostridioides difficile (C.diff) Infection (CDI) prediction task over the state-of-the-art baselines. In addition, case studies on the learned doctor, medication, and room embeddings show that our approach learns meaningful and interpretable embeddings.",
      "year": "2023",
      "journal": "arXiv (Cornell University)",
      "authors": "Hankyu Jang et al.",
      "keywords": "Leverage (statistics); Health care; Task (project management); Computer science; Transfer of learning; Deep learning; Machine learning; Medical prescription; Artificial intelligence; Data science; Medicine; Nursing; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.48550/arxiv.2303.11563",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    }
  ],
  "query_stats": [
    {
      "id": "Q1",
      "label": "Core: algorithmic bias/fairness + health",
      "search": "algorithmic bias fairness health healthcare clinical medical",
      "results_found": 179,
      "new_unique": 179,
      "cumulative": 179
    },
    {
      "id": "Q2",
      "label": "AI bias mitigation health",
      "search": "AI bias mitigation debiasing health healthcare clinical",
      "results_found": 25,
      "new_unique": 9,
      "cumulative": 188
    },
    {
      "id": "Q3",
      "label": "Machine learning fairness health",
      "search": "machine learning fairness bias health clinical medical",
      "results_found": 298,
      "new_unique": 126,
      "cumulative": 314
    },
    {
      "id": "Q4",
      "label": "Bias assessment AI healthcare",
      "search": "bias assessment evaluation audit artificial intelligence healthcare",
      "results_found": 128,
      "new_unique": 95,
      "cumulative": 409
    },
    {
      "id": "Q5",
      "label": "Racial gender bias clinical AI",
      "search": "racial gender bias clinical prediction algorithm machine learning",
      "results_found": 71,
      "new_unique": 23,
      "cumulative": 432
    },
    {
      "id": "Q6",
      "label": "Health disparities AI algorithm",
      "search": "health disparities algorithmic bias machine learning deep learning",
      "results_found": 280,
      "new_unique": 186,
      "cumulative": 618
    },
    {
      "id": "Q7",
      "label": "Fairness-aware ML health",
      "search": "fairness-aware machine learning equalized odds demographic parity health",
      "results_found": 35,
      "new_unique": 6,
      "cumulative": 624
    },
    {
      "id": "Q8",
      "label": "Bias EHR clinical decision support",
      "search": "bias electronic health record clinical decision support algorithm",
      "results_found": 139,
      "new_unique": 69,
      "cumulative": 693
    },
    {
      "id": "Q9",
      "label": "Bias medical imaging AI",
      "search": "bias medical imaging radiology dermatology deep learning AI",
      "results_found": 9,
      "new_unique": 4,
      "cumulative": 697
    },
    {
      "id": "Q10",
      "label": "Equitable AI health",
      "search": "equitable AI health equity fairness algorithm clinical",
      "results_found": 16,
      "new_unique": 0,
      "cumulative": 697
    },
    {
      "id": "Q11",
      "label": "NLP bias clinical health",
      "search": "natural language processing bias clinical health medical NLP",
      "results_found": 170,
      "new_unique": 57,
      "cumulative": 754
    },
    {
      "id": "Q12",
      "label": "Bias federated learning health",
      "search": "bias fairness federated learning health clinical",
      "results_found": 57,
      "new_unique": 6,
      "cumulative": 760
    },
    {
      "id": "Q13",
      "label": "LLM bias health",
      "search": "large language model bias health clinical medical",
      "results_found": 471,
      "new_unique": 149,
      "cumulative": 909
    },
    {
      "id": "Q14",
      "label": "Disparate impact health prediction",
      "search": "disparate impact health prediction model algorithm bias",
      "results_found": 152,
      "new_unique": 39,
      "cumulative": 948
    },
    {
      "id": "Q15",
      "label": "Bias risk prediction clinical",
      "search": "bias risk prediction mortality readmission clinical algorithm",
      "results_found": 18,
      "new_unique": 4,
      "cumulative": 952
    }
  ],
  "meta": {
    "total_unique": 952,
    "ta_included": 68,
    "ta_excluded": 884,
    "ft_included": 32,
    "ft_excluded": 36
  }
}